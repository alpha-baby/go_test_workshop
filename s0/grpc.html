
<!DOCTYPE html>
<html>
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
		<title>admin: Go Coverage Report</title>
		<style>
			body {
				background: black;
				color: rgb(80, 80, 80);
			}
			body, pre, #legend span {
				font-family: Menlo, monospace;
				font-weight: bold;
			}
			#topbar {
				background: black;
				position: fixed;
				top: 0; left: 0; right: 0;
				height: 42px;
				border-bottom: 1px solid rgb(80, 80, 80);
			}
			#content {
				margin-top: 50px;
			}
			#nav, #legend {
				float: left;
				margin-left: 10px;
			}
			#legend {
				margin-top: 12px;
			}
			#nav {
				margin-top: 10px;
			}
			#legend span {
				margin: 0 5px;
			}
			.cov0 { color: rgb(192, 0, 0) }
.cov1 { color: rgb(128, 128, 128) }
.cov2 { color: rgb(116, 140, 131) }
.cov3 { color: rgb(104, 152, 134) }
.cov4 { color: rgb(92, 164, 137) }
.cov5 { color: rgb(80, 176, 140) }
.cov6 { color: rgb(68, 188, 143) }
.cov7 { color: rgb(56, 200, 146) }
.cov8 { color: rgb(44, 212, 149) }
.cov9 { color: rgb(32, 224, 152) }
.cov10 { color: rgb(20, 236, 155) }

		</style>
	</head>
	<body>
		<div id="topbar">
			<div id="nav">
				<select id="files">
				
				<option value="file0">google.golang.org/grpc/admin/admin.go (100.0%)</option>
				
				<option value="file1">google.golang.org/grpc/admin/test/utils.go (82.9%)</option>
				
				<option value="file2">google.golang.org/grpc/attributes/attributes.go (77.8%)</option>
				
				<option value="file3">google.golang.org/grpc/authz/grpc_authz_server_interceptors.go (87.7%)</option>
				
				<option value="file4">google.golang.org/grpc/authz/rbac_translator.go (98.9%)</option>
				
				<option value="file5">google.golang.org/grpc/balancer/balancer.go (14.3%)</option>
				
				<option value="file6">google.golang.org/grpc/balancer/base/balancer.go (56.6%)</option>
				
				<option value="file7">google.golang.org/grpc/balancer/base/base.go (0.0%)</option>
				
				<option value="file8">google.golang.org/grpc/balancer/conn_state_evaluator.go (100.0%)</option>
				
				<option value="file9">google.golang.org/grpc/balancer/grpclb/grpclb.go (87.0%)</option>
				
				<option value="file10">google.golang.org/grpc/balancer/grpclb/grpclb_config.go (93.3%)</option>
				
				<option value="file11">google.golang.org/grpc/balancer/grpclb/grpclb_picker.go (98.0%)</option>
				
				<option value="file12">google.golang.org/grpc/balancer/grpclb/grpclb_remote_balancer.go (88.4%)</option>
				
				<option value="file13">google.golang.org/grpc/balancer/grpclb/grpclb_util.go (81.6%)</option>
				
				<option value="file14">google.golang.org/grpc/balancer/rls/balancer.go (89.6%)</option>
				
				<option value="file15">google.golang.org/grpc/balancer/rls/cache.go (86.5%)</option>
				
				<option value="file16">google.golang.org/grpc/balancer/rls/child_policy.go (100.0%)</option>
				
				<option value="file17">google.golang.org/grpc/balancer/rls/config.go (91.3%)</option>
				
				<option value="file18">google.golang.org/grpc/balancer/rls/control_channel.go (96.7%)</option>
				
				<option value="file19">google.golang.org/grpc/balancer/rls/internal/adaptive/adaptive.go (95.2%)</option>
				
				<option value="file20">google.golang.org/grpc/balancer/rls/internal/adaptive/lookback.go (100.0%)</option>
				
				<option value="file21">google.golang.org/grpc/balancer/rls/internal/keys/builder.go (98.1%)</option>
				
				<option value="file22">google.golang.org/grpc/balancer/rls/picker.go (93.6%)</option>
				
				<option value="file23">google.golang.org/grpc/balancer/weightedroundrobin/weightedroundrobin.go (100.0%)</option>
				
				<option value="file24">google.golang.org/grpc/balancer/weightedtarget/logging.go (100.0%)</option>
				
				<option value="file25">google.golang.org/grpc/balancer/weightedtarget/weightedtarget.go (93.8%)</option>
				
				<option value="file26">google.golang.org/grpc/balancer/weightedtarget/weightedtarget_config.go (100.0%)</option>
				
				<option value="file27">google.golang.org/grpc/balancer_conn_wrappers.go (61.5%)</option>
				
				<option value="file28">google.golang.org/grpc/benchmark/flags/flags.go (96.9%)</option>
				
				<option value="file29">google.golang.org/grpc/benchmark/latency/latency.go (77.3%)</option>
				
				<option value="file30">google.golang.org/grpc/binarylog/sink.go (42.9%)</option>
				
				<option value="file31">google.golang.org/grpc/call.go (0.0%)</option>
				
				<option value="file32">google.golang.org/grpc/channelz/service/func_nonlinux.go (0.0%)</option>
				
				<option value="file33">google.golang.org/grpc/channelz/service/service.go (86.5%)</option>
				
				<option value="file34">google.golang.org/grpc/clientconn.go (70.4%)</option>
				
				<option value="file35">google.golang.org/grpc/codes/code_string.go (10.5%)</option>
				
				<option value="file36">google.golang.org/grpc/codes/codes.go (84.6%)</option>
				
				<option value="file37">google.golang.org/grpc/credentials/alts/internal/authinfo/authinfo.go (90.0%)</option>
				
				<option value="file38">google.golang.org/grpc/credentials/alts/internal/conn/aeadrekey.go (79.4%)</option>
				
				<option value="file39">google.golang.org/grpc/credentials/alts/internal/conn/aes128gcm.go (84.6%)</option>
				
				<option value="file40">google.golang.org/grpc/credentials/alts/internal/conn/aes128gcmrekey.go (82.1%)</option>
				
				<option value="file41">google.golang.org/grpc/credentials/alts/internal/conn/common.go (93.3%)</option>
				
				<option value="file42">google.golang.org/grpc/credentials/alts/internal/conn/counter.go (100.0%)</option>
				
				<option value="file43">google.golang.org/grpc/credentials/alts/internal/conn/record.go (85.2%)</option>
				
				<option value="file44">google.golang.org/grpc/credentials/alts/internal/conn/utils.go (100.0%)</option>
				
				<option value="file45">google.golang.org/grpc/credentials/alts/internal/handshaker/handshaker.go (73.6%)</option>
				
				<option value="file46">google.golang.org/grpc/credentials/alts/internal/handshaker/service/service.go (90.0%)</option>
				
				<option value="file47">google.golang.org/grpc/credentials/credentials.go (63.2%)</option>
				
				<option value="file48">google.golang.org/grpc/credentials/google/google.go (65.5%)</option>
				
				<option value="file49">google.golang.org/grpc/credentials/google/xds.go (76.9%)</option>
				
				<option value="file50">google.golang.org/grpc/credentials/local/local.go (61.1%)</option>
				
				<option value="file51">google.golang.org/grpc/credentials/oauth/oauth.go (7.2%)</option>
				
				<option value="file52">google.golang.org/grpc/credentials/sts/sts.go (95.1%)</option>
				
				<option value="file53">google.golang.org/grpc/credentials/tls.go (58.9%)</option>
				
				<option value="file54">google.golang.org/grpc/credentials/tls/certprovider/distributor.go (95.0%)</option>
				
				<option value="file55">google.golang.org/grpc/credentials/tls/certprovider/pemfile/builder.go (95.5%)</option>
				
				<option value="file56">google.golang.org/grpc/credentials/tls/certprovider/pemfile/watcher.go (87.5%)</option>
				
				<option value="file57">google.golang.org/grpc/credentials/tls/certprovider/provider.go (80.0%)</option>
				
				<option value="file58">google.golang.org/grpc/credentials/tls/certprovider/store.go (86.2%)</option>
				
				<option value="file59">google.golang.org/grpc/credentials/xds/xds.go (88.2%)</option>
				
				<option value="file60">google.golang.org/grpc/dialoptions.go (50.5%)</option>
				
				<option value="file61">google.golang.org/grpc/encoding/proto/proto.go (80.0%)</option>
				
				<option value="file62">google.golang.org/grpc/grpclog/component.go (0.0%)</option>
				
				<option value="file63">google.golang.org/grpc/grpclog/grpclog.go (20.0%)</option>
				
				<option value="file64">google.golang.org/grpc/grpclog/logger.go (0.0%)</option>
				
				<option value="file65">google.golang.org/grpc/grpclog/loggerv2.go (59.6%)</option>
				
				<option value="file66">google.golang.org/grpc/health/client.go (36.8%)</option>
				
				<option value="file67">google.golang.org/grpc/health/server.go (38.0%)</option>
				
				<option value="file68">google.golang.org/grpc/internal/balancer/gracefulswitch/gracefulswitch.go (83.3%)</option>
				
				<option value="file69">google.golang.org/grpc/internal/balancergroup/balancergroup.go (79.9%)</option>
				
				<option value="file70">google.golang.org/grpc/internal/binarylog/binarylog.go (83.7%)</option>
				
				<option value="file71">google.golang.org/grpc/internal/binarylog/env_config.go (93.5%)</option>
				
				<option value="file72">google.golang.org/grpc/internal/binarylog/method_logger.go (80.6%)</option>
				
				<option value="file73">google.golang.org/grpc/internal/binarylog/sink.go (17.4%)</option>
				
				<option value="file74">google.golang.org/grpc/internal/buffer/unbounded.go (100.0%)</option>
				
				<option value="file75">google.golang.org/grpc/internal/cache/timeoutCache.go (92.3%)</option>
				
				<option value="file76">google.golang.org/grpc/internal/credentials/credentials.go (0.0%)</option>
				
				<option value="file77">google.golang.org/grpc/internal/credentials/spiffe.go (100.0%)</option>
				
				<option value="file78">google.golang.org/grpc/internal/credentials/syscallconn.go (100.0%)</option>
				
				<option value="file79">google.golang.org/grpc/internal/credentials/util.go (66.7%)</option>
				
				<option value="file80">google.golang.org/grpc/internal/credentials/xds/handshake_info.go (44.2%)</option>
				
				<option value="file81">google.golang.org/grpc/internal/googlecloud/googlecloud.go (50.0%)</option>
				
				<option value="file82">google.golang.org/grpc/internal/googlecloud/manufacturer.go (0.0%)</option>
				
				<option value="file83">google.golang.org/grpc/internal/grpcsync/event.go (100.0%)</option>
				
				<option value="file84">google.golang.org/grpc/internal/grpctest/grpctest.go (82.1%)</option>
				
				<option value="file85">google.golang.org/grpc/internal/grpctest/tlogger.go (74.4%)</option>
				
				<option value="file86">google.golang.org/grpc/internal/grpcutil/encode_duration.go (93.8%)</option>
				
				<option value="file87">google.golang.org/grpc/internal/grpcutil/metadata.go (0.0%)</option>
				
				<option value="file88">google.golang.org/grpc/internal/grpcutil/method.go (82.4%)</option>
				
				<option value="file89">google.golang.org/grpc/internal/grpcutil/regex.go (100.0%)</option>
				
				<option value="file90">google.golang.org/grpc/internal/hierarchy/hierarchy.go (84.6%)</option>
				
				<option value="file91">google.golang.org/grpc/internal/leakcheck/leakcheck.go (86.2%)</option>
				
				<option value="file92">google.golang.org/grpc/internal/metadata/metadata.go (59.5%)</option>
				
				<option value="file93">google.golang.org/grpc/internal/profiling/buffer/buffer.go (90.2%)</option>
				
				<option value="file94">google.golang.org/grpc/internal/profiling/goid_regular.go (100.0%)</option>
				
				<option value="file95">google.golang.org/grpc/internal/profiling/profiling.go (46.7%)</option>
				
				<option value="file96">google.golang.org/grpc/internal/resolver/config_selector.go (60.0%)</option>
				
				<option value="file97">google.golang.org/grpc/internal/resolver/dns/dns_resolver.go (89.4%)</option>
				
				<option value="file98">google.golang.org/grpc/internal/serviceconfig/serviceconfig.go (93.8%)</option>
				
				<option value="file99">google.golang.org/grpc/internal/testutils/balancer.go (2.1%)</option>
				
				<option value="file100">google.golang.org/grpc/internal/testutils/channel.go (0.0%)</option>
				
				<option value="file101">google.golang.org/grpc/internal/testutils/http_client.go (0.0%)</option>
				
				<option value="file102">google.golang.org/grpc/internal/testutils/local_listener.go (0.0%)</option>
				
				<option value="file103">google.golang.org/grpc/internal/testutils/marshal_any.go (0.0%)</option>
				
				<option value="file104">google.golang.org/grpc/internal/testutils/pipe_listener.go (75.0%)</option>
				
				<option value="file105">google.golang.org/grpc/internal/testutils/restartable_listener.go (0.0%)</option>
				
				<option value="file106">google.golang.org/grpc/internal/testutils/status_equal.go (71.4%)</option>
				
				<option value="file107">google.golang.org/grpc/internal/testutils/wrappers.go (0.0%)</option>
				
				<option value="file108">google.golang.org/grpc/internal/testutils/wrr.go (0.0%)</option>
				
				<option value="file109">google.golang.org/grpc/internal/transport/bdp_estimator.go (94.4%)</option>
				
				<option value="file110">google.golang.org/grpc/internal/transport/controlbuf.go (86.4%)</option>
				
				<option value="file111">google.golang.org/grpc/internal/transport/flowcontrol.go (92.0%)</option>
				
				<option value="file112">google.golang.org/grpc/internal/transport/handler_server.go (81.8%)</option>
				
				<option value="file113">google.golang.org/grpc/internal/transport/http2_client.go (68.5%)</option>
				
				<option value="file114">google.golang.org/grpc/internal/transport/http2_server.go (73.3%)</option>
				
				<option value="file115">google.golang.org/grpc/internal/transport/http_util.go (87.0%)</option>
				
				<option value="file116">google.golang.org/grpc/internal/transport/proxy.go (73.3%)</option>
				
				<option value="file117">google.golang.org/grpc/internal/transport/transport.go (74.2%)</option>
				
				<option value="file118">google.golang.org/grpc/internal/wrr/edf.go (86.4%)</option>
				
				<option value="file119">google.golang.org/grpc/internal/wrr/random.go (92.0%)</option>
				
				<option value="file120">google.golang.org/grpc/internal/xds/matcher/matcher_header.go (75.5%)</option>
				
				<option value="file121">google.golang.org/grpc/internal/xds/matcher/string_matcher.go (75.0%)</option>
				
				<option value="file122">google.golang.org/grpc/internal/xds/rbac/matchers.go (83.7%)</option>
				
				<option value="file123">google.golang.org/grpc/internal/xds/rbac/rbac_engine.go (80.9%)</option>
				
				<option value="file124">google.golang.org/grpc/metadata/metadata.go (63.9%)</option>
				
				<option value="file125">google.golang.org/grpc/picker_wrapper.go (66.7%)</option>
				
				<option value="file126">google.golang.org/grpc/pickfirst.go (61.5%)</option>
				
				<option value="file127">google.golang.org/grpc/preloader.go (0.0%)</option>
				
				<option value="file128">google.golang.org/grpc/reflection/serverreflection.go (95.1%)</option>
				
				<option value="file129">google.golang.org/grpc/resolver/map.go (95.1%)</option>
				
				<option value="file130">google.golang.org/grpc/resolver/resolver.go (22.2%)</option>
				
				<option value="file131">google.golang.org/grpc/resolver_conn_wrapper.go (63.9%)</option>
				
				<option value="file132">google.golang.org/grpc/rpc_util.go (23.7%)</option>
				
				<option value="file133">google.golang.org/grpc/server.go (20.9%)</option>
				
				<option value="file134">google.golang.org/grpc/service_config.go (61.1%)</option>
				
				<option value="file135">google.golang.org/grpc/stats/stats.go (100.0%)</option>
				
				<option value="file136">google.golang.org/grpc/status/status.go (76.0%)</option>
				
				<option value="file137">google.golang.org/grpc/stream.go (0.0%)</option>
				
				<option value="file138">google.golang.org/grpc/test/bufconn/bufconn.go (89.5%)</option>
				
				<option value="file139">google.golang.org/grpc/test/parse_config.go (80.0%)</option>
				
				<option value="file140">google.golang.org/grpc/test/rawConnWrapper.go (73.1%)</option>
				
				<option value="file141">google.golang.org/grpc/test/servertester.go (69.7%)</option>
				
				<option value="file142">google.golang.org/grpc/trace.go (14.8%)</option>
				
				<option value="file143">google.golang.org/grpc/xds/bootstrap/bootstrap.go (75.0%)</option>
				
				<option value="file144">google.golang.org/grpc/xds/csds/csds.go (74.2%)</option>
				
				<option value="file145">google.golang.org/grpc/xds/googledirectpath/googlec2p.go (87.5%)</option>
				
				<option value="file146">google.golang.org/grpc/xds/googledirectpath/utils.go (0.0%)</option>
				
				<option value="file147">google.golang.org/grpc/xds/internal/balancer/cdsbalancer/cdsbalancer.go (87.2%)</option>
				
				<option value="file148">google.golang.org/grpc/xds/internal/balancer/cdsbalancer/cluster_handler.go (100.0%)</option>
				
				<option value="file149">google.golang.org/grpc/xds/internal/balancer/cdsbalancer/logging.go (100.0%)</option>
				
				<option value="file150">google.golang.org/grpc/xds/internal/balancer/clusterimpl/clusterimpl.go (79.7%)</option>
				
				<option value="file151">google.golang.org/grpc/xds/internal/balancer/clusterimpl/config.go (100.0%)</option>
				
				<option value="file152">google.golang.org/grpc/xds/internal/balancer/clusterimpl/logging.go (100.0%)</option>
				
				<option value="file153">google.golang.org/grpc/xds/internal/balancer/clusterimpl/picker.go (86.2%)</option>
				
				<option value="file154">google.golang.org/grpc/xds/internal/balancer/clustermanager/balancerstateaggregator.go (81.5%)</option>
				
				<option value="file155">google.golang.org/grpc/xds/internal/balancer/clustermanager/clustermanager.go (86.0%)</option>
				
				<option value="file156">google.golang.org/grpc/xds/internal/balancer/clustermanager/config.go (100.0%)</option>
				
				<option value="file157">google.golang.org/grpc/xds/internal/balancer/clustermanager/picker.go (91.7%)</option>
				
				<option value="file158">google.golang.org/grpc/xds/internal/balancer/clusterresolver/clusterresolver.go (76.1%)</option>
				
				<option value="file159">google.golang.org/grpc/xds/internal/balancer/clusterresolver/config.go (84.4%)</option>
				
				<option value="file160">google.golang.org/grpc/xds/internal/balancer/clusterresolver/configbuilder.go (94.7%)</option>
				
				<option value="file161">google.golang.org/grpc/xds/internal/balancer/clusterresolver/configbuilder_childname.go (100.0%)</option>
				
				<option value="file162">google.golang.org/grpc/xds/internal/balancer/clusterresolver/logging.go (100.0%)</option>
				
				<option value="file163">google.golang.org/grpc/xds/internal/balancer/clusterresolver/resource_resolver.go (98.8%)</option>
				
				<option value="file164">google.golang.org/grpc/xds/internal/balancer/clusterresolver/resource_resolver_dns.go (80.8%)</option>
				
				<option value="file165">google.golang.org/grpc/xds/internal/balancer/orca/orca.go (77.3%)</option>
				
				<option value="file166">google.golang.org/grpc/xds/internal/balancer/outlierdetection/balancer.go (76.2%)</option>
				
				<option value="file167">google.golang.org/grpc/xds/internal/balancer/outlierdetection/config.go (59.5%)</option>
				
				<option value="file168">google.golang.org/grpc/xds/internal/balancer/priority/balancer.go (90.0%)</option>
				
				<option value="file169">google.golang.org/grpc/xds/internal/balancer/priority/balancer_child.go (95.1%)</option>
				
				<option value="file170">google.golang.org/grpc/xds/internal/balancer/priority/balancer_priority.go (85.4%)</option>
				
				<option value="file171">google.golang.org/grpc/xds/internal/balancer/priority/config.go (91.7%)</option>
				
				<option value="file172">google.golang.org/grpc/xds/internal/balancer/priority/ignore_resolve_now.go (100.0%)</option>
				
				<option value="file173">google.golang.org/grpc/xds/internal/balancer/priority/logging.go (100.0%)</option>
				
				<option value="file174">google.golang.org/grpc/xds/internal/balancer/priority/utils.go (83.3%)</option>
				
				<option value="file175">google.golang.org/grpc/xds/internal/balancer/ringhash/config.go (90.0%)</option>
				
				<option value="file176">google.golang.org/grpc/xds/internal/balancer/ringhash/logging.go (100.0%)</option>
				
				<option value="file177">google.golang.org/grpc/xds/internal/balancer/ringhash/picker.go (84.6%)</option>
				
				<option value="file178">google.golang.org/grpc/xds/internal/balancer/ringhash/ring.go (97.4%)</option>
				
				<option value="file179">google.golang.org/grpc/xds/internal/balancer/ringhash/ringhash.go (85.3%)</option>
				
				<option value="file180">google.golang.org/grpc/xds/internal/balancer/ringhash/util.go (75.0%)</option>
				
				<option value="file181">google.golang.org/grpc/xds/internal/clusterspecifier/rls/rls.go (62.1%)</option>
				
				<option value="file182">google.golang.org/grpc/xds/internal/httpfilter/fault/fault.go (78.5%)</option>
				
				<option value="file183">google.golang.org/grpc/xds/internal/internal.go (56.2%)</option>
				
				<option value="file184">google.golang.org/grpc/xds/internal/resolver/logging.go (100.0%)</option>
				
				<option value="file185">google.golang.org/grpc/xds/internal/resolver/serviceconfig.go (89.9%)</option>
				
				<option value="file186">google.golang.org/grpc/xds/internal/resolver/watch_service.go (80.7%)</option>
				
				<option value="file187">google.golang.org/grpc/xds/internal/resolver/xds_resolver.go (83.3%)</option>
				
				<option value="file188">google.golang.org/grpc/xds/internal/server/conn_wrapper.go (0.0%)</option>
				
				<option value="file189">google.golang.org/grpc/xds/internal/server/listener_wrapper.go (74.5%)</option>
				
				<option value="file190">google.golang.org/grpc/xds/internal/server/rds_handler.go (100.0%)</option>
				
				<option value="file191">google.golang.org/grpc/xds/internal/test/e2e/controlplane.go (0.0%)</option>
				
				<option value="file192">google.golang.org/grpc/xds/internal/test/e2e/e2e.go (0.0%)</option>
				
				<option value="file193">google.golang.org/grpc/xds/internal/test/e2e/e2e_utils.go (0.0%)</option>
				
				<option value="file194">google.golang.org/grpc/xds/internal/testutils/protos.go (0.0%)</option>
				
				<option value="file195">google.golang.org/grpc/xds/internal/testutils/testutils.go (0.0%)</option>
				
				<option value="file196">google.golang.org/grpc/xds/internal/xdsclient/attributes.go (0.0%)</option>
				
				<option value="file197">google.golang.org/grpc/xds/internal/xdsclient/authority.go (100.0%)</option>
				
				<option value="file198">google.golang.org/grpc/xds/internal/xdsclient/bootstrap/bootstrap.go (80.5%)</option>
				
				<option value="file199">google.golang.org/grpc/xds/internal/xdsclient/bootstrap/template.go (100.0%)</option>
				
				<option value="file200">google.golang.org/grpc/xds/internal/xdsclient/client_new.go (26.5%)</option>
				
				<option value="file201">google.golang.org/grpc/xds/internal/xdsclient/clientimpl.go (90.0%)</option>
				
				<option value="file202">google.golang.org/grpc/xds/internal/xdsclient/clientimpl_authority.go (88.0%)</option>
				
				<option value="file203">google.golang.org/grpc/xds/internal/xdsclient/clientimpl_dump.go (100.0%)</option>
				
				<option value="file204">google.golang.org/grpc/xds/internal/xdsclient/clientimpl_loadreport.go (81.8%)</option>
				
				<option value="file205">google.golang.org/grpc/xds/internal/xdsclient/clientimpl_validator.go (0.0%)</option>
				
				<option value="file206">google.golang.org/grpc/xds/internal/xdsclient/clientimpl_watchers.go (77.8%)</option>
				
				<option value="file207">google.golang.org/grpc/xds/internal/xdsclient/controller/controller.go (90.6%)</option>
				
				<option value="file208">google.golang.org/grpc/xds/internal/xdsclient/controller/loadreport.go (0.0%)</option>
				
				<option value="file209">google.golang.org/grpc/xds/internal/xdsclient/controller/transport.go (69.3%)</option>
				
				<option value="file210">google.golang.org/grpc/xds/internal/xdsclient/load/store.go (92.6%)</option>
				
				<option value="file211">google.golang.org/grpc/xds/internal/xdsclient/logging.go (100.0%)</option>
				
				<option value="file212">google.golang.org/grpc/xds/internal/xdsclient/requests_counter.go (56.5%)</option>
				
				<option value="file213">google.golang.org/grpc/xds/internal/xdsclient/singleton.go (92.0%)</option>
				
				<option value="file214">google.golang.org/grpc/xds/internal/xdsclient/xdsresource/errors.go (0.0%)</option>
				
				<option value="file215">google.golang.org/grpc/xds/internal/xdsclient/xdsresource/filter_chain.go (92.6%)</option>
				
				<option value="file216">google.golang.org/grpc/xds/internal/xdsclient/xdsresource/matcher.go (46.3%)</option>
				
				<option value="file217">google.golang.org/grpc/xds/internal/xdsclient/xdsresource/matcher_path.go (84.2%)</option>
				
				<option value="file218">google.golang.org/grpc/xds/internal/xdsclient/xdsresource/name.go (97.1%)</option>
				
				<option value="file219">google.golang.org/grpc/xds/internal/xdsclient/xdsresource/type.go (57.9%)</option>
				
				<option value="file220">google.golang.org/grpc/xds/internal/xdsclient/xdsresource/type_rds.go (60.0%)</option>
				
				<option value="file221">google.golang.org/grpc/xds/internal/xdsclient/xdsresource/unmarshal.go (92.0%)</option>
				
				<option value="file222">google.golang.org/grpc/xds/internal/xdsclient/xdsresource/unmarshal_cds.go (90.2%)</option>
				
				<option value="file223">google.golang.org/grpc/xds/internal/xdsclient/xdsresource/unmarshal_eds.go (85.9%)</option>
				
				<option value="file224">google.golang.org/grpc/xds/internal/xdsclient/xdsresource/unmarshal_lds.go (91.2%)</option>
				
				<option value="file225">google.golang.org/grpc/xds/internal/xdsclient/xdsresource/unmarshal_rds.go (92.3%)</option>
				
				<option value="file226">google.golang.org/grpc/xds/server.go (57.6%)</option>
				
				<option value="file227">google.golang.org/grpc/xds/server_options.go (50.0%)</option>
				
				<option value="file228">google.golang.org/grpc/xds/xds.go (5.9%)</option>
				
				</select>
			</div>
			<div id="legend">
				<span>not tracked</span>
			
				<span class="cov0">not covered</span>
				<span class="cov8">covered</span>
			
			</div>
		</div>
		<div id="content">
		
		<pre class="file" id="file0" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package admin provides a convenient method for registering a collection of
// administration services to a gRPC server. The services registered are:
//
// - Channelz: https://github.com/grpc/proposal/blob/master/A14-channelz.md
//
// - CSDS: https://github.com/grpc/proposal/blob/master/A40-csds-support.md
//
// Experimental
//
// Notice: All APIs in this package are experimental and may be removed in a
// later release.
package admin

import (
        "google.golang.org/grpc"
        channelzservice "google.golang.org/grpc/channelz/service"
        internaladmin "google.golang.org/grpc/internal/admin"
)

func init() <span class="cov8" title="1">{
        // Add a list of default services to admin here. Optional services, like
        // CSDS, will be added by other packages.
        internaladmin.AddService(func(registrar grpc.ServiceRegistrar) (func(), error) </span><span class="cov8" title="1">{
                channelzservice.RegisterChannelzServiceToServer(registrar)
                return nil, nil
        }</span>)
}

// Register registers the set of admin services to the given server.
//
// The returned cleanup function should be called to clean up the resources
// allocated for the service handlers after the server is stopped.
//
// Note that if `s` is not a *grpc.Server or a *xds.GRPCServer, CSDS will not be
// registered because CSDS generated code is old and doesn't support interface
// `grpc.ServiceRegistrar`.
// https://github.com/envoyproxy/go-control-plane/issues/403
func Register(s grpc.ServiceRegistrar) (cleanup func(), _ error) <span class="cov8" title="1">{
        return internaladmin.Register(s)
}</span>
</pre>
		
		<pre class="file" id="file1" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package test contains test only functions for package admin. It's used by
// admin/admin_test.go and admin/test/admin_test.go.
package test

import (
        "context"
        "net"
        "testing"
        "time"

        v3statusgrpc "github.com/envoyproxy/go-control-plane/envoy/service/status/v3"
        v3statuspb "github.com/envoyproxy/go-control-plane/envoy/service/status/v3"
        "github.com/google/uuid"
        "google.golang.org/grpc"
        "google.golang.org/grpc/admin"
        channelzpb "google.golang.org/grpc/channelz/grpc_channelz_v1"
        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/credentials/insecure"
        "google.golang.org/grpc/internal/xds"
        "google.golang.org/grpc/status"
)

const (
        defaultTestTimeout = 10 * time.Second
)

// ExpectedStatusCodes contains the expected status code for each RPC (can be
// OK).
type ExpectedStatusCodes struct {
        ChannelzCode codes.Code
        CSDSCode     codes.Code
}

// RunRegisterTests makes a client, runs the RPCs, and compares the status
// codes.
func RunRegisterTests(t *testing.T, ec ExpectedStatusCodes) <span class="cov8" title="1">{
        nodeID := uuid.New().String()
        bootstrapCleanup, err := xds.SetupBootstrapFile(xds.BootstrapOptions{
                Version:   xds.TransportV3,
                NodeID:    nodeID,
                ServerURI: "no.need.for.a.server",
        })
        if err != nil </span><span class="cov0" title="0">{
                t.Fatal(err)
        }</span>
        <span class="cov8" title="1">defer bootstrapCleanup()

        lis, err := net.Listen("tcp", "localhost:0")
        if err != nil </span><span class="cov0" title="0">{
                t.Fatalf("cannot create listener: %v", err)
        }</span>

        <span class="cov8" title="1">server := grpc.NewServer()
        defer server.Stop()
        cleanup, err := admin.Register(server)
        if err != nil </span><span class="cov0" title="0">{
                t.Fatalf("failed to register admin: %v", err)
        }</span>
        <span class="cov8" title="1">defer cleanup()
        go func() </span><span class="cov8" title="1">{
                server.Serve(lis)
        }</span>()

        <span class="cov8" title="1">conn, err := grpc.Dial(lis.Addr().String(), grpc.WithTransportCredentials(insecure.NewCredentials()))
        if err != nil </span><span class="cov0" title="0">{
                t.Fatalf("cannot connect to server: %v", err)
        }</span>

        <span class="cov8" title="1">t.Run("channelz", func(t *testing.T) </span><span class="cov8" title="1">{
                if err := RunChannelz(conn); status.Code(err) != ec.ChannelzCode </span><span class="cov0" title="0">{
                        t.Fatalf("%s RPC failed with error %v, want code %v", "channelz", err, ec.ChannelzCode)
                }</span>
        })
        <span class="cov8" title="1">t.Run("csds", func(t *testing.T) </span><span class="cov8" title="1">{
                if err := RunCSDS(conn); status.Code(err) != ec.CSDSCode </span><span class="cov0" title="0">{
                        t.Fatalf("%s RPC failed with error %v, want code %v", "CSDS", err, ec.CSDSCode)
                }</span>
        })
}

// RunChannelz makes a channelz RPC.
func RunChannelz(conn *grpc.ClientConn) error <span class="cov8" title="1">{
        c := channelzpb.NewChannelzClient(conn)
        ctx, cancel := context.WithTimeout(context.Background(), defaultTestTimeout)
        defer cancel()
        _, err := c.GetTopChannels(ctx, &amp;channelzpb.GetTopChannelsRequest{}, grpc.WaitForReady(true))
        return err
}</span>

// RunCSDS makes a CSDS RPC.
func RunCSDS(conn *grpc.ClientConn) error <span class="cov8" title="1">{
        c := v3statusgrpc.NewClientStatusDiscoveryServiceClient(conn)
        ctx, cancel := context.WithTimeout(context.Background(), defaultTestTimeout)
        defer cancel()
        _, err := c.FetchClientStatus(ctx, &amp;v3statuspb.ClientStatusRequest{}, grpc.WaitForReady(true))
        return err
}</span>
</pre>
		
		<pre class="file" id="file2" style="display: none">/*
 *
 * Copyright 2019 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package attributes defines a generic key/value store used in various gRPC
// components.
//
// Experimental
//
// Notice: This package is EXPERIMENTAL and may be changed or removed in a
// later release.
package attributes

// Attributes is an immutable struct for storing and retrieving generic
// key/value pairs.  Keys must be hashable, and users should define their own
// types for keys.  Values should not be modified after they are added to an
// Attributes or if they were received from one.  If values implement 'Equal(o
// interface{}) bool', it will be called by (*Attributes).Equal to determine
// whether two values with the same key should be considered equal.
type Attributes struct {
        m map[interface{}]interface{}
}

// New returns a new Attributes containing the key/value pair.
func New(key, value interface{}) *Attributes <span class="cov8" title="1">{
        return &amp;Attributes{m: map[interface{}]interface{}{key: value}}
}</span>

// WithValue returns a new Attributes containing the previous keys and values
// and the new key/value pair.  If the same key appears multiple times, the
// last value overwrites all previous values for that key.  To remove an
// existing key, use a nil value.  value should not be modified later.
func (a *Attributes) WithValue(key, value interface{}) *Attributes <span class="cov8" title="1">{
        if a == nil </span><span class="cov0" title="0">{
                return New(key, value)
        }</span>
        <span class="cov8" title="1">n := &amp;Attributes{m: make(map[interface{}]interface{}, len(a.m)+1)}
        for k, v := range a.m </span><span class="cov8" title="1">{
                n.m[k] = v
        }</span>
        <span class="cov8" title="1">n.m[key] = value
        return n</span>
}

// Value returns the value associated with these attributes for key, or nil if
// no value is associated with key.  The returned value should not be modified.
func (a *Attributes) Value(key interface{}) interface{} <span class="cov8" title="1">{
        if a == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">return a.m[key]</span>
}

// Equal returns whether a and o are equivalent.  If 'Equal(o interface{})
// bool' is implemented for a value in the attributes, it is called to
// determine if the value matches the one stored in the other attributes.  If
// Equal is not implemented, standard equality is used to determine if the two
// values are equal. Note that some types (e.g. maps) aren't comparable by
// default, so they must be wrapped in a struct, or in an alias type, with Equal
// defined.
func (a *Attributes) Equal(o *Attributes) bool <span class="cov8" title="1">{
        if a == nil &amp;&amp; o == nil </span><span class="cov0" title="0">{
                return true
        }</span>
        <span class="cov8" title="1">if a == nil || o == nil </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov8" title="1">if len(a.m) != len(o.m) </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov8" title="1">for k, v := range a.m </span><span class="cov8" title="1">{
                ov, ok := o.m[k]
                if !ok </span><span class="cov0" title="0">{
                        // o missing element of a
                        return false
                }</span>
                <span class="cov8" title="1">if eq, ok := v.(interface{ Equal(o interface{}) bool }); ok </span><span class="cov8" title="1">{
                        if !eq.Equal(ov) </span><span class="cov8" title="1">{
                                return false
                        }</span>
                } else<span class="cov8" title="1"> if v != ov </span><span class="cov8" title="1">{
                        // Fallback to a standard equality check if Value is unimplemented.
                        return false
                }</span>
        }
        <span class="cov8" title="1">return true</span>
}
</pre>
		
		<pre class="file" id="file3" style="display: none">/*
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package authz

import (
        "bytes"
        "context"
        "fmt"
        "io/ioutil"
        "sync/atomic"
        "time"
        "unsafe"

        "google.golang.org/grpc"
        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/grpclog"
        "google.golang.org/grpc/internal/xds/rbac"
        "google.golang.org/grpc/status"
)

var logger = grpclog.Component("authz")

// StaticInterceptor contains engines used to make authorization decisions. It
// either contains two engines deny engine followed by an allow engine or only
// one allow engine.
type StaticInterceptor struct {
        engines rbac.ChainEngine
}

// NewStatic returns a new StaticInterceptor from a static authorization policy
// JSON string.
func NewStatic(authzPolicy string) (*StaticInterceptor, error) <span class="cov8" title="1">{
        rbacs, err := translatePolicy(authzPolicy)
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">chainEngine, err := rbac.NewChainEngine(rbacs)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return &amp;StaticInterceptor{*chainEngine}, nil</span>
}

// UnaryInterceptor intercepts incoming Unary RPC requests.
// Only authorized requests are allowed to pass. Otherwise, an unauthorized
// error is returned to the client.
func (i *StaticInterceptor) UnaryInterceptor(ctx context.Context, req interface{}, _ *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (interface{}, error) <span class="cov8" title="1">{
        err := i.engines.IsAuthorized(ctx)
        if err != nil </span><span class="cov8" title="1">{
                if status.Code(err) == codes.PermissionDenied </span><span class="cov8" title="1">{
                        if logger.V(2) </span><span class="cov0" title="0">{
                                logger.Infof("unauthorized RPC request rejected: %v", err)
                        }</span>
                        <span class="cov8" title="1">return nil, status.Errorf(codes.PermissionDenied, "unauthorized RPC request rejected")</span>
                }
                <span class="cov0" title="0">return nil, err</span>
        }
        <span class="cov8" title="1">return handler(ctx, req)</span>
}

// StreamInterceptor intercepts incoming Stream RPC requests.
// Only authorized requests are allowed to pass. Otherwise, an unauthorized
// error is returned to the client.
func (i *StaticInterceptor) StreamInterceptor(srv interface{}, ss grpc.ServerStream, _ *grpc.StreamServerInfo, handler grpc.StreamHandler) error <span class="cov8" title="1">{
        err := i.engines.IsAuthorized(ss.Context())
        if err != nil </span><span class="cov8" title="1">{
                if status.Code(err) == codes.PermissionDenied </span><span class="cov8" title="1">{
                        if logger.V(2) </span><span class="cov0" title="0">{
                                logger.Infof("unauthorized RPC request rejected: %v", err)
                        }</span>
                        <span class="cov8" title="1">return status.Errorf(codes.PermissionDenied, "unauthorized RPC request rejected")</span>
                }
                <span class="cov0" title="0">return err</span>
        }
        <span class="cov8" title="1">return handler(srv, ss)</span>
}

// FileWatcherInterceptor contains details used to make authorization decisions
// by watching a file path that contains authorization policy in JSON format.
type FileWatcherInterceptor struct {
        internalInterceptor unsafe.Pointer // *StaticInterceptor
        policyFile          string
        policyContents      []byte
        refreshDuration     time.Duration
        cancel              context.CancelFunc
}

// NewFileWatcher returns a new FileWatcherInterceptor from a policy file
// that contains JSON string of authorization policy and a refresh duration to
// specify the amount of time between policy refreshes.
func NewFileWatcher(file string, duration time.Duration) (*FileWatcherInterceptor, error) <span class="cov8" title="1">{
        if file == "" </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("authorization policy file path is empty")
        }</span>
        <span class="cov8" title="1">if duration &lt;= time.Duration(0) </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("requires refresh interval(%v) greater than 0s", duration)
        }</span>
        <span class="cov8" title="1">i := &amp;FileWatcherInterceptor{policyFile: file, refreshDuration: duration}
        if err := i.updateInternalInterceptor(); err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">ctx, cancel := context.WithCancel(context.Background())
        i.cancel = cancel
        // Create a background go routine for policy refresh.
        go i.run(ctx)
        return i, nil</span>
}

func (i *FileWatcherInterceptor) run(ctx context.Context) <span class="cov8" title="1">{
        ticker := time.NewTicker(i.refreshDuration)
        for </span><span class="cov8" title="1">{
                if err := i.updateInternalInterceptor(); err != nil </span><span class="cov8" title="1">{
                        logger.Warningf("authorization policy reload status err: %v", err)
                }</span>
                <span class="cov8" title="1">select </span>{
                case &lt;-ctx.Done():<span class="cov8" title="1">
                        ticker.Stop()
                        return</span>
                case &lt;-ticker.C:<span class="cov8" title="1"></span>
                }
        }
}

// updateInternalInterceptor checks if the policy file that is watching has changed,
// and if so, updates the internalInterceptor with the policy. Unlike the
// constructor, if there is an error in reading the file or parsing the policy, the
// previous internalInterceptors will not be replaced.
func (i *FileWatcherInterceptor) updateInternalInterceptor() error <span class="cov8" title="1">{
        policyContents, err := ioutil.ReadFile(i.policyFile)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("policyFile(%s) read failed: %v", i.policyFile, err)
        }</span>
        <span class="cov8" title="1">if bytes.Equal(i.policyContents, policyContents) </span><span class="cov8" title="1">{
                return nil
        }</span>
        <span class="cov8" title="1">i.policyContents = policyContents
        policyContentsString := string(policyContents)
        interceptor, err := NewStatic(policyContentsString)
        if err != nil </span><span class="cov8" title="1">{
                return err
        }</span>
        <span class="cov8" title="1">atomic.StorePointer(&amp;i.internalInterceptor, unsafe.Pointer(interceptor))
        logger.Infof("authorization policy reload status: successfully loaded new policy %v", policyContentsString)
        return nil</span>
}

// Close cleans up resources allocated by the interceptor.
func (i *FileWatcherInterceptor) Close() <span class="cov8" title="1">{
        i.cancel()
}</span>

// UnaryInterceptor intercepts incoming Unary RPC requests.
// Only authorized requests are allowed to pass. Otherwise, an unauthorized
// error is returned to the client.
func (i *FileWatcherInterceptor) UnaryInterceptor(ctx context.Context, req interface{}, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (interface{}, error) <span class="cov8" title="1">{
        return ((*StaticInterceptor)(atomic.LoadPointer(&amp;i.internalInterceptor))).UnaryInterceptor(ctx, req, info, handler)
}</span>

// StreamInterceptor intercepts incoming Stream RPC requests.
// Only authorized requests are allowed to pass. Otherwise, an unauthorized
// error is returned to the client.
func (i *FileWatcherInterceptor) StreamInterceptor(srv interface{}, ss grpc.ServerStream, info *grpc.StreamServerInfo, handler grpc.StreamHandler) error <span class="cov8" title="1">{
        return ((*StaticInterceptor)(atomic.LoadPointer(&amp;i.internalInterceptor))).StreamInterceptor(srv, ss, info, handler)
}</span>
</pre>
		
		<pre class="file" id="file4" style="display: none">/*
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// Package authz exposes methods to manage authorization within gRPC.
//
// Experimental
//
// Notice: This package is EXPERIMENTAL and may be changed or removed
// in a later release.
package authz

import (
        "bytes"
        "encoding/json"
        "fmt"
        "strings"

        v3rbacpb "github.com/envoyproxy/go-control-plane/envoy/config/rbac/v3"
        v3routepb "github.com/envoyproxy/go-control-plane/envoy/config/route/v3"
        v3matcherpb "github.com/envoyproxy/go-control-plane/envoy/type/matcher/v3"
)

type header struct {
        Key    string
        Values []string
}

type peer struct {
        Principals []string
}

type request struct {
        Paths   []string
        Headers []header
}

type rule struct {
        Name    string
        Source  peer
        Request request
}

// Represents the SDK authorization policy provided by user.
type authorizationPolicy struct {
        Name       string
        DenyRules  []rule `json:"deny_rules"`
        AllowRules []rule `json:"allow_rules"`
}

func principalOr(principals []*v3rbacpb.Principal) *v3rbacpb.Principal <span class="cov8" title="1">{
        return &amp;v3rbacpb.Principal{
                Identifier: &amp;v3rbacpb.Principal_OrIds{
                        OrIds: &amp;v3rbacpb.Principal_Set{
                                Ids: principals,
                        },
                },
        }
}</span>

func permissionOr(permission []*v3rbacpb.Permission) *v3rbacpb.Permission <span class="cov8" title="1">{
        return &amp;v3rbacpb.Permission{
                Rule: &amp;v3rbacpb.Permission_OrRules{
                        OrRules: &amp;v3rbacpb.Permission_Set{
                                Rules: permission,
                        },
                },
        }
}</span>

func permissionAnd(permission []*v3rbacpb.Permission) *v3rbacpb.Permission <span class="cov8" title="1">{
        return &amp;v3rbacpb.Permission{
                Rule: &amp;v3rbacpb.Permission_AndRules{
                        AndRules: &amp;v3rbacpb.Permission_Set{
                                Rules: permission,
                        },
                },
        }
}</span>

func getStringMatcher(value string) *v3matcherpb.StringMatcher <span class="cov8" title="1">{
        switch </span>{
        case value == "*":<span class="cov8" title="1">
                return &amp;v3matcherpb.StringMatcher{
                        MatchPattern: &amp;v3matcherpb.StringMatcher_SafeRegex{
                                SafeRegex: &amp;v3matcherpb.RegexMatcher{Regex: ".+"}},
                }</span>
        case strings.HasSuffix(value, "*"):<span class="cov8" title="1">
                prefix := strings.TrimSuffix(value, "*")
                return &amp;v3matcherpb.StringMatcher{
                        MatchPattern: &amp;v3matcherpb.StringMatcher_Prefix{Prefix: prefix},
                }</span>
        case strings.HasPrefix(value, "*"):<span class="cov8" title="1">
                suffix := strings.TrimPrefix(value, "*")
                return &amp;v3matcherpb.StringMatcher{
                        MatchPattern: &amp;v3matcherpb.StringMatcher_Suffix{Suffix: suffix},
                }</span>
        default:<span class="cov8" title="1">
                return &amp;v3matcherpb.StringMatcher{
                        MatchPattern: &amp;v3matcherpb.StringMatcher_Exact{Exact: value},
                }</span>
        }
}

func getHeaderMatcher(key, value string) *v3routepb.HeaderMatcher <span class="cov8" title="1">{
        switch </span>{
        case value == "*":<span class="cov8" title="1">
                return &amp;v3routepb.HeaderMatcher{
                        Name: key,
                        HeaderMatchSpecifier: &amp;v3routepb.HeaderMatcher_SafeRegexMatch{
                                SafeRegexMatch: &amp;v3matcherpb.RegexMatcher{Regex: ".+"}},
                }</span>
        case strings.HasSuffix(value, "*"):<span class="cov8" title="1">
                prefix := strings.TrimSuffix(value, "*")
                return &amp;v3routepb.HeaderMatcher{
                        Name:                 key,
                        HeaderMatchSpecifier: &amp;v3routepb.HeaderMatcher_PrefixMatch{PrefixMatch: prefix},
                }</span>
        case strings.HasPrefix(value, "*"):<span class="cov8" title="1">
                suffix := strings.TrimPrefix(value, "*")
                return &amp;v3routepb.HeaderMatcher{
                        Name:                 key,
                        HeaderMatchSpecifier: &amp;v3routepb.HeaderMatcher_SuffixMatch{SuffixMatch: suffix},
                }</span>
        default:<span class="cov8" title="1">
                return &amp;v3routepb.HeaderMatcher{
                        Name:                 key,
                        HeaderMatchSpecifier: &amp;v3routepb.HeaderMatcher_ExactMatch{ExactMatch: value},
                }</span>
        }
}

func parsePrincipalNames(principalNames []string) []*v3rbacpb.Principal <span class="cov8" title="1">{
        ps := make([]*v3rbacpb.Principal, 0, len(principalNames))
        for _, principalName := range principalNames </span><span class="cov8" title="1">{
                newPrincipalName := &amp;v3rbacpb.Principal{
                        Identifier: &amp;v3rbacpb.Principal_Authenticated_{
                                Authenticated: &amp;v3rbacpb.Principal_Authenticated{
                                        PrincipalName: getStringMatcher(principalName),
                                },
                        }}
                ps = append(ps, newPrincipalName)
        }</span>
        <span class="cov8" title="1">return ps</span>
}

func parsePeer(source peer) *v3rbacpb.Principal <span class="cov8" title="1">{
        if len(source.Principals) == 0 </span><span class="cov8" title="1">{
                return &amp;v3rbacpb.Principal{
                        Identifier: &amp;v3rbacpb.Principal_Any{
                                Any: true,
                        },
                }
        }</span>
        <span class="cov8" title="1">return principalOr(parsePrincipalNames(source.Principals))</span>
}

func parsePaths(paths []string) []*v3rbacpb.Permission <span class="cov8" title="1">{
        ps := make([]*v3rbacpb.Permission, 0, len(paths))
        for _, path := range paths </span><span class="cov8" title="1">{
                newPath := &amp;v3rbacpb.Permission{
                        Rule: &amp;v3rbacpb.Permission_UrlPath{
                                UrlPath: &amp;v3matcherpb.PathMatcher{
                                        Rule: &amp;v3matcherpb.PathMatcher_Path{Path: getStringMatcher(path)}}}}
                ps = append(ps, newPath)
        }</span>
        <span class="cov8" title="1">return ps</span>
}

func parseHeaderValues(key string, values []string) []*v3rbacpb.Permission <span class="cov8" title="1">{
        vs := make([]*v3rbacpb.Permission, 0, len(values))
        for _, value := range values </span><span class="cov8" title="1">{
                newHeader := &amp;v3rbacpb.Permission{
                        Rule: &amp;v3rbacpb.Permission_Header{
                                Header: getHeaderMatcher(key, value)}}
                vs = append(vs, newHeader)
        }</span>
        <span class="cov8" title="1">return vs</span>
}

var unsupportedHeaders = map[string]bool{
        "host":                true,
        "connection":          true,
        "keep-alive":          true,
        "proxy-authenticate":  true,
        "proxy-authorization": true,
        "te":                  true,
        "trailer":             true,
        "transfer-encoding":   true,
        "upgrade":             true,
}

func unsupportedHeader(key string) bool <span class="cov8" title="1">{
        return key[0] == ':' || strings.HasPrefix(key, "grpc-") || unsupportedHeaders[key]
}</span>

func parseHeaders(headers []header) ([]*v3rbacpb.Permission, error) <span class="cov8" title="1">{
        hs := make([]*v3rbacpb.Permission, 0, len(headers))
        for i, header := range headers </span><span class="cov8" title="1">{
                if header.Key == "" </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf(`"headers" %d: "key" is not present`, i)
                }</span>
                <span class="cov8" title="1">header.Key = strings.ToLower(header.Key)
                if unsupportedHeader(header.Key) </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf(`"headers" %d: unsupported "key" %s`, i, header.Key)
                }</span>
                <span class="cov8" title="1">if len(header.Values) == 0 </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf(`"headers" %d: "values" is not present`, i)
                }</span>
                <span class="cov8" title="1">values := parseHeaderValues(header.Key, header.Values)
                hs = append(hs, permissionOr(values))</span>
        }
        <span class="cov8" title="1">return hs, nil</span>
}

func parseRequest(request request) (*v3rbacpb.Permission, error) <span class="cov8" title="1">{
        var and []*v3rbacpb.Permission
        if len(request.Paths) &gt; 0 </span><span class="cov8" title="1">{
                and = append(and, permissionOr(parsePaths(request.Paths)))
        }</span>
        <span class="cov8" title="1">if len(request.Headers) &gt; 0 </span><span class="cov8" title="1">{
                headers, err := parseHeaders(request.Headers)
                if err != nil </span><span class="cov8" title="1">{
                        return nil, err
                }</span>
                <span class="cov8" title="1">and = append(and, permissionAnd(headers))</span>
        }
        <span class="cov8" title="1">if len(and) &gt; 0 </span><span class="cov8" title="1">{
                return permissionAnd(and), nil
        }</span>
        <span class="cov8" title="1">return &amp;v3rbacpb.Permission{
                Rule: &amp;v3rbacpb.Permission_Any{
                        Any: true,
                },
        }, nil</span>
}

func parseRules(rules []rule, prefixName string) (map[string]*v3rbacpb.Policy, error) <span class="cov8" title="1">{
        policies := make(map[string]*v3rbacpb.Policy)
        for i, rule := range rules </span><span class="cov8" title="1">{
                if rule.Name == "" </span><span class="cov8" title="1">{
                        return policies, fmt.Errorf(`%d: "name" is not present`, i)
                }</span>
                <span class="cov8" title="1">permission, err := parseRequest(rule.Request)
                if err != nil </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("%d: %v", i, err)
                }</span>
                <span class="cov8" title="1">policyName := prefixName + "_" + rule.Name
                policies[policyName] = &amp;v3rbacpb.Policy{
                        Principals:  []*v3rbacpb.Principal{parsePeer(rule.Source)},
                        Permissions: []*v3rbacpb.Permission{permission},
                }</span>
        }
        <span class="cov8" title="1">return policies, nil</span>
}

// translatePolicy translates SDK authorization policy in JSON format to two
// Envoy RBAC polices (deny followed by allow policy) or only one Envoy RBAC
// allow policy. If the input policy cannot be parsed or is invalid, an error
// will be returned.
func translatePolicy(policyStr string) ([]*v3rbacpb.RBAC, error) <span class="cov8" title="1">{
        policy := &amp;authorizationPolicy{}
        d := json.NewDecoder(bytes.NewReader([]byte(policyStr)))
        d.DisallowUnknownFields()
        if err := d.Decode(policy); err != nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("failed to unmarshal policy: %v", err)
        }</span>
        <span class="cov8" title="1">if policy.Name == "" </span><span class="cov8" title="1">{
                return nil, fmt.Errorf(`"name" is not present`)
        }</span>
        <span class="cov8" title="1">if len(policy.AllowRules) == 0 </span><span class="cov8" title="1">{
                return nil, fmt.Errorf(`"allow_rules" is not present`)
        }</span>
        <span class="cov8" title="1">rbacs := make([]*v3rbacpb.RBAC, 0, 2)
        if len(policy.DenyRules) &gt; 0 </span><span class="cov8" title="1">{
                denyPolicies, err := parseRules(policy.DenyRules, policy.Name)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf(`"deny_rules" %v`, err)
                }</span>
                <span class="cov8" title="1">denyRBAC := &amp;v3rbacpb.RBAC{
                        Action:   v3rbacpb.RBAC_DENY,
                        Policies: denyPolicies,
                }
                rbacs = append(rbacs, denyRBAC)</span>
        }
        <span class="cov8" title="1">allowPolicies, err := parseRules(policy.AllowRules, policy.Name)
        if err != nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf(`"allow_rules" %v`, err)
        }</span>
        <span class="cov8" title="1">allowRBAC := &amp;v3rbacpb.RBAC{Action: v3rbacpb.RBAC_ALLOW, Policies: allowPolicies}
        return append(rbacs, allowRBAC), nil</span>
}
</pre>
		
		<pre class="file" id="file5" style="display: none">/*
 *
 * Copyright 2017 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package balancer defines APIs for load balancing in gRPC.
// All APIs in this package are experimental.
package balancer

import (
        "context"
        "encoding/json"
        "errors"
        "net"
        "strings"

        "google.golang.org/grpc/channelz"
        "google.golang.org/grpc/connectivity"
        "google.golang.org/grpc/credentials"
        "google.golang.org/grpc/internal"
        "google.golang.org/grpc/metadata"
        "google.golang.org/grpc/resolver"
        "google.golang.org/grpc/serviceconfig"
)

var (
        // m is a map from name to balancer builder.
        m = make(map[string]Builder)
)

// Register registers the balancer builder to the balancer map. b.Name
// (lowercased) will be used as the name registered with this builder.  If the
// Builder implements ConfigParser, ParseConfig will be called when new service
// configs are received by the resolver, and the result will be provided to the
// Balancer in UpdateClientConnState.
//
// NOTE: this function must only be called during initialization time (i.e. in
// an init() function), and is not thread-safe. If multiple Balancers are
// registered with the same name, the one registered last will take effect.
func Register(b Builder) <span class="cov0" title="0">{
        m[strings.ToLower(b.Name())] = b
}</span>

// unregisterForTesting deletes the balancer with the given name from the
// balancer map.
//
// This function is not thread-safe.
func unregisterForTesting(name string) <span class="cov0" title="0">{
        delete(m, name)
}</span>

func init() <span class="cov8" title="1">{
        internal.BalancerUnregister = unregisterForTesting
}</span>

// Get returns the resolver builder registered with the given name.
// Note that the compare is done in a case-insensitive fashion.
// If no builder is register with the name, nil will be returned.
func Get(name string) Builder <span class="cov0" title="0">{
        if b, ok := m[strings.ToLower(name)]; ok </span><span class="cov0" title="0">{
                return b
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// A SubConn represents a single connection to a gRPC backend service.
//
// Each SubConn contains a list of addresses.
//
// All SubConns start in IDLE, and will not try to connect. To trigger the
// connecting, Balancers must call Connect.  If a connection re-enters IDLE,
// Balancers must call Connect again to trigger a new connection attempt.
//
// gRPC will try to connect to the addresses in sequence, and stop trying the
// remainder once the first connection is successful. If an attempt to connect
// to all addresses encounters an error, the SubConn will enter
// TRANSIENT_FAILURE for a backoff period, and then transition to IDLE.
//
// Once established, if a connection is lost, the SubConn will transition
// directly to IDLE.
//
// This interface is to be implemented by gRPC. Users should not need their own
// implementation of this interface. For situations like testing, any
// implementations should embed this interface. This allows gRPC to add new
// methods to this interface.
type SubConn interface {
        // UpdateAddresses updates the addresses used in this SubConn.
        // gRPC checks if currently-connected address is still in the new list.
        // If it's in the list, the connection will be kept.
        // If it's not in the list, the connection will gracefully closed, and
        // a new connection will be created.
        //
        // This will trigger a state transition for the SubConn.
        //
        // Deprecated: This method is now part of the ClientConn interface and will
        // eventually be removed from here.
        UpdateAddresses([]resolver.Address)
        // Connect starts the connecting for this SubConn.
        Connect()
}

// NewSubConnOptions contains options to create new SubConn.
type NewSubConnOptions struct {
        // CredsBundle is the credentials bundle that will be used in the created
        // SubConn. If it's nil, the original creds from grpc DialOptions will be
        // used.
        //
        // Deprecated: Use the Attributes field in resolver.Address to pass
        // arbitrary data to the credential handshaker.
        CredsBundle credentials.Bundle
        // HealthCheckEnabled indicates whether health check service should be
        // enabled on this SubConn
        HealthCheckEnabled bool
}

// State contains the balancer's state relevant to the gRPC ClientConn.
type State struct {
        // State contains the connectivity state of the balancer, which is used to
        // determine the state of the ClientConn.
        ConnectivityState connectivity.State
        // Picker is used to choose connections (SubConns) for RPCs.
        Picker Picker
}

// ClientConn represents a gRPC ClientConn.
//
// This interface is to be implemented by gRPC. Users should not need a
// brand new implementation of this interface. For the situations like
// testing, the new implementation should embed this interface. This allows
// gRPC to add new methods to this interface.
type ClientConn interface {
        // NewSubConn is called by balancer to create a new SubConn.
        // It doesn't block and wait for the connections to be established.
        // Behaviors of the SubConn can be controlled by options.
        NewSubConn([]resolver.Address, NewSubConnOptions) (SubConn, error)
        // RemoveSubConn removes the SubConn from ClientConn.
        // The SubConn will be shutdown.
        RemoveSubConn(SubConn)
        // UpdateAddresses updates the addresses used in the passed in SubConn.
        // gRPC checks if the currently connected address is still in the new list.
        // If so, the connection will be kept. Else, the connection will be
        // gracefully closed, and a new connection will be created.
        //
        // This will trigger a state transition for the SubConn.
        UpdateAddresses(SubConn, []resolver.Address)

        // UpdateState notifies gRPC that the balancer's internal state has
        // changed.
        //
        // gRPC will update the connectivity state of the ClientConn, and will call
        // Pick on the new Picker to pick new SubConns.
        UpdateState(State)

        // ResolveNow is called by balancer to notify gRPC to do a name resolving.
        ResolveNow(resolver.ResolveNowOptions)

        // Target returns the dial target for this ClientConn.
        //
        // Deprecated: Use the Target field in the BuildOptions instead.
        Target() string
}

// BuildOptions contains additional information for Build.
type BuildOptions struct {
        // DialCreds is the transport credentials to use when communicating with a
        // remote load balancer server. Balancer implementations which do not
        // communicate with a remote load balancer server can ignore this field.
        DialCreds credentials.TransportCredentials
        // CredsBundle is the credentials bundle to use when communicating with a
        // remote load balancer server. Balancer implementations which do not
        // communicate with a remote load balancer server can ignore this field.
        CredsBundle credentials.Bundle
        // Dialer is the custom dialer to use when communicating with a remote load
        // balancer server. Balancer implementations which do not communicate with a
        // remote load balancer server can ignore this field.
        Dialer func(context.Context, string) (net.Conn, error)
        // Authority is the server name to use as part of the authentication
        // handshake when communicating with a remote load balancer server. Balancer
        // implementations which do not communicate with a remote load balancer
        // server can ignore this field.
        Authority string
        // ChannelzParentID is the parent ClientConn's channelz ID.
        ChannelzParentID *channelz.Identifier
        // CustomUserAgent is the custom user agent set on the parent ClientConn.
        // The balancer should set the same custom user agent if it creates a
        // ClientConn.
        CustomUserAgent string
        // Target contains the parsed address info of the dial target. It is the
        // same resolver.Target as passed to the resolver. See the documentation for
        // the resolver.Target type for details about what it contains.
        Target resolver.Target
}

// Builder creates a balancer.
type Builder interface {
        // Build creates a new balancer with the ClientConn.
        Build(cc ClientConn, opts BuildOptions) Balancer
        // Name returns the name of balancers built by this builder.
        // It will be used to pick balancers (for example in service config).
        Name() string
}

// ConfigParser parses load balancer configs.
type ConfigParser interface {
        // ParseConfig parses the JSON load balancer config provided into an
        // internal form or returns an error if the config is invalid.  For future
        // compatibility reasons, unknown fields in the config should be ignored.
        ParseConfig(LoadBalancingConfigJSON json.RawMessage) (serviceconfig.LoadBalancingConfig, error)
}

// PickInfo contains additional information for the Pick operation.
type PickInfo struct {
        // FullMethodName is the method name that NewClientStream() is called
        // with. The canonical format is /service/Method.
        FullMethodName string
        // Ctx is the RPC's context, and may contain relevant RPC-level information
        // like the outgoing header metadata.
        Ctx context.Context
}

// DoneInfo contains additional information for done.
type DoneInfo struct {
        // Err is the rpc error the RPC finished with. It could be nil.
        Err error
        // Trailer contains the metadata from the RPC's trailer, if present.
        Trailer metadata.MD
        // BytesSent indicates if any bytes have been sent to the server.
        BytesSent bool
        // BytesReceived indicates if any byte has been received from the server.
        BytesReceived bool
        // ServerLoad is the load received from server. It's usually sent as part of
        // trailing metadata.
        //
        // The only supported type now is *orca_v1.LoadReport.
        ServerLoad interface{}
}

var (
        // ErrNoSubConnAvailable indicates no SubConn is available for pick().
        // gRPC will block the RPC until a new picker is available via UpdateState().
        ErrNoSubConnAvailable = errors.New("no SubConn is available")
        // ErrTransientFailure indicates all SubConns are in TransientFailure.
        // WaitForReady RPCs will block, non-WaitForReady RPCs will fail.
        //
        // Deprecated: return an appropriate error based on the last resolution or
        // connection attempt instead.  The behavior is the same for any non-gRPC
        // status error.
        ErrTransientFailure = errors.New("all SubConns are in TransientFailure")
)

// PickResult contains information related to a connection chosen for an RPC.
type PickResult struct {
        // SubConn is the connection to use for this pick, if its state is Ready.
        // If the state is not Ready, gRPC will block the RPC until a new Picker is
        // provided by the balancer (using ClientConn.UpdateState).  The SubConn
        // must be one returned by ClientConn.NewSubConn.
        SubConn SubConn

        // Done is called when the RPC is completed.  If the SubConn is not ready,
        // this will be called with a nil parameter.  If the SubConn is not a valid
        // type, Done may not be called.  May be nil if the balancer does not wish
        // to be notified when the RPC completes.
        Done func(DoneInfo)
}

// TransientFailureError returns e.  It exists for backward compatibility and
// will be deleted soon.
//
// Deprecated: no longer necessary, picker errors are treated this way by
// default.
func TransientFailureError(e error) error <span class="cov0" title="0">{ return e }</span>

// Picker is used by gRPC to pick a SubConn to send an RPC.
// Balancer is expected to generate a new picker from its snapshot every time its
// internal state has changed.
//
// The pickers used by gRPC can be updated by ClientConn.UpdateState().
type Picker interface {
        // Pick returns the connection to use for this RPC and related information.
        //
        // Pick should not block.  If the balancer needs to do I/O or any blocking
        // or time-consuming work to service this call, it should return
        // ErrNoSubConnAvailable, and the Pick call will be repeated by gRPC when
        // the Picker is updated (using ClientConn.UpdateState).
        //
        // If an error is returned:
        //
        // - If the error is ErrNoSubConnAvailable, gRPC will block until a new
        //   Picker is provided by the balancer (using ClientConn.UpdateState).
        //
        // - If the error is a status error (implemented by the grpc/status
        //   package), gRPC will terminate the RPC with the code and message
        //   provided.
        //
        // - For all other errors, wait for ready RPCs will wait, but non-wait for
        //   ready RPCs will be terminated with this error's Error() string and
        //   status code Unavailable.
        Pick(info PickInfo) (PickResult, error)
}

// Balancer takes input from gRPC, manages SubConns, and collects and aggregates
// the connectivity states.
//
// It also generates and updates the Picker used by gRPC to pick SubConns for RPCs.
//
// UpdateClientConnState, ResolverError, UpdateSubConnState, and Close are
// guaranteed to be called synchronously from the same goroutine.  There's no
// guarantee on picker.Pick, it may be called anytime.
type Balancer interface {
        // UpdateClientConnState is called by gRPC when the state of the ClientConn
        // changes.  If the error returned is ErrBadResolverState, the ClientConn
        // will begin calling ResolveNow on the active name resolver with
        // exponential backoff until a subsequent call to UpdateClientConnState
        // returns a nil error.  Any other errors are currently ignored.
        UpdateClientConnState(ClientConnState) error
        // ResolverError is called by gRPC when the name resolver reports an error.
        ResolverError(error)
        // UpdateSubConnState is called by gRPC when the state of a SubConn
        // changes.
        UpdateSubConnState(SubConn, SubConnState)
        // Close closes the balancer. The balancer is not required to call
        // ClientConn.RemoveSubConn for its existing SubConns.
        Close()
}

// ExitIdler is an optional interface for balancers to implement.  If
// implemented, ExitIdle will be called when ClientConn.Connect is called, if
// the ClientConn is idle.  If unimplemented, ClientConn.Connect will cause
// all SubConns to connect.
//
// Notice: it will be required for all balancers to implement this in a future
// release.
type ExitIdler interface {
        // ExitIdle instructs the LB policy to reconnect to backends / exit the
        // IDLE state, if appropriate and possible.  Note that SubConns that enter
        // the IDLE state will not reconnect until SubConn.Connect is called.
        ExitIdle()
}

// SubConnState describes the state of a SubConn.
type SubConnState struct {
        // ConnectivityState is the connectivity state of the SubConn.
        ConnectivityState connectivity.State
        // ConnectionError is set if the ConnectivityState is TransientFailure,
        // describing the reason the SubConn failed.  Otherwise, it is nil.
        ConnectionError error
}

// ClientConnState describes the state of a ClientConn relevant to the
// balancer.
type ClientConnState struct {
        ResolverState resolver.State
        // The parsed load balancing configuration returned by the builder's
        // ParseConfig method, if implemented.
        BalancerConfig serviceconfig.LoadBalancingConfig
}

// ErrBadResolverState may be returned by UpdateClientConnState to indicate a
// problem with the provided name resolver data.
var ErrBadResolverState = errors.New("bad resolver state")
</pre>
		
		<pre class="file" id="file6" style="display: none">/*
 *
 * Copyright 2017 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package base

import (
        "errors"
        "fmt"

        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/connectivity"
        "google.golang.org/grpc/grpclog"
        "google.golang.org/grpc/resolver"
)

var logger = grpclog.Component("balancer")

type baseBuilder struct {
        name          string
        pickerBuilder PickerBuilder
        config        Config
}

func (bb *baseBuilder) Build(cc balancer.ClientConn, opt balancer.BuildOptions) balancer.Balancer <span class="cov8" title="1">{
        bal := &amp;baseBalancer{
                cc:            cc,
                pickerBuilder: bb.pickerBuilder,

                subConns: resolver.NewAddressMap(),
                scStates: make(map[balancer.SubConn]connectivity.State),
                csEvltr:  &amp;balancer.ConnectivityStateEvaluator{},
                config:   bb.config,
                state:    connectivity.Connecting,
        }
        // Initialize picker to a picker that always returns
        // ErrNoSubConnAvailable, because when state of a SubConn changes, we
        // may call UpdateState with this picker.
        bal.picker = NewErrPicker(balancer.ErrNoSubConnAvailable)
        return bal
}</span>

func (bb *baseBuilder) Name() string <span class="cov0" title="0">{
        return bb.name
}</span>

type baseBalancer struct {
        cc            balancer.ClientConn
        pickerBuilder PickerBuilder

        csEvltr *balancer.ConnectivityStateEvaluator
        state   connectivity.State

        subConns *resolver.AddressMap
        scStates map[balancer.SubConn]connectivity.State
        picker   balancer.Picker
        config   Config

        resolverErr error // the last error reported by the resolver; cleared on successful resolution
        connErr     error // the last connection error; cleared upon leaving TransientFailure
}

func (b *baseBalancer) ResolverError(err error) <span class="cov0" title="0">{
        b.resolverErr = err
        if b.subConns.Len() == 0 </span><span class="cov0" title="0">{
                b.state = connectivity.TransientFailure
        }</span>

        <span class="cov0" title="0">if b.state != connectivity.TransientFailure </span><span class="cov0" title="0">{
                // The picker will not change since the balancer does not currently
                // report an error.
                return
        }</span>
        <span class="cov0" title="0">b.regeneratePicker()
        b.cc.UpdateState(balancer.State{
                ConnectivityState: b.state,
                Picker:            b.picker,
        })</span>
}

func (b *baseBalancer) UpdateClientConnState(s balancer.ClientConnState) error <span class="cov8" title="1">{
        // TODO: handle s.ResolverState.ServiceConfig?
        if logger.V(2) </span><span class="cov0" title="0">{
                logger.Info("base.baseBalancer: got new ClientConn state: ", s)
        }</span>
        // Successful resolution; clear resolver error and ensure we return nil.
        <span class="cov8" title="1">b.resolverErr = nil
        // addrsSet is the set converted from addrs, it's used for quick lookup of an address.
        addrsSet := resolver.NewAddressMap()
        for _, a := range s.ResolverState.Addresses </span><span class="cov8" title="1">{
                addrsSet.Set(a, nil)
                if _, ok := b.subConns.Get(a); !ok </span><span class="cov8" title="1">{
                        // a is a new address (not existing in b.subConns).
                        sc, err := b.cc.NewSubConn([]resolver.Address{a}, balancer.NewSubConnOptions{HealthCheckEnabled: b.config.HealthCheck})
                        if err != nil </span><span class="cov0" title="0">{
                                logger.Warningf("base.baseBalancer: failed to create new SubConn: %v", err)
                                continue</span>
                        }
                        <span class="cov8" title="1">b.subConns.Set(a, sc)
                        b.scStates[sc] = connectivity.Idle
                        b.csEvltr.RecordTransition(connectivity.Shutdown, connectivity.Idle)
                        sc.Connect()</span>
                }
        }
        <span class="cov8" title="1">for _, a := range b.subConns.Keys() </span><span class="cov8" title="1">{
                sci, _ := b.subConns.Get(a)
                sc := sci.(balancer.SubConn)
                // a was removed by resolver.
                if _, ok := addrsSet.Get(a); !ok </span><span class="cov0" title="0">{
                        b.cc.RemoveSubConn(sc)
                        b.subConns.Delete(a)
                        // Keep the state of this sc in b.scStates until sc's state becomes Shutdown.
                        // The entry will be deleted in UpdateSubConnState.
                }</span>
        }
        // If resolver state contains no addresses, return an error so ClientConn
        // will trigger re-resolve. Also records this as an resolver error, so when
        // the overall state turns transient failure, the error message will have
        // the zero address information.
        <span class="cov8" title="1">if len(s.ResolverState.Addresses) == 0 </span><span class="cov0" title="0">{
                b.ResolverError(errors.New("produced zero addresses"))
                return balancer.ErrBadResolverState
        }</span>

        <span class="cov8" title="1">b.regeneratePicker()
        b.cc.UpdateState(balancer.State{ConnectivityState: b.state, Picker: b.picker})
        return nil</span>
}

// mergeErrors builds an error from the last connection error and the last
// resolver error.  Must only be called if b.state is TransientFailure.
func (b *baseBalancer) mergeErrors() error <span class="cov0" title="0">{
        // connErr must always be non-nil unless there are no SubConns, in which
        // case resolverErr must be non-nil.
        if b.connErr == nil </span><span class="cov0" title="0">{
                return fmt.Errorf("last resolver error: %v", b.resolverErr)
        }</span>
        <span class="cov0" title="0">if b.resolverErr == nil </span><span class="cov0" title="0">{
                return fmt.Errorf("last connection error: %v", b.connErr)
        }</span>
        <span class="cov0" title="0">return fmt.Errorf("last connection error: %v; last resolver error: %v", b.connErr, b.resolverErr)</span>
}

// regeneratePicker takes a snapshot of the balancer, and generates a picker
// from it. The picker is
//  - errPicker if the balancer is in TransientFailure,
//  - built by the pickerBuilder with all READY SubConns otherwise.
func (b *baseBalancer) regeneratePicker() <span class="cov8" title="1">{
        if b.state == connectivity.TransientFailure </span><span class="cov0" title="0">{
                b.picker = NewErrPicker(b.mergeErrors())
                return
        }</span>
        <span class="cov8" title="1">readySCs := make(map[balancer.SubConn]SubConnInfo)

        // Filter out all ready SCs from full subConn map.
        for _, addr := range b.subConns.Keys() </span><span class="cov8" title="1">{
                sci, _ := b.subConns.Get(addr)
                sc := sci.(balancer.SubConn)
                if st, ok := b.scStates[sc]; ok &amp;&amp; st == connectivity.Ready </span><span class="cov8" title="1">{
                        readySCs[sc] = SubConnInfo{Address: addr}
                }</span>
        }
        <span class="cov8" title="1">b.picker = b.pickerBuilder.Build(PickerBuildInfo{ReadySCs: readySCs})</span>
}

func (b *baseBalancer) UpdateSubConnState(sc balancer.SubConn, state balancer.SubConnState) <span class="cov8" title="1">{
        s := state.ConnectivityState
        if logger.V(2) </span><span class="cov0" title="0">{
                logger.Infof("base.baseBalancer: handle SubConn state change: %p, %v", sc, s)
        }</span>
        <span class="cov8" title="1">oldS, ok := b.scStates[sc]
        if !ok </span><span class="cov0" title="0">{
                if logger.V(2) </span><span class="cov0" title="0">{
                        logger.Infof("base.baseBalancer: got state changes for an unknown SubConn: %p, %v", sc, s)
                }</span>
                <span class="cov0" title="0">return</span>
        }
        <span class="cov8" title="1">if oldS == connectivity.TransientFailure &amp;&amp;
                (s == connectivity.Connecting || s == connectivity.Idle) </span><span class="cov0" title="0">{
                // Once a subconn enters TRANSIENT_FAILURE, ignore subsequent IDLE or
                // CONNECTING transitions to prevent the aggregated state from being
                // always CONNECTING when many backends exist but are all down.
                if s == connectivity.Idle </span><span class="cov0" title="0">{
                        sc.Connect()
                }</span>
                <span class="cov0" title="0">return</span>
        }
        <span class="cov8" title="1">b.scStates[sc] = s
        switch s </span>{
        case connectivity.Idle:<span class="cov0" title="0">
                sc.Connect()</span>
        case connectivity.Shutdown:<span class="cov0" title="0">
                // When an address was removed by resolver, b called RemoveSubConn but
                // kept the sc's state in scStates. Remove state for this sc here.
                delete(b.scStates, sc)</span>
        case connectivity.TransientFailure:<span class="cov0" title="0">
                // Save error to be reported via picker.
                b.connErr = state.ConnectionError</span>
        }

        <span class="cov8" title="1">b.state = b.csEvltr.RecordTransition(oldS, s)

        // Regenerate picker when one of the following happens:
        //  - this sc entered or left ready
        //  - the aggregated state of balancer is TransientFailure
        //    (may need to update error message)
        if (s == connectivity.Ready) != (oldS == connectivity.Ready) ||
                b.state == connectivity.TransientFailure </span><span class="cov8" title="1">{
                b.regeneratePicker()
        }</span>
        <span class="cov8" title="1">b.cc.UpdateState(balancer.State{ConnectivityState: b.state, Picker: b.picker})</span>
}

// Close is a nop because base balancer doesn't have internal state to clean up,
// and it doesn't need to call RemoveSubConn for the SubConns.
func (b *baseBalancer) Close() {<span class="cov0" title="0">
}</span>

// ExitIdle is a nop because the base balancer attempts to stay connected to
// all SubConns at all times.
func (b *baseBalancer) ExitIdle() {<span class="cov0" title="0">
}</span>

// NewErrPicker returns a Picker that always returns err on Pick().
func NewErrPicker(err error) balancer.Picker <span class="cov8" title="1">{
        return &amp;errPicker{err: err}
}</span>

// NewErrPickerV2 is temporarily defined for backward compatibility reasons.
//
// Deprecated: use NewErrPicker instead.
var NewErrPickerV2 = NewErrPicker

type errPicker struct {
        err error // Pick() always returns this err.
}

func (p *errPicker) Pick(info balancer.PickInfo) (balancer.PickResult, error) <span class="cov0" title="0">{
        return balancer.PickResult{}, p.err
}</span>
</pre>
		
		<pre class="file" id="file7" style="display: none">/*
 *
 * Copyright 2017 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package base defines a balancer base that can be used to build balancers with
// different picking algorithms.
//
// The base balancer creates a new SubConn for each resolved address. The
// provided picker will only be notified about READY SubConns.
//
// This package is the base of round_robin balancer, its purpose is to be used
// to build round_robin like balancers with complex picking algorithms.
// Balancers with more complicated logic should try to implement a balancer
// builder from scratch.
//
// All APIs in this package are experimental.
package base

import (
        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/resolver"
)

// PickerBuilder creates balancer.Picker.
type PickerBuilder interface {
        // Build returns a picker that will be used by gRPC to pick a SubConn.
        Build(info PickerBuildInfo) balancer.Picker
}

// PickerBuildInfo contains information needed by the picker builder to
// construct a picker.
type PickerBuildInfo struct {
        // ReadySCs is a map from all ready SubConns to the Addresses used to
        // create them.
        ReadySCs map[balancer.SubConn]SubConnInfo
}

// SubConnInfo contains information about a SubConn created by the base
// balancer.
type SubConnInfo struct {
        Address resolver.Address // the address used to create this SubConn
}

// Config contains the config info about the base balancer builder.
type Config struct {
        // HealthCheck indicates whether health checking should be enabled for this specific balancer.
        HealthCheck bool
}

// NewBalancerBuilder returns a base balancer builder configured by the provided config.
func NewBalancerBuilder(name string, pb PickerBuilder, config Config) balancer.Builder <span class="cov0" title="0">{
        return &amp;baseBuilder{
                name:          name,
                pickerBuilder: pb,
                config:        config,
        }
}</span>
</pre>
		
		<pre class="file" id="file8" style="display: none">/*
 *
 * Copyright 2022 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package balancer

import "google.golang.org/grpc/connectivity"

// ConnectivityStateEvaluator takes the connectivity states of multiple SubConns
// and returns one aggregated connectivity state.
//
// It's not thread safe.
type ConnectivityStateEvaluator struct {
        numReady            uint64 // Number of addrConns in ready state.
        numConnecting       uint64 // Number of addrConns in connecting state.
        numTransientFailure uint64 // Number of addrConns in transient failure state.
        numIdle             uint64 // Number of addrConns in idle state.
}

// RecordTransition records state change happening in subConn and based on that
// it evaluates what aggregated state should be.
//
//  - If at least one SubConn in Ready, the aggregated state is Ready;
//  - Else if at least one SubConn in Connecting, the aggregated state is Connecting;
//  - Else if at least one SubConn is Idle, the aggregated state is Idle;
//  - Else if at least one SubConn is TransientFailure (or there are no SubConns), the aggregated state is Transient Failure.
//
// Shutdown is not considered.
func (cse *ConnectivityStateEvaluator) RecordTransition(oldState, newState connectivity.State) connectivity.State <span class="cov8" title="1">{
        // Update counters.
        for idx, state := range []connectivity.State{oldState, newState} </span><span class="cov8" title="1">{
                updateVal := 2*uint64(idx) - 1 // -1 for oldState and +1 for new.
                switch state </span>{
                case connectivity.Ready:<span class="cov8" title="1">
                        cse.numReady += updateVal</span>
                case connectivity.Connecting:<span class="cov8" title="1">
                        cse.numConnecting += updateVal</span>
                case connectivity.TransientFailure:<span class="cov8" title="1">
                        cse.numTransientFailure += updateVal</span>
                case connectivity.Idle:<span class="cov8" title="1">
                        cse.numIdle += updateVal</span>
                }
        }

        // Evaluate.
        <span class="cov8" title="1">if cse.numReady &gt; 0 </span><span class="cov8" title="1">{
                return connectivity.Ready
        }</span>
        <span class="cov8" title="1">if cse.numConnecting &gt; 0 </span><span class="cov8" title="1">{
                return connectivity.Connecting
        }</span>
        <span class="cov8" title="1">if cse.numIdle &gt; 0 </span><span class="cov8" title="1">{
                return connectivity.Idle
        }</span>
        <span class="cov8" title="1">return connectivity.TransientFailure</span>
}
</pre>
		
		<pre class="file" id="file9" style="display: none">/*
 *
 * Copyright 2016 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package grpclb defines a grpclb balancer.
//
// To install grpclb balancer, import this package as:
//    import _ "google.golang.org/grpc/balancer/grpclb"
package grpclb

import (
        "context"
        "errors"
        "fmt"
        "sync"
        "time"

        "google.golang.org/grpc"
        "google.golang.org/grpc/balancer"
        grpclbstate "google.golang.org/grpc/balancer/grpclb/state"
        "google.golang.org/grpc/connectivity"
        "google.golang.org/grpc/credentials"
        "google.golang.org/grpc/grpclog"
        "google.golang.org/grpc/internal"
        "google.golang.org/grpc/internal/backoff"
        "google.golang.org/grpc/internal/resolver/dns"
        "google.golang.org/grpc/resolver"

        durationpb "github.com/golang/protobuf/ptypes/duration"
        lbpb "google.golang.org/grpc/balancer/grpclb/grpc_lb_v1"
)

const (
        lbTokenKey             = "lb-token"
        defaultFallbackTimeout = 10 * time.Second
        grpclbName             = "grpclb"
)

var errServerTerminatedConnection = errors.New("grpclb: failed to recv server list: server terminated connection")
var logger = grpclog.Component("grpclb")

func convertDuration(d *durationpb.Duration) time.Duration <span class="cov8" title="1">{
        if d == nil </span><span class="cov0" title="0">{
                return 0
        }</span>
        <span class="cov8" title="1">return time.Duration(d.Seconds)*time.Second + time.Duration(d.Nanos)*time.Nanosecond</span>
}

// Client API for LoadBalancer service.
// Mostly copied from generated pb.go file.
// To avoid circular dependency.
type loadBalancerClient struct {
        cc *grpc.ClientConn
}

func (c *loadBalancerClient) BalanceLoad(ctx context.Context, opts ...grpc.CallOption) (*balanceLoadClientStream, error) <span class="cov8" title="1">{
        desc := &amp;grpc.StreamDesc{
                StreamName:    "BalanceLoad",
                ServerStreams: true,
                ClientStreams: true,
        }
        stream, err := c.cc.NewStream(ctx, desc, "/grpc.lb.v1.LoadBalancer/BalanceLoad", opts...)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">x := &amp;balanceLoadClientStream{stream}
        return x, nil</span>
}

type balanceLoadClientStream struct {
        grpc.ClientStream
}

func (x *balanceLoadClientStream) Send(m *lbpb.LoadBalanceRequest) error <span class="cov8" title="1">{
        return x.ClientStream.SendMsg(m)
}</span>

func (x *balanceLoadClientStream) Recv() (*lbpb.LoadBalanceResponse, error) <span class="cov8" title="1">{
        m := new(lbpb.LoadBalanceResponse)
        if err := x.ClientStream.RecvMsg(m); err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return m, nil</span>
}

func init() <span class="cov8" title="1">{
        balancer.Register(newLBBuilder())
        dns.EnableSRVLookups = true
}</span>

// newLBBuilder creates a builder for grpclb.
func newLBBuilder() balancer.Builder <span class="cov8" title="1">{
        return newLBBuilderWithFallbackTimeout(defaultFallbackTimeout)
}</span>

// newLBBuilderWithFallbackTimeout creates a grpclb builder with the given
// fallbackTimeout. If no response is received from the remote balancer within
// fallbackTimeout, the backend addresses from the resolved address list will be
// used.
//
// Only call this function when a non-default fallback timeout is needed.
func newLBBuilderWithFallbackTimeout(fallbackTimeout time.Duration) balancer.Builder <span class="cov8" title="1">{
        return &amp;lbBuilder{
                fallbackTimeout: fallbackTimeout,
        }
}</span>

type lbBuilder struct {
        fallbackTimeout time.Duration
}

func (b *lbBuilder) Name() string <span class="cov8" title="1">{
        return grpclbName
}</span>

func (b *lbBuilder) Build(cc balancer.ClientConn, opt balancer.BuildOptions) balancer.Balancer <span class="cov8" title="1">{
        // This generates a manual resolver builder with a fixed scheme. This
        // scheme will be used to dial to remote LB, so we can send filtered
        // address updates to remote LB ClientConn using this manual resolver.
        r := &amp;lbManualResolver{scheme: "grpclb-internal", ccb: cc}

        lb := &amp;lbBalancer{
                cc:              newLBCacheClientConn(cc),
                dialTarget:      opt.Target.Endpoint,
                target:          opt.Target.Endpoint,
                opt:             opt,
                fallbackTimeout: b.fallbackTimeout,
                doneCh:          make(chan struct{}),

                manualResolver: r,
                subConns:       make(map[resolver.Address]balancer.SubConn),
                scStates:       make(map[balancer.SubConn]connectivity.State),
                picker:         &amp;errPicker{err: balancer.ErrNoSubConnAvailable},
                clientStats:    newRPCStats(),
                backoff:        backoff.DefaultExponential, // TODO: make backoff configurable.
        }

        var err error
        if opt.CredsBundle != nil </span><span class="cov0" title="0">{
                lb.grpclbClientConnCreds, err = opt.CredsBundle.NewWithMode(internal.CredsBundleModeBalancer)
                if err != nil </span><span class="cov0" title="0">{
                        logger.Warningf("lbBalancer: client connection creds NewWithMode failed: %v", err)
                }</span>
                <span class="cov0" title="0">lb.grpclbBackendCreds, err = opt.CredsBundle.NewWithMode(internal.CredsBundleModeBackendFromBalancer)
                if err != nil </span><span class="cov0" title="0">{
                        logger.Warningf("lbBalancer: backend creds NewWithMode failed: %v", err)
                }</span>
        }

        <span class="cov8" title="1">return lb</span>
}

type lbBalancer struct {
        cc         *lbCacheClientConn
        dialTarget string // user's dial target
        target     string // same as dialTarget unless overridden in service config
        opt        balancer.BuildOptions

        usePickFirst bool

        // grpclbClientConnCreds is the creds bundle to be used to connect to grpclb
        // servers. If it's nil, use the TransportCredentials from BuildOptions
        // instead.
        grpclbClientConnCreds credentials.Bundle
        // grpclbBackendCreds is the creds bundle to be used for addresses that are
        // returned by grpclb server. If it's nil, don't set anything when creating
        // SubConns.
        grpclbBackendCreds credentials.Bundle

        fallbackTimeout time.Duration
        doneCh          chan struct{}

        // manualResolver is used in the remote LB ClientConn inside grpclb. When
        // resolved address updates are received by grpclb, filtered updates will be
        // send to remote LB ClientConn through this resolver.
        manualResolver *lbManualResolver
        // The ClientConn to talk to the remote balancer.
        ccRemoteLB *remoteBalancerCCWrapper
        // backoff for calling remote balancer.
        backoff backoff.Strategy

        // Support client side load reporting. Each picker gets a reference to this,
        // and will update its content.
        clientStats *rpcStats

        mu sync.Mutex // guards everything following.
        // The full server list including drops, used to check if the newly received
        // serverList contains anything new. Each generate picker will also have
        // reference to this list to do the first layer pick.
        fullServerList []*lbpb.Server
        // Backend addresses. It's kept so the addresses are available when
        // switching between round_robin and pickfirst.
        backendAddrs []resolver.Address
        // All backends addresses, with metadata set to nil. This list contains all
        // backend addresses in the same order and with the same duplicates as in
        // serverlist. When generating picker, a SubConn slice with the same order
        // but with only READY SCs will be gerenated.
        backendAddrsWithoutMetadata []resolver.Address
        // Roundrobin functionalities.
        state    connectivity.State
        subConns map[resolver.Address]balancer.SubConn   // Used to new/remove SubConn.
        scStates map[balancer.SubConn]connectivity.State // Used to filter READY SubConns.
        picker   balancer.Picker
        // Support fallback to resolved backend addresses if there's no response
        // from remote balancer within fallbackTimeout.
        remoteBalancerConnected bool
        serverListReceived      bool
        inFallback              bool
        // resolvedBackendAddrs is resolvedAddrs minus remote balancers. It's set
        // when resolved address updates are received, and read in the goroutine
        // handling fallback.
        resolvedBackendAddrs []resolver.Address
        connErr              error // the last connection error
}

// regeneratePicker takes a snapshot of the balancer, and generates a picker from
// it. The picker
//  - always returns ErrTransientFailure if the balancer is in TransientFailure,
//  - does two layer roundrobin pick otherwise.
// Caller must hold lb.mu.
func (lb *lbBalancer) regeneratePicker(resetDrop bool) <span class="cov8" title="1">{
        if lb.state == connectivity.TransientFailure </span><span class="cov8" title="1">{
                lb.picker = &amp;errPicker{err: fmt.Errorf("all SubConns are in TransientFailure, last connection error: %v", lb.connErr)}
                return
        }</span>

        <span class="cov8" title="1">if lb.state == connectivity.Connecting </span><span class="cov8" title="1">{
                lb.picker = &amp;errPicker{err: balancer.ErrNoSubConnAvailable}
                return
        }</span>

        <span class="cov8" title="1">var readySCs []balancer.SubConn
        if lb.usePickFirst </span><span class="cov8" title="1">{
                for _, sc := range lb.subConns </span><span class="cov8" title="1">{
                        readySCs = append(readySCs, sc)
                        break</span>
                }
        } else<span class="cov8" title="1"> {
                for _, a := range lb.backendAddrsWithoutMetadata </span><span class="cov8" title="1">{
                        if sc, ok := lb.subConns[a]; ok </span><span class="cov8" title="1">{
                                if st, ok := lb.scStates[sc]; ok &amp;&amp; st == connectivity.Ready </span><span class="cov8" title="1">{
                                        readySCs = append(readySCs, sc)
                                }</span>
                        }
                }
        }

        <span class="cov8" title="1">if len(readySCs) &lt;= 0 </span><span class="cov0" title="0">{
                // If there's no ready SubConns, always re-pick. This is to avoid drops
                // unless at least one SubConn is ready. Otherwise we may drop more
                // often than want because of drops + re-picks(which become re-drops).
                //
                // This doesn't seem to be necessary after the connecting check above.
                // Kept for safety.
                lb.picker = &amp;errPicker{err: balancer.ErrNoSubConnAvailable}
                return
        }</span>
        <span class="cov8" title="1">if lb.inFallback </span><span class="cov8" title="1">{
                lb.picker = newRRPicker(readySCs)
                return
        }</span>
        <span class="cov8" title="1">if resetDrop </span><span class="cov8" title="1">{
                lb.picker = newLBPicker(lb.fullServerList, readySCs, lb.clientStats)
                return
        }</span>
        <span class="cov8" title="1">prevLBPicker, ok := lb.picker.(*lbPicker)
        if !ok </span><span class="cov8" title="1">{
                lb.picker = newLBPicker(lb.fullServerList, readySCs, lb.clientStats)
                return
        }</span>
        <span class="cov8" title="1">prevLBPicker.updateReadySCs(readySCs)</span>
}

// aggregateSubConnStats calculate the aggregated state of SubConns in
// lb.SubConns. These SubConns are subconns in use (when switching between
// fallback and grpclb). lb.scState contains states for all SubConns, including
// those in cache (SubConns are cached for 10 seconds after remove).
//
// The aggregated state is:
//  - If at least one SubConn in Ready, the aggregated state is Ready;
//  - Else if at least one SubConn in Connecting or IDLE, the aggregated state is Connecting;
//    - It's OK to consider IDLE as Connecting. SubConns never stay in IDLE,
//    they start to connect immediately. But there's a race between the overall
//    state is reported, and when the new SubConn state arrives. And SubConns
//    never go back to IDLE.
//  - Else the aggregated state is TransientFailure.
func (lb *lbBalancer) aggregateSubConnStates() connectivity.State <span class="cov8" title="1">{
        var numConnecting uint64

        for _, sc := range lb.subConns </span><span class="cov8" title="1">{
                if state, ok := lb.scStates[sc]; ok </span><span class="cov8" title="1">{
                        switch state </span>{
                        case connectivity.Ready:<span class="cov8" title="1">
                                return connectivity.Ready</span>
                        case connectivity.Connecting, connectivity.Idle:<span class="cov8" title="1">
                                numConnecting++</span>
                        }
                }
        }
        <span class="cov8" title="1">if numConnecting &gt; 0 </span><span class="cov8" title="1">{
                return connectivity.Connecting
        }</span>
        <span class="cov8" title="1">return connectivity.TransientFailure</span>
}

func (lb *lbBalancer) UpdateSubConnState(sc balancer.SubConn, scs balancer.SubConnState) <span class="cov8" title="1">{
        s := scs.ConnectivityState
        if logger.V(2) </span><span class="cov0" title="0">{
                logger.Infof("lbBalancer: handle SubConn state change: %p, %v", sc, s)
        }</span>
        <span class="cov8" title="1">lb.mu.Lock()
        defer lb.mu.Unlock()

        oldS, ok := lb.scStates[sc]
        if !ok </span><span class="cov0" title="0">{
                if logger.V(2) </span><span class="cov0" title="0">{
                        logger.Infof("lbBalancer: got state changes for an unknown SubConn: %p, %v", sc, s)
                }</span>
                <span class="cov0" title="0">return</span>
        }
        <span class="cov8" title="1">lb.scStates[sc] = s
        switch s </span>{
        case connectivity.Idle:<span class="cov8" title="1">
                sc.Connect()</span>
        case connectivity.Shutdown:<span class="cov8" title="1">
                // When an address was removed by resolver, b called RemoveSubConn but
                // kept the sc's state in scStates. Remove state for this sc here.
                delete(lb.scStates, sc)</span>
        case connectivity.TransientFailure:<span class="cov8" title="1">
                lb.connErr = scs.ConnectionError</span>
        }
        // Force regenerate picker if
        //  - this sc became ready from not-ready
        //  - this sc became not-ready from ready
        <span class="cov8" title="1">lb.updateStateAndPicker((oldS == connectivity.Ready) != (s == connectivity.Ready), false)

        // Enter fallback when the aggregated state is not Ready and the connection
        // to remote balancer is lost.
        if lb.state != connectivity.Ready </span><span class="cov8" title="1">{
                if !lb.inFallback &amp;&amp; !lb.remoteBalancerConnected </span><span class="cov8" title="1">{
                        // Enter fallback.
                        lb.refreshSubConns(lb.resolvedBackendAddrs, true, lb.usePickFirst)
                }</span>
        }
}

// updateStateAndPicker re-calculate the aggregated state, and regenerate picker
// if overall state is changed.
//
// If forceRegeneratePicker is true, picker will be regenerated.
func (lb *lbBalancer) updateStateAndPicker(forceRegeneratePicker bool, resetDrop bool) <span class="cov8" title="1">{
        oldAggrState := lb.state
        lb.state = lb.aggregateSubConnStates()
        // Regenerate picker when one of the following happens:
        //  - caller wants to regenerate
        //  - the aggregated state changed
        if forceRegeneratePicker || (lb.state != oldAggrState) </span><span class="cov8" title="1">{
                lb.regeneratePicker(resetDrop)
        }</span>

        <span class="cov8" title="1">lb.cc.UpdateState(balancer.State{ConnectivityState: lb.state, Picker: lb.picker})</span>
}

// fallbackToBackendsAfter blocks for fallbackTimeout and falls back to use
// resolved backends (backends received from resolver, not from remote balancer)
// if no connection to remote balancers was successful.
func (lb *lbBalancer) fallbackToBackendsAfter(fallbackTimeout time.Duration) <span class="cov8" title="1">{
        timer := time.NewTimer(fallbackTimeout)
        defer timer.Stop()
        select </span>{
        case &lt;-timer.C:<span class="cov8" title="1"></span>
        case &lt;-lb.doneCh:<span class="cov8" title="1">
                return</span>
        }
        <span class="cov8" title="1">lb.mu.Lock()
        if lb.inFallback || lb.serverListReceived </span><span class="cov0" title="0">{
                lb.mu.Unlock()
                return
        }</span>
        // Enter fallback.
        <span class="cov8" title="1">lb.refreshSubConns(lb.resolvedBackendAddrs, true, lb.usePickFirst)
        lb.mu.Unlock()</span>
}

func (lb *lbBalancer) handleServiceConfig(gc *grpclbServiceConfig) <span class="cov8" title="1">{
        lb.mu.Lock()
        defer lb.mu.Unlock()

        // grpclb uses the user's dial target to populate the `Name` field of the
        // `InitialLoadBalanceRequest` message sent to the remote balancer. But when
        // grpclb is used a child policy in the context of RLS, we want the `Name`
        // field to be populated with the value received from the RLS server. To
        // support this use case, an optional "target_name" field has been added to
        // the grpclb LB policy's config.  If specified, it overrides the name of
        // the target to be sent to the remote balancer; if not, the target to be
        // sent to the balancer will continue to be obtained from the target URI
        // passed to the gRPC client channel. Whenever that target to be sent to the
        // balancer is updated, we need to restart the stream to the balancer as
        // this target is sent in the first message on the stream.
        if gc != nil </span><span class="cov8" title="1">{
                target := lb.dialTarget
                if gc.ServiceName != "" </span><span class="cov8" title="1">{
                        target = gc.ServiceName
                }</span>
                <span class="cov8" title="1">if target != lb.target </span><span class="cov8" title="1">{
                        lb.target = target
                        if lb.ccRemoteLB != nil </span><span class="cov8" title="1">{
                                lb.ccRemoteLB.cancelRemoteBalancerCall()
                        }</span>
                }
        }

        <span class="cov8" title="1">newUsePickFirst := childIsPickFirst(gc)
        if lb.usePickFirst == newUsePickFirst </span><span class="cov8" title="1">{
                return
        }</span>
        <span class="cov8" title="1">if logger.V(2) </span><span class="cov0" title="0">{
                logger.Infof("lbBalancer: switching mode, new usePickFirst: %+v", newUsePickFirst)
        }</span>
        <span class="cov8" title="1">lb.refreshSubConns(lb.backendAddrs, lb.inFallback, newUsePickFirst)</span>
}

func (lb *lbBalancer) ResolverError(error) {<span class="cov0" title="0">
        // Ignore resolver errors.  GRPCLB is not selected unless the resolver
        // works at least once.
}</span>

func (lb *lbBalancer) UpdateClientConnState(ccs balancer.ClientConnState) error <span class="cov8" title="1">{
        if logger.V(2) </span><span class="cov0" title="0">{
                logger.Infof("lbBalancer: UpdateClientConnState: %+v", ccs)
        }</span>
        <span class="cov8" title="1">gc, _ := ccs.BalancerConfig.(*grpclbServiceConfig)
        lb.handleServiceConfig(gc)

        addrs := ccs.ResolverState.Addresses

        var remoteBalancerAddrs, backendAddrs []resolver.Address
        for _, a := range addrs </span><span class="cov8" title="1">{
                if a.Type == resolver.GRPCLB </span><span class="cov8" title="1">{
                        a.Type = resolver.Backend
                        remoteBalancerAddrs = append(remoteBalancerAddrs, a)
                }</span> else<span class="cov8" title="1"> {
                        backendAddrs = append(backendAddrs, a)
                }</span>
        }
        <span class="cov8" title="1">if sd := grpclbstate.Get(ccs.ResolverState); sd != nil </span><span class="cov8" title="1">{
                // Override any balancer addresses provided via
                // ccs.ResolverState.Addresses.
                remoteBalancerAddrs = sd.BalancerAddresses
        }</span>

        <span class="cov8" title="1">if len(backendAddrs)+len(remoteBalancerAddrs) == 0 </span><span class="cov0" title="0">{
                // There should be at least one address, either grpclb server or
                // fallback. Empty address is not valid.
                return balancer.ErrBadResolverState
        }</span>

        <span class="cov8" title="1">if len(remoteBalancerAddrs) == 0 </span><span class="cov8" title="1">{
                if lb.ccRemoteLB != nil </span><span class="cov8" title="1">{
                        lb.ccRemoteLB.close()
                        lb.ccRemoteLB = nil
                }</span>
        } else<span class="cov8" title="1"> if lb.ccRemoteLB == nil </span><span class="cov8" title="1">{
                // First time receiving resolved addresses, create a cc to remote
                // balancers.
                lb.newRemoteBalancerCCWrapper()
                // Start the fallback goroutine.
                go lb.fallbackToBackendsAfter(lb.fallbackTimeout)
        }</span>

        <span class="cov8" title="1">if lb.ccRemoteLB != nil </span><span class="cov8" title="1">{
                // cc to remote balancers uses lb.manualResolver. Send the updated remote
                // balancer addresses to it through manualResolver.
                lb.manualResolver.UpdateState(resolver.State{Addresses: remoteBalancerAddrs})
        }</span>

        <span class="cov8" title="1">lb.mu.Lock()
        lb.resolvedBackendAddrs = backendAddrs
        if len(remoteBalancerAddrs) == 0 || lb.inFallback </span><span class="cov8" title="1">{
                // If there's no remote balancer address in ClientConn update, grpclb
                // enters fallback mode immediately.
                //
                // If a new update is received while grpclb is in fallback, update the
                // list of backends being used to the new fallback backends.
                lb.refreshSubConns(lb.resolvedBackendAddrs, true, lb.usePickFirst)
        }</span>
        <span class="cov8" title="1">lb.mu.Unlock()
        return nil</span>
}

func (lb *lbBalancer) Close() <span class="cov8" title="1">{
        select </span>{
        case &lt;-lb.doneCh:<span class="cov0" title="0">
                return</span>
        default:<span class="cov8" title="1"></span>
        }
        <span class="cov8" title="1">close(lb.doneCh)
        if lb.ccRemoteLB != nil </span><span class="cov8" title="1">{
                lb.ccRemoteLB.close()
        }</span>
        <span class="cov8" title="1">lb.cc.close()</span>
}

func (lb *lbBalancer) ExitIdle() {<span class="cov0" title="0">}</span>
</pre>
		
		<pre class="file" id="file10" style="display: none">/*
 *
 * Copyright 2019 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package grpclb

import (
        "encoding/json"

        "google.golang.org/grpc"
        "google.golang.org/grpc/balancer/roundrobin"
        "google.golang.org/grpc/serviceconfig"
)

const (
        roundRobinName = roundrobin.Name
        pickFirstName  = grpc.PickFirstBalancerName
)

type grpclbServiceConfig struct {
        serviceconfig.LoadBalancingConfig
        ChildPolicy *[]map[string]json.RawMessage
        ServiceName string
}

func (b *lbBuilder) ParseConfig(lbConfig json.RawMessage) (serviceconfig.LoadBalancingConfig, error) <span class="cov8" title="1">{
        ret := &amp;grpclbServiceConfig{}
        if err := json.Unmarshal(lbConfig, ret); err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return ret, nil</span>
}

func childIsPickFirst(sc *grpclbServiceConfig) bool <span class="cov8" title="1">{
        if sc == nil </span><span class="cov8" title="1">{
                return false
        }</span>
        <span class="cov8" title="1">childConfigs := sc.ChildPolicy
        if childConfigs == nil </span><span class="cov8" title="1">{
                return false
        }</span>
        <span class="cov8" title="1">for _, childC := range *childConfigs </span><span class="cov8" title="1">{
                // If round_robin exists before pick_first, return false
                if _, ok := childC[roundRobinName]; ok </span><span class="cov8" title="1">{
                        return false
                }</span>
                // If pick_first is before round_robin, return true
                <span class="cov8" title="1">if _, ok := childC[pickFirstName]; ok </span><span class="cov8" title="1">{
                        return true
                }</span>
        }
        <span class="cov0" title="0">return false</span>
}
</pre>
		
		<pre class="file" id="file11" style="display: none">/*
 *
 * Copyright 2017 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package grpclb

import (
        "sync"
        "sync/atomic"

        "google.golang.org/grpc/balancer"
        lbpb "google.golang.org/grpc/balancer/grpclb/grpc_lb_v1"
        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/internal/grpcrand"
        "google.golang.org/grpc/status"
)

// rpcStats is same as lbpb.ClientStats, except that numCallsDropped is a map
// instead of a slice.
type rpcStats struct {
        // Only access the following fields atomically.
        numCallsStarted                        int64
        numCallsFinished                       int64
        numCallsFinishedWithClientFailedToSend int64
        numCallsFinishedKnownReceived          int64

        mu sync.Mutex
        // map load_balance_token -&gt; num_calls_dropped
        numCallsDropped map[string]int64
}

func newRPCStats() *rpcStats <span class="cov8" title="1">{
        return &amp;rpcStats{
                numCallsDropped: make(map[string]int64),
        }
}</span>

func isZeroStats(stats *lbpb.ClientStats) bool <span class="cov8" title="1">{
        return len(stats.CallsFinishedWithDrop) == 0 &amp;&amp;
                stats.NumCallsStarted == 0 &amp;&amp;
                stats.NumCallsFinished == 0 &amp;&amp;
                stats.NumCallsFinishedWithClientFailedToSend == 0 &amp;&amp;
                stats.NumCallsFinishedKnownReceived == 0
}</span>

// toClientStats converts rpcStats to lbpb.ClientStats, and clears rpcStats.
func (s *rpcStats) toClientStats() *lbpb.ClientStats <span class="cov8" title="1">{
        stats := &amp;lbpb.ClientStats{
                NumCallsStarted:                        atomic.SwapInt64(&amp;s.numCallsStarted, 0),
                NumCallsFinished:                       atomic.SwapInt64(&amp;s.numCallsFinished, 0),
                NumCallsFinishedWithClientFailedToSend: atomic.SwapInt64(&amp;s.numCallsFinishedWithClientFailedToSend, 0),
                NumCallsFinishedKnownReceived:          atomic.SwapInt64(&amp;s.numCallsFinishedKnownReceived, 0),
        }
        s.mu.Lock()
        dropped := s.numCallsDropped
        s.numCallsDropped = make(map[string]int64)
        s.mu.Unlock()
        for token, count := range dropped </span><span class="cov8" title="1">{
                stats.CallsFinishedWithDrop = append(stats.CallsFinishedWithDrop, &amp;lbpb.ClientStatsPerToken{
                        LoadBalanceToken: token,
                        NumCalls:         count,
                })
        }</span>
        <span class="cov8" title="1">return stats</span>
}

func (s *rpcStats) drop(token string) <span class="cov8" title="1">{
        atomic.AddInt64(&amp;s.numCallsStarted, 1)
        s.mu.Lock()
        s.numCallsDropped[token]++
        s.mu.Unlock()
        atomic.AddInt64(&amp;s.numCallsFinished, 1)
}</span>

func (s *rpcStats) failedToSend() <span class="cov8" title="1">{
        atomic.AddInt64(&amp;s.numCallsStarted, 1)
        atomic.AddInt64(&amp;s.numCallsFinishedWithClientFailedToSend, 1)
        atomic.AddInt64(&amp;s.numCallsFinished, 1)
}</span>

func (s *rpcStats) knownReceived() <span class="cov8" title="1">{
        atomic.AddInt64(&amp;s.numCallsStarted, 1)
        atomic.AddInt64(&amp;s.numCallsFinishedKnownReceived, 1)
        atomic.AddInt64(&amp;s.numCallsFinished, 1)
}</span>

type errPicker struct {
        // Pick always returns this err.
        err error
}

func (p *errPicker) Pick(balancer.PickInfo) (balancer.PickResult, error) <span class="cov8" title="1">{
        return balancer.PickResult{}, p.err
}</span>

// rrPicker does roundrobin on subConns. It's typically used when there's no
// response from remote balancer, and grpclb falls back to the resolved
// backends.
//
// It guaranteed that len(subConns) &gt; 0.
type rrPicker struct {
        mu           sync.Mutex
        subConns     []balancer.SubConn // The subConns that were READY when taking the snapshot.
        subConnsNext int
}

func newRRPicker(readySCs []balancer.SubConn) *rrPicker <span class="cov8" title="1">{
        return &amp;rrPicker{
                subConns:     readySCs,
                subConnsNext: grpcrand.Intn(len(readySCs)),
        }
}</span>

func (p *rrPicker) Pick(balancer.PickInfo) (balancer.PickResult, error) <span class="cov8" title="1">{
        p.mu.Lock()
        defer p.mu.Unlock()
        sc := p.subConns[p.subConnsNext]
        p.subConnsNext = (p.subConnsNext + 1) % len(p.subConns)
        return balancer.PickResult{SubConn: sc}, nil
}</span>

// lbPicker does two layers of picks:
//
// First layer: roundrobin on all servers in serverList, including drops and backends.
// - If it picks a drop, the RPC will fail as being dropped.
// - If it picks a backend, do a second layer pick to pick the real backend.
//
// Second layer: roundrobin on all READY backends.
//
// It's guaranteed that len(serverList) &gt; 0.
type lbPicker struct {
        mu             sync.Mutex
        serverList     []*lbpb.Server
        serverListNext int
        subConns       []balancer.SubConn // The subConns that were READY when taking the snapshot.
        subConnsNext   int

        stats *rpcStats
}

func newLBPicker(serverList []*lbpb.Server, readySCs []balancer.SubConn, stats *rpcStats) *lbPicker <span class="cov8" title="1">{
        return &amp;lbPicker{
                serverList:   serverList,
                subConns:     readySCs,
                subConnsNext: grpcrand.Intn(len(readySCs)),
                stats:        stats,
        }
}</span>

func (p *lbPicker) Pick(balancer.PickInfo) (balancer.PickResult, error) <span class="cov8" title="1">{
        p.mu.Lock()
        defer p.mu.Unlock()

        // Layer one roundrobin on serverList.
        s := p.serverList[p.serverListNext]
        p.serverListNext = (p.serverListNext + 1) % len(p.serverList)

        // If it's a drop, return an error and fail the RPC.
        if s.Drop </span><span class="cov8" title="1">{
                p.stats.drop(s.LoadBalanceToken)
                return balancer.PickResult{}, status.Errorf(codes.Unavailable, "request dropped by grpclb")
        }</span>

        // If not a drop but there's no ready subConns.
        <span class="cov8" title="1">if len(p.subConns) &lt;= 0 </span><span class="cov0" title="0">{
                return balancer.PickResult{}, balancer.ErrNoSubConnAvailable
        }</span>

        // Return the next ready subConn in the list, also collect rpc stats.
        <span class="cov8" title="1">sc := p.subConns[p.subConnsNext]
        p.subConnsNext = (p.subConnsNext + 1) % len(p.subConns)
        done := func(info balancer.DoneInfo) </span><span class="cov8" title="1">{
                if !info.BytesSent </span><span class="cov8" title="1">{
                        p.stats.failedToSend()
                }</span> else<span class="cov8" title="1"> if info.BytesReceived </span><span class="cov8" title="1">{
                        p.stats.knownReceived()
                }</span>
        }
        <span class="cov8" title="1">return balancer.PickResult{SubConn: sc, Done: done}, nil</span>
}

func (p *lbPicker) updateReadySCs(readySCs []balancer.SubConn) <span class="cov8" title="1">{
        p.mu.Lock()
        defer p.mu.Unlock()

        p.subConns = readySCs
        p.subConnsNext = p.subConnsNext % len(readySCs)
}</span>
</pre>
		
		<pre class="file" id="file12" style="display: none">/*
 *
 * Copyright 2017 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package grpclb

import (
        "context"
        "fmt"
        "io"
        "net"
        "sync"
        "time"

        "github.com/golang/protobuf/proto"
        timestamppb "github.com/golang/protobuf/ptypes/timestamp"
        "github.com/google/go-cmp/cmp"
        "google.golang.org/grpc"
        "google.golang.org/grpc/balancer"
        lbpb "google.golang.org/grpc/balancer/grpclb/grpc_lb_v1"
        "google.golang.org/grpc/connectivity"
        "google.golang.org/grpc/credentials/insecure"
        "google.golang.org/grpc/internal/backoff"
        imetadata "google.golang.org/grpc/internal/metadata"
        "google.golang.org/grpc/keepalive"
        "google.golang.org/grpc/metadata"
        "google.golang.org/grpc/resolver"
)

// processServerList updates balancer's internal state, create/remove SubConns
// and regenerates picker using the received serverList.
func (lb *lbBalancer) processServerList(l *lbpb.ServerList) <span class="cov8" title="1">{
        if logger.V(2) </span><span class="cov0" title="0">{
                logger.Infof("lbBalancer: processing server list: %+v", l)
        }</span>
        <span class="cov8" title="1">lb.mu.Lock()
        defer lb.mu.Unlock()

        // Set serverListReceived to true so fallback will not take effect if it has
        // not hit timeout.
        lb.serverListReceived = true

        // If the new server list == old server list, do nothing.
        if cmp.Equal(lb.fullServerList, l.Servers, cmp.Comparer(proto.Equal)) </span><span class="cov8" title="1">{
                if logger.V(2) </span><span class="cov0" title="0">{
                        logger.Infof("lbBalancer: new serverlist same as the previous one, ignoring")
                }</span>
                <span class="cov8" title="1">return</span>
        }
        <span class="cov8" title="1">lb.fullServerList = l.Servers

        var backendAddrs []resolver.Address
        for i, s := range l.Servers </span><span class="cov8" title="1">{
                if s.Drop </span><span class="cov8" title="1">{
                        continue</span>
                }

                <span class="cov8" title="1">md := metadata.Pairs(lbTokenKey, s.LoadBalanceToken)
                ip := net.IP(s.IpAddress)
                ipStr := ip.String()
                if ip.To4() == nil </span><span class="cov0" title="0">{
                        // Add square brackets to ipv6 addresses, otherwise net.Dial() and
                        // net.SplitHostPort() will return too many colons error.
                        ipStr = fmt.Sprintf("[%s]", ipStr)
                }</span>
                <span class="cov8" title="1">addr := imetadata.Set(resolver.Address{Addr: fmt.Sprintf("%s:%d", ipStr, s.Port)}, md)
                if logger.V(2) </span><span class="cov0" title="0">{
                        logger.Infof("lbBalancer: server list entry[%d]: ipStr:|%s|, port:|%d|, load balancer token:|%v|",
                                i, ipStr, s.Port, s.LoadBalanceToken)
                }</span>
                <span class="cov8" title="1">backendAddrs = append(backendAddrs, addr)</span>
        }

        // Call refreshSubConns to create/remove SubConns.  If we are in fallback,
        // this is also exiting fallback.
        <span class="cov8" title="1">lb.refreshSubConns(backendAddrs, false, lb.usePickFirst)</span>
}

// refreshSubConns creates/removes SubConns with backendAddrs, and refreshes
// balancer state and picker.
//
// Caller must hold lb.mu.
func (lb *lbBalancer) refreshSubConns(backendAddrs []resolver.Address, fallback bool, pickFirst bool) <span class="cov8" title="1">{
        opts := balancer.NewSubConnOptions{}
        if !fallback </span><span class="cov8" title="1">{
                opts.CredsBundle = lb.grpclbBackendCreds
        }</span>

        <span class="cov8" title="1">lb.backendAddrs = backendAddrs
        lb.backendAddrsWithoutMetadata = nil

        fallbackModeChanged := lb.inFallback != fallback
        lb.inFallback = fallback
        if fallbackModeChanged &amp;&amp; lb.inFallback </span><span class="cov8" title="1">{
                // Clear previous received list when entering fallback, so if the server
                // comes back and sends the same list again, the new addresses will be
                // used.
                lb.fullServerList = nil
        }</span>

        <span class="cov8" title="1">balancingPolicyChanged := lb.usePickFirst != pickFirst
        oldUsePickFirst := lb.usePickFirst
        lb.usePickFirst = pickFirst

        if fallbackModeChanged || balancingPolicyChanged </span><span class="cov8" title="1">{
                // Remove all SubConns when switching balancing policy or switching
                // fallback mode.
                //
                // For fallback mode switching with pickfirst, we want to recreate the
                // SubConn because the creds could be different.
                for a, sc := range lb.subConns </span><span class="cov8" title="1">{
                        if oldUsePickFirst </span><span class="cov8" title="1">{
                                // If old SubConn were created for pickfirst, bypass cache and
                                // remove directly.
                                lb.cc.cc.RemoveSubConn(sc)
                        }</span> else<span class="cov8" title="1"> {
                                lb.cc.RemoveSubConn(sc)
                        }</span>
                        <span class="cov8" title="1">delete(lb.subConns, a)</span>
                }
        }

        <span class="cov8" title="1">if lb.usePickFirst </span><span class="cov8" title="1">{
                var (
                        scKey resolver.Address
                        sc    balancer.SubConn
                )
                for scKey, sc = range lb.subConns </span><span class="cov8" title="1">{
                        break</span>
                }
                <span class="cov8" title="1">if sc != nil </span><span class="cov8" title="1">{
                        if len(backendAddrs) == 0 </span><span class="cov8" title="1">{
                                lb.cc.cc.RemoveSubConn(sc)
                                delete(lb.subConns, scKey)
                                return
                        }</span>
                        <span class="cov8" title="1">lb.cc.cc.UpdateAddresses(sc, backendAddrs)
                        sc.Connect()
                        return</span>
                }
                // This bypasses the cc wrapper with SubConn cache.
                <span class="cov8" title="1">sc, err := lb.cc.cc.NewSubConn(backendAddrs, opts)
                if err != nil </span><span class="cov8" title="1">{
                        logger.Warningf("grpclb: failed to create new SubConn: %v", err)
                        return
                }</span>
                <span class="cov8" title="1">sc.Connect()
                lb.subConns[backendAddrs[0]] = sc
                lb.scStates[sc] = connectivity.Idle
                return</span>
        }

        // addrsSet is the set converted from backendAddrsWithoutMetadata, it's used to quick
        // lookup for an address.
        <span class="cov8" title="1">addrsSet := make(map[resolver.Address]struct{})
        // Create new SubConns.
        for _, addr := range backendAddrs </span><span class="cov8" title="1">{
                addrWithoutAttrs := addr
                addrWithoutAttrs.Attributes = nil
                addrsSet[addrWithoutAttrs] = struct{}{}
                lb.backendAddrsWithoutMetadata = append(lb.backendAddrsWithoutMetadata, addrWithoutAttrs)

                if _, ok := lb.subConns[addrWithoutAttrs]; !ok </span><span class="cov8" title="1">{
                        // Use addrWithMD to create the SubConn.
                        sc, err := lb.cc.NewSubConn([]resolver.Address{addr}, opts)
                        if err != nil </span><span class="cov0" title="0">{
                                logger.Warningf("grpclb: failed to create new SubConn: %v", err)
                                continue</span>
                        }
                        <span class="cov8" title="1">lb.subConns[addrWithoutAttrs] = sc // Use the addr without MD as key for the map.
                        if _, ok := lb.scStates[sc]; !ok </span><span class="cov8" title="1">{
                                // Only set state of new sc to IDLE. The state could already be
                                // READY for cached SubConns.
                                lb.scStates[sc] = connectivity.Idle
                        }</span>
                        <span class="cov8" title="1">sc.Connect()</span>
                }
        }

        <span class="cov8" title="1">for a, sc := range lb.subConns </span><span class="cov8" title="1">{
                // a was removed by resolver.
                if _, ok := addrsSet[a]; !ok </span><span class="cov8" title="1">{
                        lb.cc.RemoveSubConn(sc)
                        delete(lb.subConns, a)
                        // Keep the state of this sc in b.scStates until sc's state becomes Shutdown.
                        // The entry will be deleted in UpdateSubConnState.
                }</span>
        }

        // Regenerate and update picker after refreshing subconns because with
        // cache, even if SubConn was newed/removed, there might be no state
        // changes (the subconn will be kept in cache, not actually
        // newed/removed).
        <span class="cov8" title="1">lb.updateStateAndPicker(true, true)</span>
}

type remoteBalancerCCWrapper struct {
        cc      *grpc.ClientConn
        lb      *lbBalancer
        backoff backoff.Strategy
        done    chan struct{}

        streamMu     sync.Mutex
        streamCancel func()

        // waitgroup to wait for all goroutines to exit.
        wg sync.WaitGroup
}

func (lb *lbBalancer) newRemoteBalancerCCWrapper() <span class="cov8" title="1">{
        var dopts []grpc.DialOption
        if creds := lb.opt.DialCreds; creds != nil </span><span class="cov8" title="1">{
                dopts = append(dopts, grpc.WithTransportCredentials(creds))
        }</span> else<span class="cov0" title="0"> if bundle := lb.grpclbClientConnCreds; bundle != nil </span><span class="cov0" title="0">{
                dopts = append(dopts, grpc.WithCredentialsBundle(bundle))
        }</span> else<span class="cov0" title="0"> {
                dopts = append(dopts, grpc.WithTransportCredentials(insecure.NewCredentials()))
        }</span>
        <span class="cov8" title="1">if lb.opt.Dialer != nil </span><span class="cov8" title="1">{
                dopts = append(dopts, grpc.WithContextDialer(lb.opt.Dialer))
        }</span>
        <span class="cov8" title="1">if lb.opt.CustomUserAgent != "" </span><span class="cov8" title="1">{
                dopts = append(dopts, grpc.WithUserAgent(lb.opt.CustomUserAgent))
        }</span>
        // Explicitly set pickfirst as the balancer.
        <span class="cov8" title="1">dopts = append(dopts, grpc.WithDefaultServiceConfig(`{"loadBalancingPolicy":"pick_first"}`))
        dopts = append(dopts, grpc.WithResolvers(lb.manualResolver))
        dopts = append(dopts, grpc.WithChannelzParentID(lb.opt.ChannelzParentID))

        // Enable Keepalive for grpclb client.
        dopts = append(dopts, grpc.WithKeepaliveParams(keepalive.ClientParameters{
                Time:                20 * time.Second,
                Timeout:             10 * time.Second,
                PermitWithoutStream: true,
        }))

        // The dial target is not important.
        //
        // The grpclb server addresses will set field ServerName, and creds will
        // receive ServerName as authority.
        cc, err := grpc.DialContext(context.Background(), lb.manualResolver.Scheme()+":///grpclb.subClientConn", dopts...)
        if err != nil </span><span class="cov0" title="0">{
                logger.Fatalf("failed to dial: %v", err)
        }</span>
        <span class="cov8" title="1">ccw := &amp;remoteBalancerCCWrapper{
                cc:      cc,
                lb:      lb,
                backoff: lb.backoff,
                done:    make(chan struct{}),
        }
        lb.ccRemoteLB = ccw
        ccw.wg.Add(1)
        go ccw.watchRemoteBalancer()</span>
}

// close closed the ClientConn to remote balancer, and waits until all
// goroutines to finish.
func (ccw *remoteBalancerCCWrapper) close() <span class="cov8" title="1">{
        close(ccw.done)
        ccw.cc.Close()
        ccw.wg.Wait()
}</span>

func (ccw *remoteBalancerCCWrapper) readServerList(s *balanceLoadClientStream) error <span class="cov8" title="1">{
        for </span><span class="cov8" title="1">{
                reply, err := s.Recv()
                if err != nil </span><span class="cov8" title="1">{
                        if err == io.EOF </span><span class="cov0" title="0">{
                                return errServerTerminatedConnection
                        }</span>
                        <span class="cov8" title="1">return fmt.Errorf("grpclb: failed to recv server list: %v", err)</span>
                }
                <span class="cov8" title="1">if serverList := reply.GetServerList(); serverList != nil </span><span class="cov8" title="1">{
                        ccw.lb.processServerList(serverList)
                }</span>
                <span class="cov8" title="1">if reply.GetFallbackResponse() != nil </span><span class="cov8" title="1">{
                        // Eagerly enter fallback
                        ccw.lb.mu.Lock()
                        ccw.lb.refreshSubConns(ccw.lb.resolvedBackendAddrs, true, ccw.lb.usePickFirst)
                        ccw.lb.mu.Unlock()
                }</span>
        }
}

func (ccw *remoteBalancerCCWrapper) sendLoadReport(s *balanceLoadClientStream, interval time.Duration) <span class="cov8" title="1">{
        ticker := time.NewTicker(interval)
        defer ticker.Stop()
        lastZero := false
        for </span><span class="cov8" title="1">{
                select </span>{
                case &lt;-ticker.C:<span class="cov8" title="1"></span>
                case &lt;-s.Context().Done():<span class="cov8" title="1">
                        return</span>
                }
                <span class="cov8" title="1">stats := ccw.lb.clientStats.toClientStats()
                zero := isZeroStats(stats)
                if zero &amp;&amp; lastZero </span><span class="cov8" title="1">{
                        // Quash redundant empty load reports.
                        continue</span>
                }
                <span class="cov8" title="1">lastZero = zero
                t := time.Now()
                stats.Timestamp = &amp;timestamppb.Timestamp{
                        Seconds: t.Unix(),
                        Nanos:   int32(t.Nanosecond()),
                }
                if err := s.Send(&amp;lbpb.LoadBalanceRequest{
                        LoadBalanceRequestType: &amp;lbpb.LoadBalanceRequest_ClientStats{
                                ClientStats: stats,
                        },
                }); err != nil </span><span class="cov0" title="0">{
                        return
                }</span>
        }
}

func (ccw *remoteBalancerCCWrapper) callRemoteBalancer(ctx context.Context) (backoff bool, _ error) <span class="cov8" title="1">{
        lbClient := &amp;loadBalancerClient{cc: ccw.cc}
        stream, err := lbClient.BalanceLoad(ctx, grpc.WaitForReady(true))
        if err != nil </span><span class="cov0" title="0">{
                return true, fmt.Errorf("grpclb: failed to perform RPC to the remote balancer %v", err)
        }</span>
        <span class="cov8" title="1">ccw.lb.mu.Lock()
        ccw.lb.remoteBalancerConnected = true
        ccw.lb.mu.Unlock()

        // grpclb handshake on the stream.
        initReq := &amp;lbpb.LoadBalanceRequest{
                LoadBalanceRequestType: &amp;lbpb.LoadBalanceRequest_InitialRequest{
                        InitialRequest: &amp;lbpb.InitialLoadBalanceRequest{
                                Name: ccw.lb.target,
                        },
                },
        }
        if err := stream.Send(initReq); err != nil </span><span class="cov0" title="0">{
                return true, fmt.Errorf("grpclb: failed to send init request: %v", err)
        }</span>
        <span class="cov8" title="1">reply, err := stream.Recv()
        if err != nil </span><span class="cov0" title="0">{
                return true, fmt.Errorf("grpclb: failed to recv init response: %v", err)
        }</span>
        <span class="cov8" title="1">initResp := reply.GetInitialResponse()
        if initResp == nil </span><span class="cov0" title="0">{
                return true, fmt.Errorf("grpclb: reply from remote balancer did not include initial response")
        }</span>

        <span class="cov8" title="1">ccw.wg.Add(1)
        go func() </span><span class="cov8" title="1">{
                defer ccw.wg.Done()
                if d := convertDuration(initResp.ClientStatsReportInterval); d &gt; 0 </span><span class="cov8" title="1">{
                        ccw.sendLoadReport(stream, d)
                }</span>
        }()
        // No backoff if init req/resp handshake was successful.
        <span class="cov8" title="1">return false, ccw.readServerList(stream)</span>
}

// cancelRemoteBalancerCall cancels the context used by the stream to the remote
// balancer. watchRemoteBalancer() takes care of restarting this call after the
// stream fails.
func (ccw *remoteBalancerCCWrapper) cancelRemoteBalancerCall() <span class="cov8" title="1">{
        ccw.streamMu.Lock()
        if ccw.streamCancel != nil </span><span class="cov8" title="1">{
                ccw.streamCancel()
                ccw.streamCancel = nil
        }</span>
        <span class="cov8" title="1">ccw.streamMu.Unlock()</span>
}

func (ccw *remoteBalancerCCWrapper) watchRemoteBalancer() <span class="cov8" title="1">{
        defer func() </span><span class="cov8" title="1">{
                ccw.wg.Done()
                ccw.streamMu.Lock()
                if ccw.streamCancel != nil </span><span class="cov8" title="1">{
                        // This is to make sure that we don't leak the context when we are
                        // directly returning from inside of the below `for` loop.
                        ccw.streamCancel()
                        ccw.streamCancel = nil
                }</span>
                <span class="cov8" title="1">ccw.streamMu.Unlock()</span>
        }()

        <span class="cov8" title="1">var retryCount int
        var ctx context.Context
        for </span><span class="cov8" title="1">{
                ccw.streamMu.Lock()
                if ccw.streamCancel != nil </span><span class="cov8" title="1">{
                        ccw.streamCancel()
                        ccw.streamCancel = nil
                }</span>
                <span class="cov8" title="1">ctx, ccw.streamCancel = context.WithCancel(context.Background())
                ccw.streamMu.Unlock()

                doBackoff, err := ccw.callRemoteBalancer(ctx)
                select </span>{
                case &lt;-ccw.done:<span class="cov8" title="1">
                        return</span>
                default:<span class="cov8" title="1">
                        if err != nil </span><span class="cov8" title="1">{
                                if err == errServerTerminatedConnection </span><span class="cov0" title="0">{
                                        logger.Info(err)
                                }</span> else<span class="cov8" title="1"> {
                                        logger.Warning(err)
                                }</span>
                        }
                }
                // Trigger a re-resolve when the stream errors.
                <span class="cov8" title="1">ccw.lb.cc.cc.ResolveNow(resolver.ResolveNowOptions{})

                ccw.lb.mu.Lock()
                ccw.lb.remoteBalancerConnected = false
                ccw.lb.fullServerList = nil
                // Enter fallback when connection to remote balancer is lost, and the
                // aggregated state is not Ready.
                if !ccw.lb.inFallback &amp;&amp; ccw.lb.state != connectivity.Ready </span><span class="cov0" title="0">{
                        // Entering fallback.
                        ccw.lb.refreshSubConns(ccw.lb.resolvedBackendAddrs, true, ccw.lb.usePickFirst)
                }</span>
                <span class="cov8" title="1">ccw.lb.mu.Unlock()

                if !doBackoff </span><span class="cov8" title="1">{
                        retryCount = 0
                        continue</span>
                }

                <span class="cov0" title="0">timer := time.NewTimer(ccw.backoff.Backoff(retryCount)) // Copy backoff
                select </span>{
                case &lt;-timer.C:<span class="cov0" title="0"></span>
                case &lt;-ccw.done:<span class="cov0" title="0">
                        timer.Stop()
                        return</span>
                }
                <span class="cov0" title="0">retryCount++</span>
        }
}
</pre>
		
		<pre class="file" id="file13" style="display: none">/*
 *
 * Copyright 2016 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package grpclb

import (
        "fmt"
        "sync"
        "time"

        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/resolver"
)

// The parent ClientConn should re-resolve when grpclb loses connection to the
// remote balancer. When the ClientConn inside grpclb gets a TransientFailure,
// it calls lbManualResolver.ResolveNow(), which calls parent ClientConn's
// ResolveNow, and eventually results in re-resolve happening in parent
// ClientConn's resolver (DNS for example).
//
//                          parent
//                          ClientConn
//  +-----------------------------------------------------------------+
//  |             parent          +---------------------------------+ |
//  | DNS         ClientConn      |  grpclb                         | |
//  | resolver    balancerWrapper |                                 | |
//  | +              +            |    grpclb          grpclb       | |
//  | |              |            |    ManualResolver  ClientConn   | |
//  | |              |            |     +              +            | |
//  | |              |            |     |              | Transient  | |
//  | |              |            |     |              | Failure    | |
//  | |              |            |     |  &lt;---------  |            | |
//  | |              | &lt;--------------- |  ResolveNow  |            | |
//  | |  &lt;---------  | ResolveNow |     |              |            | |
//  | |  ResolveNow  |            |     |              |            | |
//  | |              |            |     |              |            | |
//  | +              +            |     +              +            | |
//  |                             +---------------------------------+ |
//  +-----------------------------------------------------------------+

// lbManualResolver is used by the ClientConn inside grpclb. It's a manual
// resolver with a special ResolveNow() function.
//
// When ResolveNow() is called, it calls ResolveNow() on the parent ClientConn,
// so when grpclb client lose contact with remote balancers, the parent
// ClientConn's resolver will re-resolve.
type lbManualResolver struct {
        scheme string
        ccr    resolver.ClientConn

        ccb balancer.ClientConn
}

func (r *lbManualResolver) Build(_ resolver.Target, cc resolver.ClientConn, _ resolver.BuildOptions) (resolver.Resolver, error) <span class="cov8" title="1">{
        r.ccr = cc
        return r, nil
}</span>

func (r *lbManualResolver) Scheme() string <span class="cov8" title="1">{
        return r.scheme
}</span>

// ResolveNow calls resolveNow on the parent ClientConn.
func (r *lbManualResolver) ResolveNow(o resolver.ResolveNowOptions) <span class="cov8" title="1">{
        r.ccb.ResolveNow(o)
}</span>

// Close is a noop for Resolver.
func (*lbManualResolver) Close() {<span class="cov8" title="1">}</span>

// UpdateState calls cc.UpdateState.
func (r *lbManualResolver) UpdateState(s resolver.State) <span class="cov8" title="1">{
        r.ccr.UpdateState(s)
}</span>

const subConnCacheTime = time.Second * 10

// lbCacheClientConn is a wrapper balancer.ClientConn with a SubConn cache.
// SubConns will be kept in cache for subConnCacheTime before being removed.
//
// Its new and remove methods are updated to do cache first.
type lbCacheClientConn struct {
        cc      balancer.ClientConn
        timeout time.Duration

        mu sync.Mutex
        // subConnCache only keeps subConns that are being deleted.
        subConnCache  map[resolver.Address]*subConnCacheEntry
        subConnToAddr map[balancer.SubConn]resolver.Address
}

type subConnCacheEntry struct {
        sc balancer.SubConn

        cancel        func()
        abortDeleting bool
}

func newLBCacheClientConn(cc balancer.ClientConn) *lbCacheClientConn <span class="cov8" title="1">{
        return &amp;lbCacheClientConn{
                cc:            cc,
                timeout:       subConnCacheTime,
                subConnCache:  make(map[resolver.Address]*subConnCacheEntry),
                subConnToAddr: make(map[balancer.SubConn]resolver.Address),
        }
}</span>

func (ccc *lbCacheClientConn) NewSubConn(addrs []resolver.Address, opts balancer.NewSubConnOptions) (balancer.SubConn, error) <span class="cov8" title="1">{
        if len(addrs) != 1 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("grpclb calling NewSubConn with addrs of length %v", len(addrs))
        }</span>
        <span class="cov8" title="1">addrWithoutAttrs := addrs[0]
        addrWithoutAttrs.Attributes = nil

        ccc.mu.Lock()
        defer ccc.mu.Unlock()
        if entry, ok := ccc.subConnCache[addrWithoutAttrs]; ok </span><span class="cov8" title="1">{
                // If entry is in subConnCache, the SubConn was being deleted.
                // cancel function will never be nil.
                entry.cancel()
                delete(ccc.subConnCache, addrWithoutAttrs)
                return entry.sc, nil
        }</span>

        <span class="cov8" title="1">scNew, err := ccc.cc.NewSubConn(addrs, opts)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov8" title="1">ccc.subConnToAddr[scNew] = addrWithoutAttrs
        return scNew, nil</span>
}

func (ccc *lbCacheClientConn) RemoveSubConn(sc balancer.SubConn) <span class="cov8" title="1">{
        ccc.mu.Lock()
        defer ccc.mu.Unlock()
        addr, ok := ccc.subConnToAddr[sc]
        if !ok </span><span class="cov0" title="0">{
                return
        }</span>

        <span class="cov8" title="1">if entry, ok := ccc.subConnCache[addr]; ok </span><span class="cov0" title="0">{
                if entry.sc != sc </span><span class="cov0" title="0">{
                        // This could happen if NewSubConn was called multiple times for the
                        // same address, and those SubConns are all removed. We remove sc
                        // immediately here.
                        delete(ccc.subConnToAddr, sc)
                        ccc.cc.RemoveSubConn(sc)
                }</span>
                <span class="cov0" title="0">return</span>
        }

        <span class="cov8" title="1">entry := &amp;subConnCacheEntry{
                sc: sc,
        }
        ccc.subConnCache[addr] = entry

        timer := time.AfterFunc(ccc.timeout, func() </span><span class="cov8" title="1">{
                ccc.mu.Lock()
                defer ccc.mu.Unlock()
                if entry.abortDeleting </span><span class="cov0" title="0">{
                        return
                }</span>
                <span class="cov8" title="1">ccc.cc.RemoveSubConn(sc)
                delete(ccc.subConnToAddr, sc)
                delete(ccc.subConnCache, addr)</span>
        })
        <span class="cov8" title="1">entry.cancel = func() </span><span class="cov8" title="1">{
                if !timer.Stop() </span><span class="cov0" title="0">{
                        // If stop was not successful, the timer has fired (this can only
                        // happen in a race). But the deleting function is blocked on ccc.mu
                        // because the mutex was held by the caller of this function.
                        //
                        // Set abortDeleting to true to abort the deleting function. When
                        // the lock is released, the deleting function will acquire the
                        // lock, check the value of abortDeleting and return.
                        entry.abortDeleting = true
                }</span>
        }
}

func (ccc *lbCacheClientConn) UpdateState(s balancer.State) <span class="cov8" title="1">{
        ccc.cc.UpdateState(s)
}</span>

func (ccc *lbCacheClientConn) close() <span class="cov8" title="1">{
        ccc.mu.Lock()
        // Only cancel all existing timers. There's no need to remove SubConns.
        for _, entry := range ccc.subConnCache </span><span class="cov8" title="1">{
                entry.cancel()
        }</span>
        <span class="cov8" title="1">ccc.mu.Unlock()</span>
}
</pre>
		
		<pre class="file" id="file14" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package rls implements the RLS LB policy.
package rls

import (
        "encoding/json"
        "errors"
        "fmt"
        "sync"
        "sync/atomic"
        "time"
        "unsafe"

        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/connectivity"
        "google.golang.org/grpc/grpclog"
        "google.golang.org/grpc/internal"
        "google.golang.org/grpc/internal/backoff"
        "google.golang.org/grpc/internal/balancergroup"
        "google.golang.org/grpc/internal/buffer"
        internalgrpclog "google.golang.org/grpc/internal/grpclog"
        "google.golang.org/grpc/internal/grpcsync"
        "google.golang.org/grpc/internal/pretty"
        "google.golang.org/grpc/resolver"
)

const (
        // Name is the name of the RLS LB policy.
        //
        // It currently has an experimental suffix which would be removed once
        // end-to-end testing of the policy is completed.
        Name = internal.RLSLoadBalancingPolicyName
        // Default frequency for data cache purging.
        periodicCachePurgeFreq = time.Minute
)

var (
        logger            = grpclog.Component("rls")
        errBalancerClosed = errors.New("rls LB policy is closed")

        // Below defined vars for overriding in unit tests.

        // Default exponential backoff strategy for data cache entries.
        defaultBackoffStrategy = backoff.Strategy(backoff.DefaultExponential)
        // Ticker used for periodic data cache purging.
        dataCachePurgeTicker = func() *time.Ticker <span class="cov8" title="1">{ return time.NewTicker(periodicCachePurgeFreq) }</span>
        // We want every cache entry to live in the cache for at least this
        // duration. If we encounter a cache entry whose minimum expiration time is
        // in the future, we abort the LRU pass, which may temporarily leave the
        // cache being too large. This is necessary to ensure that in cases where
        // the cache is too small, when we receive an RLS Response, we keep the
        // resulting cache entry around long enough for the pending incoming
        // requests to be re-processed through the new Picker. If we didn't do this,
        // then we'd risk throwing away each RLS response as we receive it, in which
        // case we would fail to actually route any of our incoming requests.
        minEvictDuration = 5 * time.Second

        // Following functions are no-ops in actual code, but can be overridden in
        // tests to give tests visibility into exactly when certain events happen.
        clientConnUpdateHook = func() {<span class="cov8" title="1">}</span>
        dataCachePurgeHook   = func() {<span class="cov0" title="0">}</span>
        resetBackoffHook     = func() {<span class="cov0" title="0">}</span>
)

func init() <span class="cov8" title="1">{
        balancer.Register(&amp;rlsBB{})
}</span>

type rlsBB struct{}

func (rlsBB) Name() string <span class="cov8" title="1">{
        return Name
}</span>

func (rlsBB) Build(cc balancer.ClientConn, opts balancer.BuildOptions) balancer.Balancer <span class="cov8" title="1">{
        lb := &amp;rlsBalancer{
                done:          grpcsync.NewEvent(),
                cc:            cc,
                bopts:         opts,
                purgeTicker:   dataCachePurgeTicker(),
                lbCfg:         &amp;lbConfig{},
                pendingMap:    make(map[cacheKey]*backoffState),
                childPolicies: make(map[string]*childPolicyWrapper),
                updateCh:      buffer.NewUnbounded(),
        }
        lb.logger = internalgrpclog.NewPrefixLogger(logger, fmt.Sprintf("[rls-experimental-lb %p] ", lb))
        lb.dataCache = newDataCache(maxCacheSize, lb.logger)
        lb.bg = balancergroup.New(cc, opts, lb, lb.logger)
        lb.bg.Start()
        go lb.run()
        return lb
}</span>

// rlsBalancer implements the RLS LB policy.
type rlsBalancer struct {
        done        *grpcsync.Event
        cc          balancer.ClientConn
        bopts       balancer.BuildOptions
        purgeTicker *time.Ticker
        logger      *internalgrpclog.PrefixLogger

        // If both cacheMu and stateMu need to be acquired, the former must be
        // acquired first to prevent a deadlock. This order restriction is due to the
        // fact that in places where we need to acquire both the locks, we always
        // start off reading the cache.

        // cacheMu guards access to the data cache and pending requests map.
        cacheMu    sync.RWMutex
        dataCache  *dataCache                 // Cache of RLS data.
        pendingMap map[cacheKey]*backoffState // Map of pending RLS requests.

        // stateMu guards access to all LB policy state.
        stateMu            sync.Mutex
        lbCfg              *lbConfig        // Most recently received service config.
        childPolicyBuilder balancer.Builder // Cached child policy builder.
        resolverState      resolver.State   // Cached resolver state.
        ctrlCh             *controlChannel  // Control channel to the RLS server.
        bg                 *balancergroup.BalancerGroup
        childPolicies      map[string]*childPolicyWrapper
        defaultPolicy      *childPolicyWrapper
        // A reference to the most recent picker sent to gRPC as part of a state
        // update is cached in this field so that we can release the reference to the
        // default child policy wrapper when a new picker is created. See
        // sendNewPickerLocked() for details.
        lastPicker *rlsPicker
        // Set during UpdateClientConnState when pushing updates to child policies.
        // Prevents state updates from child policies causing new pickers to be sent
        // up the channel. Cleared after all child policies have processed the
        // updates sent to them, after which a new picker is sent up the channel.
        inhibitPickerUpdates bool

        // Channel on which all updates are pushed. Processed in run().
        updateCh *buffer.Unbounded
}

type resumePickerUpdates struct {
        done chan struct{}
}

// childPolicyIDAndState wraps a child policy id and its state update.
type childPolicyIDAndState struct {
        id    string
        state balancer.State
}

type controlChannelReady struct{}

// run is a long-running goroutine which handles all the updates that the
// balancer wishes to handle. The appropriate updateHandler will push the update
// on to a channel that this goroutine will select on, thereby the handling of
// the update will happen asynchronously.
func (b *rlsBalancer) run() <span class="cov8" title="1">{
        go b.purgeDataCache()
        for </span><span class="cov8" title="1">{
                select </span>{
                case u := &lt;-b.updateCh.Get():<span class="cov8" title="1">
                        b.updateCh.Load()
                        switch update := u.(type) </span>{
                        case childPolicyIDAndState:<span class="cov8" title="1">
                                b.handleChildPolicyStateUpdate(update.id, update.state)</span>
                        case controlChannelReady:<span class="cov8" title="1">
                                b.logger.Infof("Resetting backoff state after control channel getting back to READY")
                                b.cacheMu.Lock()
                                updatePicker := b.dataCache.resetBackoffState(&amp;backoffState{bs: defaultBackoffStrategy})
                                b.cacheMu.Unlock()
                                if updatePicker </span><span class="cov8" title="1">{
                                        b.sendNewPicker()
                                }</span>
                                <span class="cov8" title="1">resetBackoffHook()</span>
                        case resumePickerUpdates:<span class="cov8" title="1">
                                b.stateMu.Lock()
                                b.logger.Infof("Resuming picker updates after config propagation to child policies")
                                b.inhibitPickerUpdates = false
                                b.sendNewPickerLocked()
                                close(update.done)
                                b.stateMu.Unlock()</span>
                        default:<span class="cov0" title="0">
                                b.logger.Errorf("Unsupported update type %T", update)</span>
                        }
                case &lt;-b.done.Done():<span class="cov8" title="1">
                        return</span>
                }
        }
}

// purgeDataCache is a long-running goroutine which periodically deletes expired
// entries. An expired entry is one for which both the expiryTime and
// backoffExpiryTime are in the past.
func (b *rlsBalancer) purgeDataCache() <span class="cov8" title="1">{
        for </span><span class="cov8" title="1">{
                select </span>{
                case &lt;-b.done.Done():<span class="cov8" title="1">
                        return</span>
                case &lt;-b.purgeTicker.C:<span class="cov8" title="1">
                        b.cacheMu.Lock()
                        updatePicker := b.dataCache.evictExpiredEntries()
                        b.cacheMu.Unlock()
                        if updatePicker </span><span class="cov8" title="1">{
                                b.sendNewPicker()
                        }</span>
                        <span class="cov8" title="1">dataCachePurgeHook()</span>
                }
        }
}

func (b *rlsBalancer) UpdateClientConnState(ccs balancer.ClientConnState) error <span class="cov8" title="1">{
        defer clientConnUpdateHook()
        if b.done.HasFired() </span><span class="cov0" title="0">{
                b.logger.Warningf("Received service config after balancer close: %s", pretty.ToJSON(ccs.BalancerConfig))
                return errBalancerClosed
        }</span>

        <span class="cov8" title="1">b.stateMu.Lock()
        newCfg := ccs.BalancerConfig.(*lbConfig)
        if b.lbCfg.Equal(newCfg) </span><span class="cov0" title="0">{
                b.stateMu.Unlock()
                b.logger.Infof("New service config matches existing config")
                return nil
        }</span>

        <span class="cov8" title="1">b.logger.Infof("Delaying picker updates until config is propagated to and processed by child policies")
        b.inhibitPickerUpdates = true

        // When the RLS server name changes, the old control channel needs to be
        // swapped out for a new one. All state associated with the throttling
        // algorithm is stored on a per-control-channel basis; when we swap out
        // channels, we also swap out the throttling state.
        b.handleControlChannelUpdate(newCfg)

        // If the new config changes the size of the data cache, we might have to
        // evict entries to get the cache size down to the newly specified size.
        if newCfg.cacheSizeBytes != b.lbCfg.cacheSizeBytes </span><span class="cov8" title="1">{
                b.dataCache.resize(newCfg.cacheSizeBytes)
        }</span>

        // Any changes to child policy name or configuration needs to be handled by
        // either creating new child policies or pushing updates to existing ones.
        <span class="cov8" title="1">b.resolverState = ccs.ResolverState
        b.handleChildPolicyConfigUpdate(newCfg, &amp;ccs)

        // Update the copy of the config in the LB policy before releasing the lock.
        b.lbCfg = newCfg

        // Enqueue an event which will notify us when the above update has been
        // propagated to all child policies, and the child policies have all
        // processed their updates, and we have sent a picker update.
        done := make(chan struct{})
        b.updateCh.Put(resumePickerUpdates{done: done})
        b.stateMu.Unlock()
        &lt;-done
        return nil</span>
}

// handleControlChannelUpdate handles updates to service config fields which
// influence the control channel to the RLS server.
//
// Caller must hold lb.stateMu.
func (b *rlsBalancer) handleControlChannelUpdate(newCfg *lbConfig) <span class="cov8" title="1">{
        if newCfg.lookupService == b.lbCfg.lookupService &amp;&amp; newCfg.lookupServiceTimeout == b.lbCfg.lookupServiceTimeout </span><span class="cov8" title="1">{
                return
        }</span>

        // Create a new control channel and close the existing one.
        <span class="cov8" title="1">b.logger.Infof("Creating control channel to RLS server at: %v", newCfg.lookupService)
        backToReadyFn := func() </span><span class="cov8" title="1">{
                b.updateCh.Put(controlChannelReady{})
        }</span>
        <span class="cov8" title="1">ctrlCh, err := newControlChannel(newCfg.lookupService, newCfg.controlChannelServiceConfig, newCfg.lookupServiceTimeout, b.bopts, backToReadyFn)
        if err != nil </span><span class="cov0" title="0">{
                // This is very uncommon and usually represents a non-transient error.
                // There is not much we can do here other than wait for another update
                // which might fix things.
                b.logger.Errorf("Failed to create control channel to %q: %v", newCfg.lookupService, err)
                return
        }</span>
        <span class="cov8" title="1">if b.ctrlCh != nil </span><span class="cov8" title="1">{
                b.ctrlCh.close()
        }</span>
        <span class="cov8" title="1">b.ctrlCh = ctrlCh</span>
}

// handleChildPolicyConfigUpdate handles updates to service config fields which
// influence child policy configuration.
//
// Caller must hold lb.stateMu.
func (b *rlsBalancer) handleChildPolicyConfigUpdate(newCfg *lbConfig, ccs *balancer.ClientConnState) <span class="cov8" title="1">{
        // Update child policy builder first since other steps are dependent on this.
        if b.childPolicyBuilder == nil || b.childPolicyBuilder.Name() != newCfg.childPolicyName </span><span class="cov8" title="1">{
                b.logger.Infof("Child policy changed to %q", newCfg.childPolicyName)
                b.childPolicyBuilder = balancer.Get(newCfg.childPolicyName)
                for _, cpw := range b.childPolicies </span><span class="cov8" title="1">{
                        // If the child policy has changed, we need to remove the old policy
                        // from the BalancerGroup and add a new one. The BalancerGroup takes
                        // care of closing the old one in this case.
                        b.bg.Remove(cpw.target)
                        b.bg.Add(cpw.target, b.childPolicyBuilder)
                }</span>
        }

        <span class="cov8" title="1">configSentToDefault := false
        if b.lbCfg.defaultTarget != newCfg.defaultTarget </span><span class="cov8" title="1">{
                // If the default target has changed, create a new childPolicyWrapper for
                // the new target if required. If a new wrapper is created, add it to the
                // childPolicies map and the BalancerGroup.
                b.logger.Infof("Default target in LB config changing from %q to %q", b.lbCfg.defaultTarget, newCfg.defaultTarget)
                cpw := b.childPolicies[newCfg.defaultTarget]
                if cpw == nil </span><span class="cov8" title="1">{
                        cpw = newChildPolicyWrapper(newCfg.defaultTarget)
                        b.childPolicies[newCfg.defaultTarget] = cpw
                        b.bg.Add(newCfg.defaultTarget, b.childPolicyBuilder)
                        b.logger.Infof("Child policy %q added to BalancerGroup", newCfg.defaultTarget)
                }</span>
                <span class="cov8" title="1">if err := b.buildAndPushChildPolicyConfigs(newCfg.defaultTarget, newCfg, ccs); err != nil </span><span class="cov0" title="0">{
                        cpw.lamify(err)
                }</span>

                // If an old default exists, release its reference. If this was the last
                // reference, remove the child policy from the BalancerGroup and remove the
                // corresponding entry the childPolicies map.
                <span class="cov8" title="1">if b.defaultPolicy != nil </span><span class="cov8" title="1">{
                        if b.defaultPolicy.releaseRef() </span><span class="cov0" title="0">{
                                delete(b.childPolicies, b.lbCfg.defaultTarget)
                                b.bg.Remove(b.defaultPolicy.target)
                        }</span>
                }
                <span class="cov8" title="1">b.defaultPolicy = cpw
                configSentToDefault = true</span>
        }

        // No change in configuration affecting child policies. Return early.
        <span class="cov8" title="1">if b.lbCfg.childPolicyName == newCfg.childPolicyName &amp;&amp; b.lbCfg.childPolicyTargetField == newCfg.childPolicyTargetField &amp;&amp; childPolicyConfigEqual(b.lbCfg.childPolicyConfig, newCfg.childPolicyConfig) </span><span class="cov0" title="0">{
                return
        }</span>

        // If fields affecting child policy configuration have changed, the changes
        // are pushed to the childPolicyWrapper which handles them appropriately.
        <span class="cov8" title="1">for _, cpw := range b.childPolicies </span><span class="cov8" title="1">{
                if configSentToDefault &amp;&amp; cpw.target == newCfg.defaultTarget </span><span class="cov8" title="1">{
                        // Default target has already been taken care of.
                        continue</span>
                }
                <span class="cov8" title="1">if err := b.buildAndPushChildPolicyConfigs(cpw.target, newCfg, ccs); err != nil </span><span class="cov0" title="0">{
                        cpw.lamify(err)
                }</span>
        }
}

// buildAndPushChildPolicyConfigs builds the final child policy configuration by
// adding the `targetField` to the base child policy configuration received in
// RLS LB policy configuration. The `targetField` is set to target and
// configuration is pushed to the child policy through the BalancerGroup.
//
// Caller must hold lb.stateMu.
func (b *rlsBalancer) buildAndPushChildPolicyConfigs(target string, newCfg *lbConfig, ccs *balancer.ClientConnState) error <span class="cov8" title="1">{
        jsonTarget, err := json.Marshal(target)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to marshal child policy target %q: %v", target, err)
        }</span>

        <span class="cov8" title="1">config := newCfg.childPolicyConfig
        targetField := newCfg.childPolicyTargetField
        config[targetField] = jsonTarget
        jsonCfg, err := json.Marshal(config)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to marshal child policy config %+v: %v", config, err)
        }</span>

        <span class="cov8" title="1">parser, _ := b.childPolicyBuilder.(balancer.ConfigParser)
        parsedCfg, err := parser.ParseConfig(jsonCfg)
        if err != nil </span><span class="cov8" title="1">{
                return fmt.Errorf("childPolicy config parsing failed: %v", err)
        }</span>

        <span class="cov8" title="1">state := balancer.ClientConnState{ResolverState: ccs.ResolverState, BalancerConfig: parsedCfg}
        b.logger.Infof("Pushing new state to child policy %q: %+v", target, state)
        if err := b.bg.UpdateClientConnState(target, state); err != nil </span><span class="cov0" title="0">{
                b.logger.Warningf("UpdateClientConnState(%q, %+v) failed : %v", target, ccs, err)
        }</span>
        <span class="cov8" title="1">return nil</span>
}

func (b *rlsBalancer) ResolverError(err error) <span class="cov0" title="0">{
        b.bg.ResolverError(err)
}</span>

func (b *rlsBalancer) UpdateSubConnState(sc balancer.SubConn, state balancer.SubConnState) <span class="cov8" title="1">{
        b.bg.UpdateSubConnState(sc, state)
}</span>

func (b *rlsBalancer) Close() <span class="cov8" title="1">{
        b.done.Fire()

        b.purgeTicker.Stop()
        b.stateMu.Lock()
        if b.ctrlCh != nil </span><span class="cov8" title="1">{
                b.ctrlCh.close()
        }</span>
        <span class="cov8" title="1">b.bg.Close()
        b.stateMu.Unlock()

        b.cacheMu.Lock()
        b.dataCache.stop()
        b.cacheMu.Unlock()</span>
}

func (b *rlsBalancer) ExitIdle() <span class="cov0" title="0">{
        b.bg.ExitIdle()
}</span>

// sendNewPickerLocked pushes a new picker on to the channel.
//
//
// Note that regardless of what connectivity state is reported, the policy will
// return its own picker, and not a picker that unconditionally queues
// (typically used for IDLE or CONNECTING) or a picker that unconditionally
// fails (typically used for TRANSIENT_FAILURE). This is required because,
// irrespective of the connectivity state, we need to able to perform RLS
// lookups for incoming RPCs and affect the status of queued RPCs based on the
// receipt of RLS responses.
//
// Caller must hold lb.stateMu.
func (b *rlsBalancer) sendNewPickerLocked() <span class="cov8" title="1">{
        aggregatedState := b.aggregatedConnectivityState()

        // Acquire a separate reference for the picker. This is required to ensure
        // that the wrapper held by the old picker is not closed when the default
        // target changes in the config, and a new wrapper is created for the new
        // default target. See handleChildPolicyConfigUpdate() for how config changes
        // affecting the default target are handled.
        if b.defaultPolicy != nil </span><span class="cov8" title="1">{
                b.defaultPolicy.acquireRef()
        }</span>
        <span class="cov8" title="1">picker := &amp;rlsPicker{
                kbm:           b.lbCfg.kbMap,
                origEndpoint:  b.bopts.Target.Endpoint,
                lb:            b,
                defaultPolicy: b.defaultPolicy,
                ctrlCh:        b.ctrlCh,
                maxAge:        b.lbCfg.maxAge,
                staleAge:      b.lbCfg.staleAge,
                bg:            b.bg,
        }
        picker.logger = internalgrpclog.NewPrefixLogger(logger, fmt.Sprintf("[rls-picker %p] ", picker))
        state := balancer.State{
                ConnectivityState: aggregatedState,
                Picker:            picker,
        }

        if !b.inhibitPickerUpdates </span><span class="cov8" title="1">{
                b.logger.Infof("New balancer.State: %+v", state)
                b.cc.UpdateState(state)
        }</span> else<span class="cov8" title="1"> {
                b.logger.Infof("Delaying picker update: %+v", state)
        }</span>

        <span class="cov8" title="1">if b.lastPicker != nil </span><span class="cov8" title="1">{
                if b.defaultPolicy != nil </span><span class="cov8" title="1">{
                        b.defaultPolicy.releaseRef()
                }</span>
        }
        <span class="cov8" title="1">b.lastPicker = picker</span>
}

func (b *rlsBalancer) sendNewPicker() <span class="cov8" title="1">{
        b.stateMu.Lock()
        b.sendNewPickerLocked()
        b.stateMu.Unlock()
}</span>

// The aggregated connectivity state reported is determined as follows:
// - If there is at least one child policy in state READY, the connectivity
//   state is READY.
// - Otherwise, if there is at least one child policy in state CONNECTING, the
//   connectivity state is CONNECTING.
// - Otherwise, if there is at least one child policy in state IDLE, the
//   connectivity state is IDLE.
// - Otherwise, all child policies are in TRANSIENT_FAILURE, and the
//   connectivity state is TRANSIENT_FAILURE.
//
// If the RLS policy has no child policies and no configured default target,
// then we will report connectivity state IDLE.
//
// Caller must hold lb.stateMu.
func (b *rlsBalancer) aggregatedConnectivityState() connectivity.State <span class="cov8" title="1">{
        if len(b.childPolicies) == 0 &amp;&amp; b.lbCfg.defaultTarget == "" </span><span class="cov8" title="1">{
                return connectivity.Idle
        }</span>

        <span class="cov8" title="1">var readyN, connectingN, idleN int
        for _, cpw := range b.childPolicies </span><span class="cov8" title="1">{
                state := (*balancer.State)(atomic.LoadPointer(&amp;cpw.state))
                switch state.ConnectivityState </span>{
                case connectivity.Ready:<span class="cov8" title="1">
                        readyN++</span>
                case connectivity.Connecting:<span class="cov8" title="1">
                        connectingN++</span>
                case connectivity.Idle:<span class="cov8" title="1">
                        idleN++</span>
                }
        }

        <span class="cov8" title="1">switch </span>{
        case readyN &gt; 0:<span class="cov8" title="1">
                return connectivity.Ready</span>
        case connectingN &gt; 0:<span class="cov8" title="1">
                return connectivity.Connecting</span>
        case idleN &gt; 0:<span class="cov8" title="1">
                return connectivity.Idle</span>
        default:<span class="cov8" title="1">
                return connectivity.TransientFailure</span>
        }
}

// UpdateState is a implementation of the balancergroup.BalancerStateAggregator
// interface. The actual state aggregation functionality is handled
// asynchronously. This method only pushes the state update on to channel read
// and dispatched by the run() goroutine.
func (b *rlsBalancer) UpdateState(id string, state balancer.State) <span class="cov8" title="1">{
        b.updateCh.Put(childPolicyIDAndState{id: id, state: state})
}</span>

// handleChildPolicyStateUpdate provides the state aggregator functionality for
// the BalancerGroup.
//
// This method is invoked by the BalancerGroup whenever a child policy sends a
// state update. We cache the child policy's connectivity state and picker for
// two reasons:
// - to suppress connectivity state transitions from TRANSIENT_FAILURE to states
//   other than READY
// - to delegate picks to child policies
func (b *rlsBalancer) handleChildPolicyStateUpdate(id string, newState balancer.State) <span class="cov8" title="1">{
        b.stateMu.Lock()
        defer b.stateMu.Unlock()

        cpw := b.childPolicies[id]
        if cpw == nil </span><span class="cov0" title="0">{
                // All child policies start with an entry in the map. If ID is not in
                // map, it's either been removed, or never existed.
                b.logger.Warningf("Received state update %+v for missing child policy %q", newState, id)
                return
        }</span>

        <span class="cov8" title="1">oldState := (*balancer.State)(atomic.LoadPointer(&amp;cpw.state))
        if oldState.ConnectivityState == connectivity.TransientFailure &amp;&amp; newState.ConnectivityState == connectivity.Connecting </span><span class="cov0" title="0">{
                // Ignore state transitions from TRANSIENT_FAILURE to CONNECTING, and thus
                // fail pending RPCs instead of queuing them indefinitely when all
                // subChannels are failing, even if the subChannels are bouncing back and
                // forth between CONNECTING and TRANSIENT_FAILURE.
                return
        }</span>
        <span class="cov8" title="1">atomic.StorePointer(&amp;cpw.state, unsafe.Pointer(&amp;newState))
        b.logger.Infof("Child policy %q has new state %+v", id, newState)
        b.sendNewPickerLocked()</span>
}

// acquireChildPolicyReferences attempts to acquire references to
// childPolicyWrappers corresponding to the passed in targets. If there is no
// childPolicyWrapper corresponding to one of the targets, a new one is created
// and added to the BalancerGroup.
func (b *rlsBalancer) acquireChildPolicyReferences(targets []string) []*childPolicyWrapper <span class="cov8" title="1">{
        b.stateMu.Lock()
        var newChildPolicies []*childPolicyWrapper
        for _, target := range targets </span><span class="cov8" title="1">{
                // If the target exists in the LB policy's childPolicies map. a new
                // reference is taken here and added to the new list.
                if cpw := b.childPolicies[target]; cpw != nil </span><span class="cov8" title="1">{
                        cpw.acquireRef()
                        newChildPolicies = append(newChildPolicies, cpw)
                        continue</span>
                }

                // If the target does not exist in the child policy map, then a new
                // child policy wrapper is created and added to the new list.
                <span class="cov8" title="1">cpw := newChildPolicyWrapper(target)
                b.childPolicies[target] = cpw
                b.bg.Add(target, b.childPolicyBuilder)
                b.logger.Infof("Child policy %q added to BalancerGroup", target)
                newChildPolicies = append(newChildPolicies, cpw)
                if err := b.buildAndPushChildPolicyConfigs(target, b.lbCfg, &amp;balancer.ClientConnState{
                        ResolverState: b.resolverState,
                }); err != nil </span><span class="cov8" title="1">{
                        cpw.lamify(err)
                }</span>
        }
        <span class="cov8" title="1">b.stateMu.Unlock()
        return newChildPolicies</span>
}

// releaseChildPolicyReferences releases references to childPolicyWrappers
// corresponding to the passed in targets. If the release reference was the last
// one, the child policy is removed from the BalancerGroup.
func (b *rlsBalancer) releaseChildPolicyReferences(targets []string) <span class="cov8" title="1">{
        b.stateMu.Lock()
        for _, target := range targets </span><span class="cov8" title="1">{
                if cpw := b.childPolicies[target]; cpw.releaseRef() </span><span class="cov8" title="1">{
                        delete(b.childPolicies, cpw.target)
                        b.bg.Remove(cpw.target)
                }</span>
        }
        <span class="cov8" title="1">b.stateMu.Unlock()</span>
}
</pre>
		
		<pre class="file" id="file15" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package rls

import (
        "container/list"
        "time"

        "google.golang.org/grpc/internal/backoff"
        internalgrpclog "google.golang.org/grpc/internal/grpclog"
        "google.golang.org/grpc/internal/grpcsync"
)

// cacheKey represents the key used to uniquely identify an entry in the data
// cache and in the pending requests map.
type cacheKey struct {
        // path is the full path of the incoming RPC request.
        path string
        // keys is a stringified version of the RLS request key map built using the
        // RLS keyBuilder. Since maps are not a type which is comparable in Go, it
        // cannot be part of the key for another map (entries in the data cache and
        // pending requests map are stored in maps).
        keys string
}

// cacheEntry wraps all the data to be stored in a data cache entry.
type cacheEntry struct {
        // childPolicyWrappers contains the list of child policy wrappers
        // corresponding to the targets returned by the RLS server for this entry.
        childPolicyWrappers []*childPolicyWrapper
        // headerData is received in the RLS response and is to be sent in the
        // X-Google-RLS-Data header for matching RPCs.
        headerData string
        // expiryTime is the absolute time at which this cache entry entry stops
        // being valid. When an RLS request succeeds, this is set to the current
        // time plus the max_age field from the LB policy config.
        expiryTime time.Time
        // staleTime is the absolute time after which this cache entry will be
        // proactively refreshed if an incoming RPC matches this entry. When an RLS
        // request succeeds, this is set to the current time plus the stale_age from
        // the LB policy config.
        staleTime time.Time
        // earliestEvictTime is the absolute time before which this entry should not
        // be evicted from the cache. When a cache entry is created, this is set to
        // the current time plus a default value of 5 seconds. This is required to
        // make sure that a new entry added to the cache is not evicted before the
        // RLS response arrives (usually when the cache is too small).
        earliestEvictTime time.Time

        // status stores the RPC status of the previous RLS request for this
        // entry. Picks for entries with a non-nil value for this field are failed
        // with the error stored here.
        status error
        // backoffState contains all backoff related state. When an RLS request
        // succeeds, backoffState is reset. This state moves between the data cache
        // and the pending requests map.
        backoffState *backoffState
        // backoffTime is the absolute time at which the backoff period for this
        // entry ends. When an RLS request fails, this is set to the current time
        // plus the backoff value returned by the backoffState. The backoff timer is
        // also setup with this value. No new RLS requests are sent out for this
        // entry until the backoff period ends.
        //
        // Set to zero time instant upon a successful RLS response.
        backoffTime time.Time
        // backoffExpiryTime is the absolute time at which an entry which has gone
        // through backoff stops being valid.  When an RLS request fails, this is
        // set to the current time plus twice the backoff time. The cache expiry
        // timer will only delete entries for which both expiryTime and
        // backoffExpiryTime are in the past.
        //
        // Set to zero time instant upon a successful RLS response.
        backoffExpiryTime time.Time

        // size stores the size of this cache entry. Used to enforce the cache size
        // specified in the LB policy configuration.
        size int64
        // onEvict is the callback to be invoked when this cache entry is evicted.
        onEvict func()
}

// backoffState wraps all backoff related state associated with a cache entry.
type backoffState struct {
        // retries keeps track of the number of RLS failures, to be able to
        // determine the amount of time to backoff before the next attempt.
        retries int
        // bs is the exponential backoff implementation which returns the amount of
        // time to backoff, given the number of retries.
        bs backoff.Strategy
        // timer fires when the backoff period ends and incoming requests after this
        // will trigger a new RLS request.
        timer *time.Timer
}

// lru is a cache implementation with a least recently used eviction policy.
// Internally it uses a doubly linked list, with the least recently used element
// at the front of the list and the most recently used element at the back of
// the list. The value stored in this cache will be of type `cacheKey`.
//
// It is not safe for concurrent access.
type lru struct {
        ll *list.List

        // A map from the value stored in the lru to its underlying list element is
        // maintained to have a clean API. Without this, a subset of the lru's API
        // would accept/return cacheKey while another subset would accept/return
        // list elements.
        m map[cacheKey]*list.Element
}

// newLRU creates a new cache with a least recently used eviction policy.
func newLRU() *lru <span class="cov8" title="1">{
        return &amp;lru{
                ll: list.New(),
                m:  make(map[cacheKey]*list.Element),
        }
}</span>

func (l *lru) addEntry(key cacheKey) <span class="cov8" title="1">{
        e := l.ll.PushBack(key)
        l.m[key] = e
}</span>

func (l *lru) makeRecent(key cacheKey) <span class="cov8" title="1">{
        e := l.m[key]
        l.ll.MoveToBack(e)
}</span>

func (l *lru) removeEntry(key cacheKey) <span class="cov8" title="1">{
        e := l.m[key]
        l.ll.Remove(e)
        delete(l.m, key)
}</span>

func (l *lru) getLeastRecentlyUsed() cacheKey <span class="cov8" title="1">{
        e := l.ll.Front()
        if e == nil </span><span class="cov8" title="1">{
                return cacheKey{}
        }</span>
        <span class="cov8" title="1">return e.Value.(cacheKey)</span>
}

// iterateAndRun traverses the lru in least-recently-used order and calls the
// provided function for every element.
//
// Callers may delete the cache entry associated with the cacheKey passed into
// f, but they may not perform any other operation which reorders the elements
// in the lru.
func (l *lru) iterateAndRun(f func(cacheKey)) <span class="cov8" title="1">{
        var next *list.Element
        for e := l.ll.Front(); e != nil; e = next </span><span class="cov8" title="1">{
                next = e.Next()
                f(e.Value.(cacheKey))
        }</span>
}

// dataCache contains a cache of RLS data used by the LB policy to make routing
// decisions.
//
// The dataCache will be keyed by the request's path and keys, represented by
// the `cacheKey` type. It will maintain the cache keys in an `lru` and the
// cache data, represented by the `cacheEntry` type, in a native map.
//
// It is not safe for concurrent access.
type dataCache struct {
        maxSize     int64 // Maximum allowed size.
        currentSize int64 // Current size.
        keys        *lru  // Cache keys maintained in lru order.
        entries     map[cacheKey]*cacheEntry
        logger      *internalgrpclog.PrefixLogger
        shutdown    *grpcsync.Event
}

func newDataCache(size int64, logger *internalgrpclog.PrefixLogger) *dataCache <span class="cov8" title="1">{
        return &amp;dataCache{
                maxSize:  size,
                keys:     newLRU(),
                entries:  make(map[cacheKey]*cacheEntry),
                logger:   logger,
                shutdown: grpcsync.NewEvent(),
        }
}</span>

// resize changes the maximum allowed size of the data cache.
//
// The return value indicates if an entry with a valid backoff timer was
// evicted. This is important to the RLS LB policy which would send a new picker
// on the channel to re-process any RPCs queued as a result of this backoff
// timer.
func (dc *dataCache) resize(size int64) (backoffCancelled bool) <span class="cov8" title="1">{
        if dc.shutdown.HasFired() </span><span class="cov0" title="0">{
                return false
        }</span>

        <span class="cov8" title="1">backoffCancelled = false
        for dc.currentSize &gt; size </span><span class="cov8" title="1">{
                key := dc.keys.getLeastRecentlyUsed()
                entry, ok := dc.entries[key]
                if !ok </span><span class="cov0" title="0">{
                        // This should never happen.
                        dc.logger.Errorf("cacheKey %+v not found in the cache while attempting to resize it", key)
                        break</span>
                }

                // When we encounter a cache entry whose minimum expiration time is in
                // the future, we abort the LRU pass, which may temporarily leave the
                // cache being too large. This is necessary to ensure that in cases
                // where the cache is too small, when we receive an RLS Response, we
                // keep the resulting cache entry around long enough for the pending
                // incoming requests to be re-processed through the new Picker. If we
                // didn't do this, then we'd risk throwing away each RLS response as we
                // receive it, in which case we would fail to actually route any of our
                // incoming requests.
                <span class="cov8" title="1">if entry.earliestEvictTime.After(time.Now()) </span><span class="cov8" title="1">{
                        dc.logger.Warningf("cachekey %+v is too recent to be evicted. Stopping cache resizing for now", key)
                        break</span>
                }

                // Stop the backoff timer before evicting the entry.
                <span class="cov8" title="1">if entry.backoffState != nil &amp;&amp; entry.backoffState.timer != nil </span><span class="cov8" title="1">{
                        if entry.backoffState.timer.Stop() </span><span class="cov8" title="1">{
                                entry.backoffState.timer = nil
                                backoffCancelled = true
                        }</span>
                }
                <span class="cov8" title="1">dc.deleteAndcleanup(key, entry)</span>
        }
        <span class="cov8" title="1">dc.maxSize = size
        return backoffCancelled</span>
}

// evictExpiredEntries sweeps through the cache and deletes expired entries. An
// expired entry is one for which both the `expiryTime` and `backoffExpiryTime`
// fields are in the past.
//
// The return value indicates if any expired entries were evicted.
//
// The LB policy invokes this method periodically to purge expired entries.
func (dc *dataCache) evictExpiredEntries() (evicted bool) <span class="cov8" title="1">{
        if dc.shutdown.HasFired() </span><span class="cov0" title="0">{
                return false
        }</span>

        <span class="cov8" title="1">evicted = false
        dc.keys.iterateAndRun(func(key cacheKey) </span><span class="cov8" title="1">{
                entry, ok := dc.entries[key]
                if !ok </span><span class="cov0" title="0">{
                        // This should never happen.
                        dc.logger.Errorf("cacheKey %+v not found in the cache while attempting to perform periodic cleanup of expired entries", key)
                        return
                }</span>

                // Only evict entries for which both the data expiration time and
                // backoff expiration time fields are in the past.
                <span class="cov8" title="1">now := time.Now()
                if entry.expiryTime.After(now) || entry.backoffExpiryTime.After(now) </span><span class="cov8" title="1">{
                        return
                }</span>
                <span class="cov8" title="1">evicted = true
                dc.deleteAndcleanup(key, entry)</span>
        })
        <span class="cov8" title="1">return evicted</span>
}

// resetBackoffState sweeps through the cache and for entries with a backoff
// state, the backoff timer is cancelled and the backoff state is reset. The
// return value indicates if any entries were mutated in this fashion.
//
// The LB policy invokes this method when the control channel moves from READY
// to TRANSIENT_FAILURE back to READY. See `monitorConnectivityState` method on
// the `controlChannel` type for more details.
func (dc *dataCache) resetBackoffState(newBackoffState *backoffState) (backoffReset bool) <span class="cov8" title="1">{
        if dc.shutdown.HasFired() </span><span class="cov0" title="0">{
                return false
        }</span>

        <span class="cov8" title="1">backoffReset = false
        dc.keys.iterateAndRun(func(key cacheKey) </span><span class="cov8" title="1">{
                entry, ok := dc.entries[key]
                if !ok </span><span class="cov0" title="0">{
                        // This should never happen.
                        dc.logger.Errorf("cacheKey %+v not found in the cache while attempting to perform periodic cleanup of expired entries", key)
                        return
                }</span>

                <span class="cov8" title="1">if entry.backoffState == nil </span><span class="cov8" title="1">{
                        return
                }</span>
                <span class="cov8" title="1">if entry.backoffState.timer != nil </span><span class="cov8" title="1">{
                        entry.backoffState.timer.Stop()
                        entry.backoffState.timer = nil
                }</span>
                <span class="cov8" title="1">entry.backoffState = &amp;backoffState{bs: newBackoffState.bs}
                entry.backoffTime = time.Time{}
                entry.backoffExpiryTime = time.Time{}
                backoffReset = true</span>
        })
        <span class="cov8" title="1">return backoffReset</span>
}

// addEntry adds a cache entry for the given key.
//
// Return value backoffCancelled indicates if a cache entry with a valid backoff
// timer was evicted to make space for the current entry. This is important to
// the RLS LB policy which would send a new picker on the channel to re-process
// any RPCs queued as a result of this backoff timer.
//
// Return value ok indicates if entry was successfully added to the cache.
func (dc *dataCache) addEntry(key cacheKey, entry *cacheEntry) (backoffCancelled bool, ok bool) <span class="cov8" title="1">{
        if dc.shutdown.HasFired() </span><span class="cov8" title="1">{
                return false, false
        }</span>

        // Handle the extremely unlikely case that a single entry is bigger than the
        // size of the cache.
        <span class="cov8" title="1">if entry.size &gt; dc.maxSize </span><span class="cov0" title="0">{
                return false, false
        }</span>
        <span class="cov8" title="1">dc.entries[key] = entry
        dc.currentSize += entry.size
        dc.keys.addEntry(key)
        // If the new entry makes the cache go over its configured size, remove some
        // old entries.
        if dc.currentSize &gt; dc.maxSize </span><span class="cov8" title="1">{
                backoffCancelled = dc.resize(dc.maxSize)
        }</span>
        <span class="cov8" title="1">return backoffCancelled, true</span>
}

// updateEntrySize updates the size of a cache entry and the current size of the
// data cache. An entry's size can change upon receipt of an RLS response.
func (dc *dataCache) updateEntrySize(entry *cacheEntry, newSize int64) <span class="cov8" title="1">{
        dc.currentSize -= entry.size
        entry.size = newSize
        dc.currentSize += entry.size
}</span>

func (dc *dataCache) getEntry(key cacheKey) *cacheEntry <span class="cov8" title="1">{
        if dc.shutdown.HasFired() </span><span class="cov8" title="1">{
                return nil
        }</span>

        <span class="cov8" title="1">entry, ok := dc.entries[key]
        if !ok </span><span class="cov8" title="1">{
                return nil
        }</span>
        <span class="cov8" title="1">dc.keys.makeRecent(key)
        return entry</span>
}

func (dc *dataCache) removeEntryForTesting(key cacheKey) <span class="cov8" title="1">{
        entry, ok := dc.entries[key]
        if !ok </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov8" title="1">dc.deleteAndcleanup(key, entry)</span>
}

// deleteAndCleanup performs actions required at the time of deleting an entry
// from the data cache.
// - the entry is removed from the map of entries
// - current size of the data cache is update
// - the key is removed from the LRU
// - onEvict is invoked in a separate goroutine
func (dc *dataCache) deleteAndcleanup(key cacheKey, entry *cacheEntry) <span class="cov8" title="1">{
        delete(dc.entries, key)
        dc.currentSize -= entry.size
        dc.keys.removeEntry(key)
        if entry.onEvict != nil </span><span class="cov0" title="0">{
                go entry.onEvict()
        }</span>
}

func (dc *dataCache) stop() <span class="cov8" title="1">{
        dc.keys.iterateAndRun(func(key cacheKey) </span><span class="cov8" title="1">{
                entry, ok := dc.entries[key]
                if !ok </span><span class="cov0" title="0">{
                        // This should never happen.
                        dc.logger.Errorf("cacheKey %+v not found in the cache while shutting down", key)
                        return
                }</span>
                <span class="cov8" title="1">dc.deleteAndcleanup(key, entry)</span>
        })
        <span class="cov8" title="1">dc.shutdown.Fire()</span>
}
</pre>
		
		<pre class="file" id="file16" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package rls

import (
        "fmt"
        "sync/atomic"
        "unsafe"

        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/balancer/base"
        "google.golang.org/grpc/connectivity"
        internalgrpclog "google.golang.org/grpc/internal/grpclog"
)

// childPolicyWrapper is a reference counted wrapper around a child policy.
//
// The LB policy maintains a map of these wrappers keyed by the target returned
// by RLS. When a target is seen for the first time, a child policy wrapper is
// created for it and the wrapper is added to the child policy map. Each entry
// in the data cache holds references to the corresponding child policy
// wrappers. The LB policy also holds a reference to the child policy wrapper
// for the default target specified in the LB Policy Configuration
//
// When a cache entry is evicted, it releases references to the child policy
// wrappers that it contains. When all references have been released, the
// wrapper is removed from the child policy map and is destroyed.
//
// The child policy wrapper also caches the connectivity state and most recent
// picker from the child policy. Once the child policy wrapper reports
// TRANSIENT_FAILURE, it will continue reporting that state until it goes READY;
// transitions from TRANSIENT_FAILURE to CONNECTING are ignored.
//
// Whenever a child policy wrapper changes its connectivity state, the LB policy
// returns a new picker to the channel, since the channel may need to re-process
// the picks for queued RPCs.
//
// It is not safe for concurrent access.
type childPolicyWrapper struct {
        logger *internalgrpclog.PrefixLogger
        target string // RLS target corresponding to this child policy.
        refCnt int    // Reference count.

        // Balancer state reported by the child policy. The RLS LB policy maintains
        // these child policies in a BalancerGroup. The state reported by the child
        // policy is pushed to the state aggregator (which is also implemented by the
        // RLS LB policy) and cached here. See handleChildPolicyStateUpdate() for
        // details on how the state aggregation is performed.
        //
        // While this field is written to by the LB policy, it is read by the picker
        // at Pick time. Making this an atomic to enable the picker to read this value
        // without a mutex.
        state unsafe.Pointer // *balancer.State
}

// newChildPolicyWrapper creates a child policy wrapper for the given target,
// and is initialized with one reference and starts off in CONNECTING state.
func newChildPolicyWrapper(target string) *childPolicyWrapper <span class="cov8" title="1">{
        c := &amp;childPolicyWrapper{
                target: target,
                refCnt: 1,
                state: unsafe.Pointer(&amp;balancer.State{
                        ConnectivityState: connectivity.Connecting,
                        Picker:            base.NewErrPicker(balancer.ErrNoSubConnAvailable),
                }),
        }
        c.logger = internalgrpclog.NewPrefixLogger(logger, fmt.Sprintf("[rls-child-policy-wrapper %s %p] ", c.target, c))
        c.logger.Infof("Created")
        return c
}</span>

// acquireRef increments the reference count on the child policy wrapper.
func (c *childPolicyWrapper) acquireRef() <span class="cov8" title="1">{
        c.refCnt++
}</span>

// releaseRef decrements the reference count on the child policy wrapper. The
// return value indicates whether the released reference was the last one.
func (c *childPolicyWrapper) releaseRef() bool <span class="cov8" title="1">{
        c.refCnt--
        return c.refCnt == 0
}</span>

// lamify causes the child policy wrapper to return a picker which will always
// fail requests. This is used when the wrapper runs into errors when trying to
// build and parse the child policy configuration.
func (c *childPolicyWrapper) lamify(err error) <span class="cov8" title="1">{
        c.logger.Warningf("Entering lame mode: %v", err)
        atomic.StorePointer(&amp;c.state, unsafe.Pointer(&amp;balancer.State{
                ConnectivityState: connectivity.TransientFailure,
                Picker:            base.NewErrPicker(err),
        }))
}</span>
</pre>
		
		<pre class="file" id="file17" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package rls

import (
        "bytes"
        "encoding/json"
        "fmt"
        "net/url"
        "time"

        "github.com/golang/protobuf/ptypes"
        durationpb "github.com/golang/protobuf/ptypes/duration"
        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/balancer/rls/internal/keys"
        "google.golang.org/grpc/internal"
        "google.golang.org/grpc/internal/pretty"
        rlspb "google.golang.org/grpc/internal/proto/grpc_lookup_v1"
        "google.golang.org/grpc/resolver"
        "google.golang.org/grpc/serviceconfig"
        "google.golang.org/protobuf/encoding/protojson"
)

const (
        // Default max_age if not specified (or greater than this value) in the
        // service config.
        maxMaxAge = 5 * time.Minute
        // Upper limit for cache_size since we don't fully trust the service config.
        maxCacheSize = 5 * 1024 * 1024 * 8 // 5MB in bytes
        // Default lookup_service_timeout if not specified in the service config.
        defaultLookupServiceTimeout = 10 * time.Second
        // Default value for targetNameField in the child policy config during
        // service config validation.
        dummyChildPolicyTarget = "target_name_to_be_filled_in_later"
)

// lbConfig is the internal representation of the RLS LB policy's config.
type lbConfig struct {
        serviceconfig.LoadBalancingConfig

        cacheSizeBytes       int64 // Keep this field 64-bit aligned.
        kbMap                keys.BuilderMap
        lookupService        string
        lookupServiceTimeout time.Duration
        maxAge               time.Duration
        staleAge             time.Duration
        defaultTarget        string

        childPolicyName             string
        childPolicyConfig           map[string]json.RawMessage
        childPolicyTargetField      string
        controlChannelServiceConfig string
}

func (lbCfg *lbConfig) Equal(other *lbConfig) bool <span class="cov8" title="1">{
        return lbCfg.kbMap.Equal(other.kbMap) &amp;&amp;
                lbCfg.lookupService == other.lookupService &amp;&amp;
                lbCfg.lookupServiceTimeout == other.lookupServiceTimeout &amp;&amp;
                lbCfg.maxAge == other.maxAge &amp;&amp;
                lbCfg.staleAge == other.staleAge &amp;&amp;
                lbCfg.cacheSizeBytes == other.cacheSizeBytes &amp;&amp;
                lbCfg.defaultTarget == other.defaultTarget &amp;&amp;
                lbCfg.childPolicyName == other.childPolicyName &amp;&amp;
                lbCfg.childPolicyTargetField == other.childPolicyTargetField &amp;&amp;
                lbCfg.controlChannelServiceConfig == other.controlChannelServiceConfig &amp;&amp;
                childPolicyConfigEqual(lbCfg.childPolicyConfig, other.childPolicyConfig)
}</span>

func childPolicyConfigEqual(a, b map[string]json.RawMessage) bool <span class="cov8" title="1">{
        if (b == nil) != (a == nil) </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov8" title="1">if len(b) != len(a) </span><span class="cov8" title="1">{
                return false
        }</span>
        <span class="cov8" title="1">for k, jsonA := range a </span><span class="cov8" title="1">{
                jsonB, ok := b[k]
                if !ok </span><span class="cov0" title="0">{
                        return false
                }</span>
                <span class="cov8" title="1">if !bytes.Equal(jsonA, jsonB) </span><span class="cov8" title="1">{
                        return false
                }</span>
        }
        <span class="cov8" title="1">return true</span>
}

// This struct resembles the JSON representation of the loadBalancing config
// and makes it easier to unmarshal.
type lbConfigJSON struct {
        RouteLookupConfig                json.RawMessage
        RouteLookupChannelServiceConfig  json.RawMessage
        ChildPolicy                      []map[string]json.RawMessage
        ChildPolicyConfigTargetFieldName string
}

// ParseConfig parses the JSON load balancer config provided into an
// internal form or returns an error if the config is invalid.
//
// When parsing a config update, the following validations are performed:
// - routeLookupConfig:
//   - grpc_keybuilders field:
//     - must have at least one entry
//     - must not have two entries with the same `Name`
//     - within each entry:
//       - must have at least one `Name`
//       - must not have a `Name` with the `service` field unset or empty
//       - within each `headers` entry:
//         - must not have `required_match` set
//         - must not have `key` unset or empty
//       - across all `headers`, `constant_keys` and `extra_keys` fields:
//         - must not have the same `key` specified twice
//         - no `key` must be the empty string
//   - `lookup_service` field must be set and and must parse as a target URI
//   - if `max_age` &gt; 5m, it should be set to 5 minutes
//   - if `stale_age` &gt; `max_age`, ignore it
//   - if `stale_age` is set, then `max_age` must also be set
//   - ignore `valid_targets` field
//   - `cache_size_bytes` field must have a value greater than 0, and if its
//      value is greater than 5M, we cap it at 5M
// - routeLookupChannelServiceConfig:
//   - if specified, must parse as valid service config
// - childPolicy:
//   - must find a valid child policy with a valid config
// - childPolicyConfigTargetFieldName:
//   - must be set and non-empty
func (rlsBB) ParseConfig(c json.RawMessage) (serviceconfig.LoadBalancingConfig, error) <span class="cov8" title="1">{
        logger.Infof("Received JSON service config: %v", pretty.ToJSON(c))
        cfgJSON := &amp;lbConfigJSON{}
        if err := json.Unmarshal(c, cfgJSON); err != nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("rls: json unmarshal failed for service config %+v: %v", string(c), err)
        }</span>

        <span class="cov8" title="1">m := protojson.UnmarshalOptions{DiscardUnknown: true}
        rlsProto := &amp;rlspb.RouteLookupConfig{}
        if err := m.Unmarshal(cfgJSON.RouteLookupConfig, rlsProto); err != nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("rls: bad RouteLookupConfig proto %+v: %v", string(cfgJSON.RouteLookupConfig), err)
        }</span>
        <span class="cov8" title="1">lbCfg, err := parseRLSProto(rlsProto)
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>

        <span class="cov8" title="1">if sc := string(cfgJSON.RouteLookupChannelServiceConfig); sc != "" </span><span class="cov8" title="1">{
                parsed := internal.ParseServiceConfig.(func(string) *serviceconfig.ParseResult)(sc)
                if parsed.Err != nil </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("rls: bad control channel service config %q: %v", sc, parsed.Err)
                }</span>
                <span class="cov8" title="1">lbCfg.controlChannelServiceConfig = sc</span>
        }

        <span class="cov8" title="1">if cfgJSON.ChildPolicyConfigTargetFieldName == "" </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("rls: childPolicyConfigTargetFieldName field is not set in service config %+v", string(c))
        }</span>
        <span class="cov8" title="1">name, config, err := parseChildPolicyConfigs(cfgJSON.ChildPolicy, cfgJSON.ChildPolicyConfigTargetFieldName)
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">lbCfg.childPolicyName = name
        lbCfg.childPolicyConfig = config
        lbCfg.childPolicyTargetField = cfgJSON.ChildPolicyConfigTargetFieldName
        return lbCfg, nil</span>
}

func parseRLSProto(rlsProto *rlspb.RouteLookupConfig) (*lbConfig, error) <span class="cov8" title="1">{
        // Validations specified on the `grpc_keybuilders` field are performed here.
        kbMap, err := keys.MakeBuilderMap(rlsProto)
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>

        // `lookup_service` field must be set and and must parse as a target URI.
        <span class="cov8" title="1">lookupService := rlsProto.GetLookupService()
        if lookupService == "" </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("rls: empty lookup_service in route lookup config %+v", rlsProto)
        }</span>
        <span class="cov8" title="1">parsedTarget, err := url.Parse(lookupService)
        if err != nil </span><span class="cov8" title="1">{
                // url.Parse() fails if scheme is missing. Retry with default scheme.
                parsedTarget, err = url.Parse(resolver.GetDefaultScheme() + ":///" + lookupService)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("rls: invalid target URI in lookup_service %s", lookupService)
                }</span>
        }
        <span class="cov8" title="1">if parsedTarget.Scheme == "" </span><span class="cov8" title="1">{
                parsedTarget.Scheme = resolver.GetDefaultScheme()
        }</span>
        <span class="cov8" title="1">if resolver.Get(parsedTarget.Scheme) == nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("rls: unregistered scheme in lookup_service %s", lookupService)
        }</span>

        <span class="cov8" title="1">lookupServiceTimeout, err := convertDuration(rlsProto.GetLookupServiceTimeout())
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("rls: failed to parse lookup_service_timeout in route lookup config %+v: %v", rlsProto, err)
        }</span>
        <span class="cov8" title="1">if lookupServiceTimeout == 0 </span><span class="cov8" title="1">{
                lookupServiceTimeout = defaultLookupServiceTimeout
        }</span>

        // Validations performed here:
        // - if `max_age` &gt; 5m, it should be set to 5 minutes
        // - if `stale_age` &gt; `max_age`, ignore it
        // - if `stale_age` is set, then `max_age` must also be set
        <span class="cov8" title="1">maxAge, err := convertDuration(rlsProto.GetMaxAge())
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("rls: failed to parse max_age in route lookup config %+v: %v", rlsProto, err)
        }</span>
        <span class="cov8" title="1">staleAge, err := convertDuration(rlsProto.GetStaleAge())
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("rls: failed to parse staleAge in route lookup config %+v: %v", rlsProto, err)
        }</span>
        <span class="cov8" title="1">if staleAge != 0 &amp;&amp; maxAge == 0 </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("rls: stale_age is set, but max_age is not in route lookup config %+v", rlsProto)
        }</span>
        <span class="cov8" title="1">if staleAge &gt;= maxAge </span><span class="cov8" title="1">{
                logger.Infof("rls: stale_age %v is not less than max_age %v, ignoring it", staleAge, maxAge)
                staleAge = 0
        }</span>
        <span class="cov8" title="1">if maxAge == 0 || maxAge &gt; maxMaxAge </span><span class="cov8" title="1">{
                logger.Infof("rls: max_age in route lookup config is %v, using %v", maxAge, maxMaxAge)
                maxAge = maxMaxAge
        }</span>

        // `cache_size_bytes` field must have a value greater than 0, and if its
        // value is greater than 5M, we cap it at 5M
        <span class="cov8" title="1">cacheSizeBytes := rlsProto.GetCacheSizeBytes()
        if cacheSizeBytes &lt;= 0 </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("rls: cache_size_bytes must be set to a non-zero value: %+v", rlsProto)
        }</span>
        <span class="cov8" title="1">if cacheSizeBytes &gt; maxCacheSize </span><span class="cov8" title="1">{
                logger.Info("rls: cache_size_bytes %v is too large, setting it to: %v", cacheSizeBytes, maxCacheSize)
                cacheSizeBytes = maxCacheSize
        }</span>
        <span class="cov8" title="1">return &amp;lbConfig{
                kbMap:                kbMap,
                lookupService:        lookupService,
                lookupServiceTimeout: lookupServiceTimeout,
                maxAge:               maxAge,
                staleAge:             staleAge,
                cacheSizeBytes:       cacheSizeBytes,
                defaultTarget:        rlsProto.GetDefaultTarget(),
        }, nil</span>
}

// parseChildPolicyConfigs iterates through the list of child policies and picks
// the first registered policy and validates its config.
func parseChildPolicyConfigs(childPolicies []map[string]json.RawMessage, targetFieldName string) (string, map[string]json.RawMessage, error) <span class="cov8" title="1">{
        for i, config := range childPolicies </span><span class="cov8" title="1">{
                if len(config) != 1 </span><span class="cov8" title="1">{
                        return "", nil, fmt.Errorf("rls: invalid childPolicy: entry %v does not contain exactly 1 policy/config pair: %q", i, config)
                }</span>

                <span class="cov8" title="1">var name string
                var rawCfg json.RawMessage
                for name, rawCfg = range config </span>{<span class="cov8" title="1">
                }</span>
                <span class="cov8" title="1">builder := balancer.Get(name)
                if builder == nil </span><span class="cov8" title="1">{
                        continue</span>
                }
                <span class="cov8" title="1">parser, ok := builder.(balancer.ConfigParser)
                if !ok </span><span class="cov0" title="0">{
                        return "", nil, fmt.Errorf("rls: childPolicy %q with config %q does not support config parsing", name, string(rawCfg))
                }</span>

                // To validate child policy configs we do the following:
                // - unmarshal the raw JSON bytes of the child policy config into a map
                // - add an entry with key set to `target_field_name` and a dummy value
                // - marshal the map back to JSON and parse the config using the parser
                // retrieved previously
                <span class="cov8" title="1">var childConfig map[string]json.RawMessage
                if err := json.Unmarshal(rawCfg, &amp;childConfig); err != nil </span><span class="cov0" title="0">{
                        return "", nil, fmt.Errorf("rls: json unmarshal failed for child policy config %q: %v", string(rawCfg), err)
                }</span>
                <span class="cov8" title="1">childConfig[targetFieldName], _ = json.Marshal(dummyChildPolicyTarget)
                jsonCfg, err := json.Marshal(childConfig)
                if err != nil </span><span class="cov0" title="0">{
                        return "", nil, fmt.Errorf("rls: json marshal failed for child policy config {%+v}: %v", childConfig, err)
                }</span>
                <span class="cov8" title="1">if _, err := parser.ParseConfig(jsonCfg); err != nil </span><span class="cov8" title="1">{
                        return "", nil, fmt.Errorf("rls: childPolicy config validation failed: %v", err)
                }</span>
                <span class="cov8" title="1">return name, childConfig, nil</span>
        }
        <span class="cov8" title="1">return "", nil, fmt.Errorf("rls: invalid childPolicy config: no supported policies found in %+v", childPolicies)</span>
}

func convertDuration(d *durationpb.Duration) (time.Duration, error) <span class="cov8" title="1">{
        if d == nil </span><span class="cov8" title="1">{
                return 0, nil
        }</span>
        <span class="cov8" title="1">return ptypes.Duration(d)</span>
}
</pre>
		
		<pre class="file" id="file18" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package rls

import (
        "context"
        "fmt"
        "time"

        "google.golang.org/grpc"
        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/balancer/rls/internal/adaptive"
        "google.golang.org/grpc/connectivity"
        "google.golang.org/grpc/credentials/insecure"
        "google.golang.org/grpc/internal"
        internalgrpclog "google.golang.org/grpc/internal/grpclog"
        "google.golang.org/grpc/internal/pretty"
        rlsgrpc "google.golang.org/grpc/internal/proto/grpc_lookup_v1"
        rlspb "google.golang.org/grpc/internal/proto/grpc_lookup_v1"
)

var newAdaptiveThrottler = func() adaptiveThrottler <span class="cov8" title="1">{ return adaptive.New() }</span>

type adaptiveThrottler interface {
        ShouldThrottle() bool
        RegisterBackendResponse(throttled bool)
}

// controlChannel is a wrapper around the gRPC channel to the RLS server
// specified in the service config.
type controlChannel struct {
        // rpcTimeout specifies the timeout for the RouteLookup RPC call. The LB
        // policy receives this value in its service config.
        rpcTimeout time.Duration
        // backToReadyFunc is a callback to be invoked when the connectivity state
        // changes from READY --&gt; TRANSIENT_FAILURE --&gt; READY.
        backToReadyFunc func()
        // throttler in an adaptive throttling implementation used to avoid
        // hammering the RLS service while it is overloaded or down.
        throttler adaptiveThrottler

        cc     *grpc.ClientConn
        client rlsgrpc.RouteLookupServiceClient
        logger *internalgrpclog.PrefixLogger
}

// newControlChannel creates a controlChannel to rlsServerName and uses
// serviceConfig, if non-empty, as the default service config for the underlying
// gRPC channel.
func newControlChannel(rlsServerName, serviceConfig string, rpcTimeout time.Duration, bOpts balancer.BuildOptions, backToReadyFunc func()) (*controlChannel, error) <span class="cov8" title="1">{
        ctrlCh := &amp;controlChannel{
                rpcTimeout:      rpcTimeout,
                backToReadyFunc: backToReadyFunc,
                throttler:       newAdaptiveThrottler(),
        }
        ctrlCh.logger = internalgrpclog.NewPrefixLogger(logger, fmt.Sprintf("[rls-control-channel %p] ", ctrlCh))

        dopts, err := ctrlCh.dialOpts(bOpts, serviceConfig)
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">ctrlCh.cc, err = grpc.Dial(rlsServerName, dopts...)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">ctrlCh.client = rlsgrpc.NewRouteLookupServiceClient(ctrlCh.cc)
        ctrlCh.logger.Infof("Control channel created to RLS server at: %v", rlsServerName)

        go ctrlCh.monitorConnectivityState()
        return ctrlCh, nil</span>
}

// dialOpts constructs the dial options for the control plane channel.
func (cc *controlChannel) dialOpts(bOpts balancer.BuildOptions, serviceConfig string) ([]grpc.DialOption, error) <span class="cov8" title="1">{
        // The control plane channel will use the same authority as the parent
        // channel for server authorization. This ensures that the identity of the
        // RLS server and the identity of the backends is the same, so if the RLS
        // config is injected by an attacker, it cannot cause leakage of private
        // information contained in headers set by the application.
        dopts := []grpc.DialOption{grpc.WithAuthority(bOpts.Authority)}
        if bOpts.Dialer != nil </span><span class="cov0" title="0">{
                dopts = append(dopts, grpc.WithContextDialer(bOpts.Dialer))
        }</span>

        // The control channel will use the channel credentials from the parent
        // channel, including any call creds associated with the channel creds.
        <span class="cov8" title="1">var credsOpt grpc.DialOption
        switch </span>{
        case bOpts.DialCreds != nil:<span class="cov8" title="1">
                credsOpt = grpc.WithTransportCredentials(bOpts.DialCreds.Clone())</span>
        case bOpts.CredsBundle != nil:<span class="cov8" title="1">
                // The "fallback" mode in google default credentials (which is the only
                // type of credentials we expect to be used with RLS) uses TLS/ALTS
                // creds for transport and uses the same call creds as that on the
                // parent bundle.
                bundle, err := bOpts.CredsBundle.NewWithMode(internal.CredsBundleModeFallback)
                if err != nil </span><span class="cov8" title="1">{
                        return nil, err
                }</span>
                <span class="cov8" title="1">credsOpt = grpc.WithCredentialsBundle(bundle)</span>
        default:<span class="cov8" title="1">
                cc.logger.Warningf("no credentials available, using Insecure")
                credsOpt = grpc.WithTransportCredentials(insecure.NewCredentials())</span>
        }
        <span class="cov8" title="1">dopts = append(dopts, credsOpt)

        // If the RLS LB policy's configuration specified a service config for the
        // control channel, use that and disable service config fetching via the name
        // resolver for the control channel.
        if serviceConfig != "" </span><span class="cov8" title="1">{
                cc.logger.Infof("Disabling service config from the name resolver and instead using: %s", serviceConfig)
                dopts = append(dopts, grpc.WithDisableServiceConfig(), grpc.WithDefaultServiceConfig(serviceConfig))
        }</span>

        <span class="cov8" title="1">return dopts, nil</span>
}

func (cc *controlChannel) monitorConnectivityState() <span class="cov8" title="1">{
        cc.logger.Infof("Starting connectivity state monitoring goroutine")
        // Since we use two mechanisms to deal with RLS server being down:
        //   - adaptive throttling for the channel as a whole
        //   - exponential backoff on a per-request basis
        // we need a way to avoid double-penalizing requests by counting failures
        // toward both mechanisms when the RLS server is unreachable.
        //
        // To accomplish this, we monitor the state of the control plane channel. If
        // the state has been TRANSIENT_FAILURE since the last time it was in state
        // READY, and it then transitions into state READY, we push on a channel
        // which is being read by the LB policy.
        //
        // The LB the policy will iterate through the cache to reset the backoff
        // timeouts in all cache entries. Specifically, this means that it will
        // reset the backoff state and cancel the pending backoff timer. Note that
        // when cancelling the backoff timer, just like when the backoff timer fires
        // normally, a new picker is returned to the channel, to force it to
        // re-process any wait-for-ready RPCs that may still be queued if we failed
        // them while we were in backoff. However, we should optimize this case by
        // returning only one new picker, regardless of how many backoff timers are
        // cancelled.

        // Using the background context is fine here since we check for the ClientConn
        // entering SHUTDOWN and return early in that case.
        ctx := context.Background()

        first := true
        for </span><span class="cov8" title="1">{
                // Wait for the control channel to become READY.
                for s := cc.cc.GetState(); s != connectivity.Ready; s = cc.cc.GetState() </span><span class="cov8" title="1">{
                        if s == connectivity.Shutdown </span><span class="cov8" title="1">{
                                return
                        }</span>
                        <span class="cov8" title="1">cc.cc.WaitForStateChange(ctx, s)</span>
                }
                <span class="cov8" title="1">cc.logger.Infof("Connectivity state is READY")

                if !first </span><span class="cov8" title="1">{
                        cc.logger.Infof("Control channel back to READY")
                        cc.backToReadyFunc()
                }</span>
                <span class="cov8" title="1">first = false

                // Wait for the control channel to move out of READY.
                cc.cc.WaitForStateChange(ctx, connectivity.Ready)
                if cc.cc.GetState() == connectivity.Shutdown </span><span class="cov8" title="1">{
                        return
                }</span>
                <span class="cov8" title="1">cc.logger.Infof("Connectivity state is %s", cc.cc.GetState())</span>
        }
}

func (cc *controlChannel) close() <span class="cov8" title="1">{
        cc.logger.Infof("Closing control channel")
        cc.cc.Close()
}</span>

type lookupCallback func(targets []string, headerData string, err error)

// lookup starts a RouteLookup RPC in a separate goroutine and returns the
// results (and error, if any) in the provided callback.
//
// The returned boolean indicates whether the request was throttled by the
// client-side adaptive throttling algorithm in which case the provided callback
// will not be invoked.
func (cc *controlChannel) lookup(reqKeys map[string]string, reason rlspb.RouteLookupRequest_Reason, staleHeaders string, cb lookupCallback) (throttled bool) <span class="cov8" title="1">{
        if cc.throttler.ShouldThrottle() </span><span class="cov8" title="1">{
                cc.logger.Infof("RLS request throttled by client-side adaptive throttling")
                return true
        }</span>
        <span class="cov8" title="1">go func() </span><span class="cov8" title="1">{
                req := &amp;rlspb.RouteLookupRequest{
                        TargetType:      "grpc",
                        KeyMap:          reqKeys,
                        Reason:          reason,
                        StaleHeaderData: staleHeaders,
                }
                cc.logger.Infof("Sending RLS request %+v", pretty.ToJSON(req))

                ctx, cancel := context.WithTimeout(context.Background(), cc.rpcTimeout)
                defer cancel()
                resp, err := cc.client.RouteLookup(ctx, req)
                cb(resp.GetTargets(), resp.GetHeaderData(), err)
        }</span>()
        <span class="cov8" title="1">return false</span>
}
</pre>
		
		<pre class="file" id="file19" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package adaptive provides functionality for adaptive client-side throttling.
package adaptive

import (
        "sync"
        "time"

        "google.golang.org/grpc/internal/grpcrand"
)

// For overriding in unittests.
var (
        timeNowFunc = func() time.Time <span class="cov8" title="1">{ return time.Now() }</span>
        randFunc    = func() float64 <span class="cov0" title="0">{ return grpcrand.Float64() }</span>
)

const (
        defaultDuration        = 30 * time.Second
        defaultBins            = 100
        defaultRatioForAccepts = 2.0
        defaultRequestsPadding = 8.0
)

// Throttler implements a client-side throttling recommendation system. All
// methods are safe for concurrent use by multiple goroutines.
//
// The throttler has the following knobs for which we will use defaults for
// now. If there is a need to make them configurable at a later point in time,
// support for the same will be added.
// * Duration: amount of recent history that will be taken into account for
//   making client-side throttling decisions. A default of 30 seconds is used.
// * Bins: number of bins to be used for bucketing historical data. A default
//   of 100 is used.
// * RatioForAccepts: ratio by which accepts are multiplied, typically a value
//   slightly larger than 1.0. This is used to make the throttler behave as if
//   the backend had accepted more requests than it actually has, which lets us
//   err on the side of sending to the backend more requests than we think it
//   will accept for the sake of speeding up the propagation of state. A
//   default of 2.0 is used.
// * RequestsPadding: is used to decrease the (client-side) throttling
//   probability in the low QPS regime (to speed up propagation of state), as
//   well as to safeguard against hitting a client-side throttling probability
//   of 100%. The weight of this value decreases as the number of requests in
//   recent history grows. A default of 8 is used.
//
// The adaptive throttler attempts to estimate the probability that a request
// will be throttled using recent history. Server requests (both throttled and
// accepted) are registered with the throttler (via the RegisterBackendResponse
// method), which then recommends client-side throttling (via the
// ShouldThrottle method) with probability given by:
// (requests - RatioForAccepts * accepts) / (requests + RequestsPadding)
type Throttler struct {
        ratioForAccepts float64
        requestsPadding float64

        // Number of total accepts and throttles in the lookback period.
        mu        sync.Mutex
        accepts   *lookback
        throttles *lookback
}

// New initializes a new adaptive throttler with the default values.
func New() *Throttler <span class="cov8" title="1">{
        return newWithArgs(defaultDuration, defaultBins, defaultRatioForAccepts, defaultRequestsPadding)
}</span>

// newWithArgs initializes a new adaptive throttler with the provided values.
// Used only in unittests.
func newWithArgs(duration time.Duration, bins int64, ratioForAccepts, requestsPadding float64) *Throttler <span class="cov8" title="1">{
        return &amp;Throttler{
                ratioForAccepts: ratioForAccepts,
                requestsPadding: requestsPadding,
                accepts:         newLookback(bins, duration),
                throttles:       newLookback(bins, duration),
        }
}</span>

// ShouldThrottle returns a probabilistic estimate of whether the server would
// throttle the next request. This should be called for every request before
// allowing it to hit the network. If the returned value is true, the request
// should be aborted immediately (as if it had been throttled by the server).
func (t *Throttler) ShouldThrottle() bool <span class="cov8" title="1">{
        randomProbability := randFunc()
        now := timeNowFunc()

        t.mu.Lock()
        defer t.mu.Unlock()

        accepts, throttles := float64(t.accepts.sum(now)), float64(t.throttles.sum(now))
        requests := accepts + throttles
        throttleProbability := (requests - t.ratioForAccepts*accepts) / (requests + t.requestsPadding)
        if throttleProbability &lt;= randomProbability </span><span class="cov8" title="1">{
                return false
        }</span>

        <span class="cov8" title="1">t.throttles.add(now, 1)
        return true</span>
}

// RegisterBackendResponse registers a response received from the backend for a
// request allowed by ShouldThrottle. This should be called for every response
// received from the backend (i.e., once for each request for which
// ShouldThrottle returned false).
func (t *Throttler) RegisterBackendResponse(throttled bool) <span class="cov8" title="1">{
        now := timeNowFunc()

        t.mu.Lock()
        if throttled </span><span class="cov8" title="1">{
                t.throttles.add(now, 1)
        }</span> else<span class="cov8" title="1"> {
                t.accepts.add(now, 1)
        }</span>
        <span class="cov8" title="1">t.mu.Unlock()</span>
}
</pre>
		
		<pre class="file" id="file20" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package adaptive

import "time"

// lookback implements a moving sum over an int64 timeline.
type lookback struct {
        bins  int64         // Number of bins to use for lookback.
        width time.Duration // Width of each bin.

        head  int64   // Absolute bin index (time * bins / duration) of the current head bin.
        total int64   // Sum over all the values in buf, within the lookback window behind head.
        buf   []int64 // Ring buffer for keeping track of the sum elements.
}

// newLookback creates a new lookback for the given duration with a set number
// of bins.
func newLookback(bins int64, duration time.Duration) *lookback <span class="cov8" title="1">{
        return &amp;lookback{
                bins:  bins,
                width: duration / time.Duration(bins),
                buf:   make([]int64, bins),
        }
}</span>

// add is used to increment the lookback sum.
func (l *lookback) add(t time.Time, v int64) <span class="cov8" title="1">{
        pos := l.advance(t)

        if (l.head - pos) &gt;= l.bins </span><span class="cov8" title="1">{
                // Do not increment counters if pos is more than bins behind head.
                return
        }</span>
        <span class="cov8" title="1">l.buf[pos%l.bins] += v
        l.total += v</span>
}

// sum returns the sum of the lookback buffer at the given time or head,
// whichever is greater.
func (l *lookback) sum(t time.Time) int64 <span class="cov8" title="1">{
        l.advance(t)
        return l.total
}</span>

// advance prepares the lookback buffer for calls to add() or sum() at time t.
// If head is greater than t then the lookback buffer will be untouched. The
// absolute bin index corresponding to t is returned. It will always be less
// than or equal to head.
func (l *lookback) advance(t time.Time) int64 <span class="cov8" title="1">{
        ch := l.head                               // Current head bin index.
        nh := t.UnixNano() / l.width.Nanoseconds() // New head bin index.

        if nh &lt;= ch </span><span class="cov8" title="1">{
                // Either head unchanged or clock jitter (time has moved backwards). Do
                // not advance.
                return nh
        }</span>

        <span class="cov8" title="1">jmax := min(l.bins, nh-ch)
        for j := int64(0); j &lt; jmax; j++ </span><span class="cov8" title="1">{
                i := (ch + j + 1) % l.bins
                l.total -= l.buf[i]
                l.buf[i] = 0
        }</span>
        <span class="cov8" title="1">l.head = nh
        return nh</span>
}

func min(x int64, y int64) int64 <span class="cov8" title="1">{
        if x &lt; y </span><span class="cov8" title="1">{
                return x
        }</span>
        <span class="cov8" title="1">return y</span>
}
</pre>
		
		<pre class="file" id="file21" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package keys provides functionality required to build RLS request keys.
package keys

import (
        "errors"
        "fmt"
        "sort"
        "strings"

        rlspb "google.golang.org/grpc/internal/proto/grpc_lookup_v1"
        "google.golang.org/grpc/metadata"
)

// BuilderMap maps from request path to the key builder for that path.
type BuilderMap map[string]builder

// MakeBuilderMap parses the provided RouteLookupConfig proto and returns a map
// from paths to key builders.
func MakeBuilderMap(cfg *rlspb.RouteLookupConfig) (BuilderMap, error) <span class="cov8" title="1">{
        kbs := cfg.GetGrpcKeybuilders()
        if len(kbs) == 0 </span><span class="cov8" title="1">{
                return nil, errors.New("rls: RouteLookupConfig does not contain any GrpcKeyBuilder")
        }</span>

        <span class="cov8" title="1">bm := make(map[string]builder)
        for _, kb := range kbs </span><span class="cov8" title="1">{
                // Extract keys from `headers`, `constant_keys` and `extra_keys` fields
                // and populate appropriate values in the builder struct. Also ensure
                // that keys are not repeated.
                var matchers []matcher
                seenKeys := make(map[string]bool)
                constantKeys := kb.GetConstantKeys()
                for k := range kb.GetConstantKeys() </span><span class="cov8" title="1">{
                        seenKeys[k] = true
                }</span>
                <span class="cov8" title="1">for _, h := range kb.GetHeaders() </span><span class="cov8" title="1">{
                        if h.GetRequiredMatch() </span><span class="cov8" title="1">{
                                return nil, fmt.Errorf("rls: GrpcKeyBuilder in RouteLookupConfig has required_match field set {%+v}", kbs)
                        }</span>
                        <span class="cov8" title="1">key := h.GetKey()
                        if seenKeys[key] </span><span class="cov8" title="1">{
                                return nil, fmt.Errorf("rls: GrpcKeyBuilder in RouteLookupConfig contains repeated key %q across headers, constant_keys and extra_keys {%+v}", key, kbs)
                        }</span>
                        <span class="cov8" title="1">seenKeys[key] = true
                        matchers = append(matchers, matcher{key: h.GetKey(), names: h.GetNames()})</span>
                }
                <span class="cov8" title="1">if seenKeys[kb.GetExtraKeys().GetHost()] </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("rls: GrpcKeyBuilder in RouteLookupConfig contains repeated key %q in extra_keys from constant_keys or headers {%+v}", kb.GetExtraKeys().GetHost(), kbs)
                }</span>
                <span class="cov8" title="1">if seenKeys[kb.GetExtraKeys().GetService()] </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("rls: GrpcKeyBuilder in RouteLookupConfig contains repeated key %q in extra_keys from constant_keys or headers {%+v}", kb.GetExtraKeys().GetService(), kbs)
                }</span>
                <span class="cov8" title="1">if seenKeys[kb.GetExtraKeys().GetMethod()] </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("rls: GrpcKeyBuilder in RouteLookupConfig contains repeated key %q in extra_keys from constant_keys or headers {%+v}", kb.GetExtraKeys().GetMethod(), kbs)
                }</span>
                <span class="cov8" title="1">b := builder{
                        headerKeys:   matchers,
                        constantKeys: constantKeys,
                        hostKey:      kb.GetExtraKeys().GetHost(),
                        serviceKey:   kb.GetExtraKeys().GetService(),
                        methodKey:    kb.GetExtraKeys().GetMethod(),
                }

                // Store the builder created above in the BuilderMap based on the value
                // of the `Names` field, which wraps incoming request's service and
                // method. Also, ensure that there are no repeated `Names` field.
                names := kb.GetNames()
                if len(names) == 0 </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("rls: GrpcKeyBuilder in RouteLookupConfig does not contain any Name {%+v}", kbs)
                }</span>
                <span class="cov8" title="1">for _, name := range names </span><span class="cov8" title="1">{
                        if name.GetService() == "" </span><span class="cov8" title="1">{
                                return nil, fmt.Errorf("rls: GrpcKeyBuilder in RouteLookupConfig contains a Name field with no Service {%+v}", kbs)
                        }</span>
                        <span class="cov8" title="1">if strings.Contains(name.GetMethod(), `/`) </span><span class="cov8" title="1">{
                                return nil, fmt.Errorf("rls: GrpcKeyBuilder in RouteLookupConfig contains a method with a slash {%+v}", kbs)
                        }</span>
                        <span class="cov8" title="1">path := "/" + name.GetService() + "/" + name.GetMethod()
                        if _, ok := bm[path]; ok </span><span class="cov8" title="1">{
                                return nil, fmt.Errorf("rls: GrpcKeyBuilder in RouteLookupConfig contains repeated Name field {%+v}", kbs)
                        }</span>
                        <span class="cov8" title="1">bm[path] = b</span>
                }
        }
        <span class="cov8" title="1">return bm, nil</span>
}

// KeyMap represents the RLS keys to be used for a request.
type KeyMap struct {
        // Map is the representation of an RLS key as a Go map. This is used when
        // an actual RLS request is to be sent out on the wire, since the
        // RouteLookupRequest proto expects a Go map.
        Map map[string]string
        // Str is the representation of an RLS key as a string, sorted by keys.
        // Since the RLS keys are part of the cache key in the request cache
        // maintained by the RLS balancer, and Go maps cannot be used as keys for
        // Go maps (the cache is implemented as a map), we need a stringified
        // version of it.
        Str string
}

// RLSKey builds the RLS keys to be used for the given request, identified by
// the request path and the request headers stored in metadata.
func (bm BuilderMap) RLSKey(md metadata.MD, host, path string) KeyMap <span class="cov8" title="1">{
        // The path passed in is of the form "/service/method". The keyBuilderMap is
        // indexed with keys of the form "/service/" or "/service/method". The service
        // that we set in the keyMap (to be sent out in the RLS request) should not
        // include any slashes though.
        i := strings.LastIndex(path, "/")
        service, method := path[:i+1], path[i+1:]
        b, ok := bm[path]
        if !ok </span><span class="cov8" title="1">{
                b, ok = bm[service]
                if !ok </span><span class="cov8" title="1">{
                        return KeyMap{}
                }</span>
        }

        <span class="cov8" title="1">kvMap := b.buildHeaderKeys(md)
        if b.hostKey != "" </span><span class="cov8" title="1">{
                kvMap[b.hostKey] = host
        }</span>
        <span class="cov8" title="1">if b.serviceKey != "" </span><span class="cov8" title="1">{
                kvMap[b.serviceKey] = strings.Trim(service, "/")
        }</span>
        <span class="cov8" title="1">if b.methodKey != "" </span><span class="cov8" title="1">{
                kvMap[b.methodKey] = method
        }</span>
        <span class="cov8" title="1">for k, v := range b.constantKeys </span><span class="cov8" title="1">{
                kvMap[k] = v
        }</span>
        <span class="cov8" title="1">return KeyMap{Map: kvMap, Str: mapToString(kvMap)}</span>
}

// Equal reports whether bm and am represent equivalent BuilderMaps.
func (bm BuilderMap) Equal(am BuilderMap) bool <span class="cov8" title="1">{
        if (bm == nil) != (am == nil) </span><span class="cov8" title="1">{
                return false
        }</span>
        <span class="cov8" title="1">if len(bm) != len(am) </span><span class="cov8" title="1">{
                return false
        }</span>

        <span class="cov8" title="1">for key, bBuilder := range bm </span><span class="cov8" title="1">{
                aBuilder, ok := am[key]
                if !ok </span><span class="cov8" title="1">{
                        return false
                }</span>
                <span class="cov8" title="1">if !bBuilder.Equal(aBuilder) </span><span class="cov8" title="1">{
                        return false
                }</span>
        }
        <span class="cov8" title="1">return true</span>
}

// builder provides the actual functionality of building RLS keys.
type builder struct {
        headerKeys   []matcher
        constantKeys map[string]string
        // The following keys mirror corresponding fields in `extra_keys`.
        hostKey    string
        serviceKey string
        methodKey  string
}

// Equal reports whether b and a represent equivalent key builders.
func (b builder) Equal(a builder) bool <span class="cov8" title="1">{
        if len(b.headerKeys) != len(a.headerKeys) </span><span class="cov8" title="1">{
                return false
        }</span>
        // Protobuf serialization maintains the order of repeated fields. Matchers
        // are specified as a repeated field inside the KeyBuilder proto. If the
        // order changes, it means that the order in the protobuf changed. We report
        // this case as not being equal even though the builders could possible be
        // functionally equal.
        <span class="cov8" title="1">for i, bMatcher := range b.headerKeys </span><span class="cov8" title="1">{
                aMatcher := a.headerKeys[i]
                if !bMatcher.Equal(aMatcher) </span><span class="cov8" title="1">{
                        return false
                }</span>
        }

        <span class="cov8" title="1">if len(b.constantKeys) != len(a.constantKeys) </span><span class="cov8" title="1">{
                return false
        }</span>
        <span class="cov8" title="1">for k, v := range b.constantKeys </span><span class="cov8" title="1">{
                if a.constantKeys[k] != v </span><span class="cov8" title="1">{
                        return false
                }</span>
        }

        <span class="cov8" title="1">return b.hostKey == a.hostKey &amp;&amp; b.serviceKey == a.serviceKey &amp;&amp; b.methodKey == a.methodKey</span>
}

// matcher helps extract a key from request headers based on a given name.
type matcher struct {
        // The key used in the keyMap sent as part of the RLS request.
        key string
        // List of header names which can supply the value for this key.
        names []string
}

// Equal reports if m and are are equivalent headerKeys.
func (m matcher) Equal(a matcher) bool <span class="cov8" title="1">{
        if m.key != a.key </span><span class="cov8" title="1">{
                return false
        }</span>
        <span class="cov8" title="1">if len(m.names) != len(a.names) </span><span class="cov8" title="1">{
                return false
        }</span>
        <span class="cov8" title="1">for i := 0; i &lt; len(m.names); i++ </span><span class="cov8" title="1">{
                if m.names[i] != a.names[i] </span><span class="cov8" title="1">{
                        return false
                }</span>
        }
        <span class="cov8" title="1">return true</span>
}

func (b builder) buildHeaderKeys(md metadata.MD) map[string]string <span class="cov8" title="1">{
        kvMap := make(map[string]string)
        if len(md) == 0 </span><span class="cov0" title="0">{
                return kvMap
        }</span>
        <span class="cov8" title="1">for _, m := range b.headerKeys </span><span class="cov8" title="1">{
                for _, name := range m.names </span><span class="cov8" title="1">{
                        if vals := md.Get(name); vals != nil </span><span class="cov8" title="1">{
                                kvMap[m.key] = strings.Join(vals, ",")
                                break</span>
                        }
                }
        }
        <span class="cov8" title="1">return kvMap</span>
}

func mapToString(kv map[string]string) string <span class="cov8" title="1">{
        keys := make([]string, 0, len(kv))
        for k := range kv </span><span class="cov8" title="1">{
                keys = append(keys, k)
        }</span>
        <span class="cov8" title="1">sort.Strings(keys)
        var sb strings.Builder
        for i, k := range keys </span><span class="cov8" title="1">{
                if i != 0 </span><span class="cov8" title="1">{
                        fmt.Fprint(&amp;sb, ",")
                }</span>
                <span class="cov8" title="1">fmt.Fprintf(&amp;sb, "%s=%s", k, kv[k])</span>
        }
        <span class="cov8" title="1">return sb.String()</span>
}
</pre>
		
		<pre class="file" id="file22" style="display: none">/*
 *
 * Copyright 2022 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package rls

import (
        "errors"
        "fmt"
        "strings"
        "sync/atomic"
        "time"

        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/balancer/rls/internal/keys"
        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/connectivity"
        internalgrpclog "google.golang.org/grpc/internal/grpclog"
        rlspb "google.golang.org/grpc/internal/proto/grpc_lookup_v1"
        "google.golang.org/grpc/metadata"
        "google.golang.org/grpc/status"
)

var (
        errRLSThrottled = errors.New("RLS call throttled at client side")

        // Function to compute data cache entry size.
        computeDataCacheEntrySize = dcEntrySize
)

// exitIdler wraps the only method on the BalancerGroup that the picker calls.
type exitIdler interface {
        ExitIdleOne(id string)
}

// rlsPicker selects the subConn to be used for a particular RPC. It does not
// manage subConns directly and delegates to pickers provided by child policies.
type rlsPicker struct {
        // The keyBuilder map used to generate RLS keys for the RPC. This is built
        // by the LB policy based on the received ServiceConfig.
        kbm keys.BuilderMap
        // Endpoint from the user's original dial target. Used to set the `host_key`
        // field in `extra_keys`.
        origEndpoint string

        lb *rlsBalancer

        // The picker is given its own copy of the below fields from the RLS LB policy
        // to avoid having to grab the mutex on the latter.
        defaultPolicy *childPolicyWrapper // Child policy for the default target.
        ctrlCh        *controlChannel     // Control channel to the RLS server.
        maxAge        time.Duration       // Cache max age from LB config.
        staleAge      time.Duration       // Cache stale age from LB config.
        bg            exitIdler
        logger        *internalgrpclog.PrefixLogger
}

// isFullMethodNameValid return true if name is of the form `/service/method`.
func isFullMethodNameValid(name string) bool <span class="cov8" title="1">{
        return strings.HasPrefix(name, "/") &amp;&amp; strings.Count(name, "/") == 2
}</span>

// Pick makes the routing decision for every outbound RPC.
func (p *rlsPicker) Pick(info balancer.PickInfo) (balancer.PickResult, error) <span class="cov8" title="1">{
        if name := info.FullMethodName; !isFullMethodNameValid(name) </span><span class="cov0" title="0">{
                return balancer.PickResult{}, fmt.Errorf("rls: method name %q is not of the form '/service/method", name)
        }</span>

        // Build the request's keys using the key builders from LB config.
        <span class="cov8" title="1">md, _ := metadata.FromOutgoingContext(info.Ctx)
        reqKeys := p.kbm.RLSKey(md, p.origEndpoint, info.FullMethodName)

        // Grab a read-lock to perform a cache lookup. If it so happens that we need
        // to write to the cache (if we have to send out an RLS request), we will
        // release the read-lock and acquire a write-lock.
        p.lb.cacheMu.RLock()

        // Lookup data cache and pending request map using request path and keys.
        cacheKey := cacheKey{path: info.FullMethodName, keys: reqKeys.Str}
        dcEntry := p.lb.dataCache.getEntry(cacheKey)
        pendingEntry := p.lb.pendingMap[cacheKey]
        now := time.Now()

        switch </span>{
        // No data cache entry. No pending request.
        case dcEntry == nil &amp;&amp; pendingEntry == nil:<span class="cov8" title="1">
                p.lb.cacheMu.RUnlock()
                bs := &amp;backoffState{bs: defaultBackoffStrategy}
                return p.sendRequestAndReturnPick(cacheKey, bs, reqKeys.Map, info)</span>

        // No data cache entry. Pending request exits.
        case dcEntry == nil &amp;&amp; pendingEntry != nil:<span class="cov8" title="1">
                p.lb.cacheMu.RUnlock()
                return balancer.PickResult{}, balancer.ErrNoSubConnAvailable</span>

        // Data cache hit. No pending request.
        case dcEntry != nil &amp;&amp; pendingEntry == nil:<span class="cov8" title="1">
                if dcEntry.expiryTime.After(now) </span><span class="cov8" title="1">{
                        if !dcEntry.staleTime.IsZero() &amp;&amp; dcEntry.staleTime.Before(now) &amp;&amp; dcEntry.backoffTime.Before(now) </span><span class="cov8" title="1">{
                                // Executing the proactive cache refresh in a goroutine simplifies
                                // acquiring and releasing of locks.
                                go func(bs *backoffState) </span><span class="cov8" title="1">{
                                        p.lb.cacheMu.Lock()
                                        // It is OK to ignore the return value which indicates if this request
                                        // was throttled. This is an attempt to proactively refresh the cache,
                                        // and it is OK for it to fail.
                                        p.sendRouteLookupRequest(cacheKey, bs, reqKeys.Map, rlspb.RouteLookupRequest_REASON_STALE, dcEntry.headerData)
                                        p.lb.cacheMu.Unlock()
                                }</span>(dcEntry.backoffState)
                        }
                        // Delegate to child policies.
                        <span class="cov8" title="1">res, err := p.delegateToChildPolicies(dcEntry, info)
                        p.lb.cacheMu.RUnlock()
                        return res, err</span>
                }

                // We get here only if the data cache entry has expired. If entry is in
                // backoff, delegate to default target or fail the pick.
                <span class="cov8" title="1">if dcEntry.backoffState != nil &amp;&amp; dcEntry.backoffTime.After(now) </span><span class="cov8" title="1">{
                        st := dcEntry.status
                        p.lb.cacheMu.RUnlock()

                        // Avoid propagating the status code received on control plane RPCs to the
                        // data plane which can lead to unexpected outcomes as we do not control
                        // the status code sent by the control plane. Propagating the status
                        // message received from the control plane is still fine, as it could be
                        // useful for debugging purposes.
                        return p.useDefaultPickIfPossible(info, status.Error(codes.Unavailable, fmt.Sprintf("most recent error from RLS server: %v", st.Error())))
                }</span>

                // We get here only if the entry has expired and is not in backoff.
                <span class="cov8" title="1">bs := *dcEntry.backoffState
                p.lb.cacheMu.RUnlock()
                return p.sendRequestAndReturnPick(cacheKey, &amp;bs, reqKeys.Map, info)</span>

        // Data cache hit. Pending request exists.
        default:<span class="cov8" title="1">
                if dcEntry.expiryTime.After(now) </span><span class="cov0" title="0">{
                        res, err := p.delegateToChildPolicies(dcEntry, info)
                        p.lb.cacheMu.RUnlock()
                        return res, err
                }</span>
                // Data cache entry has expired and pending request exists. Queue pick.
                <span class="cov8" title="1">p.lb.cacheMu.RUnlock()
                return balancer.PickResult{}, balancer.ErrNoSubConnAvailable</span>
        }
}

// delegateToChildPolicies is a helper function which iterates through the list
// of child policy wrappers in a cache entry and attempts to find a child policy
// to which this RPC can be routed to. If there is no child policy in READY
// state, we delegate to the first child policy arbitrarily.
//
// Caller must hold at least a read-lock on p.lb.cacheMu.
func (p *rlsPicker) delegateToChildPolicies(dcEntry *cacheEntry, info balancer.PickInfo) (balancer.PickResult, error) <span class="cov8" title="1">{
        for _, cpw := range dcEntry.childPolicyWrappers </span><span class="cov8" title="1">{
                ok, res, err := p.pickIfFeasible(cpw, info)
                if ok </span><span class="cov8" title="1">{
                        return res, err
                }</span>
        }
        <span class="cov8" title="1">if len(dcEntry.childPolicyWrappers) != 0 </span><span class="cov8" title="1">{
                state := (*balancer.State)(atomic.LoadPointer(&amp;dcEntry.childPolicyWrappers[0].state))
                return state.Picker.Pick(info)
        }</span>
        // In the unlikely event that we have a cache entry with no targets, we end up
        // queueing the RPC.
        <span class="cov8" title="1">return balancer.PickResult{}, balancer.ErrNoSubConnAvailable</span>
}

// sendRequestAndReturnPick is called to send out an RLS request on the control
// channel. Since sending out an RLS request entails creating an entry in the
// pending request map, this method needs to acquire the write-lock on the
// cache. This also means that the caller must release the read-lock that they
// could have been holding. This means that things could have happened in
// between and therefore a fresh lookup on the cache needs to be performed here
// with the write-lock and all cases need to be handled.
//
// Acquires the write-lock on the cache. Caller must not hold p.lb.cacheMu.
func (p *rlsPicker) sendRequestAndReturnPick(cacheKey cacheKey, bs *backoffState, reqKeys map[string]string, info balancer.PickInfo) (balancer.PickResult, error) <span class="cov8" title="1">{
        p.lb.cacheMu.Lock()
        defer p.lb.cacheMu.Unlock()

        // We need to perform another cache lookup to ensure that things haven't
        // changed since the last lookup.
        dcEntry := p.lb.dataCache.getEntry(cacheKey)
        pendingEntry := p.lb.pendingMap[cacheKey]

        // Existence of a pending map entry indicates that someone sent out a request
        // before us and the response is pending. Skip sending a new request.
        // Piggyback on the existing one by queueing the pick.
        if pendingEntry != nil </span><span class="cov0" title="0">{
                return balancer.PickResult{}, balancer.ErrNoSubConnAvailable
        }</span>

        // If no data cache entry exists, it means that no one jumped in front of us.
        // We need to send out an RLS request and queue the pick.
        <span class="cov8" title="1">if dcEntry == nil </span><span class="cov8" title="1">{
                throttled := p.sendRouteLookupRequest(cacheKey, bs, reqKeys, rlspb.RouteLookupRequest_REASON_MISS, "")
                if throttled </span><span class="cov8" title="1">{
                        return p.useDefaultPickIfPossible(info, errRLSThrottled)
                }</span>
                <span class="cov8" title="1">return balancer.PickResult{}, balancer.ErrNoSubConnAvailable</span>
        }

        // Existence of a data cache entry indicates either that someone sent out a
        // request before us and received a response, or we got here in the first
        // place because we found an expired entry in the data cache.
        <span class="cov8" title="1">now := time.Now()
        switch </span>{
        // Valid data cache entry. Delegate to its child policies.
        case dcEntry.expiryTime.After(now):<span class="cov0" title="0">
                return p.delegateToChildPolicies(dcEntry, info)</span>

        // Entry is in backoff. Delegate to default target or fail the pick.
        case dcEntry.backoffState != nil &amp;&amp; dcEntry.backoffTime.After(now):<span class="cov0" title="0">
                // Avoid propagating the status code received on control plane RPCs to the
                // data plane which can lead to unexpected outcomes as we do not control
                // the status code sent by the control plane. Propagating the status
                // message received from the control plane is still fine, as it could be
                // useful for debugging purposes.
                return p.useDefaultPickIfPossible(info, status.Error(codes.Unavailable, fmt.Sprintf("most recent error from RLS server: %v", dcEntry.status.Error())))</span>

        // Entry has expired, but is not in backoff. Send request and queue pick.
        default:<span class="cov8" title="1">
                throttled := p.sendRouteLookupRequest(cacheKey, bs, reqKeys, rlspb.RouteLookupRequest_REASON_MISS, "")
                if throttled </span><span class="cov8" title="1">{
                        return p.useDefaultPickIfPossible(info, errRLSThrottled)
                }</span>
                <span class="cov8" title="1">return balancer.PickResult{}, balancer.ErrNoSubConnAvailable</span>
        }
}

// useDefaultPickIfPossible is a helper method which delegates to the default
// target if one is configured, or fails the pick with the given error.
func (p *rlsPicker) useDefaultPickIfPossible(info balancer.PickInfo, errOnNoDefault error) (balancer.PickResult, error) <span class="cov8" title="1">{
        if p.defaultPolicy != nil </span><span class="cov8" title="1">{
                _, res, err := p.pickIfFeasible(p.defaultPolicy, info)
                return res, err
        }</span>
        <span class="cov8" title="1">return balancer.PickResult{}, errOnNoDefault</span>
}

// sendRouteLookupRequest adds an entry to the pending request map and sends out
// an RLS request using the passed in arguments. Returns a value indicating if
// the request was throttled by the client-side adaptive throttler.
//
// Caller must hold a write-lock on p.lb.cacheMu.
func (p *rlsPicker) sendRouteLookupRequest(cacheKey cacheKey, bs *backoffState, reqKeys map[string]string, reason rlspb.RouteLookupRequest_Reason, staleHeaders string) bool <span class="cov8" title="1">{
        if p.lb.pendingMap[cacheKey] != nil </span><span class="cov0" title="0">{
                return false
        }</span>

        <span class="cov8" title="1">p.lb.pendingMap[cacheKey] = bs
        throttled := p.ctrlCh.lookup(reqKeys, reason, staleHeaders, func(targets []string, headerData string, err error) </span><span class="cov8" title="1">{
                p.handleRouteLookupResponse(cacheKey, targets, headerData, err)
        }</span>)
        <span class="cov8" title="1">if throttled </span><span class="cov8" title="1">{
                delete(p.lb.pendingMap, cacheKey)
        }</span>
        <span class="cov8" title="1">return throttled</span>
}

// pickIfFeasible determines if a pick can be delegated to child policy based on
// its connectivity state.
// - If state is CONNECTING, the pick is to be queued
// - If state is IDLE, the child policy is instructed to exit idle, and the pick
//   is to be queued
// - If state is READY, pick it delegated to the child policy's picker
func (p *rlsPicker) pickIfFeasible(cpw *childPolicyWrapper, info balancer.PickInfo) (bool, balancer.PickResult, error) <span class="cov8" title="1">{
        state := (*balancer.State)(atomic.LoadPointer(&amp;cpw.state))
        switch state.ConnectivityState </span>{
        case connectivity.Connecting:<span class="cov8" title="1">
                return true, balancer.PickResult{}, balancer.ErrNoSubConnAvailable</span>
        case connectivity.Idle:<span class="cov8" title="1">
                p.bg.ExitIdleOne(cpw.target)
                return true, balancer.PickResult{}, balancer.ErrNoSubConnAvailable</span>
        case connectivity.Ready:<span class="cov8" title="1">
                r, e := state.Picker.Pick(info)
                return true, r, e</span>
        }
        <span class="cov8" title="1">return false, balancer.PickResult{}, balancer.ErrNoSubConnAvailable</span>
}

// handleRouteLookupResponse is the callback invoked by the control channel upon
// receipt of an RLS response. Modifies the data cache and pending requests map
// and sends a new picker.
//
// Acquires the write-lock on the cache. Caller must not hold p.lb.cacheMu.
func (p *rlsPicker) handleRouteLookupResponse(cacheKey cacheKey, targets []string, headerData string, err error) <span class="cov8" title="1">{
        p.logger.Infof("Received RLS response for key %+v with targets %+v, headerData %q, err: %v", cacheKey, targets, headerData, err)

        p.lb.cacheMu.Lock()
        defer func() </span><span class="cov8" title="1">{
                // Pending request map entry is unconditionally deleted since the request is
                // no longer pending.
                p.logger.Infof("Removing pending request entry for key %+v", cacheKey)
                delete(p.lb.pendingMap, cacheKey)
                p.lb.sendNewPicker()
                p.lb.cacheMu.Unlock()
        }</span>()

        // Lookup the data cache entry or create a new one.
        <span class="cov8" title="1">dcEntry := p.lb.dataCache.getEntry(cacheKey)
        if dcEntry == nil </span><span class="cov8" title="1">{
                dcEntry = &amp;cacheEntry{}
                if _, ok := p.lb.dataCache.addEntry(cacheKey, dcEntry); !ok </span><span class="cov8" title="1">{
                        // This is a very unlikely case where we are unable to add a
                        // data cache entry. Log and leave.
                        p.logger.Warningf("Failed to add data cache entry for %+v", cacheKey)
                        return
                }</span>
        }

        // For failed requests, the data cache entry is modified as follows:
        // - status is set to error returned from the control channel
        // - current backoff state is available in the pending entry
        //   - `retries` field is incremented and
        //   - backoff state is moved to the data cache
        // - backoffTime is set to the time indicated by the backoff state
        // - backoffExpirationTime is set to twice the backoff time
        // - backoffTimer is set to fire after backoffTime
        //
        // When a proactive cache refresh fails, this would leave the targets and the
        // expiry time from the old entry unchanged. And this mean that the old valid
        // entry would be used until expiration, and a new picker would be sent upon
        // backoff expiry.
        <span class="cov8" title="1">now := time.Now()
        if err != nil </span><span class="cov8" title="1">{
                dcEntry.status = err
                pendingEntry := p.lb.pendingMap[cacheKey]
                pendingEntry.retries++
                backoffTime := pendingEntry.bs.Backoff(pendingEntry.retries)
                dcEntry.backoffState = pendingEntry
                dcEntry.backoffTime = now.Add(backoffTime)
                dcEntry.backoffExpiryTime = now.Add(2 * backoffTime)
                if dcEntry.backoffState.timer != nil </span><span class="cov8" title="1">{
                        dcEntry.backoffState.timer.Stop()
                }</span>
                <span class="cov8" title="1">dcEntry.backoffState.timer = time.AfterFunc(backoffTime, p.lb.sendNewPicker)
                return</span>
        }

        // For successful requests, the cache entry is modified as follows:
        // - childPolicyWrappers is set to point to the child policy wrappers
        //   associated with the targets specified in the received response
        // - headerData is set to the value received in the response
        // - expiryTime, stateTime and earliestEvictionTime are set
        // - status is set to nil (OK status)
        // - backoff state is cleared
        <span class="cov8" title="1">p.setChildPolicyWrappersInCacheEntry(dcEntry, targets)
        dcEntry.headerData = headerData
        dcEntry.expiryTime = now.Add(p.maxAge)
        if p.staleAge != 0 </span><span class="cov8" title="1">{
                dcEntry.staleTime = now.Add(p.staleAge)
        }</span>
        <span class="cov8" title="1">dcEntry.earliestEvictTime = now.Add(minEvictDuration)
        dcEntry.status = nil
        dcEntry.backoffState = &amp;backoffState{bs: defaultBackoffStrategy}
        dcEntry.backoffTime = time.Time{}
        dcEntry.backoffExpiryTime = time.Time{}
        p.lb.dataCache.updateEntrySize(dcEntry, computeDataCacheEntrySize(cacheKey, dcEntry))</span>
}

// setChildPolicyWrappersInCacheEntry sets up the childPolicyWrappers field in
// the cache entry to point to the child policy wrappers for the targets
// specified in the RLS response.
//
// Caller must hold a write-lock on p.lb.cacheMu.
func (p *rlsPicker) setChildPolicyWrappersInCacheEntry(dcEntry *cacheEntry, newTargets []string) <span class="cov8" title="1">{
        // If the childPolicyWrappers field is already pointing to the right targets,
        // then the field's value does not need to change.
        targetsChanged := true
        func() </span><span class="cov8" title="1">{
                if cpws := dcEntry.childPolicyWrappers; cpws != nil </span><span class="cov8" title="1">{
                        if len(newTargets) != len(cpws) </span><span class="cov0" title="0">{
                                return
                        }</span>
                        <span class="cov8" title="1">for i, target := range newTargets </span><span class="cov8" title="1">{
                                if cpws[i].target != target </span><span class="cov8" title="1">{
                                        return
                                }</span>
                        }
                        <span class="cov8" title="1">targetsChanged = false</span>
                }
        }()
        <span class="cov8" title="1">if !targetsChanged </span><span class="cov8" title="1">{
                return
        }</span>

        // If the childPolicyWrappers field is not already set to the right targets,
        // then it must be reset. We construct a new list of child policies and
        // then swap out the old list for the new one.
        <span class="cov8" title="1">newChildPolicies := p.lb.acquireChildPolicyReferences(newTargets)
        oldChildPolicyTargets := make([]string, len(dcEntry.childPolicyWrappers))
        for i, cpw := range dcEntry.childPolicyWrappers </span><span class="cov8" title="1">{
                oldChildPolicyTargets[i] = cpw.target
        }</span>
        <span class="cov8" title="1">p.lb.releaseChildPolicyReferences(oldChildPolicyTargets)
        dcEntry.childPolicyWrappers = newChildPolicies</span>
}

func dcEntrySize(key cacheKey, entry *cacheEntry) int64 <span class="cov8" title="1">{
        return int64(len(key.path) + len(key.keys) + len(entry.headerData))
}</span>
</pre>
		
		<pre class="file" id="file23" style="display: none">/*
 *
 * Copyright 2019 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package weightedroundrobin defines a weighted roundrobin balancer.
package weightedroundrobin

import (
        "google.golang.org/grpc/resolver"
)

// Name is the name of weighted_round_robin balancer.
const Name = "weighted_round_robin"

// attributeKey is the type used as the key to store AddrInfo in the
// BalancerAttributes field of resolver.Address.
type attributeKey struct{}

// AddrInfo will be stored in the BalancerAttributes field of Address in order
// to use weighted roundrobin balancer.
type AddrInfo struct {
        Weight uint32
}

// Equal allows the values to be compared by Attributes.Equal.
func (a AddrInfo) Equal(o interface{}) bool <span class="cov8" title="1">{
        oa, ok := o.(AddrInfo)
        return ok &amp;&amp; oa.Weight == a.Weight
}</span>

// SetAddrInfo returns a copy of addr in which the BalancerAttributes field is
// updated with addrInfo.
//
// Experimental
//
// Notice: This API is EXPERIMENTAL and may be changed or removed in a
// later release.
func SetAddrInfo(addr resolver.Address, addrInfo AddrInfo) resolver.Address <span class="cov8" title="1">{
        addr.BalancerAttributes = addr.BalancerAttributes.WithValue(attributeKey{}, addrInfo)
        return addr
}</span>

// GetAddrInfo returns the AddrInfo stored in the BalancerAttributes field of
// addr.
//
// Experimental
//
// Notice: This API is EXPERIMENTAL and may be changed or removed in a
// later release.
func GetAddrInfo(addr resolver.Address) AddrInfo <span class="cov8" title="1">{
        v := addr.BalancerAttributes.Value(attributeKey{})
        ai, _ := v.(AddrInfo)
        return ai
}</span>
</pre>
		
		<pre class="file" id="file24" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package weightedtarget

import (
        "fmt"

        "google.golang.org/grpc/grpclog"
        internalgrpclog "google.golang.org/grpc/internal/grpclog"
)

const prefix = "[weighted-target-lb %p] "

var logger = grpclog.Component("xds")

func prefixLogger(p *weightedTargetBalancer) *internalgrpclog.PrefixLogger <span class="cov8" title="1">{
        return internalgrpclog.NewPrefixLogger(logger, fmt.Sprintf(prefix, p))
}</span>
</pre>
		
		<pre class="file" id="file25" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package weightedtarget implements the weighted_target balancer.
//
// All APIs in this package are experimental.
package weightedtarget

import (
        "encoding/json"
        "fmt"

        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/balancer/weightedtarget/weightedaggregator"
        "google.golang.org/grpc/internal/balancergroup"
        "google.golang.org/grpc/internal/grpclog"
        "google.golang.org/grpc/internal/hierarchy"
        "google.golang.org/grpc/internal/pretty"
        "google.golang.org/grpc/internal/wrr"
        "google.golang.org/grpc/resolver"
        "google.golang.org/grpc/serviceconfig"
)

// Name is the name of the weighted_target balancer.
const Name = "weighted_target_experimental"

// NewRandomWRR is the WRR constructor used to pick sub-pickers from
// sub-balancers. It's to be modified in tests.
var NewRandomWRR = wrr.NewRandom

func init() <span class="cov8" title="1">{
        balancer.Register(bb{})
}</span>

type bb struct{}

func (bb) Build(cc balancer.ClientConn, bOpts balancer.BuildOptions) balancer.Balancer <span class="cov8" title="1">{
        b := &amp;weightedTargetBalancer{}
        b.logger = prefixLogger(b)
        b.stateAggregator = weightedaggregator.New(cc, b.logger, NewRandomWRR)
        b.stateAggregator.Start()
        b.bg = balancergroup.New(cc, bOpts, b.stateAggregator, b.logger)
        b.bg.Start()
        b.logger.Infof("Created")
        return b
}</span>

func (bb) Name() string <span class="cov8" title="1">{
        return Name
}</span>

func (bb) ParseConfig(c json.RawMessage) (serviceconfig.LoadBalancingConfig, error) <span class="cov8" title="1">{
        return parseConfig(c)
}</span>

type weightedTargetBalancer struct {
        logger *grpclog.PrefixLogger

        bg              *balancergroup.BalancerGroup
        stateAggregator *weightedaggregator.Aggregator

        targets map[string]Target
}

// UpdateClientConnState takes the new targets in balancer group,
// creates/deletes sub-balancers and sends them update. addresses are split into
// groups based on hierarchy path.
func (b *weightedTargetBalancer) UpdateClientConnState(s balancer.ClientConnState) error <span class="cov8" title="1">{
        b.logger.Infof("Received update from resolver, balancer config: %+v", pretty.ToJSON(s.BalancerConfig))
        newConfig, ok := s.BalancerConfig.(*LBConfig)
        if !ok </span><span class="cov0" title="0">{
                return fmt.Errorf("unexpected balancer config with type: %T", s.BalancerConfig)
        }</span>
        <span class="cov8" title="1">addressesSplit := hierarchy.Group(s.ResolverState.Addresses)

        var rebuildStateAndPicker bool

        b.stateAggregator.PauseStateUpdates()
        defer b.stateAggregator.ResumeStateUpdates()

        // Remove sub-pickers and sub-balancers that are not in the new config.
        for name := range b.targets </span><span class="cov8" title="1">{
                if _, ok := newConfig.Targets[name]; !ok </span><span class="cov8" title="1">{
                        b.stateAggregator.Remove(name)
                        b.bg.Remove(name)
                        // Trigger a state/picker update, because we don't want `ClientConn`
                        // to pick this sub-balancer anymore.
                        rebuildStateAndPicker = true
                }</span>
        }

        // For sub-balancers in the new config
        // - if it's new. add to balancer group,
        // - if it's old, but has a new weight, update weight in balancer group.
        //
        // For all sub-balancers, forward the address/balancer config update.
        <span class="cov8" title="1">for name, newT := range newConfig.Targets </span><span class="cov8" title="1">{
                oldT, ok := b.targets[name]
                if !ok </span><span class="cov8" title="1">{
                        // If this is a new sub-balancer, add weights to the picker map.
                        b.stateAggregator.Add(name, newT.Weight)
                        // Then add to the balancer group.
                        b.bg.Add(name, balancer.Get(newT.ChildPolicy.Name))
                        // Not trigger a state/picker update. Wait for the new sub-balancer
                        // to send its updates.
                }</span> else<span class="cov8" title="1"> if newT.ChildPolicy.Name != oldT.ChildPolicy.Name </span><span class="cov8" title="1">{
                        // If the child policy name is differet, remove from balancer group
                        // and re-add.
                        b.stateAggregator.Remove(name)
                        b.bg.Remove(name)
                        b.stateAggregator.Add(name, newT.Weight)
                        b.bg.Add(name, balancer.Get(newT.ChildPolicy.Name))
                        // Trigger a state/picker update, because we don't want `ClientConn`
                        // to pick this sub-balancer anymore.
                        rebuildStateAndPicker = true
                }</span> else<span class="cov8" title="1"> if newT.Weight != oldT.Weight </span><span class="cov8" title="1">{
                        // If this is an existing sub-balancer, update weight if necessary.
                        b.stateAggregator.UpdateWeight(name, newT.Weight)
                        // Trigger a state/picker update, because we don't want `ClientConn`
                        // should do picks with the new weights now.
                        rebuildStateAndPicker = true
                }</span>

                // Forwards all the update:
                // - addresses are from the map after splitting with hierarchy path,
                // - Top level service config and attributes are the same,
                // - Balancer config comes from the targets map.
                //
                // TODO: handle error? How to aggregate errors and return?
                <span class="cov8" title="1">_ = b.bg.UpdateClientConnState(name, balancer.ClientConnState{
                        ResolverState: resolver.State{
                                Addresses:     addressesSplit[name],
                                ServiceConfig: s.ResolverState.ServiceConfig,
                                Attributes:    s.ResolverState.Attributes,
                        },
                        BalancerConfig: newT.ChildPolicy.Config,
                })</span>
        }

        <span class="cov8" title="1">b.targets = newConfig.Targets

        if rebuildStateAndPicker </span><span class="cov8" title="1">{
                b.stateAggregator.BuildAndUpdate()
        }</span>
        <span class="cov8" title="1">return nil</span>
}

func (b *weightedTargetBalancer) ResolverError(err error) <span class="cov0" title="0">{
        b.bg.ResolverError(err)
}</span>

func (b *weightedTargetBalancer) UpdateSubConnState(sc balancer.SubConn, state balancer.SubConnState) <span class="cov8" title="1">{
        b.bg.UpdateSubConnState(sc, state)
}</span>

func (b *weightedTargetBalancer) Close() <span class="cov8" title="1">{
        b.stateAggregator.Stop()
        b.bg.Close()
}</span>

func (b *weightedTargetBalancer) ExitIdle() <span class="cov0" title="0">{
        b.bg.ExitIdle()
}</span>
</pre>
		
		<pre class="file" id="file26" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package weightedtarget

import (
        "encoding/json"

        internalserviceconfig "google.golang.org/grpc/internal/serviceconfig"
        "google.golang.org/grpc/serviceconfig"
)

// Target represents one target with the weight and the child policy.
type Target struct {
        // Weight is the weight of the child policy.
        Weight uint32 `json:"weight,omitempty"`
        // ChildPolicy is the child policy and it's config.
        ChildPolicy *internalserviceconfig.BalancerConfig `json:"childPolicy,omitempty"`
}

// LBConfig is the balancer config for weighted_target.
type LBConfig struct {
        serviceconfig.LoadBalancingConfig `json:"-"`

        Targets map[string]Target `json:"targets,omitempty"`
}

func parseConfig(c json.RawMessage) (*LBConfig, error) <span class="cov8" title="1">{
        var cfg LBConfig
        if err := json.Unmarshal(c, &amp;cfg); err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return &amp;cfg, nil</span>
}
</pre>
		
		<pre class="file" id="file27" style="display: none">/*
 *
 * Copyright 2017 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package grpc

import (
        "fmt"
        "strings"
        "sync"

        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/connectivity"
        "google.golang.org/grpc/internal/balancer/gracefulswitch"
        "google.golang.org/grpc/internal/buffer"
        "google.golang.org/grpc/internal/channelz"
        "google.golang.org/grpc/internal/grpcsync"
        "google.golang.org/grpc/resolver"
)

// ccBalancerWrapper sits between the ClientConn and the Balancer.
//
// ccBalancerWrapper implements methods corresponding to the ones on the
// balancer.Balancer interface. The ClientConn is free to call these methods
// concurrently and the ccBalancerWrapper ensures that calls from the ClientConn
// to the Balancer happen synchronously and in order.
//
// ccBalancerWrapper also implements the balancer.ClientConn interface and is
// passed to the Balancer implementations. It invokes unexported methods on the
// ClientConn to handle these calls from the Balancer.
//
// It uses the gracefulswitch.Balancer internally to ensure that balancer
// switches happen in a graceful manner.
type ccBalancerWrapper struct {
        cc *ClientConn

        // Since these fields are accessed only from handleXxx() methods which are
        // synchronized by the watcher goroutine, we do not need a mutex to protect
        // these fields.
        balancer        *gracefulswitch.Balancer
        curBalancerName string

        updateCh *buffer.Unbounded // Updates written on this channel are processed by watcher().
        resultCh *buffer.Unbounded // Results of calls to UpdateClientConnState() are pushed here.
        closed   *grpcsync.Event   // Indicates if close has been called.
        done     *grpcsync.Event   // Indicates if close has completed its work.
}

// newCCBalancerWrapper creates a new balancer wrapper. The underlying balancer
// is not created until the switchTo() method is invoked.
func newCCBalancerWrapper(cc *ClientConn, bopts balancer.BuildOptions) *ccBalancerWrapper <span class="cov8" title="1">{
        ccb := &amp;ccBalancerWrapper{
                cc:       cc,
                updateCh: buffer.NewUnbounded(),
                resultCh: buffer.NewUnbounded(),
                closed:   grpcsync.NewEvent(),
                done:     grpcsync.NewEvent(),
        }
        go ccb.watcher()
        ccb.balancer = gracefulswitch.NewBalancer(ccb, bopts)
        return ccb
}</span>

// The following xxxUpdate structs wrap the arguments received as part of the
// corresponding update. The watcher goroutine uses the 'type' of the update to
// invoke the appropriate handler routine to handle the update.

type ccStateUpdate struct {
        ccs *balancer.ClientConnState
}

type scStateUpdate struct {
        sc    balancer.SubConn
        state connectivity.State
        err   error
}

type exitIdleUpdate struct{}

type resolverErrorUpdate struct {
        err error
}

type switchToUpdate struct {
        name string
}

type subConnUpdate struct {
        acbw *acBalancerWrapper
}

// watcher is a long-running goroutine which reads updates from a channel and
// invokes corresponding methods on the underlying balancer. It ensures that
// these methods are invoked in a synchronous fashion. It also ensures that
// these methods are invoked in the order in which the updates were received.
func (ccb *ccBalancerWrapper) watcher() <span class="cov8" title="1">{
        for </span><span class="cov8" title="1">{
                select </span>{
                case u := &lt;-ccb.updateCh.Get():<span class="cov8" title="1">
                        ccb.updateCh.Load()
                        if ccb.closed.HasFired() </span><span class="cov8" title="1">{
                                break</span>
                        }
                        <span class="cov8" title="1">switch update := u.(type) </span>{
                        case *ccStateUpdate:<span class="cov8" title="1">
                                ccb.handleClientConnStateChange(update.ccs)</span>
                        case *scStateUpdate:<span class="cov8" title="1">
                                ccb.handleSubConnStateChange(update)</span>
                        case *exitIdleUpdate:<span class="cov8" title="1">
                                ccb.handleExitIdle()</span>
                        case *resolverErrorUpdate:<span class="cov0" title="0">
                                ccb.handleResolverError(update.err)</span>
                        case *switchToUpdate:<span class="cov8" title="1">
                                ccb.handleSwitchTo(update.name)</span>
                        case *subConnUpdate:<span class="cov0" title="0">
                                ccb.handleRemoveSubConn(update.acbw)</span>
                        default:<span class="cov0" title="0">
                                logger.Errorf("ccBalancerWrapper.watcher: unknown update %+v, type %T", update, update)</span>
                        }
                case &lt;-ccb.closed.Done():<span class="cov8" title="1"></span>
                }

                <span class="cov8" title="1">if ccb.closed.HasFired() </span><span class="cov8" title="1">{
                        ccb.handleClose()
                        return
                }</span>
        }
}

// updateClientConnState is invoked by grpc to push a ClientConnState update to
// the underlying balancer.
//
// Unlike other methods invoked by grpc to push updates to the underlying
// balancer, this method cannot simply push the update onto the update channel
// and return. It needs to return the error returned by the underlying balancer
// back to grpc which propagates that to the resolver.
func (ccb *ccBalancerWrapper) updateClientConnState(ccs *balancer.ClientConnState) error <span class="cov8" title="1">{
        ccb.updateCh.Put(&amp;ccStateUpdate{ccs: ccs})

        var res interface{}
        select </span>{
        case res = &lt;-ccb.resultCh.Get():<span class="cov8" title="1">
                ccb.resultCh.Load()</span>
        case &lt;-ccb.closed.Done():<span class="cov0" title="0">
                // Return early if the balancer wrapper is closed while we are waiting for
                // the underlying balancer to process a ClientConnState update.
                return nil</span>
        }
        // If the returned error is nil, attempting to type assert to error leads to
        // panic. So, this needs to handled separately.
        <span class="cov8" title="1">if res == nil </span><span class="cov8" title="1">{
                return nil
        }</span>
        <span class="cov8" title="1">return res.(error)</span>
}

// handleClientConnStateChange handles a ClientConnState update from the update
// channel and invokes the appropriate method on the underlying balancer.
//
// If the addresses specified in the update contain addresses of type "grpclb"
// and the selected LB policy is not "grpclb", these addresses will be filtered
// out and ccs will be modified with the updated address list.
func (ccb *ccBalancerWrapper) handleClientConnStateChange(ccs *balancer.ClientConnState) <span class="cov8" title="1">{
        if ccb.curBalancerName != grpclbName </span><span class="cov8" title="1">{
                // Filter any grpclb addresses since we don't have the grpclb balancer.
                var addrs []resolver.Address
                for _, addr := range ccs.ResolverState.Addresses </span><span class="cov8" title="1">{
                        if addr.Type == resolver.GRPCLB </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        <span class="cov8" title="1">addrs = append(addrs, addr)</span>
                }
                <span class="cov8" title="1">ccs.ResolverState.Addresses = addrs</span>
        }
        <span class="cov8" title="1">ccb.resultCh.Put(ccb.balancer.UpdateClientConnState(*ccs))</span>
}

// updateSubConnState is invoked by grpc to push a subConn state update to the
// underlying balancer.
func (ccb *ccBalancerWrapper) updateSubConnState(sc balancer.SubConn, s connectivity.State, err error) <span class="cov8" title="1">{
        // When updating addresses for a SubConn, if the address in use is not in
        // the new addresses, the old ac will be tearDown() and a new ac will be
        // created. tearDown() generates a state change with Shutdown state, we
        // don't want the balancer to receive this state change. So before
        // tearDown() on the old ac, ac.acbw (acWrapper) will be set to nil, and
        // this function will be called with (nil, Shutdown). We don't need to call
        // balancer method in this case.
        if sc == nil </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov8" title="1">ccb.updateCh.Put(&amp;scStateUpdate{
                sc:    sc,
                state: s,
                err:   err,
        })</span>
}

// handleSubConnStateChange handles a SubConnState update from the update
// channel and invokes the appropriate method on the underlying balancer.
func (ccb *ccBalancerWrapper) handleSubConnStateChange(update *scStateUpdate) <span class="cov8" title="1">{
        ccb.balancer.UpdateSubConnState(update.sc, balancer.SubConnState{ConnectivityState: update.state, ConnectionError: update.err})
}</span>

func (ccb *ccBalancerWrapper) exitIdle() <span class="cov8" title="1">{
        ccb.updateCh.Put(&amp;exitIdleUpdate{})
}</span>

func (ccb *ccBalancerWrapper) handleExitIdle() <span class="cov8" title="1">{
        if ccb.cc.GetState() != connectivity.Idle </span><span class="cov8" title="1">{
                return
        }</span>
        <span class="cov8" title="1">ccb.balancer.ExitIdle()</span>
}

func (ccb *ccBalancerWrapper) resolverError(err error) <span class="cov0" title="0">{
        ccb.updateCh.Put(&amp;resolverErrorUpdate{err: err})
}</span>

func (ccb *ccBalancerWrapper) handleResolverError(err error) <span class="cov0" title="0">{
        ccb.balancer.ResolverError(err)
}</span>

// switchTo is invoked by grpc to instruct the balancer wrapper to switch to the
// LB policy identified by name.
//
// ClientConn calls newCCBalancerWrapper() at creation time. Upon receipt of the
// first good update from the name resolver, it determines the LB policy to use
// and invokes the switchTo() method. Upon receipt of every subsequent update
// from the name resolver, it invokes this method.
//
// the ccBalancerWrapper keeps track of the current LB policy name, and skips
// the graceful balancer switching process if the name does not change.
func (ccb *ccBalancerWrapper) switchTo(name string) <span class="cov8" title="1">{
        ccb.updateCh.Put(&amp;switchToUpdate{name: name})
}</span>

// handleSwitchTo handles a balancer switch update from the update channel. It
// calls the SwitchTo() method on the gracefulswitch.Balancer with a
// balancer.Builder corresponding to name. If no balancer.Builder is registered
// for the given name, it uses the default LB policy which is "pick_first".
func (ccb *ccBalancerWrapper) handleSwitchTo(name string) <span class="cov8" title="1">{
        // TODO: Other languages use case-insensitive balancer registries. We should
        // switch as well. See: https://github.com/grpc/grpc-go/issues/5288.
        if strings.EqualFold(ccb.curBalancerName, name) </span><span class="cov0" title="0">{
                return
        }</span>

        // TODO: Ensure that name is a registered LB policy when we get here.
        // We currently only validate the `loadBalancingConfig` field. We need to do
        // the same for the `loadBalancingPolicy` field and reject the service config
        // if the specified policy is not registered.
        <span class="cov8" title="1">builder := balancer.Get(name)
        if builder == nil </span><span class="cov0" title="0">{
                channelz.Warningf(logger, ccb.cc.channelzID, "Channel switches to new LB policy %q, since the specified LB policy %q was not registered", PickFirstBalancerName, name)
                builder = newPickfirstBuilder()
        }</span> else<span class="cov8" title="1"> {
                channelz.Infof(logger, ccb.cc.channelzID, "Channel switches to new LB policy %q", name)
        }</span>

        <span class="cov8" title="1">if err := ccb.balancer.SwitchTo(builder); err != nil </span><span class="cov0" title="0">{
                channelz.Errorf(logger, ccb.cc.channelzID, "Channel failed to build new LB policy %q: %v", name, err)
                return
        }</span>
        <span class="cov8" title="1">ccb.curBalancerName = builder.Name()</span>
}

// handleRemoveSucConn handles a request from the underlying balancer to remove
// a subConn.
//
// See comments in RemoveSubConn() for more details.
func (ccb *ccBalancerWrapper) handleRemoveSubConn(acbw *acBalancerWrapper) <span class="cov0" title="0">{
        ccb.cc.removeAddrConn(acbw.getAddrConn(), errConnDrain)
}</span>

func (ccb *ccBalancerWrapper) close() <span class="cov8" title="1">{
        ccb.closed.Fire()
        &lt;-ccb.done.Done()
}</span>

func (ccb *ccBalancerWrapper) handleClose() <span class="cov8" title="1">{
        ccb.balancer.Close()
        ccb.done.Fire()
}</span>

func (ccb *ccBalancerWrapper) NewSubConn(addrs []resolver.Address, opts balancer.NewSubConnOptions) (balancer.SubConn, error) <span class="cov8" title="1">{
        if len(addrs) &lt;= 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("grpc: cannot create SubConn with empty address list")
        }</span>
        <span class="cov8" title="1">ac, err := ccb.cc.newAddrConn(addrs, opts)
        if err != nil </span><span class="cov0" title="0">{
                channelz.Warningf(logger, ccb.cc.channelzID, "acBalancerWrapper: NewSubConn: failed to newAddrConn: %v", err)
                return nil, err
        }</span>
        <span class="cov8" title="1">acbw := &amp;acBalancerWrapper{ac: ac}
        acbw.ac.mu.Lock()
        ac.acbw = acbw
        acbw.ac.mu.Unlock()
        return acbw, nil</span>
}

func (ccb *ccBalancerWrapper) RemoveSubConn(sc balancer.SubConn) <span class="cov8" title="1">{
        // Before we switched the ccBalancerWrapper to use gracefulswitch.Balancer, it
        // was required to handle the RemoveSubConn() method asynchronously by pushing
        // the update onto the update channel. This was done to avoid a deadlock as
        // switchBalancer() was holding cc.mu when calling Close() on the old
        // balancer, which would in turn call RemoveSubConn().
        //
        // With the use of gracefulswitch.Balancer in ccBalancerWrapper, handling this
        // asynchronously is probably not required anymore since the switchTo() method
        // handles the balancer switch by pushing the update onto the channel.
        // TODO(easwars): Handle this inline.
        acbw, ok := sc.(*acBalancerWrapper)
        if !ok </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov8" title="1">ccb.updateCh.Put(&amp;subConnUpdate{acbw: acbw})</span>
}

func (ccb *ccBalancerWrapper) UpdateAddresses(sc balancer.SubConn, addrs []resolver.Address) <span class="cov0" title="0">{
        acbw, ok := sc.(*acBalancerWrapper)
        if !ok </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov0" title="0">acbw.UpdateAddresses(addrs)</span>
}

func (ccb *ccBalancerWrapper) UpdateState(s balancer.State) <span class="cov8" title="1">{
        // Update picker before updating state.  Even though the ordering here does
        // not matter, it can lead to multiple calls of Pick in the common start-up
        // case where we wait for ready and then perform an RPC.  If the picker is
        // updated later, we could call the "connecting" picker when the state is
        // updated, and then call the "ready" picker after the picker gets updated.
        ccb.cc.blockingpicker.updatePicker(s.Picker)
        ccb.cc.csMgr.updateState(s.ConnectivityState)
}</span>

func (ccb *ccBalancerWrapper) ResolveNow(o resolver.ResolveNowOptions) <span class="cov0" title="0">{
        ccb.cc.resolveNow(o)
}</span>

func (ccb *ccBalancerWrapper) Target() string <span class="cov0" title="0">{
        return ccb.cc.target
}</span>

// acBalancerWrapper is a wrapper on top of ac for balancers.
// It implements balancer.SubConn interface.
type acBalancerWrapper struct {
        mu sync.Mutex
        ac *addrConn
}

func (acbw *acBalancerWrapper) UpdateAddresses(addrs []resolver.Address) <span class="cov8" title="1">{
        acbw.mu.Lock()
        defer acbw.mu.Unlock()
        if len(addrs) &lt;= 0 </span><span class="cov0" title="0">{
                acbw.ac.cc.removeAddrConn(acbw.ac, errConnDrain)
                return
        }</span>
        <span class="cov8" title="1">if !acbw.ac.tryUpdateAddrs(addrs) </span><span class="cov0" title="0">{
                cc := acbw.ac.cc
                opts := acbw.ac.scopts
                acbw.ac.mu.Lock()
                // Set old ac.acbw to nil so the Shutdown state update will be ignored
                // by balancer.
                //
                // TODO(bar) the state transition could be wrong when tearDown() old ac
                // and creating new ac, fix the transition.
                acbw.ac.acbw = nil
                acbw.ac.mu.Unlock()
                acState := acbw.ac.getState()
                acbw.ac.cc.removeAddrConn(acbw.ac, errConnDrain)

                if acState == connectivity.Shutdown </span><span class="cov0" title="0">{
                        return
                }</span>

                <span class="cov0" title="0">newAC, err := cc.newAddrConn(addrs, opts)
                if err != nil </span><span class="cov0" title="0">{
                        channelz.Warningf(logger, acbw.ac.channelzID, "acBalancerWrapper: UpdateAddresses: failed to newAddrConn: %v", err)
                        return
                }</span>
                <span class="cov0" title="0">acbw.ac = newAC
                newAC.mu.Lock()
                newAC.acbw = acbw
                newAC.mu.Unlock()
                if acState != connectivity.Idle </span><span class="cov0" title="0">{
                        go newAC.connect()
                }</span>
        }
}

func (acbw *acBalancerWrapper) Connect() <span class="cov8" title="1">{
        acbw.mu.Lock()
        defer acbw.mu.Unlock()
        go acbw.ac.connect()
}</span>

func (acbw *acBalancerWrapper) getAddrConn() *addrConn <span class="cov8" title="1">{
        acbw.mu.Lock()
        defer acbw.mu.Unlock()
        return acbw.ac
}</span>
</pre>
		
		<pre class="file" id="file28" style="display: none">/*
 *
 * Copyright 2019 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

/*
Package flags provide convenience types and routines to accept specific types
of flag values on the command line.
*/
package flags

import (
        "bytes"
        "encoding/csv"
        "flag"
        "fmt"
        "strconv"
        "strings"
        "time"
)

// stringFlagWithAllowedValues represents a string flag which can only take a
// predefined set of values.
type stringFlagWithAllowedValues struct {
        val     string
        allowed []string
}

// StringWithAllowedValues returns a flag variable of type
// stringFlagWithAllowedValues configured with the provided parameters.
// 'allowed` is the set of values that this flag can be set to.
func StringWithAllowedValues(name, defaultVal, usage string, allowed []string) *string <span class="cov8" title="1">{
        as := &amp;stringFlagWithAllowedValues{defaultVal, allowed}
        flag.CommandLine.Var(as, name, usage)
        return &amp;as.val
}</span>

// String implements the flag.Value interface.
func (as *stringFlagWithAllowedValues) String() string <span class="cov8" title="1">{
        return as.val
}</span>

// Set implements the flag.Value interface.
func (as *stringFlagWithAllowedValues) Set(val string) error <span class="cov8" title="1">{
        for _, a := range as.allowed </span><span class="cov8" title="1">{
                if a == val </span><span class="cov8" title="1">{
                        as.val = val
                        return nil
                }</span>
        }
        <span class="cov8" title="1">return fmt.Errorf("want one of: %v", strings.Join(as.allowed, ", "))</span>
}

type durationSliceValue []time.Duration

// DurationSlice returns a flag representing a slice of time.Duration objects.
func DurationSlice(name string, defaultVal []time.Duration, usage string) *[]time.Duration <span class="cov8" title="1">{
        ds := make([]time.Duration, len(defaultVal))
        copy(ds, defaultVal)
        dsv := (*durationSliceValue)(&amp;ds)
        flag.CommandLine.Var(dsv, name, usage)
        return &amp;ds
}</span>

// Set implements the flag.Value interface.
func (dsv *durationSliceValue) Set(s string) error <span class="cov8" title="1">{
        ds := strings.Split(s, ",")
        var dd []time.Duration
        for _, n := range ds </span><span class="cov8" title="1">{
                d, err := time.ParseDuration(n)
                if err != nil </span><span class="cov8" title="1">{
                        return err
                }</span>
                <span class="cov8" title="1">dd = append(dd, d)</span>
        }
        <span class="cov8" title="1">*dsv = durationSliceValue(dd)
        return nil</span>
}

// String implements the flag.Value interface.
func (dsv *durationSliceValue) String() string <span class="cov8" title="1">{
        var b bytes.Buffer
        for i, d := range *dsv </span><span class="cov8" title="1">{
                if i &gt; 0 </span><span class="cov8" title="1">{
                        b.WriteRune(',')
                }</span>
                <span class="cov8" title="1">b.WriteString(d.String())</span>
        }
        <span class="cov8" title="1">return b.String()</span>
}

type intSliceValue []int

// IntSlice returns a flag representing a slice of ints.
func IntSlice(name string, defaultVal []int, usage string) *[]int <span class="cov8" title="1">{
        is := make([]int, len(defaultVal))
        copy(is, defaultVal)
        isv := (*intSliceValue)(&amp;is)
        flag.CommandLine.Var(isv, name, usage)
        return &amp;is
}</span>

// Set implements the flag.Value interface.
func (isv *intSliceValue) Set(s string) error <span class="cov8" title="1">{
        is := strings.Split(s, ",")
        var ret []int
        for _, n := range is </span><span class="cov8" title="1">{
                i, err := strconv.Atoi(n)
                if err != nil </span><span class="cov8" title="1">{
                        return err
                }</span>
                <span class="cov8" title="1">ret = append(ret, i)</span>
        }
        <span class="cov8" title="1">*isv = intSliceValue(ret)
        return nil</span>
}

// String implements the flag.Value interface.
func (isv *intSliceValue) String() string <span class="cov8" title="1">{
        var b bytes.Buffer
        for i, n := range *isv </span><span class="cov8" title="1">{
                if i &gt; 0 </span><span class="cov8" title="1">{
                        b.WriteRune(',')
                }</span>
                <span class="cov8" title="1">b.WriteString(strconv.Itoa(n))</span>
        }
        <span class="cov8" title="1">return b.String()</span>
}

type stringSliceValue []string

// StringSlice returns a flag representing a slice of strings.
func StringSlice(name string, defaultVal []string, usage string) *[]string <span class="cov8" title="1">{
        ss := make([]string, len(defaultVal))
        copy(ss, defaultVal)
        ssv := (*stringSliceValue)(&amp;ss)
        flag.CommandLine.Var(ssv, name, usage)
        return &amp;ss
}</span>

// escapedCommaSplit splits a comma-separated list of strings in the same way
// CSV files work (escaping a comma requires double-quotes).
func escapedCommaSplit(str string) ([]string, error) <span class="cov8" title="1">{
        r := csv.NewReader(strings.NewReader(str))
        ret, err := r.Read()
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return ret, nil</span>
}

// Set implements the flag.Value interface.
func (ss *stringSliceValue) Set(str string) error <span class="cov8" title="1">{
        var err error
        *ss, err = escapedCommaSplit(str)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov8" title="1">return nil</span>
}

// String implements the flag.Value interface.
func (ss *stringSliceValue) String() string <span class="cov8" title="1">{
        return strings.Join(*ss, ",")
}</span>
</pre>
		
		<pre class="file" id="file29" style="display: none">/*
 *
 * Copyright 2017 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package latency provides wrappers for net.Conn, net.Listener, and
// net.Dialers, designed to interoperate to inject real-world latency into
// network connections.
package latency

import (
        "bytes"
        "context"
        "encoding/binary"
        "fmt"
        "io"
        "net"
        "time"
)

// Dialer is a function matching the signature of net.Dial.
type Dialer func(network, address string) (net.Conn, error)

// TimeoutDialer is a function matching the signature of net.DialTimeout.
type TimeoutDialer func(network, address string, timeout time.Duration) (net.Conn, error)

// ContextDialer is a function matching the signature of
// net.Dialer.DialContext.
type ContextDialer func(ctx context.Context, network, address string) (net.Conn, error)

// Network represents a network with the given bandwidth, latency, and MTU
// (Maximum Transmission Unit) configuration, and can produce wrappers of
// net.Listeners, net.Conn, and various forms of dialing functions.  The
// Listeners and Dialers/Conns on both sides of connections must come from this
// package, but need not be created from the same Network.  Latency is computed
// when sending (in Write), and is injected when receiving (in Read).  This
// allows senders' Write calls to be non-blocking, as in real-world
// applications.
//
// Note: Latency is injected by the sender specifying the absolute time data
// should be available, and the reader delaying until that time arrives to
// provide the data.  This package attempts to counter-act the effects of clock
// drift and existing network latency by measuring the delay between the
// sender's transmission time and the receiver's reception time during startup.
// No attempt is made to measure the existing bandwidth of the connection.
type Network struct {
        Kbps    int           // Kilobits per second; if non-positive, infinite
        Latency time.Duration // One-way latency (sending); if non-positive, no delay
        MTU     int           // Bytes per packet; if non-positive, infinite
}

var (
        //Local simulates local network.
        Local = Network{0, 0, 0}
        //LAN simulates local area network network.
        LAN = Network{100 * 1024, 2 * time.Millisecond, 1500}
        //WAN simulates wide area network.
        WAN = Network{20 * 1024, 30 * time.Millisecond, 1500}
        //Longhaul simulates bad network.
        Longhaul = Network{1000 * 1024, 200 * time.Millisecond, 9000}
)

// Conn returns a net.Conn that wraps c and injects n's latency into that
// connection.  This function also imposes latency for connection creation.
// If n's Latency is lower than the measured latency in c, an error is
// returned.
func (n *Network) Conn(c net.Conn) (net.Conn, error) <span class="cov8" title="1">{
        start := now()
        nc := &amp;conn{Conn: c, network: n, readBuf: new(bytes.Buffer)}
        if err := nc.sync(); err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">sleep(start.Add(nc.delay).Sub(now()))
        return nc, nil</span>
}

type conn struct {
        net.Conn
        network *Network

        readBuf     *bytes.Buffer // one packet worth of data received
        lastSendEnd time.Time     // time the previous Write should be fully on the wire
        delay       time.Duration // desired latency - measured latency
}

// header is sent before all data transmitted by the application.
type header struct {
        ReadTime int64 // Time the reader is allowed to read this packet (UnixNano)
        Sz       int32 // Size of the data in the packet
}

func (c *conn) Write(p []byte) (n int, err error) <span class="cov8" title="1">{
        tNow := now()
        if c.lastSendEnd.Before(tNow) </span><span class="cov8" title="1">{
                c.lastSendEnd = tNow
        }</span>
        <span class="cov8" title="1">for len(p) &gt; 0 </span><span class="cov8" title="1">{
                pkt := p
                if c.network.MTU &gt; 0 &amp;&amp; len(pkt) &gt; c.network.MTU </span><span class="cov8" title="1">{
                        pkt = pkt[:c.network.MTU]
                        p = p[c.network.MTU:]
                }</span> else<span class="cov8" title="1"> {
                        p = nil
                }</span>
                <span class="cov8" title="1">if c.network.Kbps &gt; 0 </span><span class="cov8" title="1">{
                        if congestion := c.lastSendEnd.Sub(tNow) - c.delay; congestion &gt; 0 </span><span class="cov8" title="1">{
                                // The network is full; sleep until this packet can be sent.
                                sleep(congestion)
                                tNow = tNow.Add(congestion)
                        }</span>
                }
                <span class="cov8" title="1">c.lastSendEnd = c.lastSendEnd.Add(c.network.pktTime(len(pkt)))
                hdr := header{ReadTime: c.lastSendEnd.Add(c.delay).UnixNano(), Sz: int32(len(pkt))}
                if err := binary.Write(c.Conn, binary.BigEndian, hdr); err != nil </span><span class="cov0" title="0">{
                        return n, err
                }</span>
                <span class="cov8" title="1">x, err := c.Conn.Write(pkt)
                n += x
                if err != nil </span><span class="cov0" title="0">{
                        return n, err
                }</span>
        }
        <span class="cov8" title="1">return n, nil</span>
}

func (c *conn) Read(p []byte) (n int, err error) <span class="cov8" title="1">{
        if c.readBuf.Len() == 0 </span><span class="cov8" title="1">{
                var hdr header
                if err := binary.Read(c.Conn, binary.BigEndian, &amp;hdr); err != nil </span><span class="cov0" title="0">{
                        return 0, err
                }</span>
                <span class="cov8" title="1">defer func() </span><span class="cov8" title="1">{ sleep(time.Unix(0, hdr.ReadTime).Sub(now())) }</span>()

                <span class="cov8" title="1">if _, err := io.CopyN(c.readBuf, c.Conn, int64(hdr.Sz)); err != nil </span><span class="cov0" title="0">{
                        return 0, err
                }</span>
        }
        // Read from readBuf.
        <span class="cov8" title="1">return c.readBuf.Read(p)</span>
}

// sync does a handshake and then measures the latency on the network in
// coordination with the other side.
func (c *conn) sync() error <span class="cov8" title="1">{
        const (
                pingMsg  = "syncPing"
                warmup   = 10               // minimum number of iterations to measure latency
                giveUp   = 50               // maximum number of iterations to measure latency
                accuracy = time.Millisecond // req'd accuracy to stop early
                goodRun  = 3                // stop early if latency within accuracy this many times
        )

        type syncMsg struct {
                SendT int64 // Time sent.  If zero, stop.
                RecvT int64 // Time received.  If zero, fill in and respond.
        }

        // A trivial handshake
        if err := binary.Write(c.Conn, binary.BigEndian, []byte(pingMsg)); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov8" title="1">var ping [8]byte
        if err := binary.Read(c.Conn, binary.BigEndian, &amp;ping); err != nil </span><span class="cov0" title="0">{
                return err
        }</span> else<span class="cov8" title="1"> if string(ping[:]) != pingMsg </span><span class="cov0" title="0">{
                return fmt.Errorf("malformed handshake message: %v (want %q)", ping, pingMsg)
        }</span>

        // Both sides are alive and syncing.  Calculate network delay / clock skew.
        <span class="cov8" title="1">att := 0
        good := 0
        var latency time.Duration
        localDone, remoteDone := false, false
        send := true
        for !localDone || !remoteDone </span><span class="cov8" title="1">{
                if send </span><span class="cov8" title="1">{
                        if err := binary.Write(c.Conn, binary.BigEndian, syncMsg{SendT: now().UnixNano()}); err != nil </span><span class="cov0" title="0">{
                                return err
                        }</span>
                        <span class="cov8" title="1">att++
                        send = false</span>
                }

                // Block until we get a syncMsg
                <span class="cov8" title="1">m := syncMsg{}
                if err := binary.Read(c.Conn, binary.BigEndian, &amp;m); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>

                <span class="cov8" title="1">if m.RecvT == 0 </span><span class="cov8" title="1">{
                        // Message initiated from other side.
                        if m.SendT == 0 </span><span class="cov8" title="1">{
                                remoteDone = true
                                continue</span>
                        }
                        // Send response.
                        <span class="cov8" title="1">m.RecvT = now().UnixNano()
                        if err := binary.Write(c.Conn, binary.BigEndian, m); err != nil </span><span class="cov0" title="0">{
                                return err
                        }</span>
                        <span class="cov8" title="1">continue</span>
                }

                <span class="cov8" title="1">lag := time.Duration(m.RecvT - m.SendT)
                latency += lag
                avgLatency := latency / time.Duration(att)
                if e := lag - avgLatency; e &gt; -accuracy &amp;&amp; e &lt; accuracy </span><span class="cov8" title="1">{
                        good++
                }</span> else<span class="cov0" title="0"> {
                        good = 0
                }</span>
                <span class="cov8" title="1">if att &lt; giveUp &amp;&amp; (att &lt; warmup || good &lt; goodRun) </span><span class="cov8" title="1">{
                        send = true
                        continue</span>
                }
                <span class="cov8" title="1">localDone = true
                latency = avgLatency
                // Tell the other side we're done.
                if err := binary.Write(c.Conn, binary.BigEndian, syncMsg{}); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
        }
        <span class="cov8" title="1">if c.network.Latency &lt;= 0 </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">c.delay = c.network.Latency - latency
        if c.delay &lt; 0 </span><span class="cov8" title="1">{
                return fmt.Errorf("measured network latency (%v) higher than desired latency (%v)", latency, c.network.Latency)
        }</span>
        <span class="cov8" title="1">return nil</span>
}

// Listener returns a net.Listener that wraps l and injects n's latency in its
// connections.
func (n *Network) Listener(l net.Listener) net.Listener <span class="cov8" title="1">{
        return &amp;listener{Listener: l, network: n}
}</span>

type listener struct {
        net.Listener
        network *Network
}

func (l *listener) Accept() (net.Conn, error) <span class="cov8" title="1">{
        c, err := l.Listener.Accept()
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return l.network.Conn(c)</span>
}

// Dialer returns a Dialer that wraps d and injects n's latency in its
// connections.  n's Latency is also injected to the connection's creation.
func (n *Network) Dialer(d Dialer) Dialer <span class="cov0" title="0">{
        return func(network, address string) (net.Conn, error) </span><span class="cov0" title="0">{
                conn, err := d(network, address)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov0" title="0">return n.Conn(conn)</span>
        }
}

// TimeoutDialer returns a TimeoutDialer that wraps d and injects n's latency
// in its connections.  n's Latency is also injected to the connection's
// creation.
func (n *Network) TimeoutDialer(d TimeoutDialer) TimeoutDialer <span class="cov8" title="1">{
        return func(network, address string, timeout time.Duration) (net.Conn, error) </span><span class="cov8" title="1">{
                conn, err := d(network, address, timeout)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov8" title="1">return n.Conn(conn)</span>
        }
}

// ContextDialer returns a ContextDialer that wraps d and injects n's latency
// in its connections.  n's Latency is also injected to the connection's
// creation.
func (n *Network) ContextDialer(d ContextDialer) ContextDialer <span class="cov0" title="0">{
        return func(ctx context.Context, network, address string) (net.Conn, error) </span><span class="cov0" title="0">{
                conn, err := d(ctx, network, address)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov0" title="0">return n.Conn(conn)</span>
        }
}

// pktTime returns the time it takes to transmit one packet of data of size b
// in bytes.
func (n *Network) pktTime(b int) time.Duration <span class="cov8" title="1">{
        if n.Kbps &lt;= 0 </span><span class="cov8" title="1">{
                return time.Duration(0)
        }</span>
        <span class="cov8" title="1">return time.Duration(b) * time.Second / time.Duration(n.Kbps*(1024/8))</span>
}

// Wrappers for testing

var now = time.Now
var sleep = time.Sleep
</pre>
		
		<pre class="file" id="file30" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package binarylog implementation binary logging as defined in
// https://github.com/grpc/proposal/blob/master/A16-binary-logging.md.
//
// Notice: All APIs in this package are experimental.
package binarylog

import (
        "fmt"
        "io/ioutil"

        pb "google.golang.org/grpc/binarylog/grpc_binarylog_v1"
        iblog "google.golang.org/grpc/internal/binarylog"
)

// SetSink sets the destination for the binary log entries.
//
// NOTE: this function must only be called during initialization time (i.e. in
// an init() function), and is not thread-safe.
func SetSink(s Sink) <span class="cov8" title="1">{
        if iblog.DefaultSink != nil </span><span class="cov8" title="1">{
                iblog.DefaultSink.Close()
        }</span>
        <span class="cov8" title="1">iblog.DefaultSink = s</span>
}

// Sink represents the destination for the binary log entries.
type Sink interface {
        // Write marshals the log entry and writes it to the destination. The format
        // is not specified, but should have sufficient information to rebuild the
        // entry. Some options are: proto bytes, or proto json.
        //
        // Note this function needs to be thread-safe.
        Write(*pb.GrpcLogEntry) error
        // Close closes this sink and cleans up resources (e.g. the flushing
        // goroutine).
        Close() error
}

// NewTempFileSink creates a temp file and returns a Sink that writes to this
// file.
func NewTempFileSink() (Sink, error) <span class="cov0" title="0">{
        // Two other options to replace this function:
        // 1. take filename as input.
        // 2. export NewBufferedSink().
        tempFile, err := ioutil.TempFile("/tmp", "grpcgo_binarylog_*.txt")
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create temp file: %v", err)
        }</span>
        <span class="cov0" title="0">return iblog.NewBufferedSink(tempFile), nil</span>
}
</pre>
		
		<pre class="file" id="file31" style="display: none">/*
 *
 * Copyright 2014 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package grpc

import (
        "context"
)

// Invoke sends the RPC request on the wire and returns after response is
// received.  This is typically called by generated code.
//
// All errors returned by Invoke are compatible with the status package.
func (cc *ClientConn) Invoke(ctx context.Context, method string, args, reply interface{}, opts ...CallOption) error <span class="cov0" title="0">{
        // allow interceptor to see all applicable call options, which means those
        // configured as defaults from dial option as well as per-call options
        opts = combine(cc.dopts.callOptions, opts)

        if cc.dopts.unaryInt != nil </span><span class="cov0" title="0">{
                return cc.dopts.unaryInt(ctx, method, args, reply, cc, invoke, opts...)
        }</span>
        <span class="cov0" title="0">return invoke(ctx, method, args, reply, cc, opts...)</span>
}

func combine(o1 []CallOption, o2 []CallOption) []CallOption <span class="cov0" title="0">{
        // we don't use append because o1 could have extra capacity whose
        // elements would be overwritten, which could cause inadvertent
        // sharing (and race conditions) between concurrent calls
        if len(o1) == 0 </span><span class="cov0" title="0">{
                return o2
        }</span> else<span class="cov0" title="0"> if len(o2) == 0 </span><span class="cov0" title="0">{
                return o1
        }</span>
        <span class="cov0" title="0">ret := make([]CallOption, len(o1)+len(o2))
        copy(ret, o1)
        copy(ret[len(o1):], o2)
        return ret</span>
}

// Invoke sends the RPC request on the wire and returns after response is
// received.  This is typically called by generated code.
//
// DEPRECATED: Use ClientConn.Invoke instead.
func Invoke(ctx context.Context, method string, args, reply interface{}, cc *ClientConn, opts ...CallOption) error <span class="cov0" title="0">{
        return cc.Invoke(ctx, method, args, reply, opts...)
}</span>

var unaryStreamDesc = &amp;StreamDesc{ServerStreams: false, ClientStreams: false}

func invoke(ctx context.Context, method string, req, reply interface{}, cc *ClientConn, opts ...CallOption) error <span class="cov0" title="0">{
        cs, err := newClientStream(ctx, unaryStreamDesc, cc, method, opts...)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov0" title="0">if err := cs.SendMsg(req); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov0" title="0">return cs.RecvMsg(reply)</span>
}
</pre>
		
		<pre class="file" id="file32" style="display: none">//go:build !linux
// +build !linux

/*
 *
 * Copyright 2018 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package service

import (
        channelzpb "google.golang.org/grpc/channelz/grpc_channelz_v1"
        "google.golang.org/grpc/internal/channelz"
)

func sockoptToProto(skopts *channelz.SocketOptionData) []*channelzpb.SocketOption <span class="cov0" title="0">{
        return nil
}</span>
</pre>
		
		<pre class="file" id="file33" style="display: none">/*
 *
 * Copyright 2018 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package service provides an implementation for channelz service server.
package service

import (
        "context"
        "net"

        "github.com/golang/protobuf/ptypes"
        wrpb "github.com/golang/protobuf/ptypes/wrappers"
        "google.golang.org/grpc"
        channelzgrpc "google.golang.org/grpc/channelz/grpc_channelz_v1"
        channelzpb "google.golang.org/grpc/channelz/grpc_channelz_v1"
        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/connectivity"
        "google.golang.org/grpc/credentials"
        "google.golang.org/grpc/grpclog"
        "google.golang.org/grpc/internal/channelz"
        "google.golang.org/grpc/status"
)

func init() <span class="cov8" title="1">{
        channelz.TurnOn()
}</span>

var logger = grpclog.Component("channelz")

// RegisterChannelzServiceToServer registers the channelz service to the given server.
//
// Note: it is preferred to use the admin API
// (https://pkg.go.dev/google.golang.org/grpc/admin#Register) instead to
// register Channelz and other administrative services.
func RegisterChannelzServiceToServer(s grpc.ServiceRegistrar) <span class="cov0" title="0">{
        channelzgrpc.RegisterChannelzServer(s, newCZServer())
}</span>

func newCZServer() channelzgrpc.ChannelzServer <span class="cov8" title="1">{
        return &amp;serverImpl{}
}</span>

type serverImpl struct {
        channelzgrpc.UnimplementedChannelzServer
}

func connectivityStateToProto(s connectivity.State) *channelzpb.ChannelConnectivityState <span class="cov8" title="1">{
        switch s </span>{
        case connectivity.Idle:<span class="cov8" title="1">
                return &amp;channelzpb.ChannelConnectivityState{State: channelzpb.ChannelConnectivityState_IDLE}</span>
        case connectivity.Connecting:<span class="cov8" title="1">
                return &amp;channelzpb.ChannelConnectivityState{State: channelzpb.ChannelConnectivityState_CONNECTING}</span>
        case connectivity.Ready:<span class="cov0" title="0">
                return &amp;channelzpb.ChannelConnectivityState{State: channelzpb.ChannelConnectivityState_READY}</span>
        case connectivity.TransientFailure:<span class="cov0" title="0">
                return &amp;channelzpb.ChannelConnectivityState{State: channelzpb.ChannelConnectivityState_TRANSIENT_FAILURE}</span>
        case connectivity.Shutdown:<span class="cov8" title="1">
                return &amp;channelzpb.ChannelConnectivityState{State: channelzpb.ChannelConnectivityState_SHUTDOWN}</span>
        default:<span class="cov0" title="0">
                return &amp;channelzpb.ChannelConnectivityState{State: channelzpb.ChannelConnectivityState_UNKNOWN}</span>
        }
}

func channelTraceToProto(ct *channelz.ChannelTrace) *channelzpb.ChannelTrace <span class="cov8" title="1">{
        pbt := &amp;channelzpb.ChannelTrace{}
        pbt.NumEventsLogged = ct.EventNum
        if ts, err := ptypes.TimestampProto(ct.CreationTime); err == nil </span><span class="cov8" title="1">{
                pbt.CreationTimestamp = ts
        }</span>
        <span class="cov8" title="1">events := make([]*channelzpb.ChannelTraceEvent, 0, len(ct.Events))
        for _, e := range ct.Events </span><span class="cov8" title="1">{
                cte := &amp;channelzpb.ChannelTraceEvent{
                        Description: e.Desc,
                        Severity:    channelzpb.ChannelTraceEvent_Severity(e.Severity),
                }
                if ts, err := ptypes.TimestampProto(e.Timestamp); err == nil </span><span class="cov8" title="1">{
                        cte.Timestamp = ts
                }</span>
                <span class="cov8" title="1">if e.RefID != 0 </span><span class="cov8" title="1">{
                        switch e.RefType </span>{
                        case channelz.RefChannel:<span class="cov8" title="1">
                                cte.ChildRef = &amp;channelzpb.ChannelTraceEvent_ChannelRef{ChannelRef: &amp;channelzpb.ChannelRef{ChannelId: e.RefID, Name: e.RefName}}</span>
                        case channelz.RefSubChannel:<span class="cov8" title="1">
                                cte.ChildRef = &amp;channelzpb.ChannelTraceEvent_SubchannelRef{SubchannelRef: &amp;channelzpb.SubchannelRef{SubchannelId: e.RefID, Name: e.RefName}}</span>
                        }
                }
                <span class="cov8" title="1">events = append(events, cte)</span>
        }
        <span class="cov8" title="1">pbt.Events = events
        return pbt</span>
}

func channelMetricToProto(cm *channelz.ChannelMetric) *channelzpb.Channel <span class="cov8" title="1">{
        c := &amp;channelzpb.Channel{}
        c.Ref = &amp;channelzpb.ChannelRef{ChannelId: cm.ID, Name: cm.RefName}

        c.Data = &amp;channelzpb.ChannelData{
                State:          connectivityStateToProto(cm.ChannelData.State),
                Target:         cm.ChannelData.Target,
                CallsStarted:   cm.ChannelData.CallsStarted,
                CallsSucceeded: cm.ChannelData.CallsSucceeded,
                CallsFailed:    cm.ChannelData.CallsFailed,
        }
        if ts, err := ptypes.TimestampProto(cm.ChannelData.LastCallStartedTimestamp); err == nil </span><span class="cov8" title="1">{
                c.Data.LastCallStartedTimestamp = ts
        }</span>
        <span class="cov8" title="1">nestedChans := make([]*channelzpb.ChannelRef, 0, len(cm.NestedChans))
        for id, ref := range cm.NestedChans </span><span class="cov8" title="1">{
                nestedChans = append(nestedChans, &amp;channelzpb.ChannelRef{ChannelId: id, Name: ref})
        }</span>
        <span class="cov8" title="1">c.ChannelRef = nestedChans

        subChans := make([]*channelzpb.SubchannelRef, 0, len(cm.SubChans))
        for id, ref := range cm.SubChans </span><span class="cov8" title="1">{
                subChans = append(subChans, &amp;channelzpb.SubchannelRef{SubchannelId: id, Name: ref})
        }</span>
        <span class="cov8" title="1">c.SubchannelRef = subChans

        sockets := make([]*channelzpb.SocketRef, 0, len(cm.Sockets))
        for id, ref := range cm.Sockets </span><span class="cov0" title="0">{
                sockets = append(sockets, &amp;channelzpb.SocketRef{SocketId: id, Name: ref})
        }</span>
        <span class="cov8" title="1">c.SocketRef = sockets
        c.Data.Trace = channelTraceToProto(cm.Trace)
        return c</span>
}

func subChannelMetricToProto(cm *channelz.SubChannelMetric) *channelzpb.Subchannel <span class="cov8" title="1">{
        sc := &amp;channelzpb.Subchannel{}
        sc.Ref = &amp;channelzpb.SubchannelRef{SubchannelId: cm.ID, Name: cm.RefName}

        sc.Data = &amp;channelzpb.ChannelData{
                State:          connectivityStateToProto(cm.ChannelData.State),
                Target:         cm.ChannelData.Target,
                CallsStarted:   cm.ChannelData.CallsStarted,
                CallsSucceeded: cm.ChannelData.CallsSucceeded,
                CallsFailed:    cm.ChannelData.CallsFailed,
        }
        if ts, err := ptypes.TimestampProto(cm.ChannelData.LastCallStartedTimestamp); err == nil </span><span class="cov8" title="1">{
                sc.Data.LastCallStartedTimestamp = ts
        }</span>
        <span class="cov8" title="1">nestedChans := make([]*channelzpb.ChannelRef, 0, len(cm.NestedChans))
        for id, ref := range cm.NestedChans </span><span class="cov0" title="0">{
                nestedChans = append(nestedChans, &amp;channelzpb.ChannelRef{ChannelId: id, Name: ref})
        }</span>
        <span class="cov8" title="1">sc.ChannelRef = nestedChans

        subChans := make([]*channelzpb.SubchannelRef, 0, len(cm.SubChans))
        for id, ref := range cm.SubChans </span><span class="cov0" title="0">{
                subChans = append(subChans, &amp;channelzpb.SubchannelRef{SubchannelId: id, Name: ref})
        }</span>
        <span class="cov8" title="1">sc.SubchannelRef = subChans

        sockets := make([]*channelzpb.SocketRef, 0, len(cm.Sockets))
        for id, ref := range cm.Sockets </span><span class="cov8" title="1">{
                sockets = append(sockets, &amp;channelzpb.SocketRef{SocketId: id, Name: ref})
        }</span>
        <span class="cov8" title="1">sc.SocketRef = sockets
        sc.Data.Trace = channelTraceToProto(cm.Trace)
        return sc</span>
}

func securityToProto(se credentials.ChannelzSecurityValue) *channelzpb.Security <span class="cov8" title="1">{
        switch v := se.(type) </span>{
        case *credentials.TLSChannelzSecurityValue:<span class="cov8" title="1">
                return &amp;channelzpb.Security{Model: &amp;channelzpb.Security_Tls_{Tls: &amp;channelzpb.Security_Tls{
                        CipherSuite:       &amp;channelzpb.Security_Tls_StandardName{StandardName: v.StandardName},
                        LocalCertificate:  v.LocalCertificate,
                        RemoteCertificate: v.RemoteCertificate,
                }}}</span>
        case *credentials.OtherChannelzSecurityValue:<span class="cov8" title="1">
                otherSecurity := &amp;channelzpb.Security_OtherSecurity{
                        Name: v.Name,
                }
                if anyval, err := ptypes.MarshalAny(v.Value); err == nil </span><span class="cov8" title="1">{
                        otherSecurity.Value = anyval
                }</span>
                <span class="cov8" title="1">return &amp;channelzpb.Security{Model: &amp;channelzpb.Security_Other{Other: otherSecurity}}</span>
        }
        <span class="cov0" title="0">return nil</span>
}

func addrToProto(a net.Addr) *channelzpb.Address <span class="cov8" title="1">{
        switch a.Network() </span>{
        case "udp":<span class="cov0" title="0"></span>
                // TODO: Address_OtherAddress{}. Need proto def for Value.
        case "ip":<span class="cov8" title="1">
                // Note zone info is discarded through the conversion.
                return &amp;channelzpb.Address{Address: &amp;channelzpb.Address_TcpipAddress{TcpipAddress: &amp;channelzpb.Address_TcpIpAddress{IpAddress: a.(*net.IPAddr).IP}}}</span>
        case "ip+net":<span class="cov0" title="0">
                // Note mask info is discarded through the conversion.
                return &amp;channelzpb.Address{Address: &amp;channelzpb.Address_TcpipAddress{TcpipAddress: &amp;channelzpb.Address_TcpIpAddress{IpAddress: a.(*net.IPNet).IP}}}</span>
        case "tcp":<span class="cov8" title="1">
                // Note zone info is discarded through the conversion.
                return &amp;channelzpb.Address{Address: &amp;channelzpb.Address_TcpipAddress{TcpipAddress: &amp;channelzpb.Address_TcpIpAddress{IpAddress: a.(*net.TCPAddr).IP, Port: int32(a.(*net.TCPAddr).Port)}}}</span>
        case "unix", "unixgram", "unixpacket":<span class="cov8" title="1">
                return &amp;channelzpb.Address{Address: &amp;channelzpb.Address_UdsAddress_{UdsAddress: &amp;channelzpb.Address_UdsAddress{Filename: a.String()}}}</span>
        default:<span class="cov0" title="0"></span>
        }
        <span class="cov0" title="0">return &amp;channelzpb.Address{}</span>
}

func socketMetricToProto(sm *channelz.SocketMetric) *channelzpb.Socket <span class="cov8" title="1">{
        s := &amp;channelzpb.Socket{}
        s.Ref = &amp;channelzpb.SocketRef{SocketId: sm.ID, Name: sm.RefName}

        s.Data = &amp;channelzpb.SocketData{
                StreamsStarted:   sm.SocketData.StreamsStarted,
                StreamsSucceeded: sm.SocketData.StreamsSucceeded,
                StreamsFailed:    sm.SocketData.StreamsFailed,
                MessagesSent:     sm.SocketData.MessagesSent,
                MessagesReceived: sm.SocketData.MessagesReceived,
                KeepAlivesSent:   sm.SocketData.KeepAlivesSent,
        }
        if ts, err := ptypes.TimestampProto(sm.SocketData.LastLocalStreamCreatedTimestamp); err == nil </span><span class="cov8" title="1">{
                s.Data.LastLocalStreamCreatedTimestamp = ts
        }</span>
        <span class="cov8" title="1">if ts, err := ptypes.TimestampProto(sm.SocketData.LastRemoteStreamCreatedTimestamp); err == nil </span><span class="cov8" title="1">{
                s.Data.LastRemoteStreamCreatedTimestamp = ts
        }</span>
        <span class="cov8" title="1">if ts, err := ptypes.TimestampProto(sm.SocketData.LastMessageSentTimestamp); err == nil </span><span class="cov8" title="1">{
                s.Data.LastMessageSentTimestamp = ts
        }</span>
        <span class="cov8" title="1">if ts, err := ptypes.TimestampProto(sm.SocketData.LastMessageReceivedTimestamp); err == nil </span><span class="cov8" title="1">{
                s.Data.LastMessageReceivedTimestamp = ts
        }</span>
        <span class="cov8" title="1">s.Data.LocalFlowControlWindow = &amp;wrpb.Int64Value{Value: sm.SocketData.LocalFlowControlWindow}
        s.Data.RemoteFlowControlWindow = &amp;wrpb.Int64Value{Value: sm.SocketData.RemoteFlowControlWindow}

        if sm.SocketData.SocketOptions != nil </span><span class="cov0" title="0">{
                s.Data.Option = sockoptToProto(sm.SocketData.SocketOptions)
        }</span>
        <span class="cov8" title="1">if sm.SocketData.Security != nil </span><span class="cov8" title="1">{
                s.Security = securityToProto(sm.SocketData.Security)
        }</span>

        <span class="cov8" title="1">if sm.SocketData.LocalAddr != nil </span><span class="cov8" title="1">{
                s.Local = addrToProto(sm.SocketData.LocalAddr)
        }</span>
        <span class="cov8" title="1">if sm.SocketData.RemoteAddr != nil </span><span class="cov8" title="1">{
                s.Remote = addrToProto(sm.SocketData.RemoteAddr)
        }</span>
        <span class="cov8" title="1">s.RemoteName = sm.SocketData.RemoteName
        return s</span>
}

func (s *serverImpl) GetTopChannels(ctx context.Context, req *channelzpb.GetTopChannelsRequest) (*channelzpb.GetTopChannelsResponse, error) <span class="cov8" title="1">{
        metrics, end := channelz.GetTopChannels(req.GetStartChannelId(), req.GetMaxResults())
        resp := &amp;channelzpb.GetTopChannelsResponse{}
        for _, m := range metrics </span><span class="cov8" title="1">{
                resp.Channel = append(resp.Channel, channelMetricToProto(m))
        }</span>
        <span class="cov8" title="1">resp.End = end
        return resp, nil</span>
}

func serverMetricToProto(sm *channelz.ServerMetric) *channelzpb.Server <span class="cov8" title="1">{
        s := &amp;channelzpb.Server{}
        s.Ref = &amp;channelzpb.ServerRef{ServerId: sm.ID, Name: sm.RefName}

        s.Data = &amp;channelzpb.ServerData{
                CallsStarted:   sm.ServerData.CallsStarted,
                CallsSucceeded: sm.ServerData.CallsSucceeded,
                CallsFailed:    sm.ServerData.CallsFailed,
        }

        if ts, err := ptypes.TimestampProto(sm.ServerData.LastCallStartedTimestamp); err == nil </span><span class="cov8" title="1">{
                s.Data.LastCallStartedTimestamp = ts
        }</span>
        <span class="cov8" title="1">sockets := make([]*channelzpb.SocketRef, 0, len(sm.ListenSockets))
        for id, ref := range sm.ListenSockets </span><span class="cov0" title="0">{
                sockets = append(sockets, &amp;channelzpb.SocketRef{SocketId: id, Name: ref})
        }</span>
        <span class="cov8" title="1">s.ListenSocket = sockets
        return s</span>
}

func (s *serverImpl) GetServers(ctx context.Context, req *channelzpb.GetServersRequest) (*channelzpb.GetServersResponse, error) <span class="cov8" title="1">{
        metrics, end := channelz.GetServers(req.GetStartServerId(), req.GetMaxResults())
        resp := &amp;channelzpb.GetServersResponse{}
        for _, m := range metrics </span><span class="cov8" title="1">{
                resp.Server = append(resp.Server, serverMetricToProto(m))
        }</span>
        <span class="cov8" title="1">resp.End = end
        return resp, nil</span>
}

func (s *serverImpl) GetServerSockets(ctx context.Context, req *channelzpb.GetServerSocketsRequest) (*channelzpb.GetServerSocketsResponse, error) <span class="cov8" title="1">{
        metrics, end := channelz.GetServerSockets(req.GetServerId(), req.GetStartSocketId(), req.GetMaxResults())
        resp := &amp;channelzpb.GetServerSocketsResponse{}
        for _, m := range metrics </span><span class="cov8" title="1">{
                resp.SocketRef = append(resp.SocketRef, &amp;channelzpb.SocketRef{SocketId: m.ID, Name: m.RefName})
        }</span>
        <span class="cov8" title="1">resp.End = end
        return resp, nil</span>
}

func (s *serverImpl) GetChannel(ctx context.Context, req *channelzpb.GetChannelRequest) (*channelzpb.GetChannelResponse, error) <span class="cov8" title="1">{
        var metric *channelz.ChannelMetric
        if metric = channelz.GetChannel(req.GetChannelId()); metric == nil </span><span class="cov0" title="0">{
                return nil, status.Errorf(codes.NotFound, "requested channel %d not found", req.GetChannelId())
        }</span>
        <span class="cov8" title="1">resp := &amp;channelzpb.GetChannelResponse{Channel: channelMetricToProto(metric)}
        return resp, nil</span>
}

func (s *serverImpl) GetSubchannel(ctx context.Context, req *channelzpb.GetSubchannelRequest) (*channelzpb.GetSubchannelResponse, error) <span class="cov8" title="1">{
        var metric *channelz.SubChannelMetric
        if metric = channelz.GetSubChannel(req.GetSubchannelId()); metric == nil </span><span class="cov0" title="0">{
                return nil, status.Errorf(codes.NotFound, "requested sub channel %d not found", req.GetSubchannelId())
        }</span>
        <span class="cov8" title="1">resp := &amp;channelzpb.GetSubchannelResponse{Subchannel: subChannelMetricToProto(metric)}
        return resp, nil</span>
}

func (s *serverImpl) GetSocket(ctx context.Context, req *channelzpb.GetSocketRequest) (*channelzpb.GetSocketResponse, error) <span class="cov8" title="1">{
        var metric *channelz.SocketMetric
        if metric = channelz.GetSocket(req.GetSocketId()); metric == nil </span><span class="cov0" title="0">{
                return nil, status.Errorf(codes.NotFound, "requested socket %d not found", req.GetSocketId())
        }</span>
        <span class="cov8" title="1">resp := &amp;channelzpb.GetSocketResponse{Socket: socketMetricToProto(metric)}
        return resp, nil</span>
}

func (s *serverImpl) GetServer(ctx context.Context, req *channelzpb.GetServerRequest) (*channelzpb.GetServerResponse, error) <span class="cov0" title="0">{
        var metric *channelz.ServerMetric
        if metric = channelz.GetServer(req.GetServerId()); metric == nil </span><span class="cov0" title="0">{
                return nil, status.Errorf(codes.NotFound, "requested server %d not found", req.GetServerId())
        }</span>
        <span class="cov0" title="0">resp := &amp;channelzpb.GetServerResponse{Server: serverMetricToProto(metric)}
        return resp, nil</span>
}
</pre>
		
		<pre class="file" id="file34" style="display: none">/*
 *
 * Copyright 2014 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package grpc

import (
        "context"
        "errors"
        "fmt"
        "math"
        "net/url"
        "reflect"
        "strings"
        "sync"
        "sync/atomic"
        "time"

        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/balancer/base"
        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/connectivity"
        "google.golang.org/grpc/credentials"
        "google.golang.org/grpc/internal/backoff"
        "google.golang.org/grpc/internal/channelz"
        "google.golang.org/grpc/internal/grpcsync"
        iresolver "google.golang.org/grpc/internal/resolver"
        "google.golang.org/grpc/internal/transport"
        "google.golang.org/grpc/keepalive"
        "google.golang.org/grpc/resolver"
        "google.golang.org/grpc/serviceconfig"
        "google.golang.org/grpc/status"

        _ "google.golang.org/grpc/balancer/roundrobin"           // To register roundrobin.
        _ "google.golang.org/grpc/internal/resolver/dns"         // To register dns resolver.
        _ "google.golang.org/grpc/internal/resolver/passthrough" // To register passthrough resolver.
        _ "google.golang.org/grpc/internal/resolver/unix"        // To register unix resolver.
)

const (
        // minimum time to give a connection to complete
        minConnectTimeout = 20 * time.Second
        // must match grpclbName in grpclb/grpclb.go
        grpclbName = "grpclb"
)

var (
        // ErrClientConnClosing indicates that the operation is illegal because
        // the ClientConn is closing.
        //
        // Deprecated: this error should not be relied upon by users; use the status
        // code of Canceled instead.
        ErrClientConnClosing = status.Error(codes.Canceled, "grpc: the client connection is closing")
        // errConnDrain indicates that the connection starts to be drained and does not accept any new RPCs.
        errConnDrain = errors.New("grpc: the connection is drained")
        // errConnClosing indicates that the connection is closing.
        errConnClosing = errors.New("grpc: the connection is closing")
        // invalidDefaultServiceConfigErrPrefix is used to prefix the json parsing error for the default
        // service config.
        invalidDefaultServiceConfigErrPrefix = "grpc: the provided default service config is invalid"
)

// The following errors are returned from Dial and DialContext
var (
        // errNoTransportSecurity indicates that there is no transport security
        // being set for ClientConn. Users should either set one or explicitly
        // call WithInsecure DialOption to disable security.
        errNoTransportSecurity = errors.New("grpc: no transport security set (use grpc.WithTransportCredentials(insecure.NewCredentials()) explicitly or set credentials)")
        // errTransportCredsAndBundle indicates that creds bundle is used together
        // with other individual Transport Credentials.
        errTransportCredsAndBundle = errors.New("grpc: credentials.Bundle may not be used with individual TransportCredentials")
        // errNoTransportCredsInBundle indicated that the configured creds bundle
        // returned a transport credentials which was nil.
        errNoTransportCredsInBundle = errors.New("grpc: credentials.Bundle must return non-nil transport credentials")
        // errTransportCredentialsMissing indicates that users want to transmit
        // security information (e.g., OAuth2 token) which requires secure
        // connection on an insecure connection.
        errTransportCredentialsMissing = errors.New("grpc: the credentials require transport level security (use grpc.WithTransportCredentials() to set)")
)

const (
        defaultClientMaxReceiveMessageSize = 1024 * 1024 * 4
        defaultClientMaxSendMessageSize    = math.MaxInt32
        // http2IOBufSize specifies the buffer size for sending frames.
        defaultWriteBufSize = 32 * 1024
        defaultReadBufSize  = 32 * 1024
)

// Dial creates a client connection to the given target.
func Dial(target string, opts ...DialOption) (*ClientConn, error) <span class="cov8" title="1">{
        return DialContext(context.Background(), target, opts...)
}</span>

type defaultConfigSelector struct {
        sc *ServiceConfig
}

func (dcs *defaultConfigSelector) SelectConfig(rpcInfo iresolver.RPCInfo) (*iresolver.RPCConfig, error) <span class="cov0" title="0">{
        return &amp;iresolver.RPCConfig{
                Context:      rpcInfo.Context,
                MethodConfig: getMethodConfig(dcs.sc, rpcInfo.Method),
        }, nil
}</span>

// DialContext creates a client connection to the given target. By default, it's
// a non-blocking dial (the function won't wait for connections to be
// established, and connecting happens in the background). To make it a blocking
// dial, use WithBlock() dial option.
//
// In the non-blocking case, the ctx does not act against the connection. It
// only controls the setup steps.
//
// In the blocking case, ctx can be used to cancel or expire the pending
// connection. Once this function returns, the cancellation and expiration of
// ctx will be noop. Users should call ClientConn.Close to terminate all the
// pending operations after this function returns.
//
// The target name syntax is defined in
// https://github.com/grpc/grpc/blob/master/doc/naming.md.
// e.g. to use dns resolver, a "dns:///" prefix should be applied to the target.
func DialContext(ctx context.Context, target string, opts ...DialOption) (conn *ClientConn, err error) <span class="cov8" title="1">{
        cc := &amp;ClientConn{
                target:            target,
                csMgr:             &amp;connectivityStateManager{},
                conns:             make(map[*addrConn]struct{}),
                dopts:             defaultDialOptions(),
                blockingpicker:    newPickerWrapper(),
                czData:            new(channelzData),
                firstResolveEvent: grpcsync.NewEvent(),
        }
        cc.retryThrottler.Store((*retryThrottler)(nil))
        cc.safeConfigSelector.UpdateConfigSelector(&amp;defaultConfigSelector{nil})
        cc.ctx, cc.cancel = context.WithCancel(context.Background())

        for _, opt := range extraDialOptions </span><span class="cov8" title="1">{
                opt.apply(&amp;cc.dopts)
        }</span>

        <span class="cov8" title="1">for _, opt := range opts </span><span class="cov8" title="1">{
                opt.apply(&amp;cc.dopts)
        }</span>

        <span class="cov8" title="1">chainUnaryClientInterceptors(cc)
        chainStreamClientInterceptors(cc)

        defer func() </span><span class="cov8" title="1">{
                if err != nil </span><span class="cov8" title="1">{
                        cc.Close()
                }</span>
        }()

        <span class="cov8" title="1">pid := cc.dopts.channelzParentID
        cc.channelzID = channelz.RegisterChannel(&amp;channelzChannel{cc}, pid, target)
        ted := &amp;channelz.TraceEventDesc{
                Desc:     "Channel created",
                Severity: channelz.CtInfo,
        }
        if cc.dopts.channelzParentID != nil </span><span class="cov0" title="0">{
                ted.Parent = &amp;channelz.TraceEventDesc{
                        Desc:     fmt.Sprintf("Nested Channel(id:%d) created", cc.channelzID.Int()),
                        Severity: channelz.CtInfo,
                }
        }</span>
        <span class="cov8" title="1">channelz.AddTraceEvent(logger, cc.channelzID, 1, ted)
        cc.csMgr.channelzID = cc.channelzID

        if cc.dopts.copts.TransportCredentials == nil &amp;&amp; cc.dopts.copts.CredsBundle == nil </span><span class="cov8" title="1">{
                return nil, errNoTransportSecurity
        }</span>
        <span class="cov8" title="1">if cc.dopts.copts.TransportCredentials != nil &amp;&amp; cc.dopts.copts.CredsBundle != nil </span><span class="cov8" title="1">{
                return nil, errTransportCredsAndBundle
        }</span>
        <span class="cov8" title="1">if cc.dopts.copts.CredsBundle != nil &amp;&amp; cc.dopts.copts.CredsBundle.TransportCredentials() == nil </span><span class="cov8" title="1">{
                return nil, errNoTransportCredsInBundle
        }</span>
        <span class="cov8" title="1">transportCreds := cc.dopts.copts.TransportCredentials
        if transportCreds == nil </span><span class="cov0" title="0">{
                transportCreds = cc.dopts.copts.CredsBundle.TransportCredentials()
        }</span>
        <span class="cov8" title="1">if transportCreds.Info().SecurityProtocol == "insecure" </span><span class="cov8" title="1">{
                for _, cd := range cc.dopts.copts.PerRPCCredentials </span><span class="cov8" title="1">{
                        if cd.RequireTransportSecurity() </span><span class="cov8" title="1">{
                                return nil, errTransportCredentialsMissing
                        }</span>
                }
        }

        <span class="cov8" title="1">if cc.dopts.defaultServiceConfigRawJSON != nil </span><span class="cov8" title="1">{
                scpr := parseServiceConfig(*cc.dopts.defaultServiceConfigRawJSON)
                if scpr.Err != nil </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("%s: %v", invalidDefaultServiceConfigErrPrefix, scpr.Err)
                }</span>
                <span class="cov8" title="1">cc.dopts.defaultServiceConfig, _ = scpr.Config.(*ServiceConfig)</span>
        }
        <span class="cov8" title="1">cc.mkp = cc.dopts.copts.KeepaliveParams

        if cc.dopts.copts.UserAgent != "" </span><span class="cov0" title="0">{
                cc.dopts.copts.UserAgent += " " + grpcUA
        }</span> else<span class="cov8" title="1"> {
                cc.dopts.copts.UserAgent = grpcUA
        }</span>

        <span class="cov8" title="1">if cc.dopts.timeout &gt; 0 </span><span class="cov8" title="1">{
                var cancel context.CancelFunc
                ctx, cancel = context.WithTimeout(ctx, cc.dopts.timeout)
                defer cancel()
        }</span>
        <span class="cov8" title="1">defer func() </span><span class="cov8" title="1">{
                select </span>{
                case &lt;-ctx.Done():<span class="cov8" title="1">
                        switch </span>{
                        case ctx.Err() == err:<span class="cov8" title="1">
                                conn = nil</span>
                        case err == nil || !cc.dopts.returnLastError:<span class="cov0" title="0">
                                conn, err = nil, ctx.Err()</span>
                        default:<span class="cov8" title="1">
                                conn, err = nil, fmt.Errorf("%v: %v", ctx.Err(), err)</span>
                        }
                default:<span class="cov8" title="1"></span>
                }
        }()

        <span class="cov8" title="1">scSet := false
        if cc.dopts.scChan != nil </span><span class="cov0" title="0">{
                // Try to get an initial service config.
                select </span>{
                case sc, ok := &lt;-cc.dopts.scChan:<span class="cov0" title="0">
                        if ok </span><span class="cov0" title="0">{
                                cc.sc = &amp;sc
                                cc.safeConfigSelector.UpdateConfigSelector(&amp;defaultConfigSelector{&amp;sc})
                                scSet = true
                        }</span>
                default:<span class="cov0" title="0"></span>
                }
        }
        <span class="cov8" title="1">if cc.dopts.bs == nil </span><span class="cov8" title="1">{
                cc.dopts.bs = backoff.DefaultExponential
        }</span>

        // Determine the resolver to use.
        <span class="cov8" title="1">resolverBuilder, err := cc.parseTargetAndFindResolver()
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">cc.authority, err = determineAuthority(cc.parsedTarget.Endpoint, cc.target, cc.dopts)
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">channelz.Infof(logger, cc.channelzID, "Channel authority set to %q", cc.authority)

        if cc.dopts.scChan != nil &amp;&amp; !scSet </span><span class="cov0" title="0">{
                // Blocking wait for the initial service config.
                select </span>{
                case sc, ok := &lt;-cc.dopts.scChan:<span class="cov0" title="0">
                        if ok </span><span class="cov0" title="0">{
                                cc.sc = &amp;sc
                                cc.safeConfigSelector.UpdateConfigSelector(&amp;defaultConfigSelector{&amp;sc})
                        }</span>
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        return nil, ctx.Err()</span>
                }
        }
        <span class="cov8" title="1">if cc.dopts.scChan != nil </span><span class="cov0" title="0">{
                go cc.scWatcher()
        }</span>

        <span class="cov8" title="1">var credsClone credentials.TransportCredentials
        if creds := cc.dopts.copts.TransportCredentials; creds != nil </span><span class="cov8" title="1">{
                credsClone = creds.Clone()
        }</span>
        <span class="cov8" title="1">cc.balancerWrapper = newCCBalancerWrapper(cc, balancer.BuildOptions{
                DialCreds:        credsClone,
                CredsBundle:      cc.dopts.copts.CredsBundle,
                Dialer:           cc.dopts.copts.Dialer,
                Authority:        cc.authority,
                CustomUserAgent:  cc.dopts.copts.UserAgent,
                ChannelzParentID: cc.channelzID,
                Target:           cc.parsedTarget,
        })

        // Build the resolver.
        rWrapper, err := newCCResolverWrapper(cc, resolverBuilder)
        if err != nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("failed to build resolver: %v", err)
        }</span>
        <span class="cov8" title="1">cc.mu.Lock()
        cc.resolverWrapper = rWrapper
        cc.mu.Unlock()

        // A blocking dial blocks until the clientConn is ready.
        if cc.dopts.block </span><span class="cov8" title="1">{
                for </span><span class="cov8" title="1">{
                        cc.Connect()
                        s := cc.GetState()
                        if s == connectivity.Ready </span><span class="cov8" title="1">{
                                break</span>
                        } else<span class="cov8" title="1"> if cc.dopts.copts.FailOnNonTempDialError &amp;&amp; s == connectivity.TransientFailure </span><span class="cov8" title="1">{
                                if err = cc.connectionError(); err != nil </span><span class="cov8" title="1">{
                                        terr, ok := err.(interface {
                                                Temporary() bool
                                        })
                                        if ok &amp;&amp; !terr.Temporary() </span><span class="cov8" title="1">{
                                                return nil, err
                                        }</span>
                                }
                        }
                        <span class="cov8" title="1">if !cc.WaitForStateChange(ctx, s) </span><span class="cov8" title="1">{
                                // ctx got timeout or canceled.
                                if err = cc.connectionError(); err != nil &amp;&amp; cc.dopts.returnLastError </span><span class="cov8" title="1">{
                                        return nil, err
                                }</span>
                                <span class="cov8" title="1">return nil, ctx.Err()</span>
                        }
                }
        }

        <span class="cov8" title="1">return cc, nil</span>
}

// chainUnaryClientInterceptors chains all unary client interceptors into one.
func chainUnaryClientInterceptors(cc *ClientConn) <span class="cov8" title="1">{
        interceptors := cc.dopts.chainUnaryInts
        // Prepend dopts.unaryInt to the chaining interceptors if it exists, since unaryInt will
        // be executed before any other chained interceptors.
        if cc.dopts.unaryInt != nil </span><span class="cov0" title="0">{
                interceptors = append([]UnaryClientInterceptor{cc.dopts.unaryInt}, interceptors...)
        }</span>
        <span class="cov8" title="1">var chainedInt UnaryClientInterceptor
        if len(interceptors) == 0 </span><span class="cov8" title="1">{
                chainedInt = nil
        }</span> else<span class="cov0" title="0"> if len(interceptors) == 1 </span><span class="cov0" title="0">{
                chainedInt = interceptors[0]
        }</span> else<span class="cov0" title="0"> {
                chainedInt = func(ctx context.Context, method string, req, reply interface{}, cc *ClientConn, invoker UnaryInvoker, opts ...CallOption) error </span><span class="cov0" title="0">{
                        return interceptors[0](ctx, method, req, reply, cc, getChainUnaryInvoker(interceptors, 0, invoker), opts...)
                }</span>
        }
        <span class="cov8" title="1">cc.dopts.unaryInt = chainedInt</span>
}

// getChainUnaryInvoker recursively generate the chained unary invoker.
func getChainUnaryInvoker(interceptors []UnaryClientInterceptor, curr int, finalInvoker UnaryInvoker) UnaryInvoker <span class="cov0" title="0">{
        if curr == len(interceptors)-1 </span><span class="cov0" title="0">{
                return finalInvoker
        }</span>
        <span class="cov0" title="0">return func(ctx context.Context, method string, req, reply interface{}, cc *ClientConn, opts ...CallOption) error </span><span class="cov0" title="0">{
                return interceptors[curr+1](ctx, method, req, reply, cc, getChainUnaryInvoker(interceptors, curr+1, finalInvoker), opts...)
        }</span>
}

// chainStreamClientInterceptors chains all stream client interceptors into one.
func chainStreamClientInterceptors(cc *ClientConn) <span class="cov8" title="1">{
        interceptors := cc.dopts.chainStreamInts
        // Prepend dopts.streamInt to the chaining interceptors if it exists, since streamInt will
        // be executed before any other chained interceptors.
        if cc.dopts.streamInt != nil </span><span class="cov0" title="0">{
                interceptors = append([]StreamClientInterceptor{cc.dopts.streamInt}, interceptors...)
        }</span>
        <span class="cov8" title="1">var chainedInt StreamClientInterceptor
        if len(interceptors) == 0 </span><span class="cov8" title="1">{
                chainedInt = nil
        }</span> else<span class="cov0" title="0"> if len(interceptors) == 1 </span><span class="cov0" title="0">{
                chainedInt = interceptors[0]
        }</span> else<span class="cov0" title="0"> {
                chainedInt = func(ctx context.Context, desc *StreamDesc, cc *ClientConn, method string, streamer Streamer, opts ...CallOption) (ClientStream, error) </span><span class="cov0" title="0">{
                        return interceptors[0](ctx, desc, cc, method, getChainStreamer(interceptors, 0, streamer), opts...)
                }</span>
        }
        <span class="cov8" title="1">cc.dopts.streamInt = chainedInt</span>
}

// getChainStreamer recursively generate the chained client stream constructor.
func getChainStreamer(interceptors []StreamClientInterceptor, curr int, finalStreamer Streamer) Streamer <span class="cov0" title="0">{
        if curr == len(interceptors)-1 </span><span class="cov0" title="0">{
                return finalStreamer
        }</span>
        <span class="cov0" title="0">return func(ctx context.Context, desc *StreamDesc, cc *ClientConn, method string, opts ...CallOption) (ClientStream, error) </span><span class="cov0" title="0">{
                return interceptors[curr+1](ctx, desc, cc, method, getChainStreamer(interceptors, curr+1, finalStreamer), opts...)
        }</span>
}

// connectivityStateManager keeps the connectivity.State of ClientConn.
// This struct will eventually be exported so the balancers can access it.
type connectivityStateManager struct {
        mu         sync.Mutex
        state      connectivity.State
        notifyChan chan struct{}
        channelzID *channelz.Identifier
}

// updateState updates the connectivity.State of ClientConn.
// If there's a change it notifies goroutines waiting on state change to
// happen.
func (csm *connectivityStateManager) updateState(state connectivity.State) <span class="cov8" title="1">{
        csm.mu.Lock()
        defer csm.mu.Unlock()
        if csm.state == connectivity.Shutdown </span><span class="cov8" title="1">{
                return
        }</span>
        <span class="cov8" title="1">if csm.state == state </span><span class="cov8" title="1">{
                return
        }</span>
        <span class="cov8" title="1">csm.state = state
        channelz.Infof(logger, csm.channelzID, "Channel Connectivity change to %v", state)
        if csm.notifyChan != nil </span><span class="cov8" title="1">{
                // There are other goroutines waiting on this channel.
                close(csm.notifyChan)
                csm.notifyChan = nil
        }</span>
}

func (csm *connectivityStateManager) getState() connectivity.State <span class="cov8" title="1">{
        csm.mu.Lock()
        defer csm.mu.Unlock()
        return csm.state
}</span>

func (csm *connectivityStateManager) getNotifyChan() &lt;-chan struct{} <span class="cov8" title="1">{
        csm.mu.Lock()
        defer csm.mu.Unlock()
        if csm.notifyChan == nil </span><span class="cov8" title="1">{
                csm.notifyChan = make(chan struct{})
        }</span>
        <span class="cov8" title="1">return csm.notifyChan</span>
}

// ClientConnInterface defines the functions clients need to perform unary and
// streaming RPCs.  It is implemented by *ClientConn, and is only intended to
// be referenced by generated code.
type ClientConnInterface interface {
        // Invoke performs a unary RPC and returns after the response is received
        // into reply.
        Invoke(ctx context.Context, method string, args interface{}, reply interface{}, opts ...CallOption) error
        // NewStream begins a streaming RPC.
        NewStream(ctx context.Context, desc *StreamDesc, method string, opts ...CallOption) (ClientStream, error)
}

// Assert *ClientConn implements ClientConnInterface.
var _ ClientConnInterface = (*ClientConn)(nil)

// ClientConn represents a virtual connection to a conceptual endpoint, to
// perform RPCs.
//
// A ClientConn is free to have zero or more actual connections to the endpoint
// based on configuration, load, etc. It is also free to determine which actual
// endpoints to use and may change it every RPC, permitting client-side load
// balancing.
//
// A ClientConn encapsulates a range of functionality including name
// resolution, TCP connection establishment (with retries and backoff) and TLS
// handshakes. It also handles errors on established connections by
// re-resolving the name and reconnecting.
type ClientConn struct {
        ctx    context.Context    // Initialized using the background context at dial time.
        cancel context.CancelFunc // Cancelled on close.

        // The following are initialized at dial time, and are read-only after that.
        target          string               // User's dial target.
        parsedTarget    resolver.Target      // See parseTargetAndFindResolver().
        authority       string               // See determineAuthority().
        dopts           dialOptions          // Default and user specified dial options.
        channelzID      *channelz.Identifier // Channelz identifier for the channel.
        balancerWrapper *ccBalancerWrapper   // Uses gracefulswitch.balancer underneath.

        // The following provide their own synchronization, and therefore don't
        // require cc.mu to be held to access them.
        csMgr              *connectivityStateManager
        blockingpicker     *pickerWrapper
        safeConfigSelector iresolver.SafeConfigSelector
        czData             *channelzData
        retryThrottler     atomic.Value // Updated from service config.

        // firstResolveEvent is used to track whether the name resolver sent us at
        // least one update. RPCs block on this event.
        firstResolveEvent *grpcsync.Event

        // mu protects the following fields.
        // TODO: split mu so the same mutex isn't used for everything.
        mu              sync.RWMutex
        resolverWrapper *ccResolverWrapper         // Initialized in Dial; cleared in Close.
        sc              *ServiceConfig             // Latest service config received from the resolver.
        conns           map[*addrConn]struct{}     // Set to nil on close.
        mkp             keepalive.ClientParameters // May be updated upon receipt of a GoAway.

        lceMu               sync.Mutex // protects lastConnectionError
        lastConnectionError error
}

// WaitForStateChange waits until the connectivity.State of ClientConn changes from sourceState or
// ctx expires. A true value is returned in former case and false in latter.
//
// Experimental
//
// Notice: This API is EXPERIMENTAL and may be changed or removed in a
// later release.
func (cc *ClientConn) WaitForStateChange(ctx context.Context, sourceState connectivity.State) bool <span class="cov8" title="1">{
        ch := cc.csMgr.getNotifyChan()
        if cc.csMgr.getState() != sourceState </span><span class="cov0" title="0">{
                return true
        }</span>
        <span class="cov8" title="1">select </span>{
        case &lt;-ctx.Done():<span class="cov8" title="1">
                return false</span>
        case &lt;-ch:<span class="cov8" title="1">
                return true</span>
        }
}

// GetState returns the connectivity.State of ClientConn.
//
// Experimental
//
// Notice: This API is EXPERIMENTAL and may be changed or removed in a later
// release.
func (cc *ClientConn) GetState() connectivity.State <span class="cov8" title="1">{
        return cc.csMgr.getState()
}</span>

// Connect causes all subchannels in the ClientConn to attempt to connect if
// the channel is idle.  Does not wait for the connection attempts to begin
// before returning.
//
// Experimental
//
// Notice: This API is EXPERIMENTAL and may be changed or removed in a later
// release.
func (cc *ClientConn) Connect() <span class="cov8" title="1">{
        cc.balancerWrapper.exitIdle()
}</span>

func (cc *ClientConn) scWatcher() <span class="cov0" title="0">{
        for </span><span class="cov0" title="0">{
                select </span>{
                case sc, ok := &lt;-cc.dopts.scChan:<span class="cov0" title="0">
                        if !ok </span><span class="cov0" title="0">{
                                return
                        }</span>
                        <span class="cov0" title="0">cc.mu.Lock()
                        // TODO: load balance policy runtime change is ignored.
                        // We may revisit this decision in the future.
                        cc.sc = &amp;sc
                        cc.safeConfigSelector.UpdateConfigSelector(&amp;defaultConfigSelector{&amp;sc})
                        cc.mu.Unlock()</span>
                case &lt;-cc.ctx.Done():<span class="cov0" title="0">
                        return</span>
                }
        }
}

// waitForResolvedAddrs blocks until the resolver has provided addresses or the
// context expires.  Returns nil unless the context expires first; otherwise
// returns a status error based on the context.
func (cc *ClientConn) waitForResolvedAddrs(ctx context.Context) error <span class="cov0" title="0">{
        // This is on the RPC path, so we use a fast path to avoid the
        // more-expensive "select" below after the resolver has returned once.
        if cc.firstResolveEvent.HasFired() </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">select </span>{
        case &lt;-cc.firstResolveEvent.Done():<span class="cov0" title="0">
                return nil</span>
        case &lt;-ctx.Done():<span class="cov0" title="0">
                return status.FromContextError(ctx.Err()).Err()</span>
        case &lt;-cc.ctx.Done():<span class="cov0" title="0">
                return ErrClientConnClosing</span>
        }
}

var emptyServiceConfig *ServiceConfig

func init() <span class="cov8" title="1">{
        cfg := parseServiceConfig("{}")
        if cfg.Err != nil </span><span class="cov0" title="0">{
                panic(fmt.Sprintf("impossible error parsing empty service config: %v", cfg.Err))</span>
        }
        <span class="cov8" title="1">emptyServiceConfig = cfg.Config.(*ServiceConfig)</span>
}

func (cc *ClientConn) maybeApplyDefaultServiceConfig(addrs []resolver.Address) <span class="cov8" title="1">{
        if cc.sc != nil </span><span class="cov0" title="0">{
                cc.applyServiceConfigAndBalancer(cc.sc, nil, addrs)
                return
        }</span>
        <span class="cov8" title="1">if cc.dopts.defaultServiceConfig != nil </span><span class="cov8" title="1">{
                cc.applyServiceConfigAndBalancer(cc.dopts.defaultServiceConfig, &amp;defaultConfigSelector{cc.dopts.defaultServiceConfig}, addrs)
        }</span> else<span class="cov8" title="1"> {
                cc.applyServiceConfigAndBalancer(emptyServiceConfig, &amp;defaultConfigSelector{emptyServiceConfig}, addrs)
        }</span>
}

func (cc *ClientConn) updateResolverState(s resolver.State, err error) error <span class="cov8" title="1">{
        defer cc.firstResolveEvent.Fire()
        cc.mu.Lock()
        // Check if the ClientConn is already closed. Some fields (e.g.
        // balancerWrapper) are set to nil when closing the ClientConn, and could
        // cause nil pointer panic if we don't have this check.
        if cc.conns == nil </span><span class="cov8" title="1">{
                cc.mu.Unlock()
                return nil
        }</span>

        <span class="cov8" title="1">if err != nil </span><span class="cov0" title="0">{
                // May need to apply the initial service config in case the resolver
                // doesn't support service configs, or doesn't provide a service config
                // with the new addresses.
                cc.maybeApplyDefaultServiceConfig(nil)

                cc.balancerWrapper.resolverError(err)

                // No addresses are valid with err set; return early.
                cc.mu.Unlock()
                return balancer.ErrBadResolverState
        }</span>

        <span class="cov8" title="1">var ret error
        if cc.dopts.disableServiceConfig </span><span class="cov8" title="1">{
                channelz.Infof(logger, cc.channelzID, "ignoring service config from resolver (%v) and applying the default because service config is disabled", s.ServiceConfig)
                cc.maybeApplyDefaultServiceConfig(s.Addresses)
        }</span> else<span class="cov8" title="1"> if s.ServiceConfig == nil </span><span class="cov8" title="1">{
                cc.maybeApplyDefaultServiceConfig(s.Addresses)
                // TODO: do we need to apply a failing LB policy if there is no
                // default, per the error handling design?
        }</span> else<span class="cov8" title="1"> {
                if sc, ok := s.ServiceConfig.Config.(*ServiceConfig); s.ServiceConfig.Err == nil &amp;&amp; ok </span><span class="cov8" title="1">{
                        configSelector := iresolver.GetConfigSelector(s)
                        if configSelector != nil </span><span class="cov0" title="0">{
                                if len(s.ServiceConfig.Config.(*ServiceConfig).Methods) != 0 </span><span class="cov0" title="0">{
                                        channelz.Infof(logger, cc.channelzID, "method configs in service config will be ignored due to presence of config selector")
                                }</span>
                        } else<span class="cov8" title="1"> {
                                configSelector = &amp;defaultConfigSelector{sc}
                        }</span>
                        <span class="cov8" title="1">cc.applyServiceConfigAndBalancer(sc, configSelector, s.Addresses)</span>
                } else<span class="cov0" title="0"> {
                        ret = balancer.ErrBadResolverState
                        if cc.sc == nil </span><span class="cov0" title="0">{
                                // Apply the failing LB only if we haven't received valid service config
                                // from the name resolver in the past.
                                cc.applyFailingLB(s.ServiceConfig)
                                cc.mu.Unlock()
                                return ret
                        }</span>
                }
        }

        <span class="cov8" title="1">var balCfg serviceconfig.LoadBalancingConfig
        if cc.sc != nil &amp;&amp; cc.sc.lbConfig != nil </span><span class="cov8" title="1">{
                balCfg = cc.sc.lbConfig.cfg
        }</span>
        <span class="cov8" title="1">bw := cc.balancerWrapper
        cc.mu.Unlock()

        uccsErr := bw.updateClientConnState(&amp;balancer.ClientConnState{ResolverState: s, BalancerConfig: balCfg})
        if ret == nil </span><span class="cov8" title="1">{
                ret = uccsErr // prefer ErrBadResolver state since any other error is
                // currently meaningless to the caller.
        }</span>
        <span class="cov8" title="1">return ret</span>
}

// applyFailingLB is akin to configuring an LB policy on the channel which
// always fails RPCs. Here, an actual LB policy is not configured, but an always
// erroring picker is configured, which returns errors with information about
// what was invalid in the received service config. A config selector with no
// service config is configured, and the connectivity state of the channel is
// set to TransientFailure.
//
// Caller must hold cc.mu.
func (cc *ClientConn) applyFailingLB(sc *serviceconfig.ParseResult) <span class="cov0" title="0">{
        var err error
        if sc.Err != nil </span><span class="cov0" title="0">{
                err = status.Errorf(codes.Unavailable, "error parsing service config: %v", sc.Err)
        }</span> else<span class="cov0" title="0"> {
                err = status.Errorf(codes.Unavailable, "illegal service config type: %T", sc.Config)
        }</span>
        <span class="cov0" title="0">cc.safeConfigSelector.UpdateConfigSelector(&amp;defaultConfigSelector{nil})
        cc.blockingpicker.updatePicker(base.NewErrPicker(err))
        cc.csMgr.updateState(connectivity.TransientFailure)</span>
}

func (cc *ClientConn) handleSubConnStateChange(sc balancer.SubConn, s connectivity.State, err error) <span class="cov8" title="1">{
        cc.balancerWrapper.updateSubConnState(sc, s, err)
}</span>

// newAddrConn creates an addrConn for addrs and adds it to cc.conns.
//
// Caller needs to make sure len(addrs) &gt; 0.
func (cc *ClientConn) newAddrConn(addrs []resolver.Address, opts balancer.NewSubConnOptions) (*addrConn, error) <span class="cov8" title="1">{
        ac := &amp;addrConn{
                state:        connectivity.Idle,
                cc:           cc,
                addrs:        addrs,
                scopts:       opts,
                dopts:        cc.dopts,
                czData:       new(channelzData),
                resetBackoff: make(chan struct{}),
        }
        ac.ctx, ac.cancel = context.WithCancel(cc.ctx)
        // Track ac in cc. This needs to be done before any getTransport(...) is called.
        cc.mu.Lock()
        defer cc.mu.Unlock()
        if cc.conns == nil </span><span class="cov0" title="0">{
                return nil, ErrClientConnClosing
        }</span>

        <span class="cov8" title="1">var err error
        ac.channelzID, err = channelz.RegisterSubChannel(ac, cc.channelzID, "")
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">channelz.AddTraceEvent(logger, ac.channelzID, 0, &amp;channelz.TraceEventDesc{
                Desc:     "Subchannel created",
                Severity: channelz.CtInfo,
                Parent: &amp;channelz.TraceEventDesc{
                        Desc:     fmt.Sprintf("Subchannel(id:%d) created", ac.channelzID.Int()),
                        Severity: channelz.CtInfo,
                },
        })

        cc.conns[ac] = struct{}{}
        return ac, nil</span>
}

// removeAddrConn removes the addrConn in the subConn from clientConn.
// It also tears down the ac with the given error.
func (cc *ClientConn) removeAddrConn(ac *addrConn, err error) <span class="cov0" title="0">{
        cc.mu.Lock()
        if cc.conns == nil </span><span class="cov0" title="0">{
                cc.mu.Unlock()
                return
        }</span>
        <span class="cov0" title="0">delete(cc.conns, ac)
        cc.mu.Unlock()
        ac.tearDown(err)</span>
}

func (cc *ClientConn) channelzMetric() *channelz.ChannelInternalMetric <span class="cov0" title="0">{
        return &amp;channelz.ChannelInternalMetric{
                State:                    cc.GetState(),
                Target:                   cc.target,
                CallsStarted:             atomic.LoadInt64(&amp;cc.czData.callsStarted),
                CallsSucceeded:           atomic.LoadInt64(&amp;cc.czData.callsSucceeded),
                CallsFailed:              atomic.LoadInt64(&amp;cc.czData.callsFailed),
                LastCallStartedTimestamp: time.Unix(0, atomic.LoadInt64(&amp;cc.czData.lastCallStartedTime)),
        }
}</span>

// Target returns the target string of the ClientConn.
//
// Experimental
//
// Notice: This API is EXPERIMENTAL and may be changed or removed in a
// later release.
func (cc *ClientConn) Target() string <span class="cov8" title="1">{
        return cc.target
}</span>

func (cc *ClientConn) incrCallsStarted() <span class="cov0" title="0">{
        atomic.AddInt64(&amp;cc.czData.callsStarted, 1)
        atomic.StoreInt64(&amp;cc.czData.lastCallStartedTime, time.Now().UnixNano())
}</span>

func (cc *ClientConn) incrCallsSucceeded() <span class="cov0" title="0">{
        atomic.AddInt64(&amp;cc.czData.callsSucceeded, 1)
}</span>

func (cc *ClientConn) incrCallsFailed() <span class="cov0" title="0">{
        atomic.AddInt64(&amp;cc.czData.callsFailed, 1)
}</span>

// connect starts creating a transport.
// It does nothing if the ac is not IDLE.
// TODO(bar) Move this to the addrConn section.
func (ac *addrConn) connect() error <span class="cov8" title="1">{
        ac.mu.Lock()
        if ac.state == connectivity.Shutdown </span><span class="cov8" title="1">{
                ac.mu.Unlock()
                return errConnClosing
        }</span>
        <span class="cov8" title="1">if ac.state != connectivity.Idle </span><span class="cov8" title="1">{
                ac.mu.Unlock()
                return nil
        }</span>
        // Update connectivity state within the lock to prevent subsequent or
        // concurrent calls from resetting the transport more than once.
        <span class="cov8" title="1">ac.updateConnectivityState(connectivity.Connecting, nil)
        ac.mu.Unlock()

        ac.resetTransport()
        return nil</span>
}

func equalAddresses(a, b []resolver.Address) bool <span class="cov8" title="1">{
        if len(a) != len(b) </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov8" title="1">for i, v := range a </span><span class="cov8" title="1">{
                if !v.Equal(b[i]) </span><span class="cov0" title="0">{
                        return false
                }</span>
        }
        <span class="cov8" title="1">return true</span>
}

// tryUpdateAddrs tries to update ac.addrs with the new addresses list.
//
// If ac is TransientFailure, it updates ac.addrs and returns true. The updated
// addresses will be picked up by retry in the next iteration after backoff.
//
// If ac is Shutdown or Idle, it updates ac.addrs and returns true.
//
// If the addresses is the same as the old list, it does nothing and returns
// true.
//
// If ac is Connecting, it returns false. The caller should tear down the ac and
// create a new one. Note that the backoff will be reset when this happens.
//
// If ac is Ready, it checks whether current connected address of ac is in the
// new addrs list.
//  - If true, it updates ac.addrs and returns true. The ac will keep using
//    the existing connection.
//  - If false, it does nothing and returns false.
func (ac *addrConn) tryUpdateAddrs(addrs []resolver.Address) bool <span class="cov8" title="1">{
        ac.mu.Lock()
        defer ac.mu.Unlock()
        channelz.Infof(logger, ac.channelzID, "addrConn: tryUpdateAddrs curAddr: %v, addrs: %v", ac.curAddr, addrs)
        if ac.state == connectivity.Shutdown ||
                ac.state == connectivity.TransientFailure ||
                ac.state == connectivity.Idle </span><span class="cov0" title="0">{
                ac.addrs = addrs
                return true
        }</span>

        <span class="cov8" title="1">if equalAddresses(ac.addrs, addrs) </span><span class="cov8" title="1">{
                return true
        }</span>

        <span class="cov0" title="0">if ac.state == connectivity.Connecting </span><span class="cov0" title="0">{
                return false
        }</span>

        // ac.state is Ready, try to find the connected address.
        <span class="cov0" title="0">var curAddrFound bool
        for _, a := range addrs </span><span class="cov0" title="0">{
                a.ServerName = ac.cc.getServerName(a)
                if reflect.DeepEqual(ac.curAddr, a) </span><span class="cov0" title="0">{
                        curAddrFound = true
                        break</span>
                }
        }
        <span class="cov0" title="0">channelz.Infof(logger, ac.channelzID, "addrConn: tryUpdateAddrs curAddrFound: %v", curAddrFound)
        if curAddrFound </span><span class="cov0" title="0">{
                ac.addrs = addrs
        }</span>

        <span class="cov0" title="0">return curAddrFound</span>
}

// getServerName determines the serverName to be used in the connection
// handshake. The default value for the serverName is the authority on the
// ClientConn, which either comes from the user's dial target or through an
// authority override specified using the WithAuthority dial option. Name
// resolvers can specify a per-address override for the serverName through the
// resolver.Address.ServerName field which is used only if the WithAuthority
// dial option was not used. The rationale is that per-address authority
// overrides specified by the name resolver can represent a security risk, while
// an override specified by the user is more dependable since they probably know
// what they are doing.
func (cc *ClientConn) getServerName(addr resolver.Address) string <span class="cov8" title="1">{
        if cc.dopts.authority != "" </span><span class="cov8" title="1">{
                return cc.dopts.authority
        }</span>
        <span class="cov8" title="1">if addr.ServerName != "" </span><span class="cov0" title="0">{
                return addr.ServerName
        }</span>
        <span class="cov8" title="1">return cc.authority</span>
}

func getMethodConfig(sc *ServiceConfig, method string) MethodConfig <span class="cov8" title="1">{
        if sc == nil </span><span class="cov0" title="0">{
                return MethodConfig{}
        }</span>
        <span class="cov8" title="1">if m, ok := sc.Methods[method]; ok </span><span class="cov8" title="1">{
                return m
        }</span>
        <span class="cov8" title="1">i := strings.LastIndex(method, "/")
        if m, ok := sc.Methods[method[:i+1]]; ok </span><span class="cov0" title="0">{
                return m
        }</span>
        <span class="cov8" title="1">return sc.Methods[""]</span>
}

// GetMethodConfig gets the method config of the input method.
// If there's an exact match for input method (i.e. /service/method), we return
// the corresponding MethodConfig.
// If there isn't an exact match for the input method, we look for the service's default
// config under the service (i.e /service/) and then for the default for all services (empty string).
//
// If there is a default MethodConfig for the service, we return it.
// Otherwise, we return an empty MethodConfig.
func (cc *ClientConn) GetMethodConfig(method string) MethodConfig <span class="cov8" title="1">{
        // TODO: Avoid the locking here.
        cc.mu.RLock()
        defer cc.mu.RUnlock()
        return getMethodConfig(cc.sc, method)
}</span>

func (cc *ClientConn) healthCheckConfig() *healthCheckConfig <span class="cov8" title="1">{
        cc.mu.RLock()
        defer cc.mu.RUnlock()
        if cc.sc == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">return cc.sc.healthCheckConfig</span>
}

func (cc *ClientConn) getTransport(ctx context.Context, failfast bool, method string) (transport.ClientTransport, func(balancer.DoneInfo), error) <span class="cov0" title="0">{
        return cc.blockingpicker.pick(ctx, failfast, balancer.PickInfo{
                Ctx:            ctx,
                FullMethodName: method,
        })
}</span>

func (cc *ClientConn) applyServiceConfigAndBalancer(sc *ServiceConfig, configSelector iresolver.ConfigSelector, addrs []resolver.Address) <span class="cov8" title="1">{
        if sc == nil </span><span class="cov0" title="0">{
                // should never reach here.
                return
        }</span>
        <span class="cov8" title="1">cc.sc = sc
        if configSelector != nil </span><span class="cov8" title="1">{
                cc.safeConfigSelector.UpdateConfigSelector(configSelector)
        }</span>

        <span class="cov8" title="1">if cc.sc.retryThrottling != nil </span><span class="cov0" title="0">{
                newThrottler := &amp;retryThrottler{
                        tokens: cc.sc.retryThrottling.MaxTokens,
                        max:    cc.sc.retryThrottling.MaxTokens,
                        thresh: cc.sc.retryThrottling.MaxTokens / 2,
                        ratio:  cc.sc.retryThrottling.TokenRatio,
                }
                cc.retryThrottler.Store(newThrottler)
        }</span> else<span class="cov8" title="1"> {
                cc.retryThrottler.Store((*retryThrottler)(nil))
        }</span>

        <span class="cov8" title="1">var newBalancerName string
        if cc.sc != nil &amp;&amp; cc.sc.lbConfig != nil </span><span class="cov8" title="1">{
                newBalancerName = cc.sc.lbConfig.name
        }</span> else<span class="cov8" title="1"> {
                var isGRPCLB bool
                for _, a := range addrs </span><span class="cov8" title="1">{
                        if a.Type == resolver.GRPCLB </span><span class="cov0" title="0">{
                                isGRPCLB = true
                                break</span>
                        }
                }
                <span class="cov8" title="1">if isGRPCLB </span><span class="cov0" title="0">{
                        newBalancerName = grpclbName
                }</span> else<span class="cov8" title="1"> if cc.sc != nil &amp;&amp; cc.sc.LB != nil </span><span class="cov8" title="1">{
                        newBalancerName = *cc.sc.LB
                }</span> else<span class="cov8" title="1"> {
                        newBalancerName = PickFirstBalancerName
                }</span>
        }
        <span class="cov8" title="1">cc.balancerWrapper.switchTo(newBalancerName)</span>
}

func (cc *ClientConn) resolveNow(o resolver.ResolveNowOptions) <span class="cov8" title="1">{
        cc.mu.RLock()
        r := cc.resolverWrapper
        cc.mu.RUnlock()
        if r == nil </span><span class="cov8" title="1">{
                return
        }</span>
        <span class="cov8" title="1">go r.resolveNow(o)</span>
}

// ResetConnectBackoff wakes up all subchannels in transient failure and causes
// them to attempt another connection immediately.  It also resets the backoff
// times used for subsequent attempts regardless of the current state.
//
// In general, this function should not be used.  Typical service or network
// outages result in a reasonable client reconnection strategy by default.
// However, if a previously unavailable network becomes available, this may be
// used to trigger an immediate reconnect.
//
// Experimental
//
// Notice: This API is EXPERIMENTAL and may be changed or removed in a
// later release.
func (cc *ClientConn) ResetConnectBackoff() <span class="cov8" title="1">{
        cc.mu.Lock()
        conns := cc.conns
        cc.mu.Unlock()
        for ac := range conns </span><span class="cov8" title="1">{
                ac.resetConnectBackoff()
        }</span>
}

// Close tears down the ClientConn and all underlying connections.
func (cc *ClientConn) Close() error <span class="cov8" title="1">{
        defer cc.cancel()

        cc.mu.Lock()
        if cc.conns == nil </span><span class="cov0" title="0">{
                cc.mu.Unlock()
                return ErrClientConnClosing
        }</span>
        <span class="cov8" title="1">conns := cc.conns
        cc.conns = nil
        cc.csMgr.updateState(connectivity.Shutdown)

        rWrapper := cc.resolverWrapper
        cc.resolverWrapper = nil
        bWrapper := cc.balancerWrapper
        cc.mu.Unlock()

        // The order of closing matters here since the balancer wrapper assumes the
        // picker is closed before it is closed.
        cc.blockingpicker.close()
        if bWrapper != nil </span><span class="cov8" title="1">{
                bWrapper.close()
        }</span>
        <span class="cov8" title="1">if rWrapper != nil </span><span class="cov8" title="1">{
                rWrapper.close()
        }</span>

        <span class="cov8" title="1">for ac := range conns </span><span class="cov8" title="1">{
                ac.tearDown(ErrClientConnClosing)
        }</span>
        <span class="cov8" title="1">ted := &amp;channelz.TraceEventDesc{
                Desc:     "Channel deleted",
                Severity: channelz.CtInfo,
        }
        if cc.dopts.channelzParentID != nil </span><span class="cov0" title="0">{
                ted.Parent = &amp;channelz.TraceEventDesc{
                        Desc:     fmt.Sprintf("Nested channel(id:%d) deleted", cc.channelzID.Int()),
                        Severity: channelz.CtInfo,
                }
        }</span>
        <span class="cov8" title="1">channelz.AddTraceEvent(logger, cc.channelzID, 0, ted)
        // TraceEvent needs to be called before RemoveEntry, as TraceEvent may add
        // trace reference to the entity being deleted, and thus prevent it from being
        // deleted right away.
        channelz.RemoveEntry(cc.channelzID)

        return nil</span>
}

// addrConn is a network connection to a given address.
type addrConn struct {
        ctx    context.Context
        cancel context.CancelFunc

        cc     *ClientConn
        dopts  dialOptions
        acbw   balancer.SubConn
        scopts balancer.NewSubConnOptions

        // transport is set when there's a viable transport (note: ac state may not be READY as LB channel
        // health checking may require server to report healthy to set ac to READY), and is reset
        // to nil when the current transport should no longer be used to create a stream (e.g. after GoAway
        // is received, transport is closed, ac has been torn down).
        transport transport.ClientTransport // The current transport.

        mu      sync.Mutex
        curAddr resolver.Address   // The current address.
        addrs   []resolver.Address // All addresses that the resolver resolved to.

        // Use updateConnectivityState for updating addrConn's connectivity state.
        state connectivity.State

        backoffIdx   int // Needs to be stateful for resetConnectBackoff.
        resetBackoff chan struct{}

        channelzID *channelz.Identifier
        czData     *channelzData
}

// Note: this requires a lock on ac.mu.
func (ac *addrConn) updateConnectivityState(s connectivity.State, lastErr error) <span class="cov8" title="1">{
        if ac.state == s </span><span class="cov8" title="1">{
                return
        }</span>
        <span class="cov8" title="1">ac.state = s
        channelz.Infof(logger, ac.channelzID, "Subchannel Connectivity change to %v", s)
        ac.cc.handleSubConnStateChange(ac.acbw, s, lastErr)</span>
}

// adjustParams updates parameters used to create transports upon
// receiving a GoAway.
func (ac *addrConn) adjustParams(r transport.GoAwayReason) <span class="cov8" title="1">{
        switch r </span>{
        case transport.GoAwayTooManyPings:<span class="cov8" title="1">
                v := 2 * ac.dopts.copts.KeepaliveParams.Time
                ac.cc.mu.Lock()
                if v &gt; ac.cc.mkp.Time </span><span class="cov8" title="1">{
                        ac.cc.mkp.Time = v
                }</span>
                <span class="cov8" title="1">ac.cc.mu.Unlock()</span>
        }
}

func (ac *addrConn) resetTransport() <span class="cov8" title="1">{
        ac.mu.Lock()
        if ac.state == connectivity.Shutdown </span><span class="cov0" title="0">{
                ac.mu.Unlock()
                return
        }</span>

        <span class="cov8" title="1">addrs := ac.addrs
        backoffFor := ac.dopts.bs.Backoff(ac.backoffIdx)
        // This will be the duration that dial gets to finish.
        dialDuration := minConnectTimeout
        if ac.dopts.minConnectTimeout != nil </span><span class="cov8" title="1">{
                dialDuration = ac.dopts.minConnectTimeout()
        }</span>

        <span class="cov8" title="1">if dialDuration &lt; backoffFor </span><span class="cov8" title="1">{
                // Give dial more time as we keep failing to connect.
                dialDuration = backoffFor
        }</span>
        // We can potentially spend all the time trying the first address, and
        // if the server accepts the connection and then hangs, the following
        // addresses will never be tried.
        //
        // The spec doesn't mention what should be done for multiple addresses.
        // https://github.com/grpc/grpc/blob/master/doc/connection-backoff.md#proposed-backoff-algorithm
        <span class="cov8" title="1">connectDeadline := time.Now().Add(dialDuration)

        ac.updateConnectivityState(connectivity.Connecting, nil)
        ac.mu.Unlock()

        if err := ac.tryAllAddrs(addrs, connectDeadline); err != nil </span><span class="cov8" title="1">{
                ac.cc.resolveNow(resolver.ResolveNowOptions{})
                // After exhausting all addresses, the addrConn enters
                // TRANSIENT_FAILURE.
                ac.mu.Lock()
                if ac.state == connectivity.Shutdown </span><span class="cov8" title="1">{
                        ac.mu.Unlock()
                        return
                }</span>
                <span class="cov8" title="1">ac.updateConnectivityState(connectivity.TransientFailure, err)

                // Backoff.
                b := ac.resetBackoff
                ac.mu.Unlock()

                timer := time.NewTimer(backoffFor)
                select </span>{
                case &lt;-timer.C:<span class="cov8" title="1">
                        ac.mu.Lock()
                        ac.backoffIdx++
                        ac.mu.Unlock()</span>
                case &lt;-b:<span class="cov8" title="1">
                        timer.Stop()</span>
                case &lt;-ac.ctx.Done():<span class="cov8" title="1">
                        timer.Stop()
                        return</span>
                }

                <span class="cov8" title="1">ac.mu.Lock()
                if ac.state != connectivity.Shutdown </span><span class="cov8" title="1">{
                        ac.updateConnectivityState(connectivity.Idle, err)
                }</span>
                <span class="cov8" title="1">ac.mu.Unlock()
                return</span>
        }
        // Success; reset backoff.
        <span class="cov8" title="1">ac.mu.Lock()
        ac.backoffIdx = 0
        ac.mu.Unlock()</span>
}

// tryAllAddrs tries to creates a connection to the addresses, and stop when at
// the first successful one. It returns an error if no address was successfully
// connected, or updates ac appropriately with the new transport.
func (ac *addrConn) tryAllAddrs(addrs []resolver.Address, connectDeadline time.Time) error <span class="cov8" title="1">{
        var firstConnErr error
        for _, addr := range addrs </span><span class="cov8" title="1">{
                ac.mu.Lock()
                if ac.state == connectivity.Shutdown </span><span class="cov0" title="0">{
                        ac.mu.Unlock()
                        return errConnClosing
                }</span>

                <span class="cov8" title="1">ac.cc.mu.RLock()
                ac.dopts.copts.KeepaliveParams = ac.cc.mkp
                ac.cc.mu.RUnlock()

                copts := ac.dopts.copts
                if ac.scopts.CredsBundle != nil </span><span class="cov0" title="0">{
                        copts.CredsBundle = ac.scopts.CredsBundle
                }</span>
                <span class="cov8" title="1">ac.mu.Unlock()

                channelz.Infof(logger, ac.channelzID, "Subchannel picks a new address %q to connect", addr.Addr)

                err := ac.createTransport(addr, copts, connectDeadline)
                if err == nil </span><span class="cov8" title="1">{
                        return nil
                }</span>
                <span class="cov8" title="1">if firstConnErr == nil </span><span class="cov8" title="1">{
                        firstConnErr = err
                }</span>
                <span class="cov8" title="1">ac.cc.updateConnectionError(err)</span>
        }

        // Couldn't connect to any address.
        <span class="cov8" title="1">return firstConnErr</span>
}

// createTransport creates a connection to addr. It returns an error if the
// address was not successfully connected, or updates ac appropriately with the
// new transport.
func (ac *addrConn) createTransport(addr resolver.Address, copts transport.ConnectOptions, connectDeadline time.Time) error <span class="cov8" title="1">{
        // TODO: Delete prefaceReceived and move the logic to wait for it into the
        // transport.
        prefaceReceived := grpcsync.NewEvent()
        connClosed := grpcsync.NewEvent()

        addr.ServerName = ac.cc.getServerName(addr)
        hctx, hcancel := context.WithCancel(ac.ctx)
        hcStarted := false // protected by ac.mu

        onClose := func() </span><span class="cov8" title="1">{
                ac.mu.Lock()
                defer ac.mu.Unlock()
                defer connClosed.Fire()
                defer hcancel()
                if !hcStarted || hctx.Err() != nil </span><span class="cov8" title="1">{
                        // We didn't start the health check or set the state to READY, so
                        // no need to do anything else here.
                        //
                        // OR, we have already cancelled the health check context, meaning
                        // we have already called onClose once for this transport.  In this
                        // case it would be dangerous to clear the transport and update the
                        // state, since there may be a new transport in this addrConn.
                        return
                }</span>
                <span class="cov8" title="1">ac.transport = nil
                // Refresh the name resolver
                ac.cc.resolveNow(resolver.ResolveNowOptions{})
                if ac.state != connectivity.Shutdown </span><span class="cov8" title="1">{
                        ac.updateConnectivityState(connectivity.Idle, nil)
                }</span>
        }

        <span class="cov8" title="1">onGoAway := func(r transport.GoAwayReason) </span><span class="cov8" title="1">{
                ac.mu.Lock()
                ac.adjustParams(r)
                ac.mu.Unlock()
                onClose()
        }</span>

        <span class="cov8" title="1">connectCtx, cancel := context.WithDeadline(ac.ctx, connectDeadline)
        defer cancel()
        copts.ChannelzParentID = ac.channelzID

        newTr, err := transport.NewClientTransport(connectCtx, ac.cc.ctx, addr, copts, func() </span><span class="cov8" title="1">{ prefaceReceived.Fire() }</span>, onGoAway, onClose)
        <span class="cov8" title="1">if err != nil </span><span class="cov8" title="1">{
                // newTr is either nil, or closed.
                hcancel()
                channelz.Warningf(logger, ac.channelzID, "grpc: addrConn.createTransport failed to connect to %s. Err: %v", addr, err)
                return err
        }</span>

        <span class="cov8" title="1">select </span>{
        case &lt;-connectCtx.Done():<span class="cov8" title="1">
                // We didn't get the preface in time.
                // The error we pass to Close() is immaterial since there are no open
                // streams at this point, so no trailers with error details will be sent
                // out. We just need to pass a non-nil error.
                newTr.Close(transport.ErrConnClosing)
                if connectCtx.Err() == context.DeadlineExceeded </span><span class="cov8" title="1">{
                        err := errors.New("failed to receive server preface within timeout")
                        channelz.Warningf(logger, ac.channelzID, "grpc: addrConn.createTransport failed to connect to %s: %v", addr, err)
                        return err
                }</span>
                <span class="cov8" title="1">return nil</span>
        case &lt;-prefaceReceived.Done():<span class="cov8" title="1">
                // We got the preface - huzzah! things are good.
                ac.mu.Lock()
                defer ac.mu.Unlock()
                if connClosed.HasFired() </span><span class="cov0" title="0">{
                        // onClose called first; go idle but do nothing else.
                        if ac.state != connectivity.Shutdown </span><span class="cov0" title="0">{
                                ac.updateConnectivityState(connectivity.Idle, nil)
                        }</span>
                        <span class="cov0" title="0">return nil</span>
                }
                <span class="cov8" title="1">if ac.state == connectivity.Shutdown </span><span class="cov0" title="0">{
                        // This can happen if the subConn was removed while in `Connecting`
                        // state. tearDown() would have set the state to `Shutdown`, but
                        // would not have closed the transport since ac.transport would not
                        // been set at that point.
                        //
                        // We run this in a goroutine because newTr.Close() calls onClose()
                        // inline, which requires locking ac.mu.
                        //
                        // The error we pass to Close() is immaterial since there are no open
                        // streams at this point, so no trailers with error details will be sent
                        // out. We just need to pass a non-nil error.
                        go newTr.Close(transport.ErrConnClosing)
                        return nil
                }</span>
                <span class="cov8" title="1">ac.curAddr = addr
                ac.transport = newTr
                hcStarted = true
                ac.startHealthCheck(hctx) // Will set state to READY if appropriate.
                return nil</span>
        case &lt;-connClosed.Done():<span class="cov8" title="1">
                // The transport has already closed.  If we received the preface, too,
                // this is not an error.
                select </span>{
                case &lt;-prefaceReceived.Done():<span class="cov0" title="0">
                        return nil</span>
                default:<span class="cov8" title="1">
                        return errors.New("connection closed before server preface received")</span>
                }
        }
}

// startHealthCheck starts the health checking stream (RPC) to watch the health
// stats of this connection if health checking is requested and configured.
//
// LB channel health checking is enabled when all requirements below are met:
// 1. it is not disabled by the user with the WithDisableHealthCheck DialOption
// 2. internal.HealthCheckFunc is set by importing the grpc/health package
// 3. a service config with non-empty healthCheckConfig field is provided
// 4. the load balancer requests it
//
// It sets addrConn to READY if the health checking stream is not started.
//
// Caller must hold ac.mu.
func (ac *addrConn) startHealthCheck(ctx context.Context) <span class="cov8" title="1">{
        var healthcheckManagingState bool
        defer func() </span><span class="cov8" title="1">{
                if !healthcheckManagingState </span><span class="cov8" title="1">{
                        ac.updateConnectivityState(connectivity.Ready, nil)
                }</span>
        }()

        <span class="cov8" title="1">if ac.cc.dopts.disableHealthCheck </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov8" title="1">healthCheckConfig := ac.cc.healthCheckConfig()
        if healthCheckConfig == nil </span><span class="cov8" title="1">{
                return
        }</span>
        <span class="cov0" title="0">if !ac.scopts.HealthCheckEnabled </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov0" title="0">healthCheckFunc := ac.cc.dopts.healthCheckFunc
        if healthCheckFunc == nil </span><span class="cov0" title="0">{
                // The health package is not imported to set health check function.
                //
                // TODO: add a link to the health check doc in the error message.
                channelz.Error(logger, ac.channelzID, "Health check is requested but health check function is not set.")
                return
        }</span>

        <span class="cov0" title="0">healthcheckManagingState = true

        // Set up the health check helper functions.
        currentTr := ac.transport
        newStream := func(method string) (interface{}, error) </span><span class="cov0" title="0">{
                ac.mu.Lock()
                if ac.transport != currentTr </span><span class="cov0" title="0">{
                        ac.mu.Unlock()
                        return nil, status.Error(codes.Canceled, "the provided transport is no longer valid to use")
                }</span>
                <span class="cov0" title="0">ac.mu.Unlock()
                return newNonRetryClientStream(ctx, &amp;StreamDesc{ServerStreams: true}, method, currentTr, ac)</span>
        }
        <span class="cov0" title="0">setConnectivityState := func(s connectivity.State, lastErr error) </span><span class="cov0" title="0">{
                ac.mu.Lock()
                defer ac.mu.Unlock()
                if ac.transport != currentTr </span><span class="cov0" title="0">{
                        return
                }</span>
                <span class="cov0" title="0">ac.updateConnectivityState(s, lastErr)</span>
        }
        // Start the health checking stream.
        <span class="cov0" title="0">go func() </span><span class="cov0" title="0">{
                err := ac.cc.dopts.healthCheckFunc(ctx, newStream, setConnectivityState, healthCheckConfig.ServiceName)
                if err != nil </span><span class="cov0" title="0">{
                        if status.Code(err) == codes.Unimplemented </span><span class="cov0" title="0">{
                                channelz.Error(logger, ac.channelzID, "Subchannel health check is unimplemented at server side, thus health check is disabled")
                        }</span> else<span class="cov0" title="0"> {
                                channelz.Errorf(logger, ac.channelzID, "HealthCheckFunc exits with unexpected error %v", err)
                        }</span>
                }
        }()
}

func (ac *addrConn) resetConnectBackoff() <span class="cov8" title="1">{
        ac.mu.Lock()
        close(ac.resetBackoff)
        ac.backoffIdx = 0
        ac.resetBackoff = make(chan struct{})
        ac.mu.Unlock()
}</span>

// getReadyTransport returns the transport if ac's state is READY or nil if not.
func (ac *addrConn) getReadyTransport() transport.ClientTransport <span class="cov8" title="1">{
        ac.mu.Lock()
        defer ac.mu.Unlock()
        if ac.state == connectivity.Ready </span><span class="cov8" title="1">{
                return ac.transport
        }</span>
        <span class="cov8" title="1">return nil</span>
}

// tearDown starts to tear down the addrConn.
//
// Note that tearDown doesn't remove ac from ac.cc.conns, so the addrConn struct
// will leak. In most cases, call cc.removeAddrConn() instead.
func (ac *addrConn) tearDown(err error) <span class="cov8" title="1">{
        ac.mu.Lock()
        if ac.state == connectivity.Shutdown </span><span class="cov0" title="0">{
                ac.mu.Unlock()
                return
        }</span>
        <span class="cov8" title="1">curTr := ac.transport
        ac.transport = nil
        // We have to set the state to Shutdown before anything else to prevent races
        // between setting the state and logic that waits on context cancellation / etc.
        ac.updateConnectivityState(connectivity.Shutdown, nil)
        ac.cancel()
        ac.curAddr = resolver.Address{}
        if err == errConnDrain &amp;&amp; curTr != nil </span><span class="cov0" title="0">{
                // GracefulClose(...) may be executed multiple times when
                // i) receiving multiple GoAway frames from the server; or
                // ii) there are concurrent name resolver/Balancer triggered
                // address removal and GoAway.
                // We have to unlock and re-lock here because GracefulClose =&gt; Close =&gt; onClose, which requires locking ac.mu.
                ac.mu.Unlock()
                curTr.GracefulClose()
                ac.mu.Lock()
        }</span>
        <span class="cov8" title="1">channelz.AddTraceEvent(logger, ac.channelzID, 0, &amp;channelz.TraceEventDesc{
                Desc:     "Subchannel deleted",
                Severity: channelz.CtInfo,
                Parent: &amp;channelz.TraceEventDesc{
                        Desc:     fmt.Sprintf("Subchannel(id:%d) deleted", ac.channelzID.Int()),
                        Severity: channelz.CtInfo,
                },
        })
        // TraceEvent needs to be called before RemoveEntry, as TraceEvent may add
        // trace reference to the entity being deleted, and thus prevent it from
        // being deleted right away.
        channelz.RemoveEntry(ac.channelzID)
        ac.mu.Unlock()</span>
}

func (ac *addrConn) getState() connectivity.State <span class="cov0" title="0">{
        ac.mu.Lock()
        defer ac.mu.Unlock()
        return ac.state
}</span>

func (ac *addrConn) ChannelzMetric() *channelz.ChannelInternalMetric <span class="cov0" title="0">{
        ac.mu.Lock()
        addr := ac.curAddr.Addr
        ac.mu.Unlock()
        return &amp;channelz.ChannelInternalMetric{
                State:                    ac.getState(),
                Target:                   addr,
                CallsStarted:             atomic.LoadInt64(&amp;ac.czData.callsStarted),
                CallsSucceeded:           atomic.LoadInt64(&amp;ac.czData.callsSucceeded),
                CallsFailed:              atomic.LoadInt64(&amp;ac.czData.callsFailed),
                LastCallStartedTimestamp: time.Unix(0, atomic.LoadInt64(&amp;ac.czData.lastCallStartedTime)),
        }
}</span>

func (ac *addrConn) incrCallsStarted() <span class="cov0" title="0">{
        atomic.AddInt64(&amp;ac.czData.callsStarted, 1)
        atomic.StoreInt64(&amp;ac.czData.lastCallStartedTime, time.Now().UnixNano())
}</span>

func (ac *addrConn) incrCallsSucceeded() <span class="cov0" title="0">{
        atomic.AddInt64(&amp;ac.czData.callsSucceeded, 1)
}</span>

func (ac *addrConn) incrCallsFailed() <span class="cov0" title="0">{
        atomic.AddInt64(&amp;ac.czData.callsFailed, 1)
}</span>

type retryThrottler struct {
        max    float64
        thresh float64
        ratio  float64

        mu     sync.Mutex
        tokens float64 // TODO(dfawley): replace with atomic and remove lock.
}

// throttle subtracts a retry token from the pool and returns whether a retry
// should be throttled (disallowed) based upon the retry throttling policy in
// the service config.
func (rt *retryThrottler) throttle() bool <span class="cov0" title="0">{
        if rt == nil </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov0" title="0">rt.mu.Lock()
        defer rt.mu.Unlock()
        rt.tokens--
        if rt.tokens &lt; 0 </span><span class="cov0" title="0">{
                rt.tokens = 0
        }</span>
        <span class="cov0" title="0">return rt.tokens &lt;= rt.thresh</span>
}

func (rt *retryThrottler) successfulRPC() <span class="cov0" title="0">{
        if rt == nil </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov0" title="0">rt.mu.Lock()
        defer rt.mu.Unlock()
        rt.tokens += rt.ratio
        if rt.tokens &gt; rt.max </span><span class="cov0" title="0">{
                rt.tokens = rt.max
        }</span>
}

type channelzChannel struct {
        cc *ClientConn
}

func (c *channelzChannel) ChannelzMetric() *channelz.ChannelInternalMetric <span class="cov0" title="0">{
        return c.cc.channelzMetric()
}</span>

// ErrClientConnTimeout indicates that the ClientConn cannot establish the
// underlying connections within the specified timeout.
//
// Deprecated: This error is never returned by grpc and should not be
// referenced by users.
var ErrClientConnTimeout = errors.New("grpc: timed out when dialing")

func (cc *ClientConn) getResolver(scheme string) resolver.Builder <span class="cov8" title="1">{
        for _, rb := range cc.dopts.resolvers </span><span class="cov8" title="1">{
                if scheme == rb.Scheme() </span><span class="cov8" title="1">{
                        return rb
                }</span>
        }
        <span class="cov8" title="1">return resolver.Get(scheme)</span>
}

func (cc *ClientConn) updateConnectionError(err error) <span class="cov8" title="1">{
        cc.lceMu.Lock()
        cc.lastConnectionError = err
        cc.lceMu.Unlock()
}</span>

func (cc *ClientConn) connectionError() error <span class="cov8" title="1">{
        cc.lceMu.Lock()
        defer cc.lceMu.Unlock()
        return cc.lastConnectionError
}</span>

func (cc *ClientConn) parseTargetAndFindResolver() (resolver.Builder, error) <span class="cov8" title="1">{
        channelz.Infof(logger, cc.channelzID, "original dial target is: %q", cc.target)

        var rb resolver.Builder
        parsedTarget, err := parseTarget(cc.target)
        if err != nil </span><span class="cov8" title="1">{
                channelz.Infof(logger, cc.channelzID, "dial target %q parse failed: %v", cc.target, err)
        }</span> else<span class="cov8" title="1"> {
                channelz.Infof(logger, cc.channelzID, "parsed dial target is: %+v", parsedTarget)
                rb = cc.getResolver(parsedTarget.Scheme)
                if rb != nil </span><span class="cov8" title="1">{
                        cc.parsedTarget = parsedTarget
                        return rb, nil
                }</span>
        }

        // We are here because the user's dial target did not contain a scheme or
        // specified an unregistered scheme. We should fallback to the default
        // scheme, except when a custom dialer is specified in which case, we should
        // always use passthrough scheme.
        <span class="cov8" title="1">defScheme := resolver.GetDefaultScheme()
        channelz.Infof(logger, cc.channelzID, "fallback to scheme %q", defScheme)
        canonicalTarget := defScheme + ":///" + cc.target

        parsedTarget, err = parseTarget(canonicalTarget)
        if err != nil </span><span class="cov0" title="0">{
                channelz.Infof(logger, cc.channelzID, "dial target %q parse failed: %v", canonicalTarget, err)
                return nil, err
        }</span>
        <span class="cov8" title="1">channelz.Infof(logger, cc.channelzID, "parsed dial target is: %+v", parsedTarget)
        rb = cc.getResolver(parsedTarget.Scheme)
        if rb == nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("could not get resolver for default scheme: %q", parsedTarget.Scheme)
        }</span>
        <span class="cov8" title="1">cc.parsedTarget = parsedTarget
        return rb, nil</span>
}

// parseTarget uses RFC 3986 semantics to parse the given target into a
// resolver.Target struct containing scheme, authority and endpoint. Query
// params are stripped from the endpoint.
func parseTarget(target string) (resolver.Target, error) <span class="cov8" title="1">{
        u, err := url.Parse(target)
        if err != nil </span><span class="cov8" title="1">{
                return resolver.Target{}, err
        }</span>
        // For targets of the form "[scheme]://[authority]/endpoint, the endpoint
        // value returned from url.Parse() contains a leading "/". Although this is
        // in accordance with RFC 3986, we do not want to break existing resolver
        // implementations which expect the endpoint without the leading "/". So, we
        // end up stripping the leading "/" here. But this will result in an
        // incorrect parsing for something like "unix:///path/to/socket". Since we
        // own the "unix" resolver, we can workaround in the unix resolver by using
        // the `URL` field instead of the `Endpoint` field.
        <span class="cov8" title="1">endpoint := u.Path
        if endpoint == "" </span><span class="cov8" title="1">{
                endpoint = u.Opaque
        }</span>
        <span class="cov8" title="1">endpoint = strings.TrimPrefix(endpoint, "/")
        return resolver.Target{
                Scheme:    u.Scheme,
                Authority: u.Host,
                Endpoint:  endpoint,
                URL:       *u,
        }, nil</span>
}

// Determine channel authority. The order of precedence is as follows:
// - user specified authority override using `WithAuthority` dial option
// - creds' notion of server name for the authentication handshake
// - endpoint from dial target of the form "scheme://[authority]/endpoint"
func determineAuthority(endpoint, target string, dopts dialOptions) (string, error) <span class="cov8" title="1">{
        // Historically, we had two options for users to specify the serverName or
        // authority for a channel. One was through the transport credentials
        // (either in its constructor, or through the OverrideServerName() method).
        // The other option (for cases where WithInsecure() dial option was used)
        // was to use the WithAuthority() dial option.
        //
        // A few things have changed since:
        // - `insecure` package with an implementation of the `TransportCredentials`
        //   interface for the insecure case
        // - WithAuthority() dial option support for secure credentials
        authorityFromCreds := ""
        if creds := dopts.copts.TransportCredentials; creds != nil &amp;&amp; creds.Info().ServerName != "" </span><span class="cov8" title="1">{
                authorityFromCreds = creds.Info().ServerName
        }</span>
        <span class="cov8" title="1">authorityFromDialOption := dopts.authority
        if (authorityFromCreds != "" &amp;&amp; authorityFromDialOption != "") &amp;&amp; authorityFromCreds != authorityFromDialOption </span><span class="cov8" title="1">{
                return "", fmt.Errorf("ClientConn's authority from transport creds %q and dial option %q don't match", authorityFromCreds, authorityFromDialOption)
        }</span>

        <span class="cov8" title="1">switch </span>{
        case authorityFromDialOption != "":<span class="cov8" title="1">
                return authorityFromDialOption, nil</span>
        case authorityFromCreds != "":<span class="cov8" title="1">
                return authorityFromCreds, nil</span>
        case strings.HasPrefix(target, "unix:") || strings.HasPrefix(target, "unix-abstract:"):<span class="cov8" title="1">
                // TODO: remove when the unix resolver implements optional interface to
                // return channel authority.
                return "localhost", nil</span>
        case strings.HasPrefix(endpoint, ":"):<span class="cov8" title="1">
                return "localhost" + endpoint, nil</span>
        default:<span class="cov8" title="1">
                // TODO: Define an optional interface on the resolver builder to return
                // the channel authority given the user's dial target. For resolvers
                // which don't implement this interface, we will use the endpoint from
                // "scheme://authority/endpoint" as the default authority.
                return endpoint, nil</span>
        }
}
</pre>
		
		<pre class="file" id="file35" style="display: none">/*
 *
 * Copyright 2017 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package codes

import "strconv"

func (c Code) String() string <span class="cov8" title="1">{
        switch c </span>{
        case OK:<span class="cov8" title="1">
                return "OK"</span>
        case Canceled:<span class="cov0" title="0">
                return "Canceled"</span>
        case Unknown:<span class="cov0" title="0">
                return "Unknown"</span>
        case InvalidArgument:<span class="cov0" title="0">
                return "InvalidArgument"</span>
        case DeadlineExceeded:<span class="cov0" title="0">
                return "DeadlineExceeded"</span>
        case NotFound:<span class="cov0" title="0">
                return "NotFound"</span>
        case AlreadyExists:<span class="cov0" title="0">
                return "AlreadyExists"</span>
        case PermissionDenied:<span class="cov0" title="0">
                return "PermissionDenied"</span>
        case ResourceExhausted:<span class="cov0" title="0">
                return "ResourceExhausted"</span>
        case FailedPrecondition:<span class="cov0" title="0">
                return "FailedPrecondition"</span>
        case Aborted:<span class="cov0" title="0">
                return "Aborted"</span>
        case OutOfRange:<span class="cov0" title="0">
                return "OutOfRange"</span>
        case Unimplemented:<span class="cov0" title="0">
                return "Unimplemented"</span>
        case Internal:<span class="cov0" title="0">
                return "Internal"</span>
        case Unavailable:<span class="cov0" title="0">
                return "Unavailable"</span>
        case DataLoss:<span class="cov0" title="0">
                return "DataLoss"</span>
        case Unauthenticated:<span class="cov0" title="0">
                return "Unauthenticated"</span>
        default:<span class="cov0" title="0">
                return "Code(" + strconv.FormatInt(int64(c), 10) + ")"</span>
        }
}
</pre>
		
		<pre class="file" id="file36" style="display: none">/*
 *
 * Copyright 2014 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package codes defines the canonical error codes used by gRPC. It is
// consistent across various languages.
package codes // import "google.golang.org/grpc/codes"

import (
        "fmt"
        "strconv"
)

// A Code is an unsigned 32-bit error code as defined in the gRPC spec.
type Code uint32

const (
        // OK is returned on success.
        OK Code = 0

        // Canceled indicates the operation was canceled (typically by the caller).
        //
        // The gRPC framework will generate this error code when cancellation
        // is requested.
        Canceled Code = 1

        // Unknown error. An example of where this error may be returned is
        // if a Status value received from another address space belongs to
        // an error-space that is not known in this address space. Also
        // errors raised by APIs that do not return enough error information
        // may be converted to this error.
        //
        // The gRPC framework will generate this error code in the above two
        // mentioned cases.
        Unknown Code = 2

        // InvalidArgument indicates client specified an invalid argument.
        // Note that this differs from FailedPrecondition. It indicates arguments
        // that are problematic regardless of the state of the system
        // (e.g., a malformed file name).
        //
        // This error code will not be generated by the gRPC framework.
        InvalidArgument Code = 3

        // DeadlineExceeded means operation expired before completion.
        // For operations that change the state of the system, this error may be
        // returned even if the operation has completed successfully. For
        // example, a successful response from a server could have been delayed
        // long enough for the deadline to expire.
        //
        // The gRPC framework will generate this error code when the deadline is
        // exceeded.
        DeadlineExceeded Code = 4

        // NotFound means some requested entity (e.g., file or directory) was
        // not found.
        //
        // This error code will not be generated by the gRPC framework.
        NotFound Code = 5

        // AlreadyExists means an attempt to create an entity failed because one
        // already exists.
        //
        // This error code will not be generated by the gRPC framework.
        AlreadyExists Code = 6

        // PermissionDenied indicates the caller does not have permission to
        // execute the specified operation. It must not be used for rejections
        // caused by exhausting some resource (use ResourceExhausted
        // instead for those errors). It must not be
        // used if the caller cannot be identified (use Unauthenticated
        // instead for those errors).
        //
        // This error code will not be generated by the gRPC core framework,
        // but expect authentication middleware to use it.
        PermissionDenied Code = 7

        // ResourceExhausted indicates some resource has been exhausted, perhaps
        // a per-user quota, or perhaps the entire file system is out of space.
        //
        // This error code will be generated by the gRPC framework in
        // out-of-memory and server overload situations, or when a message is
        // larger than the configured maximum size.
        ResourceExhausted Code = 8

        // FailedPrecondition indicates operation was rejected because the
        // system is not in a state required for the operation's execution.
        // For example, directory to be deleted may be non-empty, an rmdir
        // operation is applied to a non-directory, etc.
        //
        // A litmus test that may help a service implementor in deciding
        // between FailedPrecondition, Aborted, and Unavailable:
        //  (a) Use Unavailable if the client can retry just the failing call.
        //  (b) Use Aborted if the client should retry at a higher-level
        //      (e.g., restarting a read-modify-write sequence).
        //  (c) Use FailedPrecondition if the client should not retry until
        //      the system state has been explicitly fixed. E.g., if an "rmdir"
        //      fails because the directory is non-empty, FailedPrecondition
        //      should be returned since the client should not retry unless
        //      they have first fixed up the directory by deleting files from it.
        //  (d) Use FailedPrecondition if the client performs conditional
        //      REST Get/Update/Delete on a resource and the resource on the
        //      server does not match the condition. E.g., conflicting
        //      read-modify-write on the same resource.
        //
        // This error code will not be generated by the gRPC framework.
        FailedPrecondition Code = 9

        // Aborted indicates the operation was aborted, typically due to a
        // concurrency issue like sequencer check failures, transaction aborts,
        // etc.
        //
        // See litmus test above for deciding between FailedPrecondition,
        // Aborted, and Unavailable.
        //
        // This error code will not be generated by the gRPC framework.
        Aborted Code = 10

        // OutOfRange means operation was attempted past the valid range.
        // E.g., seeking or reading past end of file.
        //
        // Unlike InvalidArgument, this error indicates a problem that may
        // be fixed if the system state changes. For example, a 32-bit file
        // system will generate InvalidArgument if asked to read at an
        // offset that is not in the range [0,2^32-1], but it will generate
        // OutOfRange if asked to read from an offset past the current
        // file size.
        //
        // There is a fair bit of overlap between FailedPrecondition and
        // OutOfRange. We recommend using OutOfRange (the more specific
        // error) when it applies so that callers who are iterating through
        // a space can easily look for an OutOfRange error to detect when
        // they are done.
        //
        // This error code will not be generated by the gRPC framework.
        OutOfRange Code = 11

        // Unimplemented indicates operation is not implemented or not
        // supported/enabled in this service.
        //
        // This error code will be generated by the gRPC framework. Most
        // commonly, you will see this error code when a method implementation
        // is missing on the server. It can also be generated for unknown
        // compression algorithms or a disagreement as to whether an RPC should
        // be streaming.
        Unimplemented Code = 12

        // Internal errors. Means some invariants expected by underlying
        // system has been broken. If you see one of these errors,
        // something is very broken.
        //
        // This error code will be generated by the gRPC framework in several
        // internal error conditions.
        Internal Code = 13

        // Unavailable indicates the service is currently unavailable.
        // This is a most likely a transient condition and may be corrected
        // by retrying with a backoff. Note that it is not always safe to retry
        // non-idempotent operations.
        //
        // See litmus test above for deciding between FailedPrecondition,
        // Aborted, and Unavailable.
        //
        // This error code will be generated by the gRPC framework during
        // abrupt shutdown of a server process or network connection.
        Unavailable Code = 14

        // DataLoss indicates unrecoverable data loss or corruption.
        //
        // This error code will not be generated by the gRPC framework.
        DataLoss Code = 15

        // Unauthenticated indicates the request does not have valid
        // authentication credentials for the operation.
        //
        // The gRPC framework will generate this error code when the
        // authentication metadata is invalid or a Credentials callback fails,
        // but also expect authentication middleware to generate it.
        Unauthenticated Code = 16

        _maxCode = 17
)

var strToCode = map[string]Code{
        `"OK"`: OK,
        `"CANCELLED"`:/* [sic] */ Canceled,
        `"UNKNOWN"`:             Unknown,
        `"INVALID_ARGUMENT"`:    InvalidArgument,
        `"DEADLINE_EXCEEDED"`:   DeadlineExceeded,
        `"NOT_FOUND"`:           NotFound,
        `"ALREADY_EXISTS"`:      AlreadyExists,
        `"PERMISSION_DENIED"`:   PermissionDenied,
        `"RESOURCE_EXHAUSTED"`:  ResourceExhausted,
        `"FAILED_PRECONDITION"`: FailedPrecondition,
        `"ABORTED"`:             Aborted,
        `"OUT_OF_RANGE"`:        OutOfRange,
        `"UNIMPLEMENTED"`:       Unimplemented,
        `"INTERNAL"`:            Internal,
        `"UNAVAILABLE"`:         Unavailable,
        `"DATA_LOSS"`:           DataLoss,
        `"UNAUTHENTICATED"`:     Unauthenticated,
}

// UnmarshalJSON unmarshals b into the Code.
func (c *Code) UnmarshalJSON(b []byte) error <span class="cov8" title="1">{
        // From json.Unmarshaler: By convention, to approximate the behavior of
        // Unmarshal itself, Unmarshalers implement UnmarshalJSON([]byte("null")) as
        // a no-op.
        if string(b) == "null" </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">if c == nil </span><span class="cov8" title="1">{
                return fmt.Errorf("nil receiver passed to UnmarshalJSON")
        }</span>

        <span class="cov8" title="1">if ci, err := strconv.ParseUint(string(b), 10, 32); err == nil </span><span class="cov8" title="1">{
                if ci &gt;= _maxCode </span><span class="cov0" title="0">{
                        return fmt.Errorf("invalid code: %q", ci)
                }</span>

                <span class="cov8" title="1">*c = Code(ci)
                return nil</span>
        }

        <span class="cov8" title="1">if jc, ok := strToCode[string(b)]; ok </span><span class="cov8" title="1">{
                *c = jc
                return nil
        }</span>
        <span class="cov8" title="1">return fmt.Errorf("invalid code: %q", string(b))</span>
}
</pre>
		
		<pre class="file" id="file37" style="display: none">/*
 *
 * Copyright 2018 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package authinfo provide authentication information returned by handshakers.
package authinfo

import (
        "google.golang.org/grpc/credentials"
        altspb "google.golang.org/grpc/credentials/alts/internal/proto/grpc_gcp"
)

var _ credentials.AuthInfo = (*altsAuthInfo)(nil)

// altsAuthInfo exposes security information from the ALTS handshake to the
// application. altsAuthInfo is immutable and implements credentials.AuthInfo.
type altsAuthInfo struct {
        p *altspb.AltsContext
        credentials.CommonAuthInfo
}

// New returns a new altsAuthInfo object given handshaker results.
func New(result *altspb.HandshakerResult) credentials.AuthInfo <span class="cov0" title="0">{
        return newAuthInfo(result)
}</span>

func newAuthInfo(result *altspb.HandshakerResult) *altsAuthInfo <span class="cov8" title="1">{
        return &amp;altsAuthInfo{
                p: &amp;altspb.AltsContext{
                        ApplicationProtocol: result.GetApplicationProtocol(),
                        RecordProtocol:      result.GetRecordProtocol(),
                        // TODO: assign security level from result.
                        SecurityLevel:       altspb.SecurityLevel_INTEGRITY_AND_PRIVACY,
                        PeerServiceAccount:  result.GetPeerIdentity().GetServiceAccount(),
                        LocalServiceAccount: result.GetLocalIdentity().GetServiceAccount(),
                        PeerRpcVersions:     result.GetPeerRpcVersions(),
                        PeerAttributes:      result.GetPeerIdentity().GetAttributes(),
                },
                CommonAuthInfo: credentials.CommonAuthInfo{SecurityLevel: credentials.PrivacyAndIntegrity},
        }
}</span>

// AuthType identifies the context as providing ALTS authentication information.
func (s *altsAuthInfo) AuthType() string <span class="cov8" title="1">{
        return "alts"
}</span>

// ApplicationProtocol returns the context's application protocol.
func (s *altsAuthInfo) ApplicationProtocol() string <span class="cov8" title="1">{
        return s.p.GetApplicationProtocol()
}</span>

// RecordProtocol returns the context's record protocol.
func (s *altsAuthInfo) RecordProtocol() string <span class="cov8" title="1">{
        return s.p.GetRecordProtocol()
}</span>

// SecurityLevel returns the context's security level.
func (s *altsAuthInfo) SecurityLevel() altspb.SecurityLevel <span class="cov8" title="1">{
        return s.p.GetSecurityLevel()
}</span>

// PeerServiceAccount returns the context's peer service account.
func (s *altsAuthInfo) PeerServiceAccount() string <span class="cov8" title="1">{
        return s.p.GetPeerServiceAccount()
}</span>

// LocalServiceAccount returns the context's local service account.
func (s *altsAuthInfo) LocalServiceAccount() string <span class="cov8" title="1">{
        return s.p.GetLocalServiceAccount()
}</span>

// PeerRPCVersions returns the context's peer RPC versions.
func (s *altsAuthInfo) PeerRPCVersions() *altspb.RpcProtocolVersions <span class="cov8" title="1">{
        return s.p.GetPeerRpcVersions()
}</span>

// PeerAttributes returns the context's peer attributes.
func (s *altsAuthInfo) PeerAttributes() map[string]string <span class="cov8" title="1">{
        return s.p.GetPeerAttributes()
}</span>
</pre>
		
		<pre class="file" id="file38" style="display: none">/*
 *
 * Copyright 2018 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package conn

import (
        "bytes"
        "crypto/aes"
        "crypto/cipher"
        "crypto/hmac"
        "crypto/sha256"
        "encoding/binary"
        "fmt"
        "strconv"
)

// rekeyAEAD holds the necessary information for an AEAD based on
// AES-GCM that performs nonce-based key derivation and XORs the
// nonce with a random mask.
type rekeyAEAD struct {
        kdfKey     []byte
        kdfCounter []byte
        nonceMask  []byte
        nonceBuf   []byte
        gcmAEAD    cipher.AEAD
}

// KeySizeError signals that the given key does not have the correct size.
type KeySizeError int

func (k KeySizeError) Error() string <span class="cov0" title="0">{
        return "alts/conn: invalid key size " + strconv.Itoa(int(k))
}</span>

// newRekeyAEAD creates a new instance of aes128gcm with rekeying.
// The key argument should be 44 bytes, the first 32 bytes are used as a key
// for HKDF-expand and the remainining 12 bytes are used as a random mask for
// the counter.
func newRekeyAEAD(key []byte) (*rekeyAEAD, error) <span class="cov8" title="1">{
        k := len(key)
        if k != kdfKeyLen+nonceLen </span><span class="cov0" title="0">{
                return nil, KeySizeError(k)
        }</span>
        <span class="cov8" title="1">return &amp;rekeyAEAD{
                kdfKey:     key[:kdfKeyLen],
                kdfCounter: make([]byte, kdfCounterLen),
                nonceMask:  key[kdfKeyLen:],
                nonceBuf:   make([]byte, nonceLen),
                gcmAEAD:    nil,
        }, nil</span>
}

// Seal rekeys if nonce[2:8] is different than in the last call, masks the nonce,
// and calls Seal for aes128gcm.
func (s *rekeyAEAD) Seal(dst, nonce, plaintext, additionalData []byte) []byte <span class="cov8" title="1">{
        if err := s.rekeyIfRequired(nonce); err != nil </span><span class="cov0" title="0">{
                panic(fmt.Sprintf("Rekeying failed with: %s", err.Error()))</span>
        }
        <span class="cov8" title="1">maskNonce(s.nonceBuf, nonce, s.nonceMask)
        return s.gcmAEAD.Seal(dst, s.nonceBuf, plaintext, additionalData)</span>
}

// Open rekeys if nonce[2:8] is different than in the last call, masks the nonce,
// and calls Open for aes128gcm.
func (s *rekeyAEAD) Open(dst, nonce, ciphertext, additionalData []byte) ([]byte, error) <span class="cov8" title="1">{
        if err := s.rekeyIfRequired(nonce); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">maskNonce(s.nonceBuf, nonce, s.nonceMask)
        return s.gcmAEAD.Open(dst, s.nonceBuf, ciphertext, additionalData)</span>
}

// rekeyIfRequired creates a new aes128gcm AEAD if the existing AEAD is nil
// or cannot be used with given nonce.
func (s *rekeyAEAD) rekeyIfRequired(nonce []byte) error <span class="cov8" title="1">{
        newKdfCounter := nonce[kdfCounterOffset : kdfCounterOffset+kdfCounterLen]
        if s.gcmAEAD != nil &amp;&amp; bytes.Equal(newKdfCounter, s.kdfCounter) </span><span class="cov8" title="1">{
                return nil
        }</span>
        <span class="cov8" title="1">copy(s.kdfCounter, newKdfCounter)
        a, err := aes.NewCipher(hkdfExpand(s.kdfKey, s.kdfCounter))
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov8" title="1">s.gcmAEAD, err = cipher.NewGCM(a)
        return err</span>
}

// maskNonce XORs the given nonce with the mask and stores the result in dst.
func maskNonce(dst, nonce, mask []byte) <span class="cov8" title="1">{
        nonce1 := binary.LittleEndian.Uint64(nonce[:sizeUint64])
        nonce2 := binary.LittleEndian.Uint32(nonce[sizeUint64:])
        mask1 := binary.LittleEndian.Uint64(mask[:sizeUint64])
        mask2 := binary.LittleEndian.Uint32(mask[sizeUint64:])
        binary.LittleEndian.PutUint64(dst[:sizeUint64], nonce1^mask1)
        binary.LittleEndian.PutUint32(dst[sizeUint64:], nonce2^mask2)
}</span>

// NonceSize returns the required nonce size.
func (s *rekeyAEAD) NonceSize() int <span class="cov0" title="0">{
        return s.gcmAEAD.NonceSize()
}</span>

// Overhead returns the ciphertext overhead.
func (s *rekeyAEAD) Overhead() int <span class="cov0" title="0">{
        return s.gcmAEAD.Overhead()
}</span>

// hkdfExpand computes the first 16 bytes of the HKDF-expand function
// defined in RFC5869.
func hkdfExpand(key, info []byte) []byte <span class="cov8" title="1">{
        mac := hmac.New(sha256.New, key)
        mac.Write(info)
        mac.Write([]byte{0x01}[:])
        return mac.Sum(nil)[:aeadKeyLen]
}</span>
</pre>
		
		<pre class="file" id="file39" style="display: none">/*
 *
 * Copyright 2018 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package conn

import (
        "crypto/aes"
        "crypto/cipher"

        core "google.golang.org/grpc/credentials/alts/internal"
)

const (
        // Overflow length n in bytes, never encrypt more than 2^(n*8) frames (in
        // each direction).
        overflowLenAES128GCM = 5
)

// aes128gcm is the struct that holds necessary information for ALTS record.
// The counter value is NOT included in the payload during the encryption and
// decryption operations.
type aes128gcm struct {
        // inCounter is used in ALTS record to check that incoming counters are
        // as expected, since ALTS record guarantees that messages are unwrapped
        // in the same order that the peer wrapped them.
        inCounter  Counter
        outCounter Counter
        aead       cipher.AEAD
}

// NewAES128GCM creates an instance that uses aes128gcm for ALTS record.
func NewAES128GCM(side core.Side, key []byte) (ALTSRecordCrypto, error) <span class="cov8" title="1">{
        c, err := aes.NewCipher(key)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">a, err := cipher.NewGCM(c)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return &amp;aes128gcm{
                inCounter:  NewInCounter(side, overflowLenAES128GCM),
                outCounter: NewOutCounter(side, overflowLenAES128GCM),
                aead:       a,
        }, nil</span>
}

// Encrypt is the encryption function. dst can contain bytes at the beginning of
// the ciphertext that will not be encrypted but will be authenticated. If dst
// has enough capacity to hold these bytes, the ciphertext and the tag, no
// allocation and copy operations will be performed. dst and plaintext do not
// overlap.
func (s *aes128gcm) Encrypt(dst, plaintext []byte) ([]byte, error) <span class="cov8" title="1">{
        // If we need to allocate an output buffer, we want to include space for
        // GCM tag to avoid forcing ALTS record to reallocate as well.
        dlen := len(dst)
        dst, out := SliceForAppend(dst, len(plaintext)+GcmTagSize)
        seq, err := s.outCounter.Value()
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">data := out[:len(plaintext)]
        copy(data, plaintext) // data may alias plaintext

        // Seal appends the ciphertext and the tag to its first argument and
        // returns the updated slice. However, SliceForAppend above ensures that
        // dst has enough capacity to avoid a reallocation and copy due to the
        // append.
        dst = s.aead.Seal(dst[:dlen], seq, data, nil)
        s.outCounter.Inc()
        return dst, nil</span>
}

func (s *aes128gcm) EncryptionOverhead() int <span class="cov8" title="1">{
        return GcmTagSize
}</span>

func (s *aes128gcm) Decrypt(dst, ciphertext []byte) ([]byte, error) <span class="cov8" title="1">{
        seq, err := s.inCounter.Value()
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        // If dst is equal to ciphertext[:0], ciphertext storage is reused.
        <span class="cov8" title="1">plaintext, err := s.aead.Open(dst, seq, ciphertext, nil)
        if err != nil </span><span class="cov8" title="1">{
                return nil, ErrAuth
        }</span>
        <span class="cov8" title="1">s.inCounter.Inc()
        return plaintext, nil</span>
}
</pre>
		
		<pre class="file" id="file40" style="display: none">/*
 *
 * Copyright 2018 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package conn

import (
        "crypto/cipher"

        core "google.golang.org/grpc/credentials/alts/internal"
)

const (
        // Overflow length n in bytes, never encrypt more than 2^(n*8) frames (in
        // each direction).
        overflowLenAES128GCMRekey = 8
        nonceLen                  = 12
        aeadKeyLen                = 16
        kdfKeyLen                 = 32
        kdfCounterOffset          = 2
        kdfCounterLen             = 6
        sizeUint64                = 8
)

// aes128gcmRekey is the struct that holds necessary information for ALTS record.
// The counter value is NOT included in the payload during the encryption and
// decryption operations.
type aes128gcmRekey struct {
        // inCounter is used in ALTS record to check that incoming counters are
        // as expected, since ALTS record guarantees that messages are unwrapped
        // in the same order that the peer wrapped them.
        inCounter  Counter
        outCounter Counter
        inAEAD     cipher.AEAD
        outAEAD    cipher.AEAD
}

// NewAES128GCMRekey creates an instance that uses aes128gcm with rekeying
// for ALTS record. The key argument should be 44 bytes, the first 32 bytes
// are used as a key for HKDF-expand and the remainining 12 bytes are used
// as a random mask for the counter.
func NewAES128GCMRekey(side core.Side, key []byte) (ALTSRecordCrypto, error) <span class="cov8" title="1">{
        inCounter := NewInCounter(side, overflowLenAES128GCMRekey)
        outCounter := NewOutCounter(side, overflowLenAES128GCMRekey)
        inAEAD, err := newRekeyAEAD(key)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">outAEAD, err := newRekeyAEAD(key)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return &amp;aes128gcmRekey{
                inCounter,
                outCounter,
                inAEAD,
                outAEAD,
        }, nil</span>
}

// Encrypt is the encryption function. dst can contain bytes at the beginning of
// the ciphertext that will not be encrypted but will be authenticated. If dst
// has enough capacity to hold these bytes, the ciphertext and the tag, no
// allocation and copy operations will be performed. dst and plaintext do not
// overlap.
func (s *aes128gcmRekey) Encrypt(dst, plaintext []byte) ([]byte, error) <span class="cov8" title="1">{
        // If we need to allocate an output buffer, we want to include space for
        // GCM tag to avoid forcing ALTS record to reallocate as well.
        dlen := len(dst)
        dst, out := SliceForAppend(dst, len(plaintext)+GcmTagSize)
        seq, err := s.outCounter.Value()
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">data := out[:len(plaintext)]
        copy(data, plaintext) // data may alias plaintext

        // Seal appends the ciphertext and the tag to its first argument and
        // returns the updated slice. However, SliceForAppend above ensures that
        // dst has enough capacity to avoid a reallocation and copy due to the
        // append.
        dst = s.outAEAD.Seal(dst[:dlen], seq, data, nil)
        s.outCounter.Inc()
        return dst, nil</span>
}

func (s *aes128gcmRekey) EncryptionOverhead() int <span class="cov0" title="0">{
        return GcmTagSize
}</span>

func (s *aes128gcmRekey) Decrypt(dst, ciphertext []byte) ([]byte, error) <span class="cov8" title="1">{
        seq, err := s.inCounter.Value()
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">plaintext, err := s.inAEAD.Open(dst, seq, ciphertext, nil)
        if err != nil </span><span class="cov8" title="1">{
                return nil, ErrAuth
        }</span>
        <span class="cov8" title="1">s.inCounter.Inc()
        return plaintext, nil</span>
}
</pre>
		
		<pre class="file" id="file41" style="display: none">/*
 *
 * Copyright 2018 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package conn

import (
        "encoding/binary"
        "errors"
        "fmt"
)

const (
        // GcmTagSize is the GCM tag size is the difference in length between
        // plaintext and ciphertext. From crypto/cipher/gcm.go in Go crypto
        // library.
        GcmTagSize = 16
)

// ErrAuth occurs on authentication failure.
var ErrAuth = errors.New("message authentication failed")

// SliceForAppend takes a slice and a requested number of bytes. It returns a
// slice with the contents of the given slice followed by that many bytes and a
// second slice that aliases into it and contains only the extra bytes. If the
// original slice has sufficient capacity then no allocation is performed.
func SliceForAppend(in []byte, n int) (head, tail []byte) <span class="cov8" title="1">{
        if total := len(in) + n; cap(in) &gt;= total </span><span class="cov8" title="1">{
                head = in[:total]
        }</span> else<span class="cov8" title="1"> {
                head = make([]byte, total)
                copy(head, in)
        }</span>
        <span class="cov8" title="1">tail = head[len(in):]
        return head, tail</span>
}

// ParseFramedMsg parse the provided buffer and returns a frame of the format
// msgLength+msg and any remaining bytes in that buffer.
func ParseFramedMsg(b []byte, maxLen uint32) ([]byte, []byte, error) <span class="cov8" title="1">{
        // If the size field is not complete, return the provided buffer as
        // remaining buffer.
        if len(b) &lt; MsgLenFieldSize </span><span class="cov8" title="1">{
                return nil, b, nil
        }</span>
        <span class="cov8" title="1">msgLenField := b[:MsgLenFieldSize]
        length := binary.LittleEndian.Uint32(msgLenField)
        if length &gt; maxLen </span><span class="cov8" title="1">{
                return nil, nil, fmt.Errorf("received the frame length %d larger than the limit %d", length, maxLen)
        }</span>
        <span class="cov8" title="1">if len(b) &lt; int(length)+4 </span><span class="cov0" title="0">{ // account for the first 4 msg length bytes.
                // Frame is not complete yet.
                return nil, b, nil
        }</span>
        <span class="cov8" title="1">return b[:MsgLenFieldSize+length], b[MsgLenFieldSize+length:], nil</span>
}
</pre>
		
		<pre class="file" id="file42" style="display: none">/*
 *
 * Copyright 2018 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package conn

import (
        "errors"
)

const counterLen = 12

var (
        errInvalidCounter = errors.New("invalid counter")
)

// Counter is a 96-bit, little-endian counter.
type Counter struct {
        value       [counterLen]byte
        invalid     bool
        overflowLen int
}

// Value returns the current value of the counter as a byte slice.
func (c *Counter) Value() ([]byte, error) <span class="cov8" title="1">{
        if c.invalid </span><span class="cov8" title="1">{
                return nil, errInvalidCounter
        }</span>
        <span class="cov8" title="1">return c.value[:], nil</span>
}

// Inc increments the counter and checks for overflow.
func (c *Counter) Inc() <span class="cov8" title="1">{
        // If the counter is already invalid, there is no need to increase it.
        if c.invalid </span><span class="cov8" title="1">{
                return
        }</span>
        <span class="cov8" title="1">i := 0
        for ; i &lt; c.overflowLen; i++ </span><span class="cov8" title="1">{
                c.value[i]++
                if c.value[i] != 0 </span><span class="cov8" title="1">{
                        break</span>
                }
        }
        <span class="cov8" title="1">if i == c.overflowLen </span><span class="cov8" title="1">{
                c.invalid = true
        }</span>
}
</pre>
		
		<pre class="file" id="file43" style="display: none">/*
 *
 * Copyright 2018 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package conn contains an implementation of a secure channel created by gRPC
// handshakers.
package conn

import (
        "encoding/binary"
        "fmt"
        "math"
        "net"

        core "google.golang.org/grpc/credentials/alts/internal"
)

// ALTSRecordCrypto is the interface for gRPC ALTS record protocol.
type ALTSRecordCrypto interface {
        // Encrypt encrypts the plaintext and computes the tag (if any) of dst
        // and plaintext. dst and plaintext may fully overlap or not at all.
        Encrypt(dst, plaintext []byte) ([]byte, error)
        // EncryptionOverhead returns the tag size (if any) in bytes.
        EncryptionOverhead() int
        // Decrypt decrypts ciphertext and verify the tag (if any). dst and
        // ciphertext may alias exactly or not at all. To reuse ciphertext's
        // storage for the decrypted output, use ciphertext[:0] as dst.
        Decrypt(dst, ciphertext []byte) ([]byte, error)
}

// ALTSRecordFunc is a function type for factory functions that create
// ALTSRecordCrypto instances.
type ALTSRecordFunc func(s core.Side, keyData []byte) (ALTSRecordCrypto, error)

const (
        // MsgLenFieldSize is the byte size of the frame length field of a
        // framed message.
        MsgLenFieldSize = 4
        // The byte size of the message type field of a framed message.
        msgTypeFieldSize = 4
        // The bytes size limit for a ALTS record message.
        altsRecordLengthLimit = 1024 * 1024 // 1 MiB
        // The default bytes size of a ALTS record message.
        altsRecordDefaultLength = 4 * 1024 // 4KiB
        // Message type value included in ALTS record framing.
        altsRecordMsgType = uint32(0x06)
        // The initial write buffer size.
        altsWriteBufferInitialSize = 32 * 1024 // 32KiB
        // The maximum write buffer size. This *must* be multiple of
        // altsRecordDefaultLength.
        altsWriteBufferMaxSize = 512 * 1024 // 512KiB
)

var (
        protocols = make(map[string]ALTSRecordFunc)
)

// RegisterProtocol register a ALTS record encryption protocol.
func RegisterProtocol(protocol string, f ALTSRecordFunc) error <span class="cov8" title="1">{
        if _, ok := protocols[protocol]; ok </span><span class="cov0" title="0">{
                return fmt.Errorf("protocol %v is already registered", protocol)
        }</span>
        <span class="cov8" title="1">protocols[protocol] = f
        return nil</span>
}

// conn represents a secured connection. It implements the net.Conn interface.
type conn struct {
        net.Conn
        crypto ALTSRecordCrypto
        // buf holds data that has been read from the connection and decrypted,
        // but has not yet been returned by Read.
        buf                []byte
        payloadLengthLimit int
        // protected holds data read from the network but have not yet been
        // decrypted. This data might not compose a complete frame.
        protected []byte
        // writeBuf is a buffer used to contain encrypted frames before being
        // written to the network.
        writeBuf []byte
        // nextFrame stores the next frame (in protected buffer) info.
        nextFrame []byte
        // overhead is the calculated overhead of each frame.
        overhead int
}

// NewConn creates a new secure channel instance given the other party role and
// handshaking result.
func NewConn(c net.Conn, side core.Side, recordProtocol string, key []byte, protected []byte) (net.Conn, error) <span class="cov8" title="1">{
        newCrypto := protocols[recordProtocol]
        if newCrypto == nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("negotiated unknown next_protocol %q", recordProtocol)
        }</span>
        <span class="cov8" title="1">crypto, err := newCrypto(side, key)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("protocol %q: %v", recordProtocol, err)
        }</span>
        <span class="cov8" title="1">overhead := MsgLenFieldSize + msgTypeFieldSize + crypto.EncryptionOverhead()
        payloadLengthLimit := altsRecordDefaultLength - overhead
        var protectedBuf []byte
        if protected == nil </span><span class="cov8" title="1">{
                // We pre-allocate protected to be of size
                // 2*altsRecordDefaultLength-1 during initialization. We only
                // read from the network into protected when protected does not
                // contain a complete frame, which is at most
                // altsRecordDefaultLength-1 (bytes). And we read at most
                // altsRecordDefaultLength (bytes) data into protected at one
                // time. Therefore, 2*altsRecordDefaultLength-1 is large enough
                // to buffer data read from the network.
                protectedBuf = make([]byte, 0, 2*altsRecordDefaultLength-1)
        }</span> else<span class="cov8" title="1"> {
                protectedBuf = make([]byte, len(protected))
                copy(protectedBuf, protected)
        }</span>

        <span class="cov8" title="1">altsConn := &amp;conn{
                Conn:               c,
                crypto:             crypto,
                payloadLengthLimit: payloadLengthLimit,
                protected:          protectedBuf,
                writeBuf:           make([]byte, altsWriteBufferInitialSize),
                nextFrame:          protectedBuf,
                overhead:           overhead,
        }
        return altsConn, nil</span>
}

// Read reads and decrypts a frame from the underlying connection, and copies the
// decrypted payload into b. If the size of the payload is greater than len(b),
// Read retains the remaining bytes in an internal buffer, and subsequent calls
// to Read will read from this buffer until it is exhausted.
func (p *conn) Read(b []byte) (n int, err error) <span class="cov8" title="1">{
        if len(p.buf) == 0 </span><span class="cov8" title="1">{
                var framedMsg []byte
                framedMsg, p.nextFrame, err = ParseFramedMsg(p.nextFrame, altsRecordLengthLimit)
                if err != nil </span><span class="cov0" title="0">{
                        return n, err
                }</span>
                // Check whether the next frame to be decrypted has been
                // completely received yet.
                <span class="cov8" title="1">if len(framedMsg) == 0 </span><span class="cov8" title="1">{
                        copy(p.protected, p.nextFrame)
                        p.protected = p.protected[:len(p.nextFrame)]
                        // Always copy next incomplete frame to the beginning of
                        // the protected buffer and reset nextFrame to it.
                        p.nextFrame = p.protected
                }</span>
                // Check whether a complete frame has been received yet.
                <span class="cov8" title="1">for len(framedMsg) == 0 </span><span class="cov8" title="1">{
                        if len(p.protected) == cap(p.protected) </span><span class="cov0" title="0">{
                                tmp := make([]byte, len(p.protected), cap(p.protected)+altsRecordDefaultLength)
                                copy(tmp, p.protected)
                                p.protected = tmp
                        }</span>
                        <span class="cov8" title="1">n, err = p.Conn.Read(p.protected[len(p.protected):min(cap(p.protected), len(p.protected)+altsRecordDefaultLength)])
                        if err != nil </span><span class="cov0" title="0">{
                                return 0, err
                        }</span>
                        <span class="cov8" title="1">p.protected = p.protected[:len(p.protected)+n]
                        framedMsg, p.nextFrame, err = ParseFramedMsg(p.protected, altsRecordLengthLimit)
                        if err != nil </span><span class="cov8" title="1">{
                                return 0, err
                        }</span>
                }
                // Now we have a complete frame, decrypted it.
                <span class="cov8" title="1">msg := framedMsg[MsgLenFieldSize:]
                msgType := binary.LittleEndian.Uint32(msg[:msgTypeFieldSize])
                if msgType&amp;0xff != altsRecordMsgType </span><span class="cov8" title="1">{
                        return 0, fmt.Errorf("received frame with incorrect message type %v, expected lower byte %v",
                                msgType, altsRecordMsgType)
                }</span>
                <span class="cov8" title="1">ciphertext := msg[msgTypeFieldSize:]

                // Decrypt requires that if the dst and ciphertext alias, they
                // must alias exactly. Code here used to use msg[:0], but msg
                // starts MsgLenFieldSize+msgTypeFieldSize bytes earlier than
                // ciphertext, so they alias inexactly. Using ciphertext[:0]
                // arranges the appropriate aliasing without needing to copy
                // ciphertext or use a separate destination buffer. For more info
                // check: https://golang.org/pkg/crypto/cipher/#AEAD.
                p.buf, err = p.crypto.Decrypt(ciphertext[:0], ciphertext)
                if err != nil </span><span class="cov0" title="0">{
                        return 0, err
                }</span>
        }

        <span class="cov8" title="1">n = copy(b, p.buf)
        p.buf = p.buf[n:]
        return n, nil</span>
}

// Write encrypts, frames, and writes bytes from b to the underlying connection.
func (p *conn) Write(b []byte) (n int, err error) <span class="cov8" title="1">{
        n = len(b)
        // Calculate the output buffer size with framing and encryption overhead.
        numOfFrames := int(math.Ceil(float64(len(b)) / float64(p.payloadLengthLimit)))
        size := len(b) + numOfFrames*p.overhead
        // If writeBuf is too small, increase its size up to the maximum size.
        partialBSize := len(b)
        if size &gt; altsWriteBufferMaxSize </span><span class="cov8" title="1">{
                size = altsWriteBufferMaxSize
                const numOfFramesInMaxWriteBuf = altsWriteBufferMaxSize / altsRecordDefaultLength
                partialBSize = numOfFramesInMaxWriteBuf * p.payloadLengthLimit
        }</span>
        <span class="cov8" title="1">if len(p.writeBuf) &lt; size </span><span class="cov8" title="1">{
                p.writeBuf = make([]byte, size)
        }</span>

        <span class="cov8" title="1">for partialBStart := 0; partialBStart &lt; len(b); partialBStart += partialBSize </span><span class="cov8" title="1">{
                partialBEnd := partialBStart + partialBSize
                if partialBEnd &gt; len(b) </span><span class="cov8" title="1">{
                        partialBEnd = len(b)
                }</span>
                <span class="cov8" title="1">partialB := b[partialBStart:partialBEnd]
                writeBufIndex := 0
                for len(partialB) &gt; 0 </span><span class="cov8" title="1">{
                        payloadLen := len(partialB)
                        if payloadLen &gt; p.payloadLengthLimit </span><span class="cov8" title="1">{
                                payloadLen = p.payloadLengthLimit
                        }</span>
                        <span class="cov8" title="1">buf := partialB[:payloadLen]
                        partialB = partialB[payloadLen:]

                        // Write buffer contains: length, type, payload, and tag
                        // if any.

                        // 1. Fill in type field.
                        msg := p.writeBuf[writeBufIndex+MsgLenFieldSize:]
                        binary.LittleEndian.PutUint32(msg, altsRecordMsgType)

                        // 2. Encrypt the payload and create a tag if any.
                        msg, err = p.crypto.Encrypt(msg[:msgTypeFieldSize], buf)
                        if err != nil </span><span class="cov0" title="0">{
                                return n, err
                        }</span>

                        // 3. Fill in the size field.
                        <span class="cov8" title="1">binary.LittleEndian.PutUint32(p.writeBuf[writeBufIndex:], uint32(len(msg)))

                        // 4. Increase writeBufIndex.
                        writeBufIndex += len(buf) + p.overhead</span>
                }
                <span class="cov8" title="1">nn, err := p.Conn.Write(p.writeBuf[:writeBufIndex])
                if err != nil </span><span class="cov0" title="0">{
                        // We need to calculate the actual data size that was
                        // written. This means we need to remove header,
                        // encryption overheads, and any partially-written
                        // frame data.
                        numOfWrittenFrames := int(math.Floor(float64(nn) / float64(altsRecordDefaultLength)))
                        return partialBStart + numOfWrittenFrames*p.payloadLengthLimit, err
                }</span>
        }
        <span class="cov8" title="1">return n, nil</span>
}

func min(a, b int) int <span class="cov8" title="1">{
        if a &lt; b </span><span class="cov0" title="0">{
                return a
        }</span>
        <span class="cov8" title="1">return b</span>
}
</pre>
		
		<pre class="file" id="file44" style="display: none">/*
 *
 * Copyright 2018 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package conn

import core "google.golang.org/grpc/credentials/alts/internal"

// NewOutCounter returns an outgoing counter initialized to the starting sequence
// number for the client/server side of a connection.
func NewOutCounter(s core.Side, overflowLen int) (c Counter) <span class="cov8" title="1">{
        c.overflowLen = overflowLen
        if s == core.ServerSide </span><span class="cov8" title="1">{
                // Server counters in ALTS record have the little-endian high bit
                // set.
                c.value[counterLen-1] = 0x80
        }</span>
        <span class="cov8" title="1">return</span>
}

// NewInCounter returns an incoming counter initialized to the starting sequence
// number for the client/server side of a connection. This is used in ALTS record
// to check that incoming counters are as expected, since ALTS record guarantees
// that messages are unwrapped in the same order that the peer wrapped them.
func NewInCounter(s core.Side, overflowLen int) (c Counter) <span class="cov8" title="1">{
        c.overflowLen = overflowLen
        if s == core.ClientSide </span><span class="cov8" title="1">{
                // Server counters in ALTS record have the little-endian high bit
                // set.
                c.value[counterLen-1] = 0x80
        }</span>
        <span class="cov8" title="1">return</span>
}

// CounterFromValue creates a new counter given an initial value.
func CounterFromValue(value []byte, overflowLen int) (c Counter) <span class="cov8" title="1">{
        c.overflowLen = overflowLen
        copy(c.value[:], value)
        return
}</span>

// CounterSide returns the connection side (client/server) a sequence counter is
// associated with.
func CounterSide(c []byte) core.Side <span class="cov8" title="1">{
        if c[counterLen-1]&amp;0x80 == 0x80 </span><span class="cov8" title="1">{
                return core.ServerSide
        }</span>
        <span class="cov8" title="1">return core.ClientSide</span>
}
</pre>
		
		<pre class="file" id="file45" style="display: none">/*
 *
 * Copyright 2018 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package handshaker provides ALTS handshaking functionality for GCP.
package handshaker

import (
        "context"
        "errors"
        "fmt"
        "io"
        "net"
        "sync"

        grpc "google.golang.org/grpc"
        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/credentials"
        core "google.golang.org/grpc/credentials/alts/internal"
        "google.golang.org/grpc/credentials/alts/internal/authinfo"
        "google.golang.org/grpc/credentials/alts/internal/conn"
        altsgrpc "google.golang.org/grpc/credentials/alts/internal/proto/grpc_gcp"
        altspb "google.golang.org/grpc/credentials/alts/internal/proto/grpc_gcp"
)

const (
        // The maximum byte size of receive frames.
        frameLimit              = 64 * 1024 // 64 KB
        rekeyRecordProtocolName = "ALTSRP_GCM_AES128_REKEY"
        // maxPendingHandshakes represents the maximum number of concurrent
        // handshakes.
        maxPendingHandshakes = 100
)

var (
        hsProtocol      = altspb.HandshakeProtocol_ALTS
        appProtocols    = []string{"grpc"}
        recordProtocols = []string{rekeyRecordProtocolName}
        keyLength       = map[string]int{
                rekeyRecordProtocolName: 44,
        }
        altsRecordFuncs = map[string]conn.ALTSRecordFunc{
                // ALTS handshaker protocols.
                rekeyRecordProtocolName: func(s core.Side, keyData []byte) (conn.ALTSRecordCrypto, error) <span class="cov8" title="1">{
                        return conn.NewAES128GCMRekey(s, keyData)
                }</span>,
        }
        // control number of concurrent created (but not closed) handshakers.
        mu                   sync.Mutex
        concurrentHandshakes = int64(0)
        // errDropped occurs when maxPendingHandshakes is reached.
        errDropped = errors.New("maximum number of concurrent ALTS handshakes is reached")
        // errOutOfBound occurs when the handshake service returns a consumed
        // bytes value larger than the buffer that was passed to it originally.
        errOutOfBound = errors.New("handshaker service consumed bytes value is out-of-bound")
)

func init() <span class="cov8" title="1">{
        for protocol, f := range altsRecordFuncs </span><span class="cov8" title="1">{
                if err := conn.RegisterProtocol(protocol, f); err != nil </span><span class="cov0" title="0">{
                        panic(err)</span>
                }
        }
}

func acquire() bool <span class="cov8" title="1">{
        mu.Lock()
        // If we need n to be configurable, we can pass it as an argument.
        n := int64(1)
        success := maxPendingHandshakes-concurrentHandshakes &gt;= n
        if success </span><span class="cov8" title="1">{
                concurrentHandshakes += n
        }</span>
        <span class="cov8" title="1">mu.Unlock()
        return success</span>
}

func release() <span class="cov8" title="1">{
        mu.Lock()
        // If we need n to be configurable, we can pass it as an argument.
        n := int64(1)
        concurrentHandshakes -= n
        if concurrentHandshakes &lt; 0 </span><span class="cov0" title="0">{
                mu.Unlock()
                panic("bad release")</span>
        }
        <span class="cov8" title="1">mu.Unlock()</span>
}

// ClientHandshakerOptions contains the client handshaker options that can
// provided by the caller.
type ClientHandshakerOptions struct {
        // ClientIdentity is the handshaker client local identity.
        ClientIdentity *altspb.Identity
        // TargetName is the server service account name for secure name
        // checking.
        TargetName string
        // TargetServiceAccounts contains a list of expected target service
        // accounts. One of these accounts should match one of the accounts in
        // the handshaker results. Otherwise, the handshake fails.
        TargetServiceAccounts []string
        // RPCVersions specifies the gRPC versions accepted by the client.
        RPCVersions *altspb.RpcProtocolVersions
}

// ServerHandshakerOptions contains the server handshaker options that can
// provided by the caller.
type ServerHandshakerOptions struct {
        // RPCVersions specifies the gRPC versions accepted by the server.
        RPCVersions *altspb.RpcProtocolVersions
}

// DefaultClientHandshakerOptions returns the default client handshaker options.
func DefaultClientHandshakerOptions() *ClientHandshakerOptions <span class="cov0" title="0">{
        return &amp;ClientHandshakerOptions{}
}</span>

// DefaultServerHandshakerOptions returns the default client handshaker options.
func DefaultServerHandshakerOptions() *ServerHandshakerOptions <span class="cov8" title="1">{
        return &amp;ServerHandshakerOptions{}
}</span>

// TODO: add support for future local and remote endpoint in both client options
//       and server options (server options struct does not exist now. When
//       caller can provide endpoints, it should be created.

// altsHandshaker is used to complete a ALTS handshaking between client and
// server. This handshaker talks to the ALTS handshaker service in the metadata
// server.
type altsHandshaker struct {
        // RPC stream used to access the ALTS Handshaker service.
        stream altsgrpc.HandshakerService_DoHandshakeClient
        // the connection to the peer.
        conn net.Conn
        // client handshake options.
        clientOpts *ClientHandshakerOptions
        // server handshake options.
        serverOpts *ServerHandshakerOptions
        // defines the side doing the handshake, client or server.
        side core.Side
}

// NewClientHandshaker creates a ALTS handshaker for GCP which contains an RPC
// stub created using the passed conn and used to talk to the ALTS Handshaker
// service in the metadata server.
func NewClientHandshaker(ctx context.Context, conn *grpc.ClientConn, c net.Conn, opts *ClientHandshakerOptions) (core.Handshaker, error) <span class="cov0" title="0">{
        stream, err := altsgrpc.NewHandshakerServiceClient(conn).DoHandshake(ctx, grpc.WaitForReady(true))
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">return &amp;altsHandshaker{
                stream:     stream,
                conn:       c,
                clientOpts: opts,
                side:       core.ClientSide,
        }, nil</span>
}

// NewServerHandshaker creates a ALTS handshaker for GCP which contains an RPC
// stub created using the passed conn and used to talk to the ALTS Handshaker
// service in the metadata server.
func NewServerHandshaker(ctx context.Context, conn *grpc.ClientConn, c net.Conn, opts *ServerHandshakerOptions) (core.Handshaker, error) <span class="cov0" title="0">{
        stream, err := altsgrpc.NewHandshakerServiceClient(conn).DoHandshake(ctx, grpc.WaitForReady(true))
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">return &amp;altsHandshaker{
                stream:     stream,
                conn:       c,
                serverOpts: opts,
                side:       core.ServerSide,
        }, nil</span>
}

// ClientHandshake starts and completes a client ALTS handshaking for GCP. Once
// done, ClientHandshake returns a secure connection.
func (h *altsHandshaker) ClientHandshake(ctx context.Context) (net.Conn, credentials.AuthInfo, error) <span class="cov8" title="1">{
        if !acquire() </span><span class="cov8" title="1">{
                return nil, nil, errDropped
        }</span>
        <span class="cov8" title="1">defer release()

        if h.side != core.ClientSide </span><span class="cov0" title="0">{
                return nil, nil, errors.New("only handshakers created using NewClientHandshaker can perform a client handshaker")
        }</span>

        // Create target identities from service account list.
        <span class="cov8" title="1">targetIdentities := make([]*altspb.Identity, 0, len(h.clientOpts.TargetServiceAccounts))
        for _, account := range h.clientOpts.TargetServiceAccounts </span><span class="cov8" title="1">{
                targetIdentities = append(targetIdentities, &amp;altspb.Identity{
                        IdentityOneof: &amp;altspb.Identity_ServiceAccount{
                                ServiceAccount: account,
                        },
                })
        }</span>
        <span class="cov8" title="1">req := &amp;altspb.HandshakerReq{
                ReqOneof: &amp;altspb.HandshakerReq_ClientStart{
                        ClientStart: &amp;altspb.StartClientHandshakeReq{
                                HandshakeSecurityProtocol: hsProtocol,
                                ApplicationProtocols:      appProtocols,
                                RecordProtocols:           recordProtocols,
                                TargetIdentities:          targetIdentities,
                                LocalIdentity:             h.clientOpts.ClientIdentity,
                                TargetName:                h.clientOpts.TargetName,
                                RpcVersions:               h.clientOpts.RPCVersions,
                        },
                },
        }

        conn, result, err := h.doHandshake(req)
        if err != nil </span><span class="cov8" title="1">{
                return nil, nil, err
        }</span>
        <span class="cov8" title="1">authInfo := authinfo.New(result)
        return conn, authInfo, nil</span>
}

// ServerHandshake starts and completes a server ALTS handshaking for GCP. Once
// done, ServerHandshake returns a secure connection.
func (h *altsHandshaker) ServerHandshake(ctx context.Context) (net.Conn, credentials.AuthInfo, error) <span class="cov8" title="1">{
        if !acquire() </span><span class="cov8" title="1">{
                return nil, nil, errDropped
        }</span>
        <span class="cov8" title="1">defer release()

        if h.side != core.ServerSide </span><span class="cov0" title="0">{
                return nil, nil, errors.New("only handshakers created using NewServerHandshaker can perform a server handshaker")
        }</span>

        <span class="cov8" title="1">p := make([]byte, frameLimit)
        n, err := h.conn.Read(p)
        if err != nil </span><span class="cov0" title="0">{
                return nil, nil, err
        }</span>

        // Prepare server parameters.
        // TODO: currently only ALTS parameters are provided. Might need to use
        //       more options in the future.
        <span class="cov8" title="1">params := make(map[int32]*altspb.ServerHandshakeParameters)
        params[int32(altspb.HandshakeProtocol_ALTS)] = &amp;altspb.ServerHandshakeParameters{
                RecordProtocols: recordProtocols,
        }
        req := &amp;altspb.HandshakerReq{
                ReqOneof: &amp;altspb.HandshakerReq_ServerStart{
                        ServerStart: &amp;altspb.StartServerHandshakeReq{
                                ApplicationProtocols: appProtocols,
                                HandshakeParameters:  params,
                                InBytes:              p[:n],
                                RpcVersions:          h.serverOpts.RPCVersions,
                        },
                },
        }

        conn, result, err := h.doHandshake(req)
        if err != nil </span><span class="cov0" title="0">{
                return nil, nil, err
        }</span>
        <span class="cov8" title="1">authInfo := authinfo.New(result)
        return conn, authInfo, nil</span>
}

func (h *altsHandshaker) doHandshake(req *altspb.HandshakerReq) (net.Conn, *altspb.HandshakerResult, error) <span class="cov8" title="1">{
        resp, err := h.accessHandshakerService(req)
        if err != nil </span><span class="cov0" title="0">{
                return nil, nil, err
        }</span>
        // Check of the returned status is an error.
        <span class="cov8" title="1">if resp.GetStatus() != nil </span><span class="cov0" title="0">{
                if got, want := resp.GetStatus().Code, uint32(codes.OK); got != want </span><span class="cov0" title="0">{
                        return nil, nil, fmt.Errorf("%v", resp.GetStatus().Details)
                }</span>
        }

        <span class="cov8" title="1">var extra []byte
        if req.GetServerStart() != nil </span><span class="cov8" title="1">{
                if resp.GetBytesConsumed() &gt; uint32(len(req.GetServerStart().GetInBytes())) </span><span class="cov0" title="0">{
                        return nil, nil, errOutOfBound
                }</span>
                <span class="cov8" title="1">extra = req.GetServerStart().GetInBytes()[resp.GetBytesConsumed():]</span>
        }
        <span class="cov8" title="1">result, extra, err := h.processUntilDone(resp, extra)
        if err != nil </span><span class="cov8" title="1">{
                return nil, nil, err
        }</span>
        // The handshaker returns a 128 bytes key. It should be truncated based
        // on the returned record protocol.
        <span class="cov8" title="1">keyLen, ok := keyLength[result.RecordProtocol]
        if !ok </span><span class="cov0" title="0">{
                return nil, nil, fmt.Errorf("unknown resulted record protocol %v", result.RecordProtocol)
        }</span>
        <span class="cov8" title="1">sc, err := conn.NewConn(h.conn, h.side, result.GetRecordProtocol(), result.KeyData[:keyLen], extra)
        if err != nil </span><span class="cov0" title="0">{
                return nil, nil, err
        }</span>
        <span class="cov8" title="1">return sc, result, nil</span>
}

func (h *altsHandshaker) accessHandshakerService(req *altspb.HandshakerReq) (*altspb.HandshakerResp, error) <span class="cov8" title="1">{
        if err := h.stream.Send(req); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">resp, err := h.stream.Recv()
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return resp, nil</span>
}

// processUntilDone processes the handshake until the handshaker service returns
// the results. Handshaker service takes care of frame parsing, so we read
// whatever received from the network and send it to the handshaker service.
func (h *altsHandshaker) processUntilDone(resp *altspb.HandshakerResp, extra []byte) (*altspb.HandshakerResult, []byte, error) <span class="cov8" title="1">{
        for </span><span class="cov8" title="1">{
                if len(resp.OutFrames) &gt; 0 </span><span class="cov8" title="1">{
                        if _, err := h.conn.Write(resp.OutFrames); err != nil </span><span class="cov0" title="0">{
                                return nil, nil, err
                        }</span>
                }
                <span class="cov8" title="1">if resp.Result != nil </span><span class="cov8" title="1">{
                        return resp.Result, extra, nil
                }</span>
                <span class="cov8" title="1">buf := make([]byte, frameLimit)
                n, err := h.conn.Read(buf)
                if err != nil &amp;&amp; err != io.EOF </span><span class="cov0" title="0">{
                        return nil, nil, err
                }</span>
                // If there is nothing to send to the handshaker service, and
                // nothing is received from the peer, then we are stuck.
                // This covers the case when the peer is not responding. Note
                // that handshaker service connection issues are caught in
                // accessHandshakerService before we even get here.
                <span class="cov8" title="1">if len(resp.OutFrames) == 0 &amp;&amp; n == 0 </span><span class="cov8" title="1">{
                        return nil, nil, core.PeerNotRespondingError
                }</span>
                // Append extra bytes from the previous interaction with the
                // handshaker service with the current buffer read from conn.
                <span class="cov8" title="1">p := append(extra, buf[:n]...)
                // From here on, p and extra point to the same slice.
                resp, err = h.accessHandshakerService(&amp;altspb.HandshakerReq{
                        ReqOneof: &amp;altspb.HandshakerReq_Next{
                                Next: &amp;altspb.NextHandshakeMessageReq{
                                        InBytes: p,
                                },
                        },
                })
                if err != nil </span><span class="cov0" title="0">{
                        return nil, nil, err
                }</span>
                // Set extra based on handshaker service response.
                <span class="cov8" title="1">if resp.GetBytesConsumed() &gt; uint32(len(p)) </span><span class="cov0" title="0">{
                        return nil, nil, errOutOfBound
                }</span>
                <span class="cov8" title="1">extra = p[resp.GetBytesConsumed():]</span>
        }
}

// Close terminates the Handshaker. It should be called when the caller obtains
// the secure connection.
func (h *altsHandshaker) Close() <span class="cov8" title="1">{
        h.stream.CloseSend()
}</span>
</pre>
		
		<pre class="file" id="file46" style="display: none">/*
 *
 * Copyright 2018 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package service manages connections between the VM application and the ALTS
// handshaker service.
package service

import (
        "sync"

        grpc "google.golang.org/grpc"
        "google.golang.org/grpc/credentials/insecure"
)

var (
        // mu guards hsConnMap and hsDialer.
        mu sync.Mutex
        // hsConn represents a mapping from a hypervisor handshaker service address
        // to a corresponding connection to a hypervisor handshaker service
        // instance.
        hsConnMap = make(map[string]*grpc.ClientConn)
        // hsDialer will be reassigned in tests.
        hsDialer = grpc.Dial
)

// Dial dials the handshake service in the hypervisor. If a connection has
// already been established, this function returns it. Otherwise, a new
// connection is created.
func Dial(hsAddress string) (*grpc.ClientConn, error) <span class="cov8" title="1">{
        mu.Lock()
        defer mu.Unlock()

        hsConn, ok := hsConnMap[hsAddress]
        if !ok </span><span class="cov8" title="1">{
                // Create a new connection to the handshaker service. Note that
                // this connection stays open until the application is closed.
                var err error
                hsConn, err = hsDialer(hsAddress, grpc.WithTransportCredentials(insecure.NewCredentials()))
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov8" title="1">hsConnMap[hsAddress] = hsConn</span>
        }
        <span class="cov8" title="1">return hsConn, nil</span>
}
</pre>
		
		<pre class="file" id="file47" style="display: none">/*
 *
 * Copyright 2014 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package credentials implements various credentials supported by gRPC library,
// which encapsulate all the state needed by a client to authenticate with a
// server and make various assertions, e.g., about the client's identity, role,
// or whether it is authorized to make a particular call.
package credentials // import "google.golang.org/grpc/credentials"

import (
        "context"
        "errors"
        "fmt"
        "net"

        "github.com/golang/protobuf/proto"
        "google.golang.org/grpc/attributes"
        icredentials "google.golang.org/grpc/internal/credentials"
)

// PerRPCCredentials defines the common interface for the credentials which need to
// attach security information to every RPC (e.g., oauth2).
type PerRPCCredentials interface {
        // GetRequestMetadata gets the current request metadata, refreshing
        // tokens if required. This should be called by the transport layer on
        // each request, and the data should be populated in headers or other
        // context. If a status code is returned, it will be used as the status
        // for the RPC. uri is the URI of the entry point for the request.
        // When supported by the underlying implementation, ctx can be used for
        // timeout and cancellation. Additionally, RequestInfo data will be
        // available via ctx to this call.
        // TODO(zhaoq): Define the set of the qualified keys instead of leaving
        // it as an arbitrary string.
        GetRequestMetadata(ctx context.Context, uri ...string) (map[string]string, error)
        // RequireTransportSecurity indicates whether the credentials requires
        // transport security.
        RequireTransportSecurity() bool
}

// SecurityLevel defines the protection level on an established connection.
//
// This API is experimental.
type SecurityLevel int

const (
        // InvalidSecurityLevel indicates an invalid security level.
        // The zero SecurityLevel value is invalid for backward compatibility.
        InvalidSecurityLevel SecurityLevel = iota
        // NoSecurity indicates a connection is insecure.
        NoSecurity
        // IntegrityOnly indicates a connection only provides integrity protection.
        IntegrityOnly
        // PrivacyAndIntegrity indicates a connection provides both privacy and integrity protection.
        PrivacyAndIntegrity
)

// String returns SecurityLevel in a string format.
func (s SecurityLevel) String() string <span class="cov8" title="1">{
        switch s </span>{
        case NoSecurity:<span class="cov0" title="0">
                return "NoSecurity"</span>
        case IntegrityOnly:<span class="cov8" title="1">
                return "IntegrityOnly"</span>
        case PrivacyAndIntegrity:<span class="cov8" title="1">
                return "PrivacyAndIntegrity"</span>
        }
        <span class="cov0" title="0">return fmt.Sprintf("invalid SecurityLevel: %v", int(s))</span>
}

// CommonAuthInfo contains authenticated information common to AuthInfo implementations.
// It should be embedded in a struct implementing AuthInfo to provide additional information
// about the credentials.
//
// This API is experimental.
type CommonAuthInfo struct {
        SecurityLevel SecurityLevel
}

// GetCommonAuthInfo returns the pointer to CommonAuthInfo struct.
func (c CommonAuthInfo) GetCommonAuthInfo() CommonAuthInfo <span class="cov8" title="1">{
        return c
}</span>

// ProtocolInfo provides information regarding the gRPC wire protocol version,
// security protocol, security protocol version in use, server name, etc.
type ProtocolInfo struct {
        // ProtocolVersion is the gRPC wire protocol version.
        ProtocolVersion string
        // SecurityProtocol is the security protocol in use.
        SecurityProtocol string
        // SecurityVersion is the security protocol version.  It is a static version string from the
        // credentials, not a value that reflects per-connection protocol negotiation.  To retrieve
        // details about the credentials used for a connection, use the Peer's AuthInfo field instead.
        //
        // Deprecated: please use Peer.AuthInfo.
        SecurityVersion string
        // ServerName is the user-configured server name.
        ServerName string
}

// AuthInfo defines the common interface for the auth information the users are interested in.
// A struct that implements AuthInfo should embed CommonAuthInfo by including additional
// information about the credentials in it.
type AuthInfo interface {
        AuthType() string
}

// ErrConnDispatched indicates that rawConn has been dispatched out of gRPC
// and the caller should not close rawConn.
var ErrConnDispatched = errors.New("credentials: rawConn is dispatched out of gRPC")

// TransportCredentials defines the common interface for all the live gRPC wire
// protocols and supported transport security protocols (e.g., TLS, SSL).
type TransportCredentials interface {
        // ClientHandshake does the authentication handshake specified by the
        // corresponding authentication protocol on rawConn for clients. It returns
        // the authenticated connection and the corresponding auth information
        // about the connection.  The auth information should embed CommonAuthInfo
        // to return additional information about the credentials. Implementations
        // must use the provided context to implement timely cancellation.  gRPC
        // will try to reconnect if the error returned is a temporary error
        // (io.EOF, context.DeadlineExceeded or err.Temporary() == true).  If the
        // returned error is a wrapper error, implementations should make sure that
        // the error implements Temporary() to have the correct retry behaviors.
        // Additionally, ClientHandshakeInfo data will be available via the context
        // passed to this call.
        //
        // The second argument to this method is the `:authority` header value used
        // while creating new streams on this connection after authentication
        // succeeds. Implementations must use this as the server name during the
        // authentication handshake.
        //
        // If the returned net.Conn is closed, it MUST close the net.Conn provided.
        ClientHandshake(context.Context, string, net.Conn) (net.Conn, AuthInfo, error)
        // ServerHandshake does the authentication handshake for servers. It returns
        // the authenticated connection and the corresponding auth information about
        // the connection. The auth information should embed CommonAuthInfo to return additional information
        // about the credentials.
        //
        // If the returned net.Conn is closed, it MUST close the net.Conn provided.
        ServerHandshake(net.Conn) (net.Conn, AuthInfo, error)
        // Info provides the ProtocolInfo of this TransportCredentials.
        Info() ProtocolInfo
        // Clone makes a copy of this TransportCredentials.
        Clone() TransportCredentials
        // OverrideServerName specifies the value used for the following:
        // - verifying the hostname on the returned certificates
        // - as SNI in the client's handshake to support virtual hosting
        // - as the value for `:authority` header at stream creation time
        //
        // Deprecated: use grpc.WithAuthority instead. Will be supported
        // throughout 1.x.
        OverrideServerName(string) error
}

// Bundle is a combination of TransportCredentials and PerRPCCredentials.
//
// It also contains a mode switching method, so it can be used as a combination
// of different credential policies.
//
// Bundle cannot be used together with individual TransportCredentials.
// PerRPCCredentials from Bundle will be appended to other PerRPCCredentials.
//
// This API is experimental.
type Bundle interface {
        // TransportCredentials returns the transport credentials from the Bundle.
        //
        // Implementations must return non-nil transport credentials. If transport
        // security is not needed by the Bundle, implementations may choose to
        // return insecure.NewCredentials().
        TransportCredentials() TransportCredentials

        // PerRPCCredentials returns the per-RPC credentials from the Bundle.
        //
        // May be nil if per-RPC credentials are not needed.
        PerRPCCredentials() PerRPCCredentials

        // NewWithMode should make a copy of Bundle, and switch mode. Modifying the
        // existing Bundle may cause races.
        //
        // NewWithMode returns nil if the requested mode is not supported.
        NewWithMode(mode string) (Bundle, error)
}

// RequestInfo contains request data attached to the context passed to GetRequestMetadata calls.
//
// This API is experimental.
type RequestInfo struct {
        // The method passed to Invoke or NewStream for this RPC. (For proto methods, this has the format "/some.Service/Method")
        Method string
        // AuthInfo contains the information from a security handshake (TransportCredentials.ClientHandshake, TransportCredentials.ServerHandshake)
        AuthInfo AuthInfo
}

// RequestInfoFromContext extracts the RequestInfo from the context if it exists.
//
// This API is experimental.
func RequestInfoFromContext(ctx context.Context) (ri RequestInfo, ok bool) <span class="cov0" title="0">{
        ri, ok = icredentials.RequestInfoFromContext(ctx).(RequestInfo)
        return ri, ok
}</span>

// ClientHandshakeInfo holds data to be passed to ClientHandshake. This makes
// it possible to pass arbitrary data to the handshaker from gRPC, resolver,
// balancer etc. Individual credential implementations control the actual
// format of the data that they are willing to receive.
//
// This API is experimental.
type ClientHandshakeInfo struct {
        // Attributes contains the attributes for the address. It could be provided
        // by the gRPC, resolver, balancer etc.
        Attributes *attributes.Attributes
}

// ClientHandshakeInfoFromContext returns the ClientHandshakeInfo struct stored
// in ctx.
//
// This API is experimental.
func ClientHandshakeInfoFromContext(ctx context.Context) ClientHandshakeInfo <span class="cov0" title="0">{
        chi, _ := icredentials.ClientHandshakeInfoFromContext(ctx).(ClientHandshakeInfo)
        return chi
}</span>

// CheckSecurityLevel checks if a connection's security level is greater than or equal to the specified one.
// It returns success if 1) the condition is satisified or 2) AuthInfo struct does not implement GetCommonAuthInfo() method
// or 3) CommonAuthInfo.SecurityLevel has an invalid zero value. For 2) and 3), it is for the purpose of backward-compatibility.
//
// This API is experimental.
func CheckSecurityLevel(ai AuthInfo, level SecurityLevel) error <span class="cov8" title="1">{
        type internalInfo interface {
                GetCommonAuthInfo() CommonAuthInfo
        }
        if ai == nil </span><span class="cov0" title="0">{
                return errors.New("AuthInfo is nil")
        }</span>
        <span class="cov8" title="1">if ci, ok := ai.(internalInfo); ok </span><span class="cov8" title="1">{
                // CommonAuthInfo.SecurityLevel has an invalid value.
                if ci.GetCommonAuthInfo().SecurityLevel == InvalidSecurityLevel </span><span class="cov8" title="1">{
                        return nil
                }</span>
                <span class="cov8" title="1">if ci.GetCommonAuthInfo().SecurityLevel &lt; level </span><span class="cov8" title="1">{
                        return fmt.Errorf("requires SecurityLevel %v; connection has %v", level, ci.GetCommonAuthInfo().SecurityLevel)
                }</span>
        }
        // The condition is satisfied or AuthInfo struct does not implement GetCommonAuthInfo() method.
        <span class="cov8" title="1">return nil</span>
}

// ChannelzSecurityInfo defines the interface that security protocols should implement
// in order to provide security info to channelz.
//
// This API is experimental.
type ChannelzSecurityInfo interface {
        GetSecurityValue() ChannelzSecurityValue
}

// ChannelzSecurityValue defines the interface that GetSecurityValue() return value
// should satisfy. This interface should only be satisfied by *TLSChannelzSecurityValue
// and *OtherChannelzSecurityValue.
//
// This API is experimental.
type ChannelzSecurityValue interface {
        isChannelzSecurityValue()
}

// OtherChannelzSecurityValue defines the struct that non-TLS protocol should return
// from GetSecurityValue(), which contains protocol specific security info. Note
// the Value field will be sent to users of channelz requesting channel info, and
// thus sensitive info should better be avoided.
//
// This API is experimental.
type OtherChannelzSecurityValue struct {
        ChannelzSecurityValue
        Name  string
        Value proto.Message
}
</pre>
		
		<pre class="file" id="file48" style="display: none">/*
 *
 * Copyright 2018 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package google defines credentials for google cloud services.
package google

import (
        "context"
        "fmt"
        "time"

        "google.golang.org/grpc/credentials"
        "google.golang.org/grpc/credentials/alts"
        "google.golang.org/grpc/credentials/oauth"
        "google.golang.org/grpc/grpclog"
        "google.golang.org/grpc/internal"
)

const tokenRequestTimeout = 30 * time.Second

var logger = grpclog.Component("credentials")

// DefaultCredentialsOptions constructs options to build DefaultCredentials.
type DefaultCredentialsOptions struct {
        // PerRPCCreds is a per RPC credentials that is passed to a bundle.
        PerRPCCreds credentials.PerRPCCredentials
}

// NewDefaultCredentialsWithOptions returns a credentials bundle that is
// configured to work with google services.
//
// This API is experimental.
func NewDefaultCredentialsWithOptions(opts DefaultCredentialsOptions) credentials.Bundle <span class="cov8" title="1">{
        if opts.PerRPCCreds == nil </span><span class="cov8" title="1">{
                ctx, cancel := context.WithTimeout(context.Background(), tokenRequestTimeout)
                defer cancel()
                var err error
                opts.PerRPCCreds, err = newADC(ctx)
                if err != nil </span><span class="cov0" title="0">{
                        logger.Warningf("NewDefaultCredentialsWithOptions: failed to create application oauth: %v", err)
                }</span>
        }
        <span class="cov8" title="1">c := &amp;creds{opts: opts}
        bundle, err := c.NewWithMode(internal.CredsBundleModeFallback)
        if err != nil </span><span class="cov0" title="0">{
                logger.Warningf("NewDefaultCredentialsWithOptions: failed to create new creds: %v", err)
        }</span>
        <span class="cov8" title="1">return bundle</span>
}

// NewDefaultCredentials returns a credentials bundle that is configured to work
// with google services.
//
// This API is experimental.
func NewDefaultCredentials() credentials.Bundle <span class="cov8" title="1">{
        return NewDefaultCredentialsWithOptions(DefaultCredentialsOptions{})
}</span>

// NewComputeEngineCredentials returns a credentials bundle that is configured to work
// with google services. This API must only be used when running on GCE. Authentication configured
// by this API represents the GCE VM's default service account.
//
// This API is experimental.
func NewComputeEngineCredentials() credentials.Bundle <span class="cov8" title="1">{
        return NewDefaultCredentialsWithOptions(DefaultCredentialsOptions{
                PerRPCCreds: oauth.NewComputeEngine(),
        })
}</span>

// creds implements credentials.Bundle.
type creds struct {
        opts DefaultCredentialsOptions

        // Supported modes are defined in internal/internal.go.
        mode string
        // The active transport credentials associated with this bundle.
        transportCreds credentials.TransportCredentials
        // The active per RPC credentials associated with this bundle.
        perRPCCreds credentials.PerRPCCredentials
}

func (c *creds) TransportCredentials() credentials.TransportCredentials <span class="cov8" title="1">{
        return c.transportCreds
}</span>

func (c *creds) PerRPCCredentials() credentials.PerRPCCredentials <span class="cov0" title="0">{
        if c == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">return c.perRPCCreds</span>
}

var (
        newTLS = func() credentials.TransportCredentials <span class="cov0" title="0">{
                return credentials.NewTLS(nil)
        }</span>
        newALTS = func() credentials.TransportCredentials <span class="cov0" title="0">{
                return alts.NewClientCreds(alts.DefaultClientOptions())
        }</span>
        newADC = func(ctx context.Context) (credentials.PerRPCCredentials, error) <span class="cov0" title="0">{
                return oauth.NewApplicationDefault(ctx)
        }</span>
)

// NewWithMode should make a copy of Bundle, and switch mode. Modifying the
// existing Bundle may cause races.
func (c *creds) NewWithMode(mode string) (credentials.Bundle, error) <span class="cov8" title="1">{
        newCreds := &amp;creds{
                opts: c.opts,
                mode: mode,
        }

        // Create transport credentials.
        switch mode </span>{
        case internal.CredsBundleModeFallback:<span class="cov8" title="1">
                newCreds.transportCreds = newClusterTransportCreds(newTLS(), newALTS())</span>
        case internal.CredsBundleModeBackendFromBalancer, internal.CredsBundleModeBalancer:<span class="cov0" title="0">
                // Only the clients can use google default credentials, so we only need
                // to create new ALTS client creds here.
                newCreds.transportCreds = newALTS()</span>
        default:<span class="cov0" title="0">
                return nil, fmt.Errorf("unsupported mode: %v", mode)</span>
        }

        <span class="cov8" title="1">if mode == internal.CredsBundleModeFallback || mode == internal.CredsBundleModeBackendFromBalancer </span><span class="cov8" title="1">{
                newCreds.perRPCCreds = newCreds.opts.PerRPCCreds
        }</span>

        <span class="cov8" title="1">return newCreds, nil</span>
}
</pre>
		
		<pre class="file" id="file49" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package google

import (
        "context"
        "net"
        "net/url"
        "strings"

        "google.golang.org/grpc/credentials"
        "google.golang.org/grpc/internal"
)

const cfeClusterNamePrefix = "google_cfe_"
const cfeClusterResourceNamePrefix = "/envoy.config.cluster.v3.Cluster/google_cfe_"
const cfeClusterAuthorityName = "traffic-director-c2p.xds.googleapis.com"

// clusterTransportCreds is a combo of TLS + ALTS.
//
// On the client, ClientHandshake picks TLS or ALTS based on address attributes.
// - if attributes has cluster name
//   - if cluster name has prefix "google_cfe_", or
//     "xdstp://traffic-director-c2p.xds.googleapis.com/envoy.config.cluster.v3.Cluster/google_cfe_",
//     use TLS
//   - otherwise, use ALTS
// - else, do TLS
//
// On the server, ServerHandshake always does TLS.
type clusterTransportCreds struct {
        tls  credentials.TransportCredentials
        alts credentials.TransportCredentials
}

func newClusterTransportCreds(tls, alts credentials.TransportCredentials) *clusterTransportCreds <span class="cov8" title="1">{
        return &amp;clusterTransportCreds{
                tls:  tls,
                alts: alts,
        }
}</span>

// clusterName returns the xDS cluster name stored in the attributes in the
// context.
func clusterName(ctx context.Context) string <span class="cov8" title="1">{
        chi := credentials.ClientHandshakeInfoFromContext(ctx)
        if chi.Attributes == nil </span><span class="cov8" title="1">{
                return ""
        }</span>
        <span class="cov8" title="1">cluster, _ := internal.GetXDSHandshakeClusterName(chi.Attributes)
        return cluster</span>
}

// isDirectPathCluster returns true if the cluster in the context is a
// directpath cluster, meaning ALTS should be used.
func isDirectPathCluster(ctx context.Context) bool <span class="cov8" title="1">{
        cluster := clusterName(ctx)
        if cluster == "" </span><span class="cov8" title="1">{
                // No cluster; not xDS; use TLS.
                return false
        }</span>
        <span class="cov8" title="1">if strings.HasPrefix(cluster, cfeClusterNamePrefix) </span><span class="cov8" title="1">{
                // xDS cluster prefixed by "google_cfe_"; use TLS.
                return false
        }</span>
        <span class="cov8" title="1">if !strings.HasPrefix(cluster, "xdstp:") </span><span class="cov8" title="1">{
                // Other xDS cluster name; use ALTS.
                return true
        }</span>
        <span class="cov8" title="1">u, err := url.Parse(cluster)
        if err != nil </span><span class="cov0" title="0">{
                // Shouldn't happen, but assume ALTS.
                return true
        }</span>
        // If authority AND path match our CFE checks, use TLS; otherwise use ALTS.
        <span class="cov8" title="1">return u.Host != cfeClusterAuthorityName || !strings.HasPrefix(u.Path, cfeClusterResourceNamePrefix)</span>
}

func (c *clusterTransportCreds) ClientHandshake(ctx context.Context, authority string, rawConn net.Conn) (net.Conn, credentials.AuthInfo, error) <span class="cov8" title="1">{
        if isDirectPathCluster(ctx) </span><span class="cov8" title="1">{
                // If attributes have cluster name, and cluster name is not cfe, it's a
                // backend address, use ALTS.
                return c.alts.ClientHandshake(ctx, authority, rawConn)
        }</span>
        <span class="cov8" title="1">return c.tls.ClientHandshake(ctx, authority, rawConn)</span>
}

func (c *clusterTransportCreds) ServerHandshake(conn net.Conn) (net.Conn, credentials.AuthInfo, error) <span class="cov8" title="1">{
        return c.tls.ServerHandshake(conn)
}</span>

func (c *clusterTransportCreds) Info() credentials.ProtocolInfo <span class="cov0" title="0">{
        // TODO: this always returns tls.Info now, because we don't have a cluster
        // name to check when this method is called. This method doesn't affect
        // anything important now. We may want to revisit this if it becomes more
        // important later.
        return c.tls.Info()
}</span>

func (c *clusterTransportCreds) Clone() credentials.TransportCredentials <span class="cov0" title="0">{
        return &amp;clusterTransportCreds{
                tls:  c.tls.Clone(),
                alts: c.alts.Clone(),
        }
}</span>

func (c *clusterTransportCreds) OverrideServerName(s string) error <span class="cov0" title="0">{
        if err := c.tls.OverrideServerName(s); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov0" title="0">return c.alts.OverrideServerName(s)</span>
}
</pre>
		
		<pre class="file" id="file50" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package local implements local transport credentials.
// Local credentials reports the security level based on the type
// of connetion. If the connection is local TCP, NoSecurity will be
// reported, and if the connection is UDS, PrivacyAndIntegrity will be
// reported. If local credentials is not used in local connections
// (local TCP or UDS), it will fail.
//
// Experimental
//
// Notice: This package is EXPERIMENTAL and may be changed or removed in a
// later release.
package local

import (
        "context"
        "fmt"
        "net"
        "strings"

        "google.golang.org/grpc/credentials"
)

// info contains the auth information for a local connection.
// It implements the AuthInfo interface.
type info struct {
        credentials.CommonAuthInfo
}

// AuthType returns the type of info as a string.
func (info) AuthType() string <span class="cov0" title="0">{
        return "local"
}</span>

// localTC is the credentials required to establish a local connection.
type localTC struct {
        info credentials.ProtocolInfo
}

func (c *localTC) Info() credentials.ProtocolInfo <span class="cov0" title="0">{
        return c.info
}</span>

// getSecurityLevel returns the security level for a local connection.
// It returns an error if a connection is not local.
func getSecurityLevel(network, addr string) (credentials.SecurityLevel, error) <span class="cov8" title="1">{
        switch </span>{
        // Local TCP connection
        case strings.HasPrefix(addr, "127."), strings.HasPrefix(addr, "[::1]:"):<span class="cov8" title="1">
                return credentials.NoSecurity, nil</span>
        // UDS connection
        case network == "unix":<span class="cov8" title="1">
                return credentials.PrivacyAndIntegrity, nil</span>
        // Not a local connection and should fail
        default:<span class="cov8" title="1">
                return credentials.InvalidSecurityLevel, fmt.Errorf("local credentials rejected connection to non-local address %q", addr)</span>
        }
}

func (*localTC) ClientHandshake(ctx context.Context, authority string, conn net.Conn) (net.Conn, credentials.AuthInfo, error) <span class="cov8" title="1">{
        secLevel, err := getSecurityLevel(conn.RemoteAddr().Network(), conn.RemoteAddr().String())
        if err != nil </span><span class="cov0" title="0">{
                return nil, nil, err
        }</span>
        <span class="cov8" title="1">return conn, info{credentials.CommonAuthInfo{SecurityLevel: secLevel}}, nil</span>
}

func (*localTC) ServerHandshake(conn net.Conn) (net.Conn, credentials.AuthInfo, error) <span class="cov8" title="1">{
        secLevel, err := getSecurityLevel(conn.RemoteAddr().Network(), conn.RemoteAddr().String())
        if err != nil </span><span class="cov0" title="0">{
                return nil, nil, err
        }</span>
        <span class="cov8" title="1">return conn, info{credentials.CommonAuthInfo{SecurityLevel: secLevel}}, nil</span>
}

// NewCredentials returns a local credential implementing credentials.TransportCredentials.
func NewCredentials() credentials.TransportCredentials <span class="cov8" title="1">{
        return &amp;localTC{
                info: credentials.ProtocolInfo{
                        SecurityProtocol: "local",
                },
        }
}</span>

// Clone makes a copy of Local credentials.
func (c *localTC) Clone() credentials.TransportCredentials <span class="cov0" title="0">{
        return &amp;localTC{info: c.info}
}</span>

// OverrideServerName overrides the server name used to verify the hostname on the returned certificates from the server.
// Since this feature is specific to TLS (SNI + hostname verification check), it does not take any effet for local credentials.
func (c *localTC) OverrideServerName(serverNameOverride string) error <span class="cov0" title="0">{
        c.info.ServerName = serverNameOverride
        return nil
}</span>
</pre>
		
		<pre class="file" id="file51" style="display: none">/*
 *
 * Copyright 2015 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package oauth implements gRPC credentials using OAuth.
package oauth

import (
        "context"
        "fmt"
        "io/ioutil"
        "net/url"
        "sync"

        "golang.org/x/oauth2"
        "golang.org/x/oauth2/google"
        "golang.org/x/oauth2/jwt"
        "google.golang.org/grpc/credentials"
)

// TokenSource supplies PerRPCCredentials from an oauth2.TokenSource.
type TokenSource struct {
        oauth2.TokenSource
}

// GetRequestMetadata gets the request metadata as a map from a TokenSource.
func (ts TokenSource) GetRequestMetadata(ctx context.Context, uri ...string) (map[string]string, error) <span class="cov0" title="0">{
        token, err := ts.Token()
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">ri, _ := credentials.RequestInfoFromContext(ctx)
        if err = credentials.CheckSecurityLevel(ri.AuthInfo, credentials.PrivacyAndIntegrity); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("unable to transfer TokenSource PerRPCCredentials: %v", err)
        }</span>
        <span class="cov0" title="0">return map[string]string{
                "authorization": token.Type() + " " + token.AccessToken,
        }, nil</span>
}

// RequireTransportSecurity indicates whether the credentials requires transport security.
func (ts TokenSource) RequireTransportSecurity() bool <span class="cov0" title="0">{
        return true
}</span>

// removeServiceNameFromJWTURI removes RPC service name from URI.
func removeServiceNameFromJWTURI(uri string) (string, error) <span class="cov8" title="1">{
        parsed, err := url.Parse(uri)
        if err != nil </span><span class="cov8" title="1">{
                return "", err
        }</span>
        <span class="cov8" title="1">parsed.Path = "/"
        return parsed.String(), nil</span>
}

type jwtAccess struct {
        jsonKey []byte
}

// NewJWTAccessFromFile creates PerRPCCredentials from the given keyFile.
func NewJWTAccessFromFile(keyFile string) (credentials.PerRPCCredentials, error) <span class="cov0" title="0">{
        jsonKey, err := ioutil.ReadFile(keyFile)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("credentials: failed to read the service account key file: %v", err)
        }</span>
        <span class="cov0" title="0">return NewJWTAccessFromKey(jsonKey)</span>
}

// NewJWTAccessFromKey creates PerRPCCredentials from the given jsonKey.
func NewJWTAccessFromKey(jsonKey []byte) (credentials.PerRPCCredentials, error) <span class="cov0" title="0">{
        return jwtAccess{jsonKey}, nil
}</span>

func (j jwtAccess) GetRequestMetadata(ctx context.Context, uri ...string) (map[string]string, error) <span class="cov0" title="0">{
        // Remove RPC service name from URI that will be used as audience
        // in a self-signed JWT token. It follows https://google.aip.dev/auth/4111.
        aud, err := removeServiceNameFromJWTURI(uri[0])
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        // TODO: the returned TokenSource is reusable. Store it in a sync.Map, with
        // uri as the key, to avoid recreating for every RPC.
        <span class="cov0" title="0">ts, err := google.JWTAccessTokenSourceFromJSON(j.jsonKey, aud)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">token, err := ts.Token()
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">ri, _ := credentials.RequestInfoFromContext(ctx)
        if err = credentials.CheckSecurityLevel(ri.AuthInfo, credentials.PrivacyAndIntegrity); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("unable to transfer jwtAccess PerRPCCredentials: %v", err)
        }</span>
        <span class="cov0" title="0">return map[string]string{
                "authorization": token.Type() + " " + token.AccessToken,
        }, nil</span>
}

func (j jwtAccess) RequireTransportSecurity() bool <span class="cov0" title="0">{
        return true
}</span>

// oauthAccess supplies PerRPCCredentials from a given token.
type oauthAccess struct {
        token oauth2.Token
}

// NewOauthAccess constructs the PerRPCCredentials using a given token.
func NewOauthAccess(token *oauth2.Token) credentials.PerRPCCredentials <span class="cov0" title="0">{
        return oauthAccess{token: *token}
}</span>

func (oa oauthAccess) GetRequestMetadata(ctx context.Context, uri ...string) (map[string]string, error) <span class="cov0" title="0">{
        ri, _ := credentials.RequestInfoFromContext(ctx)
        if err := credentials.CheckSecurityLevel(ri.AuthInfo, credentials.PrivacyAndIntegrity); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("unable to transfer oauthAccess PerRPCCredentials: %v", err)
        }</span>
        <span class="cov0" title="0">return map[string]string{
                "authorization": oa.token.Type() + " " + oa.token.AccessToken,
        }, nil</span>
}

func (oa oauthAccess) RequireTransportSecurity() bool <span class="cov0" title="0">{
        return true
}</span>

// NewComputeEngine constructs the PerRPCCredentials that fetches access tokens from
// Google Compute Engine (GCE)'s metadata server. It is only valid to use this
// if your program is running on a GCE instance.
// TODO(dsymonds): Deprecate and remove this.
func NewComputeEngine() credentials.PerRPCCredentials <span class="cov0" title="0">{
        return TokenSource{google.ComputeTokenSource("")}
}</span>

// serviceAccount represents PerRPCCredentials via JWT signing key.
type serviceAccount struct {
        mu     sync.Mutex
        config *jwt.Config
        t      *oauth2.Token
}

func (s *serviceAccount) GetRequestMetadata(ctx context.Context, uri ...string) (map[string]string, error) <span class="cov0" title="0">{
        s.mu.Lock()
        defer s.mu.Unlock()
        if !s.t.Valid() </span><span class="cov0" title="0">{
                var err error
                s.t, err = s.config.TokenSource(ctx).Token()
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
        }
        <span class="cov0" title="0">ri, _ := credentials.RequestInfoFromContext(ctx)
        if err := credentials.CheckSecurityLevel(ri.AuthInfo, credentials.PrivacyAndIntegrity); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("unable to transfer serviceAccount PerRPCCredentials: %v", err)
        }</span>
        <span class="cov0" title="0">return map[string]string{
                "authorization": s.t.Type() + " " + s.t.AccessToken,
        }, nil</span>
}

func (s *serviceAccount) RequireTransportSecurity() bool <span class="cov0" title="0">{
        return true
}</span>

// NewServiceAccountFromKey constructs the PerRPCCredentials using the JSON key slice
// from a Google Developers service account.
func NewServiceAccountFromKey(jsonKey []byte, scope ...string) (credentials.PerRPCCredentials, error) <span class="cov0" title="0">{
        config, err := google.JWTConfigFromJSON(jsonKey, scope...)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">return &amp;serviceAccount{config: config}, nil</span>
}

// NewServiceAccountFromFile constructs the PerRPCCredentials using the JSON key file
// of a Google Developers service account.
func NewServiceAccountFromFile(keyFile string, scope ...string) (credentials.PerRPCCredentials, error) <span class="cov0" title="0">{
        jsonKey, err := ioutil.ReadFile(keyFile)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("credentials: failed to read the service account key file: %v", err)
        }</span>
        <span class="cov0" title="0">return NewServiceAccountFromKey(jsonKey, scope...)</span>
}

// NewApplicationDefault returns "Application Default Credentials". For more
// detail, see https://developers.google.com/accounts/docs/application-default-credentials.
func NewApplicationDefault(ctx context.Context, scope ...string) (credentials.PerRPCCredentials, error) <span class="cov0" title="0">{
        creds, err := google.FindDefaultCredentials(ctx, scope...)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        // If JSON is nil, the authentication is provided by the environment and not
        // with a credentials file, e.g. when code is running on Google Cloud
        // Platform. Use the returned token source.
        <span class="cov0" title="0">if creds.JSON == nil </span><span class="cov0" title="0">{
                return TokenSource{creds.TokenSource}, nil
        }</span>

        // If auth is provided by env variable or creds file, the behavior will be
        // different based on whether scope is set. Because the returned
        // creds.TokenSource does oauth with jwt by default, and it requires scope.
        // We can only use it if scope is not empty, otherwise it will fail with
        // missing scope error.
        //
        // If scope is set, use it, it should just work.
        //
        // If scope is not set, we try to use jwt directly without oauth (this only
        // works if it's a service account).

        <span class="cov0" title="0">if len(scope) != 0 </span><span class="cov0" title="0">{
                return TokenSource{creds.TokenSource}, nil
        }</span>

        // Try to convert JSON to a jwt config without setting the optional scope
        // parameter to check if it's a service account (the function errors if it's
        // not). This is necessary because the returned config doesn't show the type
        // of the account.
        <span class="cov0" title="0">if _, err := google.JWTConfigFromJSON(creds.JSON); err != nil </span><span class="cov0" title="0">{
                // If this fails, it's not a service account, return the original
                // TokenSource from above.
                return TokenSource{creds.TokenSource}, nil
        }</span>

        // If it's a service account, create a JWT only access with the key.
        <span class="cov0" title="0">return NewJWTAccessFromKey(creds.JSON)</span>
}
</pre>
		
		<pre class="file" id="file52" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package sts implements call credentials using STS (Security Token Service) as
// defined in https://tools.ietf.org/html/rfc8693.
//
// Experimental
//
// Notice: All APIs in this package are experimental and may be changed or
// removed in a later release.
package sts

import (
        "bytes"
        "context"
        "crypto/tls"
        "crypto/x509"
        "encoding/json"
        "errors"
        "fmt"
        "io/ioutil"
        "net/http"
        "net/url"
        "sync"
        "time"

        "google.golang.org/grpc/credentials"
        "google.golang.org/grpc/grpclog"
)

const (
        // HTTP request timeout set on the http.Client used to make STS requests.
        stsRequestTimeout = 5 * time.Second
        // If lifetime left in a cached token is lesser than this value, we fetch a
        // new one instead of returning the current one.
        minCachedTokenLifetime = 300 * time.Second

        tokenExchangeGrantType    = "urn:ietf:params:oauth:grant-type:token-exchange"
        defaultCloudPlatformScope = "https://www.googleapis.com/auth/cloud-platform"
)

// For overriding in tests.
var (
        loadSystemCertPool   = x509.SystemCertPool
        makeHTTPDoer         = makeHTTPClient
        readSubjectTokenFrom = ioutil.ReadFile
        readActorTokenFrom   = ioutil.ReadFile
        logger               = grpclog.Component("credentials")
)

// Options configures the parameters used for an STS based token exchange.
type Options struct {
        // TokenExchangeServiceURI is the address of the server which implements STS
        // token exchange functionality.
        TokenExchangeServiceURI string // Required.

        // Resource is a URI that indicates the target service or resource where the
        // client intends to use the requested security token.
        Resource string // Optional.

        // Audience is the logical name of the target service where the client
        // intends to use the requested security token
        Audience string // Optional.

        // Scope is a list of space-delimited, case-sensitive strings, that allow
        // the client to specify the desired scope of the requested security token
        // in the context of the service or resource where the token will be used.
        // If this field is left unspecified, a default value of
        // https://www.googleapis.com/auth/cloud-platform will be used.
        Scope string // Optional.

        // RequestedTokenType is an identifier, as described in
        // https://tools.ietf.org/html/rfc8693#section-3, that indicates the type of
        // the requested security token.
        RequestedTokenType string // Optional.

        // SubjectTokenPath is a filesystem path which contains the security token
        // that represents the identity of the party on behalf of whom the request
        // is being made.
        SubjectTokenPath string // Required.

        // SubjectTokenType is an identifier, as described in
        // https://tools.ietf.org/html/rfc8693#section-3, that indicates the type of
        // the security token in the "subject_token_path" parameter.
        SubjectTokenType string // Required.

        // ActorTokenPath is a  security token that represents the identity of the
        // acting party.
        ActorTokenPath string // Optional.

        // ActorTokenType is an identifier, as described in
        // https://tools.ietf.org/html/rfc8693#section-3, that indicates the type of
        // the the security token in the "actor_token_path" parameter.
        ActorTokenType string // Optional.
}

func (o Options) String() string <span class="cov0" title="0">{
        return fmt.Sprintf("%s:%s:%s:%s:%s:%s:%s:%s:%s", o.TokenExchangeServiceURI, o.Resource, o.Audience, o.Scope, o.RequestedTokenType, o.SubjectTokenPath, o.SubjectTokenType, o.ActorTokenPath, o.ActorTokenType)
}</span>

// NewCredentials returns a new PerRPCCredentials implementation, configured
// using opts, which performs token exchange using STS.
func NewCredentials(opts Options) (credentials.PerRPCCredentials, error) <span class="cov8" title="1">{
        if err := validateOptions(opts); err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>

        // Load the system roots to validate the certificate presented by the STS
        // endpoint during the TLS handshake.
        <span class="cov8" title="1">roots, err := loadSystemCertPool()
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>

        <span class="cov8" title="1">return &amp;callCreds{
                opts:   opts,
                client: makeHTTPDoer(roots),
        }, nil</span>
}

// callCreds provides the implementation of call credentials based on an STS
// token exchange.
type callCreds struct {
        opts   Options
        client httpDoer

        // Cached accessToken to avoid an STS token exchange for every call to
        // GetRequestMetadata.
        mu            sync.Mutex
        tokenMetadata map[string]string
        tokenExpiry   time.Time
}

// GetRequestMetadata returns the cached accessToken, if available and valid, or
// fetches a new one by performing an STS token exchange.
func (c *callCreds) GetRequestMetadata(ctx context.Context, _ ...string) (map[string]string, error) <span class="cov8" title="1">{
        ri, _ := credentials.RequestInfoFromContext(ctx)
        if err := credentials.CheckSecurityLevel(ri.AuthInfo, credentials.PrivacyAndIntegrity); err != nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("unable to transfer STS PerRPCCredentials: %v", err)
        }</span>

        // Holding the lock for the whole duration of the STS request and response
        // processing ensures that concurrent RPCs don't end up in multiple
        // requests being made.
        <span class="cov8" title="1">c.mu.Lock()
        defer c.mu.Unlock()

        if md := c.cachedMetadata(); md != nil </span><span class="cov8" title="1">{
                return md, nil
        }</span>
        <span class="cov8" title="1">req, err := constructRequest(ctx, c.opts)
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">respBody, err := sendRequest(c.client, req)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">ti, err := tokenInfoFromResponse(respBody)
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">c.tokenMetadata = map[string]string{"Authorization": fmt.Sprintf("%s %s", ti.tokenType, ti.token)}
        c.tokenExpiry = ti.expiryTime
        return c.tokenMetadata, nil</span>
}

// RequireTransportSecurity indicates whether the credentials requires
// transport security.
func (c *callCreds) RequireTransportSecurity() bool <span class="cov8" title="1">{
        return true
}</span>

// httpDoer wraps the single method on the http.Client type that we use. This
// helps with overriding in unittests.
type httpDoer interface {
        Do(req *http.Request) (*http.Response, error)
}

func makeHTTPClient(roots *x509.CertPool) httpDoer <span class="cov8" title="1">{
        return &amp;http.Client{
                Timeout: stsRequestTimeout,
                Transport: &amp;http.Transport{
                        TLSClientConfig: &amp;tls.Config{
                                RootCAs: roots,
                        },
                },
        }
}</span>

// validateOptions performs the following validation checks on opts:
// - tokenExchangeServiceURI is not empty
// - tokenExchangeServiceURI is a valid URI with a http(s) scheme
// - subjectTokenPath and subjectTokenType are not empty.
func validateOptions(opts Options) error <span class="cov8" title="1">{
        if opts.TokenExchangeServiceURI == "" </span><span class="cov8" title="1">{
                return errors.New("empty token_exchange_service_uri in options")
        }</span>
        <span class="cov8" title="1">u, err := url.Parse(opts.TokenExchangeServiceURI)
        if err != nil </span><span class="cov8" title="1">{
                return err
        }</span>
        <span class="cov8" title="1">if u.Scheme != "http" &amp;&amp; u.Scheme != "https" </span><span class="cov8" title="1">{
                return fmt.Errorf("scheme is not supported: %q. Only http(s) is supported", u.Scheme)
        }</span>

        <span class="cov8" title="1">if opts.SubjectTokenPath == "" </span><span class="cov8" title="1">{
                return errors.New("required field SubjectTokenPath is not specified")
        }</span>
        <span class="cov8" title="1">if opts.SubjectTokenType == "" </span><span class="cov8" title="1">{
                return errors.New("required field SubjectTokenType is not specified")
        }</span>
        <span class="cov8" title="1">return nil</span>
}

// cachedMetadata returns the cached metadata provided it is not going to
// expire anytime soon.
//
// Caller must hold c.mu.
func (c *callCreds) cachedMetadata() map[string]string <span class="cov8" title="1">{
        now := time.Now()
        // If the cached token has not expired and the lifetime remaining on that
        // token is greater than the minimum value we are willing to accept, go
        // ahead and use it.
        if c.tokenExpiry.After(now) &amp;&amp; c.tokenExpiry.Sub(now) &gt; minCachedTokenLifetime </span><span class="cov8" title="1">{
                return c.tokenMetadata
        }</span>
        <span class="cov8" title="1">return nil</span>
}

// constructRequest creates the STS request body in JSON based on the provided
// options.
// - Contents of the subjectToken are read from the file specified in
//   options. If we encounter an error here, we bail out.
// - Contents of the actorToken are read from the file specified in options.
//   If we encounter an error here, we ignore this field because this is
//   optional.
// - Most of the other fields in the request come directly from options.
//
// A new HTTP request is created by calling http.NewRequestWithContext() and
// passing the provided context, thereby enforcing any timeouts specified in
// the latter.
func constructRequest(ctx context.Context, opts Options) (*http.Request, error) <span class="cov8" title="1">{
        subToken, err := readSubjectTokenFrom(opts.SubjectTokenPath)
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">reqScope := opts.Scope
        if reqScope == "" </span><span class="cov8" title="1">{
                reqScope = defaultCloudPlatformScope
        }</span>
        <span class="cov8" title="1">reqParams := &amp;requestParameters{
                GrantType:          tokenExchangeGrantType,
                Resource:           opts.Resource,
                Audience:           opts.Audience,
                Scope:              reqScope,
                RequestedTokenType: opts.RequestedTokenType,
                SubjectToken:       string(subToken),
                SubjectTokenType:   opts.SubjectTokenType,
        }
        if opts.ActorTokenPath != "" </span><span class="cov8" title="1">{
                actorToken, err := readActorTokenFrom(opts.ActorTokenPath)
                if err != nil </span><span class="cov8" title="1">{
                        return nil, err
                }</span>
                <span class="cov8" title="1">reqParams.ActorToken = string(actorToken)
                reqParams.ActorTokenType = opts.ActorTokenType</span>
        }
        <span class="cov8" title="1">jsonBody, err := json.Marshal(reqParams)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">req, err := http.NewRequestWithContext(ctx, "POST", opts.TokenExchangeServiceURI, bytes.NewBuffer(jsonBody))
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create http request: %v", err)
        }</span>
        <span class="cov8" title="1">req.Header.Set("Content-Type", "application/json")
        return req, nil</span>
}

func sendRequest(client httpDoer, req *http.Request) ([]byte, error) <span class="cov8" title="1">{
        // http.Client returns a non-nil error only if it encounters an error
        // caused by client policy (such as CheckRedirect), or failure to speak
        // HTTP (such as a network connectivity problem). A non-2xx status code
        // doesn't cause an error.
        resp, err := client.Do(req)
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>

        // When the http.Client returns a non-nil error, it is the
        // responsibility of the caller to read the response body till an EOF is
        // encountered and to close it.
        <span class="cov8" title="1">body, err := ioutil.ReadAll(resp.Body)
        resp.Body.Close()
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>

        <span class="cov8" title="1">if resp.StatusCode == http.StatusOK </span><span class="cov8" title="1">{
                return body, nil
        }</span>
        <span class="cov8" title="1">logger.Warningf("http status %d, body: %s", resp.StatusCode, string(body))
        return nil, fmt.Errorf("http status %d, body: %s", resp.StatusCode, string(body))</span>
}

func tokenInfoFromResponse(respBody []byte) (*tokenInfo, error) <span class="cov8" title="1">{
        respData := &amp;responseParameters{}
        if err := json.Unmarshal(respBody, respData); err != nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("json.Unmarshal(%v): %v", respBody, err)
        }</span>
        <span class="cov8" title="1">if respData.AccessToken == "" </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("empty accessToken in response (%v)", string(respBody))
        }</span>
        <span class="cov8" title="1">return &amp;tokenInfo{
                tokenType:  respData.TokenType,
                token:      respData.AccessToken,
                expiryTime: time.Now().Add(time.Duration(respData.ExpiresIn) * time.Second),
        }, nil</span>
}

// requestParameters stores all STS request attributes defined in
// https://tools.ietf.org/html/rfc8693#section-2.1.
type requestParameters struct {
        // REQUIRED. The value "urn:ietf:params:oauth:grant-type:token-exchange"
        // indicates that a token exchange is being performed.
        GrantType string `json:"grant_type"`
        // OPTIONAL. Indicates the location of the target service or resource where
        // the client intends to use the requested security token.
        Resource string `json:"resource,omitempty"`
        // OPTIONAL. The logical name of the target service where the client intends
        // to use the requested security token.
        Audience string `json:"audience,omitempty"`
        // OPTIONAL. A list of space-delimited, case-sensitive strings, that allow
        // the client to specify the desired scope of the requested security token
        // in the context of the service or Resource where the token will be used.
        Scope string `json:"scope,omitempty"`
        // OPTIONAL. An identifier, for the type of the requested security token.
        RequestedTokenType string `json:"requested_token_type,omitempty"`
        // REQUIRED. A security token that represents the identity of the party on
        // behalf of whom the request is being made.
        SubjectToken string `json:"subject_token"`
        // REQUIRED. An identifier, that indicates the type of the security token in
        // the "subject_token" parameter.
        SubjectTokenType string `json:"subject_token_type"`
        // OPTIONAL. A security token that represents the identity of the acting
        // party.
        ActorToken string `json:"actor_token,omitempty"`
        // An identifier, that indicates the type of the security token in the
        // "actor_token" parameter.
        ActorTokenType string `json:"actor_token_type,omitempty"`
}

// nesponseParameters stores all attributes sent as JSON in a successful STS
// response. These attributes are defined in
// https://tools.ietf.org/html/rfc8693#section-2.2.1.
type responseParameters struct {
        // REQUIRED. The security token issued by the authorization server
        // in response to the token exchange request.
        AccessToken string `json:"access_token"`
        // REQUIRED. An identifier, representation of the issued security token.
        IssuedTokenType string `json:"issued_token_type"`
        // REQUIRED. A case-insensitive value specifying the method of using the access
        // token issued. It provides the client with information about how to utilize the
        // access token to access protected resources.
        TokenType string `json:"token_type"`
        // RECOMMENDED. The validity lifetime, in seconds, of the token issued by the
        // authorization server.
        ExpiresIn int64 `json:"expires_in"`
        // OPTIONAL, if the Scope of the issued security token is identical to the
        // Scope requested by the client; otherwise, REQUIRED.
        Scope string `json:"scope"`
        // OPTIONAL. A refresh token will typically not be issued when the exchange is
        // of one temporary credential (the subject_token) for a different temporary
        // credential (the issued token) for use in some other context.
        RefreshToken string `json:"refresh_token"`
}

// tokenInfo wraps the information received in a successful STS response.
type tokenInfo struct {
        tokenType  string
        token      string
        expiryTime time.Time
}
</pre>
		
		<pre class="file" id="file53" style="display: none">/*
 *
 * Copyright 2014 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package credentials

import (
        "context"
        "crypto/tls"
        "crypto/x509"
        "fmt"
        "io/ioutil"
        "net"
        "net/url"

        credinternal "google.golang.org/grpc/internal/credentials"
)

// TLSInfo contains the auth information for a TLS authenticated connection.
// It implements the AuthInfo interface.
type TLSInfo struct {
        State tls.ConnectionState
        CommonAuthInfo
        // This API is experimental.
        SPIFFEID *url.URL
}

// AuthType returns the type of TLSInfo as a string.
func (t TLSInfo) AuthType() string <span class="cov8" title="1">{
        return "tls"
}</span>

// GetSecurityValue returns security info requested by channelz.
func (t TLSInfo) GetSecurityValue() ChannelzSecurityValue <span class="cov0" title="0">{
        v := &amp;TLSChannelzSecurityValue{
                StandardName: cipherSuiteLookup[t.State.CipherSuite],
        }
        // Currently there's no way to get LocalCertificate info from tls package.
        if len(t.State.PeerCertificates) &gt; 0 </span><span class="cov0" title="0">{
                v.RemoteCertificate = t.State.PeerCertificates[0].Raw
        }</span>
        <span class="cov0" title="0">return v</span>
}

// tlsCreds is the credentials required for authenticating a connection using TLS.
type tlsCreds struct {
        // TLS configuration
        config *tls.Config
}

func (c tlsCreds) Info() ProtocolInfo <span class="cov8" title="1">{
        return ProtocolInfo{
                SecurityProtocol: "tls",
                SecurityVersion:  "1.2",
                ServerName:       c.config.ServerName,
        }
}</span>

func (c *tlsCreds) ClientHandshake(ctx context.Context, authority string, rawConn net.Conn) (_ net.Conn, _ AuthInfo, err error) <span class="cov8" title="1">{
        // use local cfg to avoid clobbering ServerName if using multiple endpoints
        cfg := credinternal.CloneTLSConfig(c.config)
        if cfg.ServerName == "" </span><span class="cov8" title="1">{
                serverName, _, err := net.SplitHostPort(authority)
                if err != nil </span><span class="cov0" title="0">{
                        // If the authority had no host port or if the authority cannot be parsed, use it as-is.
                        serverName = authority
                }</span>
                <span class="cov8" title="1">cfg.ServerName = serverName</span>
        }
        <span class="cov8" title="1">conn := tls.Client(rawConn, cfg)
        errChannel := make(chan error, 1)
        go func() </span><span class="cov8" title="1">{
                errChannel &lt;- conn.Handshake()
                close(errChannel)
        }</span>()
        <span class="cov8" title="1">select </span>{
        case err := &lt;-errChannel:<span class="cov8" title="1">
                if err != nil </span><span class="cov0" title="0">{
                        conn.Close()
                        return nil, nil, err
                }</span>
        case &lt;-ctx.Done():<span class="cov0" title="0">
                conn.Close()
                return nil, nil, ctx.Err()</span>
        }
        <span class="cov8" title="1">tlsInfo := TLSInfo{
                State: conn.ConnectionState(),
                CommonAuthInfo: CommonAuthInfo{
                        SecurityLevel: PrivacyAndIntegrity,
                },
        }
        id := credinternal.SPIFFEIDFromState(conn.ConnectionState())
        if id != nil </span><span class="cov0" title="0">{
                tlsInfo.SPIFFEID = id
        }</span>
        <span class="cov8" title="1">return credinternal.WrapSyscallConn(rawConn, conn), tlsInfo, nil</span>
}

func (c *tlsCreds) ServerHandshake(rawConn net.Conn) (net.Conn, AuthInfo, error) <span class="cov8" title="1">{
        conn := tls.Server(rawConn, c.config)
        if err := conn.Handshake(); err != nil </span><span class="cov0" title="0">{
                conn.Close()
                return nil, nil, err
        }</span>
        <span class="cov8" title="1">tlsInfo := TLSInfo{
                State: conn.ConnectionState(),
                CommonAuthInfo: CommonAuthInfo{
                        SecurityLevel: PrivacyAndIntegrity,
                },
        }
        id := credinternal.SPIFFEIDFromState(conn.ConnectionState())
        if id != nil </span><span class="cov0" title="0">{
                tlsInfo.SPIFFEID = id
        }</span>
        <span class="cov8" title="1">return credinternal.WrapSyscallConn(rawConn, conn), tlsInfo, nil</span>
}

func (c *tlsCreds) Clone() TransportCredentials <span class="cov8" title="1">{
        return NewTLS(c.config)
}</span>

func (c *tlsCreds) OverrideServerName(serverNameOverride string) error <span class="cov8" title="1">{
        c.config.ServerName = serverNameOverride
        return nil
}</span>

// NewTLS uses c to construct a TransportCredentials based on TLS.
func NewTLS(c *tls.Config) TransportCredentials <span class="cov8" title="1">{
        tc := &amp;tlsCreds{credinternal.CloneTLSConfig(c)}
        tc.config.NextProtos = credinternal.AppendH2ToNextProtos(tc.config.NextProtos)
        return tc
}</span>

// NewClientTLSFromCert constructs TLS credentials from the provided root
// certificate authority certificate(s) to validate server connections. If
// certificates to establish the identity of the client need to be included in
// the credentials (eg: for mTLS), use NewTLS instead, where a complete
// tls.Config can be specified.
// serverNameOverride is for testing only. If set to a non empty string,
// it will override the virtual host name of authority (e.g. :authority header
// field) in requests.
func NewClientTLSFromCert(cp *x509.CertPool, serverNameOverride string) TransportCredentials <span class="cov0" title="0">{
        return NewTLS(&amp;tls.Config{ServerName: serverNameOverride, RootCAs: cp})
}</span>

// NewClientTLSFromFile constructs TLS credentials from the provided root
// certificate authority certificate file(s) to validate server connections. If
// certificates to establish the identity of the client need to be included in
// the credentials (eg: for mTLS), use NewTLS instead, where a complete
// tls.Config can be specified.
// serverNameOverride is for testing only. If set to a non empty string,
// it will override the virtual host name of authority (e.g. :authority header
// field) in requests.
func NewClientTLSFromFile(certFile, serverNameOverride string) (TransportCredentials, error) <span class="cov0" title="0">{
        b, err := ioutil.ReadFile(certFile)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">cp := x509.NewCertPool()
        if !cp.AppendCertsFromPEM(b) </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("credentials: failed to append certificates")
        }</span>
        <span class="cov0" title="0">return NewTLS(&amp;tls.Config{ServerName: serverNameOverride, RootCAs: cp}), nil</span>
}

// NewServerTLSFromCert constructs TLS credentials from the input certificate for server.
func NewServerTLSFromCert(cert *tls.Certificate) TransportCredentials <span class="cov0" title="0">{
        return NewTLS(&amp;tls.Config{Certificates: []tls.Certificate{*cert}})
}</span>

// NewServerTLSFromFile constructs TLS credentials from the input certificate file and key
// file for server.
func NewServerTLSFromFile(certFile, keyFile string) (TransportCredentials, error) <span class="cov8" title="1">{
        cert, err := tls.LoadX509KeyPair(certFile, keyFile)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return NewTLS(&amp;tls.Config{Certificates: []tls.Certificate{cert}}), nil</span>
}

// TLSChannelzSecurityValue defines the struct that TLS protocol should return
// from GetSecurityValue(), containing security info like cipher and certificate used.
//
// Experimental
//
// Notice: This type is EXPERIMENTAL and may be changed or removed in a
// later release.
type TLSChannelzSecurityValue struct {
        ChannelzSecurityValue
        StandardName      string
        LocalCertificate  []byte
        RemoteCertificate []byte
}

var cipherSuiteLookup = map[uint16]string{
        tls.TLS_RSA_WITH_RC4_128_SHA:                "TLS_RSA_WITH_RC4_128_SHA",
        tls.TLS_RSA_WITH_3DES_EDE_CBC_SHA:           "TLS_RSA_WITH_3DES_EDE_CBC_SHA",
        tls.TLS_RSA_WITH_AES_128_CBC_SHA:            "TLS_RSA_WITH_AES_128_CBC_SHA",
        tls.TLS_RSA_WITH_AES_256_CBC_SHA:            "TLS_RSA_WITH_AES_256_CBC_SHA",
        tls.TLS_RSA_WITH_AES_128_GCM_SHA256:         "TLS_RSA_WITH_AES_128_GCM_SHA256",
        tls.TLS_RSA_WITH_AES_256_GCM_SHA384:         "TLS_RSA_WITH_AES_256_GCM_SHA384",
        tls.TLS_ECDHE_ECDSA_WITH_RC4_128_SHA:        "TLS_ECDHE_ECDSA_WITH_RC4_128_SHA",
        tls.TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA:    "TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA",
        tls.TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA:    "TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA",
        tls.TLS_ECDHE_RSA_WITH_RC4_128_SHA:          "TLS_ECDHE_RSA_WITH_RC4_128_SHA",
        tls.TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA:     "TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA",
        tls.TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA:      "TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA",
        tls.TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA:      "TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA",
        tls.TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256:   "TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256",
        tls.TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256: "TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256",
        tls.TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384:   "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384",
        tls.TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384: "TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384",
        tls.TLS_FALLBACK_SCSV:                       "TLS_FALLBACK_SCSV",
        tls.TLS_RSA_WITH_AES_128_CBC_SHA256:         "TLS_RSA_WITH_AES_128_CBC_SHA256",
        tls.TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256: "TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256",
        tls.TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256:   "TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256",
        tls.TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305:    "TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305",
        tls.TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305:  "TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305",
        tls.TLS_AES_128_GCM_SHA256:                  "TLS_AES_128_GCM_SHA256",
        tls.TLS_AES_256_GCM_SHA384:                  "TLS_AES_256_GCM_SHA384",
        tls.TLS_CHACHA20_POLY1305_SHA256:            "TLS_CHACHA20_POLY1305_SHA256",
}
</pre>
		
		<pre class="file" id="file54" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package certprovider

import (
        "context"
        "sync"

        "google.golang.org/grpc/internal/grpcsync"
)

// Distributor makes it easy for provider implementations to furnish new key
// materials by handling synchronization between the producer and consumers of
// the key material.
//
// Provider implementations which choose to use a Distributor should do the
// following:
// - create a new Distributor using the NewDistributor() function.
// - invoke the Set() method whenever they have new key material or errors to
//   report.
// - delegate to the distributor when handing calls to KeyMaterial().
// - invoke the Stop() method when they are done using the distributor.
type Distributor struct {
        // mu protects the underlying key material.
        mu   sync.Mutex
        km   *KeyMaterial
        pErr error

        // ready channel to unblock KeyMaterial() invocations blocked on
        // availability of key material.
        ready *grpcsync.Event
        // done channel to notify provider implementations and unblock any
        // KeyMaterial() calls, once the Distributor is closed.
        closed *grpcsync.Event
}

// NewDistributor returns a new Distributor.
func NewDistributor() *Distributor <span class="cov8" title="1">{
        return &amp;Distributor{
                ready:  grpcsync.NewEvent(),
                closed: grpcsync.NewEvent(),
        }
}</span>

// Set updates the key material in the distributor with km.
//
// Provider implementations which use the distributor must not modify the
// contents of the KeyMaterial struct pointed to by km.
//
// A non-nil err value indicates the error that the provider implementation ran
// into when trying to fetch key material, and makes it possible to surface the
// error to the user. A non-nil error value passed here causes distributor's
// KeyMaterial() method to return nil key material.
func (d *Distributor) Set(km *KeyMaterial, err error) <span class="cov8" title="1">{
        d.mu.Lock()
        d.km = km
        d.pErr = err
        if err != nil </span><span class="cov8" title="1">{
                // If a non-nil err is passed, we ignore the key material being passed.
                d.km = nil
        }</span>
        <span class="cov8" title="1">d.ready.Fire()
        d.mu.Unlock()</span>
}

// KeyMaterial returns the most recent key material provided to the Distributor.
// If no key material was provided at the time of this call, it will block until
// the deadline on the context expires or fresh key material arrives.
func (d *Distributor) KeyMaterial(ctx context.Context) (*KeyMaterial, error) <span class="cov8" title="1">{
        if d.closed.HasFired() </span><span class="cov8" title="1">{
                return nil, errProviderClosed
        }</span>

        <span class="cov8" title="1">if d.ready.HasFired() </span><span class="cov8" title="1">{
                return d.keyMaterial()
        }</span>

        <span class="cov8" title="1">select </span>{
        case &lt;-ctx.Done():<span class="cov8" title="1">
                return nil, ctx.Err()</span>
        case &lt;-d.closed.Done():<span class="cov0" title="0">
                return nil, errProviderClosed</span>
        case &lt;-d.ready.Done():<span class="cov8" title="1">
                return d.keyMaterial()</span>
        }
}

func (d *Distributor) keyMaterial() (*KeyMaterial, error) <span class="cov8" title="1">{
        d.mu.Lock()
        defer d.mu.Unlock()
        return d.km, d.pErr
}</span>

// Stop turns down the distributor, releases allocated resources and fails any
// active KeyMaterial() call waiting for new key material.
func (d *Distributor) Stop() <span class="cov8" title="1">{
        d.closed.Fire()
}</span>
</pre>
		
		<pre class="file" id="file55" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package pemfile

import (
        "encoding/json"
        "fmt"
        "time"

        "google.golang.org/grpc/credentials/tls/certprovider"
        "google.golang.org/protobuf/encoding/protojson"
        "google.golang.org/protobuf/types/known/durationpb"
)

const (
        pluginName             = "file_watcher"
        defaultRefreshInterval = 10 * time.Minute
)

func init() <span class="cov8" title="1">{
        certprovider.Register(&amp;pluginBuilder{})
}</span>

type pluginBuilder struct{}

func (p *pluginBuilder) ParseConfig(c interface{}) (*certprovider.BuildableConfig, error) <span class="cov8" title="1">{
        data, ok := c.(json.RawMessage)
        if !ok </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("meshca: unsupported config type: %T", c)
        }</span>
        <span class="cov8" title="1">opts, err := pluginConfigFromJSON(data)
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return certprovider.NewBuildableConfig(pluginName, opts.canonical(), func(certprovider.BuildOptions) certprovider.Provider </span><span class="cov0" title="0">{
                return newProvider(opts)
        }</span>), nil
}

func (p *pluginBuilder) Name() string <span class="cov8" title="1">{
        return pluginName
}</span>

func pluginConfigFromJSON(jd json.RawMessage) (Options, error) <span class="cov8" title="1">{
        // The only difference between this anonymous struct and the Options struct
        // is that the refresh_interval is represented here as a duration proto,
        // while in the latter a time.Duration is used.
        cfg := &amp;struct {
                CertificateFile   string          `json:"certificate_file,omitempty"`
                PrivateKeyFile    string          `json:"private_key_file,omitempty"`
                CACertificateFile string          `json:"ca_certificate_file,omitempty"`
                RefreshInterval   json.RawMessage `json:"refresh_interval,omitempty"`
        }{}
        if err := json.Unmarshal(jd, cfg); err != nil </span><span class="cov8" title="1">{
                return Options{}, fmt.Errorf("pemfile: json.Unmarshal(%s) failed: %v", string(jd), err)
        }</span>

        <span class="cov8" title="1">opts := Options{
                CertFile: cfg.CertificateFile,
                KeyFile:  cfg.PrivateKeyFile,
                RootFile: cfg.CACertificateFile,
                // Refresh interval is the only field in the configuration for which we
                // support a default value. We cannot possibly have valid defaults for
                // file paths to watch. Also, it is valid to specify an empty path for
                // some of those fields if the user does not want to watch them.
                RefreshDuration: defaultRefreshInterval,
        }
        if cfg.RefreshInterval != nil </span><span class="cov8" title="1">{
                dur := &amp;durationpb.Duration{}
                if err := protojson.Unmarshal(cfg.RefreshInterval, dur); err != nil </span><span class="cov8" title="1">{
                        return Options{}, fmt.Errorf("pemfile: protojson.Unmarshal(%+v) failed: %v", cfg.RefreshInterval, err)
                }</span>
                <span class="cov8" title="1">opts.RefreshDuration = dur.AsDuration()</span>
        }

        <span class="cov8" title="1">if err := opts.validate(); err != nil </span><span class="cov8" title="1">{
                return Options{}, err
        }</span>
        <span class="cov8" title="1">return opts, nil</span>
}
</pre>
		
		<pre class="file" id="file56" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package pemfile provides a file watching certificate provider plugin
// implementation which works for files with PEM contents.
//
// Experimental
//
// Notice: All APIs in this package are experimental and may be removed in a
// later release.
package pemfile

import (
        "bytes"
        "context"
        "crypto/tls"
        "crypto/x509"
        "errors"
        "fmt"
        "io/ioutil"
        "path/filepath"
        "time"

        "google.golang.org/grpc/credentials/tls/certprovider"
        "google.golang.org/grpc/grpclog"
)

const defaultCertRefreshDuration = 1 * time.Hour

var (
        // For overriding from unit tests.
        newDistributor = func() distributor <span class="cov8" title="1">{ return certprovider.NewDistributor() }</span>

        logger = grpclog.Component("pemfile")
)

// Options configures a certificate provider plugin that watches a specified set
// of files that contain certificates and keys in PEM format.
type Options struct {
        // CertFile is the file that holds the identity certificate.
        // Optional. If this is set, KeyFile must also be set.
        CertFile string
        // KeyFile is the file that holds identity private key.
        // Optional. If this is set, CertFile must also be set.
        KeyFile string
        // RootFile is the file that holds trusted root certificate(s).
        // Optional.
        RootFile string
        // RefreshDuration is the amount of time the plugin waits before checking
        // for updates in the specified files.
        // Optional. If not set, a default value (1 hour) will be used.
        RefreshDuration time.Duration
}

func (o Options) canonical() []byte <span class="cov8" title="1">{
        return []byte(fmt.Sprintf("%s:%s:%s:%s", o.CertFile, o.KeyFile, o.RootFile, o.RefreshDuration))
}</span>

func (o Options) validate() error <span class="cov8" title="1">{
        if o.CertFile == "" &amp;&amp; o.KeyFile == "" &amp;&amp; o.RootFile == "" </span><span class="cov8" title="1">{
                return fmt.Errorf("pemfile: at least one credential file needs to be specified")
        }</span>
        <span class="cov8" title="1">if keySpecified, certSpecified := o.KeyFile != "", o.CertFile != ""; keySpecified != certSpecified </span><span class="cov8" title="1">{
                return fmt.Errorf("pemfile: private key file and identity cert file should be both specified or not specified")
        }</span>
        // C-core has a limitation that they cannot verify that a certificate file
        // matches a key file. So, the only way to get around this is to make sure
        // that both files are in the same directory and that they do an atomic
        // read. Even though Java/Go do not have this limitation, we want the
        // overall plugin behavior to be consistent across languages.
        <span class="cov8" title="1">if certDir, keyDir := filepath.Dir(o.CertFile), filepath.Dir(o.KeyFile); certDir != keyDir </span><span class="cov8" title="1">{
                return errors.New("pemfile: certificate and key file must be in the same directory")
        }</span>
        <span class="cov8" title="1">return nil</span>
}

// NewProvider returns a new certificate provider plugin that is configured to
// watch the PEM files specified in the passed in options.
func NewProvider(o Options) (certprovider.Provider, error) <span class="cov8" title="1">{
        if err := o.validate(); err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return newProvider(o), nil</span>
}

// newProvider is used to create a new certificate provider plugin after
// validating the options, and hence does not return an error.
func newProvider(o Options) certprovider.Provider <span class="cov8" title="1">{
        if o.RefreshDuration == 0 </span><span class="cov8" title="1">{
                o.RefreshDuration = defaultCertRefreshDuration
        }</span>

        <span class="cov8" title="1">provider := &amp;watcher{opts: o}
        if o.CertFile != "" &amp;&amp; o.KeyFile != "" </span><span class="cov8" title="1">{
                provider.identityDistributor = newDistributor()
        }</span>
        <span class="cov8" title="1">if o.RootFile != "" </span><span class="cov8" title="1">{
                provider.rootDistributor = newDistributor()
        }</span>

        <span class="cov8" title="1">ctx, cancel := context.WithCancel(context.Background())
        provider.cancel = cancel
        go provider.run(ctx)
        return provider</span>
}

// watcher is a certificate provider plugin that implements the
// certprovider.Provider interface. It watches a set of certificate and key
// files and provides the most up-to-date key material for consumption by
// credentials implementation.
type watcher struct {
        identityDistributor distributor
        rootDistributor     distributor
        opts                Options
        certFileContents    []byte
        keyFileContents     []byte
        rootFileContents    []byte
        cancel              context.CancelFunc
}

// distributor wraps the methods on certprovider.Distributor which are used by
// the plugin. This is very useful in tests which need to know exactly when the
// plugin updates its key material.
type distributor interface {
        KeyMaterial(ctx context.Context) (*certprovider.KeyMaterial, error)
        Set(km *certprovider.KeyMaterial, err error)
        Stop()
}

// updateIdentityDistributor checks if the cert/key files that the plugin is
// watching have changed, and if so, reads the new contents and updates the
// identityDistributor with the new key material.
//
// Skips updates when file reading or parsing fails.
// TODO(easwars): Retry with limit (on the number of retries or the amount of
// time) upon failures.
func (w *watcher) updateIdentityDistributor() <span class="cov8" title="1">{
        if w.identityDistributor == nil </span><span class="cov8" title="1">{
                return
        }</span>

        <span class="cov8" title="1">certFileContents, err := ioutil.ReadFile(w.opts.CertFile)
        if err != nil </span><span class="cov0" title="0">{
                logger.Warningf("certFile (%s) read failed: %v", w.opts.CertFile, err)
                return
        }</span>
        <span class="cov8" title="1">keyFileContents, err := ioutil.ReadFile(w.opts.KeyFile)
        if err != nil </span><span class="cov0" title="0">{
                logger.Warningf("keyFile (%s) read failed: %v", w.opts.KeyFile, err)
                return
        }</span>
        // If the file contents have not changed, skip updating the distributor.
        <span class="cov8" title="1">if bytes.Equal(w.certFileContents, certFileContents) &amp;&amp; bytes.Equal(w.keyFileContents, keyFileContents) </span><span class="cov8" title="1">{
                return
        }</span>

        <span class="cov8" title="1">cert, err := tls.X509KeyPair(certFileContents, keyFileContents)
        if err != nil </span><span class="cov8" title="1">{
                logger.Warningf("tls.X509KeyPair(%q, %q) failed: %v", certFileContents, keyFileContents, err)
                return
        }</span>
        <span class="cov8" title="1">w.certFileContents = certFileContents
        w.keyFileContents = keyFileContents
        w.identityDistributor.Set(&amp;certprovider.KeyMaterial{Certs: []tls.Certificate{cert}}, nil)</span>
}

// updateRootDistributor checks if the root cert file that the plugin is
// watching hs changed, and if so, updates the rootDistributor with the new key
// material.
//
// Skips updates when root cert reading or parsing fails.
// TODO(easwars): Retry with limit (on the number of retries or the amount of
// time) upon failures.
func (w *watcher) updateRootDistributor() <span class="cov8" title="1">{
        if w.rootDistributor == nil </span><span class="cov8" title="1">{
                return
        }</span>

        <span class="cov8" title="1">rootFileContents, err := ioutil.ReadFile(w.opts.RootFile)
        if err != nil </span><span class="cov0" title="0">{
                logger.Warningf("rootFile (%s) read failed: %v", w.opts.RootFile, err)
                return
        }</span>
        <span class="cov8" title="1">trustPool := x509.NewCertPool()
        if !trustPool.AppendCertsFromPEM(rootFileContents) </span><span class="cov0" title="0">{
                logger.Warning("failed to parse root certificate")
                return
        }</span>
        // If the file contents have not changed, skip updating the distributor.
        <span class="cov8" title="1">if bytes.Equal(w.rootFileContents, rootFileContents) </span><span class="cov8" title="1">{
                return
        }</span>

        <span class="cov8" title="1">w.rootFileContents = rootFileContents
        w.rootDistributor.Set(&amp;certprovider.KeyMaterial{Roots: trustPool}, nil)</span>
}

// run is a long running goroutine which watches the configured files for
// changes, and pushes new key material into the appropriate distributors which
// is returned from calls to KeyMaterial().
func (w *watcher) run(ctx context.Context) <span class="cov8" title="1">{
        ticker := time.NewTicker(w.opts.RefreshDuration)
        for </span><span class="cov8" title="1">{
                w.updateIdentityDistributor()
                w.updateRootDistributor()
                select </span>{
                case &lt;-ctx.Done():<span class="cov8" title="1">
                        ticker.Stop()
                        if w.identityDistributor != nil </span><span class="cov8" title="1">{
                                w.identityDistributor.Stop()
                        }</span>
                        <span class="cov8" title="1">if w.rootDistributor != nil </span><span class="cov8" title="1">{
                                w.rootDistributor.Stop()
                        }</span>
                        <span class="cov8" title="1">return</span>
                case &lt;-ticker.C:<span class="cov8" title="1"></span>
                }
        }
}

// KeyMaterial returns the key material sourced by the watcher.
// Callers are expected to use the returned value as read-only.
func (w *watcher) KeyMaterial(ctx context.Context) (*certprovider.KeyMaterial, error) <span class="cov8" title="1">{
        km := &amp;certprovider.KeyMaterial{}
        if w.identityDistributor != nil </span><span class="cov8" title="1">{
                identityKM, err := w.identityDistributor.KeyMaterial(ctx)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov8" title="1">km.Certs = identityKM.Certs</span>
        }
        <span class="cov8" title="1">if w.rootDistributor != nil </span><span class="cov8" title="1">{
                rootKM, err := w.rootDistributor.KeyMaterial(ctx)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov8" title="1">km.Roots = rootKM.Roots</span>
        }
        <span class="cov8" title="1">return km, nil</span>
}

// Close cleans up resources allocated by the watcher.
func (w *watcher) Close() <span class="cov8" title="1">{
        w.cancel()
}</span>
</pre>
		
		<pre class="file" id="file57" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package certprovider defines APIs for Certificate Providers in gRPC.
//
// Experimental
//
// Notice: All APIs in this package are experimental and may be removed in a
// later release.
package certprovider

import (
        "context"
        "crypto/tls"
        "crypto/x509"
        "errors"

        "google.golang.org/grpc/internal"
)

func init() <span class="cov8" title="1">{
        internal.GetCertificateProviderBuilder = getBuilder
}</span>

var (
        // errProviderClosed is returned by Distributor.KeyMaterial when it is
        // closed.
        errProviderClosed = errors.New("provider instance is closed")

        // m is a map from name to Provider builder.
        m = make(map[string]Builder)
)

// Register registers the Provider builder, whose name as returned by its Name()
// method will be used as the name registered with this builder. Registered
// Builders are used by the Store to create Providers.
func Register(b Builder) <span class="cov8" title="1">{
        m[b.Name()] = b
}</span>

// getBuilder returns the Provider builder registered with the given name.
// If no builder is registered with the provided name, nil will be returned.
func getBuilder(name string) Builder <span class="cov8" title="1">{
        if b, ok := m[name]; ok </span><span class="cov8" title="1">{
                return b
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// Builder creates a Provider.
type Builder interface {
        // ParseConfig parses the given config, which is in a format specific to individual
        // implementations, and returns a BuildableConfig on success.
        ParseConfig(interface{}) (*BuildableConfig, error)

        // Name returns the name of providers built by this builder.
        Name() string
}

// Provider makes it possible to keep channel credential implementations up to
// date with secrets that they rely on to secure communications on the
// underlying channel.
//
// Provider implementations are free to rely on local or remote sources to fetch
// the latest secrets, and free to share any state between different
// instantiations as they deem fit.
type Provider interface {
        // KeyMaterial returns the key material sourced by the Provider.
        // Callers are expected to use the returned value as read-only.
        KeyMaterial(ctx context.Context) (*KeyMaterial, error)

        // Close cleans up resources allocated by the Provider.
        Close()
}

// KeyMaterial wraps the certificates and keys returned by a Provider instance.
type KeyMaterial struct {
        // Certs contains a slice of cert/key pairs used to prove local identity.
        Certs []tls.Certificate
        // Roots contains the set of trusted roots to validate the peer's identity.
        Roots *x509.CertPool
}

// BuildOptions contains parameters passed to a Provider at build time.
type BuildOptions struct {
        // CertName holds the certificate name, whose key material is of interest to
        // the caller.
        CertName string
        // WantRoot indicates if the caller is interested in the root certificate.
        WantRoot bool
        // WantIdentity indicates if the caller is interested in the identity
        // certificate.
        WantIdentity bool
}
</pre>
		
		<pre class="file" id="file58" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package certprovider

import (
        "fmt"
        "sync"
)

// provStore is the global singleton certificate provider store.
var provStore = &amp;store{
        providers: make(map[storeKey]*wrappedProvider),
}

// storeKey acts as the key to the map of providers maintained by the store. A
// combination of provider name and configuration is used to uniquely identify
// every provider instance in the store. Go maps need to be indexed by
// comparable types, so the provider configuration is converted from
// `interface{}` to string using the ParseConfig method while creating this key.
type storeKey struct {
        // name of the certificate provider.
        name string
        // configuration of the certificate provider in string form.
        config string
        // opts contains the certificate name and other keyMaterial options.
        opts BuildOptions
}

// wrappedProvider wraps a provider instance with a reference count.
type wrappedProvider struct {
        Provider
        refCount int

        // A reference to the key and store are also kept here to override the
        // Close method on the provider.
        storeKey storeKey
        store    *store
}

// store is a collection of provider instances, safe for concurrent access.
type store struct {
        mu        sync.Mutex
        providers map[storeKey]*wrappedProvider
}

// Close overrides the Close method of the embedded provider. It releases the
// reference held by the caller on the underlying provider and if the
// provider's reference count reaches zero, it is removed from the store, and
// its Close method is also invoked.
func (wp *wrappedProvider) Close() <span class="cov8" title="1">{
        ps := wp.store
        ps.mu.Lock()
        defer ps.mu.Unlock()

        wp.refCount--
        if wp.refCount == 0 </span><span class="cov8" title="1">{
                wp.Provider.Close()
                delete(ps.providers, wp.storeKey)
        }</span>
}

// BuildableConfig wraps parsed provider configuration and functionality to
// instantiate provider instances.
type BuildableConfig struct {
        name    string
        config  []byte
        starter func(BuildOptions) Provider
        pStore  *store
}

// NewBuildableConfig creates a new BuildableConfig with the given arguments.
// Provider implementations are expected to invoke this function after parsing
// the given configuration as part of their ParseConfig() method.
// Equivalent configurations are expected to invoke this function with the same
// config argument.
func NewBuildableConfig(name string, config []byte, starter func(BuildOptions) Provider) *BuildableConfig <span class="cov8" title="1">{
        return &amp;BuildableConfig{
                name:    name,
                config:  config,
                starter: starter,
                pStore:  provStore,
        }
}</span>

// Build kicks off a provider instance with the wrapped configuration. Multiple
// invocations of this method with the same opts will result in provider
// instances being reused.
func (bc *BuildableConfig) Build(opts BuildOptions) (Provider, error) <span class="cov8" title="1">{
        provStore.mu.Lock()
        defer provStore.mu.Unlock()

        sk := storeKey{
                name:   bc.name,
                config: string(bc.config),
                opts:   opts,
        }
        if wp, ok := provStore.providers[sk]; ok </span><span class="cov8" title="1">{
                wp.refCount++
                return wp, nil
        }</span>

        <span class="cov8" title="1">provider := bc.starter(opts)
        if provider == nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("provider(%q, %q).Build(%v) failed", sk.name, sk.config, opts)
        }</span>
        <span class="cov8" title="1">wp := &amp;wrappedProvider{
                Provider: provider,
                refCount: 1,
                storeKey: sk,
                store:    provStore,
        }
        provStore.providers[sk] = wp
        return wp, nil</span>
}

// String returns the provider name and config as a colon separated string.
func (bc *BuildableConfig) String() string <span class="cov0" title="0">{
        return fmt.Sprintf("%s:%s", bc.name, string(bc.config))
}</span>

// ParseConfig is a convenience function to create a BuildableConfig given a
// provider name and configuration. Returns an error if there is no registered
// builder for the given name or if the config parsing fails.
func ParseConfig(name string, config interface{}) (*BuildableConfig, error) <span class="cov8" title="1">{
        parser := getBuilder(name)
        if parser == nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no certificate provider builder found for %q", name)
        }</span>
        <span class="cov8" title="1">return parser.ParseConfig(config)</span>
}

// GetProvider is a convenience function to create a provider given the name,
// config and build options.
func GetProvider(name string, config interface{}, opts BuildOptions) (Provider, error) <span class="cov8" title="1">{
        bc, err := ParseConfig(name, config)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return bc.Build(opts)</span>
}
</pre>
		
		<pre class="file" id="file59" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package xds provides a transport credentials implementation where the
// security configuration is pushed by a management server using xDS APIs.
package xds

import (
        "context"
        "crypto/tls"
        "crypto/x509"
        "errors"
        "fmt"
        "net"
        "time"

        "google.golang.org/grpc/credentials"
        credinternal "google.golang.org/grpc/internal/credentials"
        xdsinternal "google.golang.org/grpc/internal/credentials/xds"
)

// ClientOptions contains parameters to configure a new client-side xDS
// credentials implementation.
type ClientOptions struct {
        // FallbackCreds specifies the fallback credentials to be used when either
        // the `xds` scheme is not used in the user's dial target or when the
        // management server does not return any security configuration. Attempts to
        // create client credentials without fallback credentials will fail.
        FallbackCreds credentials.TransportCredentials
}

// NewClientCredentials returns a new client-side transport credentials
// implementation which uses xDS APIs to fetch its security configuration.
func NewClientCredentials(opts ClientOptions) (credentials.TransportCredentials, error) <span class="cov8" title="1">{
        if opts.FallbackCreds == nil </span><span class="cov8" title="1">{
                return nil, errors.New("missing fallback credentials")
        }</span>
        <span class="cov8" title="1">return &amp;credsImpl{
                isClient: true,
                fallback: opts.FallbackCreds,
        }, nil</span>
}

// ServerOptions contains parameters to configure a new server-side xDS
// credentials implementation.
type ServerOptions struct {
        // FallbackCreds specifies the fallback credentials to be used when the
        // management server does not return any security configuration. Attempts to
        // create server credentials without fallback credentials will fail.
        FallbackCreds credentials.TransportCredentials
}

// NewServerCredentials returns a new server-side transport credentials
// implementation which uses xDS APIs to fetch its security configuration.
func NewServerCredentials(opts ServerOptions) (credentials.TransportCredentials, error) <span class="cov8" title="1">{
        if opts.FallbackCreds == nil </span><span class="cov8" title="1">{
                return nil, errors.New("missing fallback credentials")
        }</span>
        <span class="cov8" title="1">return &amp;credsImpl{
                isClient: false,
                fallback: opts.FallbackCreds,
        }, nil</span>
}

// credsImpl is an implementation of the credentials.TransportCredentials
// interface which uses xDS APIs to fetch its security configuration.
type credsImpl struct {
        isClient bool
        fallback credentials.TransportCredentials
}

// ClientHandshake performs the TLS handshake on the client-side.
//
// It looks for the presence of a HandshakeInfo value in the passed in context
// (added using a call to NewContextWithHandshakeInfo()), and retrieves identity
// and root certificates from there. It also retrieves a list of acceptable SANs
// and uses a custom verification function to validate the certificate presented
// by the peer. It uses fallback credentials if no HandshakeInfo is present in
// the passed in context.
func (c *credsImpl) ClientHandshake(ctx context.Context, authority string, rawConn net.Conn) (net.Conn, credentials.AuthInfo, error) <span class="cov8" title="1">{
        if !c.isClient </span><span class="cov0" title="0">{
                return nil, nil, errors.New("ClientHandshake() is not supported for server credentials")
        }</span>

        // The CDS balancer constructs a new HandshakeInfo using a call to
        // NewHandshakeInfo(), and then adds it to the attributes field of the
        // resolver.Address when handling calls to NewSubConn(). The transport layer
        // takes care of shipping these attributes in the context to this handshake
        // function. We first read the credentials.ClientHandshakeInfo type from the
        // context, which contains the attributes added by the CDS balancer. We then
        // read the HandshakeInfo from the attributes to get to the actual data that
        // we need here for the handshake.
        <span class="cov8" title="1">chi := credentials.ClientHandshakeInfoFromContext(ctx)
        // If there are no attributes in the received context or the attributes does
        // not contain a HandshakeInfo, it could either mean that the user did not
        // specify an `xds` scheme in their dial target or that the xDS server did
        // not provide any security configuration. In both of these cases, we use
        // the fallback credentials specified by the user.
        if chi.Attributes == nil </span><span class="cov8" title="1">{
                return c.fallback.ClientHandshake(ctx, authority, rawConn)
        }</span>
        <span class="cov8" title="1">hi := xdsinternal.GetHandshakeInfo(chi.Attributes)
        if hi.UseFallbackCreds() </span><span class="cov0" title="0">{
                return c.fallback.ClientHandshake(ctx, authority, rawConn)
        }</span>

        // We build the tls.Config with the following values
        // 1. Root certificate as returned by the root provider.
        // 2. Identity certificate as returned by the identity provider. This may be
        //    empty on the client side, if the client is not doing mTLS.
        // 3. InsecureSkipVerify to true. Certificates used in Mesh environments
        //    usually contains the identity of the workload presenting the
        //    certificate as a SAN (instead of a hostname in the CommonName field).
        //    This means that normal certificate verification as done by the
        //    standard library will fail.
        // 4. Key usage to match whether client/server usage.
        // 5. A `VerifyPeerCertificate` function which performs normal peer
        //           cert verification using configured roots, and the custom SAN checks.
        <span class="cov8" title="1">cfg, err := hi.ClientSideTLSConfig(ctx)
        if err != nil </span><span class="cov8" title="1">{
                return nil, nil, err
        }</span>
        <span class="cov8" title="1">cfg.VerifyPeerCertificate = func(rawCerts [][]byte, verifiedChains [][]*x509.Certificate) error </span><span class="cov8" title="1">{
                // Parse all raw certificates presented by the peer.
                var certs []*x509.Certificate
                for _, rc := range rawCerts </span><span class="cov8" title="1">{
                        cert, err := x509.ParseCertificate(rc)
                        if err != nil </span><span class="cov0" title="0">{
                                return err
                        }</span>
                        <span class="cov8" title="1">certs = append(certs, cert)</span>
                }

                // Build the intermediates list and verify that the leaf certificate
                // is signed by one of the root certificates.
                <span class="cov8" title="1">intermediates := x509.NewCertPool()
                for _, cert := range certs[1:] </span><span class="cov0" title="0">{
                        intermediates.AddCert(cert)
                }</span>
                <span class="cov8" title="1">opts := x509.VerifyOptions{
                        Roots:         cfg.RootCAs,
                        Intermediates: intermediates,
                        KeyUsages:     []x509.ExtKeyUsage{x509.ExtKeyUsageServerAuth},
                }
                if _, err := certs[0].Verify(opts); err != nil </span><span class="cov8" title="1">{
                        return err
                }</span>
                // The SANs sent by the MeshCA are encoded as SPIFFE IDs. We need to
                // only look at the SANs on the leaf cert.
                <span class="cov8" title="1">if !hi.MatchingSANExists(certs[0]) </span><span class="cov8" title="1">{
                        return fmt.Errorf("SANs received in leaf certificate %+v does not match any of the accepted SANs", certs[0])
                }</span>
                <span class="cov8" title="1">return nil</span>
        }

        // Perform the TLS handshake with the tls.Config that we have. We run the
        // actual Handshake() function in a goroutine because we need to respect the
        // deadline specified on the passed in context, and we need a way to cancel
        // the handshake if the context is cancelled.
        <span class="cov8" title="1">conn := tls.Client(rawConn, cfg)
        errCh := make(chan error, 1)
        go func() </span><span class="cov8" title="1">{
                errCh &lt;- conn.Handshake()
                close(errCh)
        }</span>()
        <span class="cov8" title="1">select </span>{
        case err := &lt;-errCh:<span class="cov8" title="1">
                if err != nil </span><span class="cov8" title="1">{
                        conn.Close()
                        return nil, nil, err
                }</span>
        case &lt;-ctx.Done():<span class="cov8" title="1">
                conn.Close()
                return nil, nil, ctx.Err()</span>
        }
        <span class="cov8" title="1">info := credentials.TLSInfo{
                State: conn.ConnectionState(),
                CommonAuthInfo: credentials.CommonAuthInfo{
                        SecurityLevel: credentials.PrivacyAndIntegrity,
                },
                SPIFFEID: credinternal.SPIFFEIDFromState(conn.ConnectionState()),
        }
        return credinternal.WrapSyscallConn(rawConn, conn), info, nil</span>
}

// ServerHandshake performs the TLS handshake on the server-side.
func (c *credsImpl) ServerHandshake(rawConn net.Conn) (net.Conn, credentials.AuthInfo, error) <span class="cov8" title="1">{
        if c.isClient </span><span class="cov0" title="0">{
                return nil, nil, errors.New("ServerHandshake is not supported for client credentials")
        }</span>

        // An xds-enabled gRPC server wraps the underlying raw net.Conn in a type
        // that provides a way to retrieve `HandshakeInfo`, which contains the
        // certificate providers to be used during the handshake. If the net.Conn
        // passed to this function does not implement this interface, or if the
        // `HandshakeInfo` does not contain the information we are looking for, we
        // delegate the handshake to the fallback credentials.
        <span class="cov8" title="1">hiConn, ok := rawConn.(interface {
                XDSHandshakeInfo() (*xdsinternal.HandshakeInfo, error)
        })
        if !ok </span><span class="cov0" title="0">{
                return c.fallback.ServerHandshake(rawConn)
        }</span>
        <span class="cov8" title="1">hi, err := hiConn.XDSHandshakeInfo()
        if err != nil </span><span class="cov8" title="1">{
                return nil, nil, err
        }</span>
        <span class="cov8" title="1">if hi.UseFallbackCreds() </span><span class="cov8" title="1">{
                return c.fallback.ServerHandshake(rawConn)
        }</span>

        // An xds-enabled gRPC server is expected to wrap the underlying raw
        // net.Conn in a type which provides a way to retrieve the deadline set on
        // it. If we cannot retrieve the deadline here, we fail (by setting deadline
        // to time.Now()), instead of using a default deadline and possibly taking
        // longer to eventually fail.
        <span class="cov8" title="1">deadline := time.Now()
        if dConn, ok := rawConn.(interface{ GetDeadline() time.Time }); ok </span><span class="cov8" title="1">{
                deadline = dConn.GetDeadline()
        }</span>
        <span class="cov8" title="1">ctx, cancel := context.WithDeadline(context.Background(), deadline)
        defer cancel()
        cfg, err := hi.ServerSideTLSConfig(ctx)
        if err != nil </span><span class="cov8" title="1">{
                return nil, nil, err
        }</span>

        <span class="cov8" title="1">conn := tls.Server(rawConn, cfg)
        if err := conn.Handshake(); err != nil </span><span class="cov8" title="1">{
                conn.Close()
                return nil, nil, err
        }</span>
        <span class="cov8" title="1">info := credentials.TLSInfo{
                State: conn.ConnectionState(),
                CommonAuthInfo: credentials.CommonAuthInfo{
                        SecurityLevel: credentials.PrivacyAndIntegrity,
                },
        }
        info.SPIFFEID = credinternal.SPIFFEIDFromState(conn.ConnectionState())
        return credinternal.WrapSyscallConn(rawConn, conn), info, nil</span>
}

// Info provides the ProtocolInfo of this TransportCredentials.
func (c *credsImpl) Info() credentials.ProtocolInfo <span class="cov0" title="0">{
        return credentials.ProtocolInfo{SecurityProtocol: "tls"}
}</span>

// Clone makes a copy of this TransportCredentials.
func (c *credsImpl) Clone() credentials.TransportCredentials <span class="cov8" title="1">{
        clone := *c
        return &amp;clone
}</span>

func (c *credsImpl) OverrideServerName(_ string) error <span class="cov0" title="0">{
        return errors.New("serverName for peer validation must be configured as a list of acceptable SANs")
}</span>

// UsesXDS returns true if c uses xDS to fetch security configuration
// used at handshake time, and false otherwise.
func (c *credsImpl) UsesXDS() bool <span class="cov0" title="0">{
        return true
}</span>
</pre>
		
		<pre class="file" id="file60" style="display: none">/*
 *
 * Copyright 2018 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package grpc

import (
        "context"
        "net"
        "time"

        "google.golang.org/grpc/backoff"
        "google.golang.org/grpc/channelz"
        "google.golang.org/grpc/credentials"
        "google.golang.org/grpc/credentials/insecure"
        "google.golang.org/grpc/internal"
        internalbackoff "google.golang.org/grpc/internal/backoff"
        "google.golang.org/grpc/internal/transport"
        "google.golang.org/grpc/keepalive"
        "google.golang.org/grpc/resolver"
        "google.golang.org/grpc/stats"
)

func init() <span class="cov8" title="1">{
        internal.AddExtraDialOptions = func(opt ...DialOption) </span><span class="cov8" title="1">{
                extraDialOptions = append(extraDialOptions, opt...)
        }</span>
        <span class="cov8" title="1">internal.ClearExtraDialOptions = func() </span><span class="cov8" title="1">{
                extraDialOptions = nil
        }</span>
}

// dialOptions configure a Dial call. dialOptions are set by the DialOption
// values passed to Dial.
type dialOptions struct {
        unaryInt  UnaryClientInterceptor
        streamInt StreamClientInterceptor

        chainUnaryInts  []UnaryClientInterceptor
        chainStreamInts []StreamClientInterceptor

        cp                          Compressor
        dc                          Decompressor
        bs                          internalbackoff.Strategy
        block                       bool
        returnLastError             bool
        timeout                     time.Duration
        scChan                      &lt;-chan ServiceConfig
        authority                   string
        copts                       transport.ConnectOptions
        callOptions                 []CallOption
        channelzParentID            *channelz.Identifier
        disableServiceConfig        bool
        disableRetry                bool
        disableHealthCheck          bool
        healthCheckFunc             internal.HealthChecker
        minConnectTimeout           func() time.Duration
        defaultServiceConfig        *ServiceConfig // defaultServiceConfig is parsed from defaultServiceConfigRawJSON.
        defaultServiceConfigRawJSON *string
        resolvers                   []resolver.Builder
}

// DialOption configures how we set up the connection.
type DialOption interface {
        apply(*dialOptions)
}

var extraDialOptions []DialOption

// EmptyDialOption does not alter the dial configuration. It can be embedded in
// another structure to build custom dial options.
//
// # Experimental
//
// Notice: This type is EXPERIMENTAL and may be changed or removed in a
// later release.
type EmptyDialOption struct{}

func (EmptyDialOption) apply(*dialOptions) {<span class="cov0" title="0">}</span>

// funcDialOption wraps a function that modifies dialOptions into an
// implementation of the DialOption interface.
type funcDialOption struct {
        f func(*dialOptions)
}

func (fdo *funcDialOption) apply(do *dialOptions) <span class="cov8" title="1">{
        fdo.f(do)
}</span>

func newFuncDialOption(f func(*dialOptions)) *funcDialOption <span class="cov8" title="1">{
        return &amp;funcDialOption{
                f: f,
        }
}</span>

// WithWriteBufferSize determines how much data can be batched before doing a
// write on the wire. The corresponding memory allocation for this buffer will
// be twice the size to keep syscalls low. The default value for this buffer is
// 32KB.
//
// Zero will disable the write buffer such that each write will be on underlying
// connection. Note: A Send call may not directly translate to a write.
func WithWriteBufferSize(s int) DialOption <span class="cov0" title="0">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov0" title="0">{
                o.copts.WriteBufferSize = s
        }</span>)
}

// WithReadBufferSize lets you set the size of read buffer, this determines how
// much data can be read at most for each read syscall.
//
// The default value for this buffer is 32KB. Zero will disable read buffer for
// a connection so data framer can access the underlying conn directly.
func WithReadBufferSize(s int) DialOption <span class="cov0" title="0">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov0" title="0">{
                o.copts.ReadBufferSize = s
        }</span>)
}

// WithInitialWindowSize returns a DialOption which sets the value for initial
// window size on a stream. The lower bound for window size is 64K and any value
// smaller than that will be ignored.
func WithInitialWindowSize(s int32) DialOption <span class="cov0" title="0">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov0" title="0">{
                o.copts.InitialWindowSize = s
        }</span>)
}

// WithInitialConnWindowSize returns a DialOption which sets the value for
// initial window size on a connection. The lower bound for window size is 64K
// and any value smaller than that will be ignored.
func WithInitialConnWindowSize(s int32) DialOption <span class="cov0" title="0">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov0" title="0">{
                o.copts.InitialConnWindowSize = s
        }</span>)
}

// WithMaxMsgSize returns a DialOption which sets the maximum message size the
// client can receive.
//
// Deprecated: use WithDefaultCallOptions(MaxCallRecvMsgSize(s)) instead.  Will
// be supported throughout 1.x.
func WithMaxMsgSize(s int) DialOption <span class="cov0" title="0">{
        return WithDefaultCallOptions(MaxCallRecvMsgSize(s))
}</span>

// WithDefaultCallOptions returns a DialOption which sets the default
// CallOptions for calls over the connection.
func WithDefaultCallOptions(cos ...CallOption) DialOption <span class="cov0" title="0">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov0" title="0">{
                o.callOptions = append(o.callOptions, cos...)
        }</span>)
}

// WithCodec returns a DialOption which sets a codec for message marshaling and
// unmarshaling.
//
// Deprecated: use WithDefaultCallOptions(ForceCodec(_)) instead.  Will be
// supported throughout 1.x.
func WithCodec(c Codec) DialOption <span class="cov0" title="0">{
        return WithDefaultCallOptions(CallCustomCodec(c))
}</span>

// WithCompressor returns a DialOption which sets a Compressor to use for
// message compression. It has lower priority than the compressor set by the
// UseCompressor CallOption.
//
// Deprecated: use UseCompressor instead.  Will be supported throughout 1.x.
func WithCompressor(cp Compressor) DialOption <span class="cov0" title="0">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov0" title="0">{
                o.cp = cp
        }</span>)
}

// WithDecompressor returns a DialOption which sets a Decompressor to use for
// incoming message decompression.  If incoming response messages are encoded
// using the decompressor's Type(), it will be used.  Otherwise, the message
// encoding will be used to look up the compressor registered via
// encoding.RegisterCompressor, which will then be used to decompress the
// message.  If no compressor is registered for the encoding, an Unimplemented
// status error will be returned.
//
// Deprecated: use encoding.RegisterCompressor instead.  Will be supported
// throughout 1.x.
func WithDecompressor(dc Decompressor) DialOption <span class="cov0" title="0">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov0" title="0">{
                o.dc = dc
        }</span>)
}

// WithServiceConfig returns a DialOption which has a channel to read the
// service configuration.
//
// Deprecated: service config should be received through name resolver or via
// WithDefaultServiceConfig, as specified at
// https://github.com/grpc/grpc/blob/master/doc/service_config.md.  Will be
// removed in a future 1.x release.
func WithServiceConfig(c &lt;-chan ServiceConfig) DialOption <span class="cov0" title="0">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov0" title="0">{
                o.scChan = c
        }</span>)
}

// WithConnectParams configures the ClientConn to use the provided ConnectParams
// for creating and maintaining connections to servers.
//
// The backoff configuration specified as part of the ConnectParams overrides
// all defaults specified in
// https://github.com/grpc/grpc/blob/master/doc/connection-backoff.md. Consider
// using the backoff.DefaultConfig as a base, in cases where you want to
// override only a subset of the backoff configuration.
func WithConnectParams(p ConnectParams) DialOption <span class="cov8" title="1">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov8" title="1">{
                o.bs = internalbackoff.Exponential{Config: p.Backoff}
                o.minConnectTimeout = func() time.Duration </span><span class="cov8" title="1">{
                        return p.MinConnectTimeout
                }</span>
        })
}

// WithBackoffMaxDelay configures the dialer to use the provided maximum delay
// when backing off after failed connection attempts.
//
// Deprecated: use WithConnectParams instead. Will be supported throughout 1.x.
func WithBackoffMaxDelay(md time.Duration) DialOption <span class="cov8" title="1">{
        return WithBackoffConfig(BackoffConfig{MaxDelay: md})
}</span>

// WithBackoffConfig configures the dialer to use the provided backoff
// parameters after connection failures.
//
// Deprecated: use WithConnectParams instead. Will be supported throughout 1.x.
func WithBackoffConfig(b BackoffConfig) DialOption <span class="cov8" title="1">{
        bc := backoff.DefaultConfig
        bc.MaxDelay = b.MaxDelay
        return withBackoff(internalbackoff.Exponential{Config: bc})
}</span>

// withBackoff sets the backoff strategy used for connectRetryNum after a failed
// connection attempt.
//
// This can be exported if arbitrary backoff strategies are allowed by gRPC.
func withBackoff(bs internalbackoff.Strategy) DialOption <span class="cov8" title="1">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov8" title="1">{
                o.bs = bs
        }</span>)
}

// WithBlock returns a DialOption which makes callers of Dial block until the
// underlying connection is up. Without this, Dial returns immediately and
// connecting the server happens in background.
func WithBlock() DialOption <span class="cov8" title="1">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov8" title="1">{
                o.block = true
        }</span>)
}

// WithReturnConnectionError returns a DialOption which makes the client connection
// return a string containing both the last connection error that occurred and
// the context.DeadlineExceeded error.
// Implies WithBlock()
//
// # Experimental
//
// Notice: This API is EXPERIMENTAL and may be changed or removed in a
// later release.
func WithReturnConnectionError() DialOption <span class="cov8" title="1">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov8" title="1">{
                o.block = true
                o.returnLastError = true
        }</span>)
}

// WithInsecure returns a DialOption which disables transport security for this
// ClientConn. Under the hood, it uses insecure.NewCredentials().
//
// Note that using this DialOption with per-RPC credentials (through
// WithCredentialsBundle or WithPerRPCCredentials) which require transport
// security is incompatible and will cause grpc.Dial() to fail.
//
// Deprecated: use WithTransportCredentials and insecure.NewCredentials()
// instead. Will be supported throughout 1.x.
func WithInsecure() DialOption <span class="cov0" title="0">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov0" title="0">{
                o.copts.TransportCredentials = insecure.NewCredentials()
        }</span>)
}

// WithNoProxy returns a DialOption which disables the use of proxies for this
// ClientConn. This is ignored if WithDialer or WithContextDialer are used.
//
// # Experimental
//
// Notice: This API is EXPERIMENTAL and may be changed or removed in a
// later release.
func WithNoProxy() DialOption <span class="cov0" title="0">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov0" title="0">{
                o.copts.UseProxy = false
        }</span>)
}

// WithTransportCredentials returns a DialOption which configures a connection
// level security credentials (e.g., TLS/SSL). This should not be used together
// with WithCredentialsBundle.
func WithTransportCredentials(creds credentials.TransportCredentials) DialOption <span class="cov8" title="1">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov8" title="1">{
                o.copts.TransportCredentials = creds
        }</span>)
}

// WithPerRPCCredentials returns a DialOption which sets credentials and places
// auth state on each outbound RPC.
func WithPerRPCCredentials(creds credentials.PerRPCCredentials) DialOption <span class="cov8" title="1">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov8" title="1">{
                o.copts.PerRPCCredentials = append(o.copts.PerRPCCredentials, creds)
        }</span>)
}

// WithCredentialsBundle returns a DialOption to set a credentials bundle for
// the ClientConn.WithCreds. This should not be used together with
// WithTransportCredentials.
//
// # Experimental
//
// Notice: This API is EXPERIMENTAL and may be changed or removed in a
// later release.
func WithCredentialsBundle(b credentials.Bundle) DialOption <span class="cov8" title="1">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov8" title="1">{
                o.copts.CredsBundle = b
        }</span>)
}

// WithTimeout returns a DialOption that configures a timeout for dialing a
// ClientConn initially. This is valid if and only if WithBlock() is present.
//
// Deprecated: use DialContext instead of Dial and context.WithTimeout
// instead.  Will be supported throughout 1.x.
func WithTimeout(d time.Duration) DialOption <span class="cov8" title="1">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov8" title="1">{
                o.timeout = d
        }</span>)
}

// WithContextDialer returns a DialOption that sets a dialer to create
// connections. If FailOnNonTempDialError() is set to true, and an error is
// returned by f, gRPC checks the error's Temporary() method to decide if it
// should try to reconnect to the network address.
func WithContextDialer(f func(context.Context, string) (net.Conn, error)) DialOption <span class="cov8" title="1">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov8" title="1">{
                o.copts.Dialer = f
        }</span>)
}

func init() <span class="cov8" title="1">{
        internal.WithHealthCheckFunc = withHealthCheckFunc
}</span>

// WithDialer returns a DialOption that specifies a function to use for dialing
// network addresses. If FailOnNonTempDialError() is set to true, and an error
// is returned by f, gRPC checks the error's Temporary() method to decide if it
// should try to reconnect to the network address.
//
// Deprecated: use WithContextDialer instead.  Will be supported throughout
// 1.x.
func WithDialer(f func(string, time.Duration) (net.Conn, error)) DialOption <span class="cov8" title="1">{
        return WithContextDialer(
                func(ctx context.Context, addr string) (net.Conn, error) </span><span class="cov8" title="1">{
                        if deadline, ok := ctx.Deadline(); ok </span><span class="cov8" title="1">{
                                return f(addr, time.Until(deadline))
                        }</span>
                        <span class="cov0" title="0">return f(addr, 0)</span>
                })
}

// WithStatsHandler returns a DialOption that specifies the stats handler for
// all the RPCs and underlying network connections in this ClientConn.
func WithStatsHandler(h stats.Handler) DialOption <span class="cov0" title="0">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov0" title="0">{
                if h == nil </span><span class="cov0" title="0">{
                        logger.Error("ignoring nil parameter in grpc.WithStatsHandler ClientOption")
                        // Do not allow a nil stats handler, which would otherwise cause
                        // panics.
                        return
                }</span>
                <span class="cov0" title="0">o.copts.StatsHandlers = append(o.copts.StatsHandlers, h)</span>
        })
}

// FailOnNonTempDialError returns a DialOption that specifies if gRPC fails on
// non-temporary dial errors. If f is true, and dialer returns a non-temporary
// error, gRPC will fail the connection to the network address and won't try to
// reconnect. The default value of FailOnNonTempDialError is false.
//
// FailOnNonTempDialError only affects the initial dial, and does not do
// anything useful unless you are also using WithBlock().
//
// # Experimental
//
// Notice: This API is EXPERIMENTAL and may be changed or removed in a
// later release.
func FailOnNonTempDialError(f bool) DialOption <span class="cov8" title="1">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov8" title="1">{
                o.copts.FailOnNonTempDialError = f
        }</span>)
}

// WithUserAgent returns a DialOption that specifies a user agent string for all
// the RPCs.
func WithUserAgent(s string) DialOption <span class="cov0" title="0">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov0" title="0">{
                o.copts.UserAgent = s
        }</span>)
}

// WithKeepaliveParams returns a DialOption that specifies keepalive parameters
// for the client transport.
func WithKeepaliveParams(kp keepalive.ClientParameters) DialOption <span class="cov8" title="1">{
        if kp.Time &lt; internal.KeepaliveMinPingTime </span><span class="cov0" title="0">{
                logger.Warningf("Adjusting keepalive ping interval to minimum period of %v", internal.KeepaliveMinPingTime)
                kp.Time = internal.KeepaliveMinPingTime
        }</span>
        <span class="cov8" title="1">return newFuncDialOption(func(o *dialOptions) </span><span class="cov8" title="1">{
                o.copts.KeepaliveParams = kp
        }</span>)
}

// WithUnaryInterceptor returns a DialOption that specifies the interceptor for
// unary RPCs.
func WithUnaryInterceptor(f UnaryClientInterceptor) DialOption <span class="cov0" title="0">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov0" title="0">{
                o.unaryInt = f
        }</span>)
}

// WithChainUnaryInterceptor returns a DialOption that specifies the chained
// interceptor for unary RPCs. The first interceptor will be the outer most,
// while the last interceptor will be the inner most wrapper around the real call.
// All interceptors added by this method will be chained, and the interceptor
// defined by WithUnaryInterceptor will always be prepended to the chain.
func WithChainUnaryInterceptor(interceptors ...UnaryClientInterceptor) DialOption <span class="cov0" title="0">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov0" title="0">{
                o.chainUnaryInts = append(o.chainUnaryInts, interceptors...)
        }</span>)
}

// WithStreamInterceptor returns a DialOption that specifies the interceptor for
// streaming RPCs.
func WithStreamInterceptor(f StreamClientInterceptor) DialOption <span class="cov0" title="0">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov0" title="0">{
                o.streamInt = f
        }</span>)
}

// WithChainStreamInterceptor returns a DialOption that specifies the chained
// interceptor for streaming RPCs. The first interceptor will be the outer most,
// while the last interceptor will be the inner most wrapper around the real call.
// All interceptors added by this method will be chained, and the interceptor
// defined by WithStreamInterceptor will always be prepended to the chain.
func WithChainStreamInterceptor(interceptors ...StreamClientInterceptor) DialOption <span class="cov0" title="0">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov0" title="0">{
                o.chainStreamInts = append(o.chainStreamInts, interceptors...)
        }</span>)
}

// WithAuthority returns a DialOption that specifies the value to be used as the
// :authority pseudo-header and as the server name in authentication handshake.
func WithAuthority(a string) DialOption <span class="cov8" title="1">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov8" title="1">{
                o.authority = a
        }</span>)
}

// WithChannelzParentID returns a DialOption that specifies the channelz ID of
// current ClientConn's parent. This function is used in nested channel creation
// (e.g. grpclb dial).
//
// # Experimental
//
// Notice: This API is EXPERIMENTAL and may be changed or removed in a
// later release.
func WithChannelzParentID(id *channelz.Identifier) DialOption <span class="cov0" title="0">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov0" title="0">{
                o.channelzParentID = id
        }</span>)
}

// WithDisableServiceConfig returns a DialOption that causes gRPC to ignore any
// service config provided by the resolver and provides a hint to the resolver
// to not fetch service configs.
//
// Note that this dial option only disables service config from resolver. If
// default service config is provided, gRPC will use the default service config.
func WithDisableServiceConfig() DialOption <span class="cov8" title="1">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov8" title="1">{
                o.disableServiceConfig = true
        }</span>)
}

// WithDefaultServiceConfig returns a DialOption that configures the default
// service config, which will be used in cases where:
//
// 1. WithDisableServiceConfig is also used, or
//
// 2. The name resolver does not provide a service config or provides an
// invalid service config.
//
// The parameter s is the JSON representation of the default service config.
// For more information about service configs, see:
// https://github.com/grpc/grpc/blob/master/doc/service_config.md
// For a simple example of usage, see:
// examples/features/load_balancing/client/main.go
func WithDefaultServiceConfig(s string) DialOption <span class="cov8" title="1">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov8" title="1">{
                o.defaultServiceConfigRawJSON = &amp;s
        }</span>)
}

// WithDisableRetry returns a DialOption that disables retries, even if the
// service config enables them.  This does not impact transparent retries, which
// will happen automatically if no data is written to the wire or if the RPC is
// unprocessed by the remote server.
func WithDisableRetry() DialOption <span class="cov0" title="0">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov0" title="0">{
                o.disableRetry = true
        }</span>)
}

// WithMaxHeaderListSize returns a DialOption that specifies the maximum
// (uncompressed) size of header list that the client is prepared to accept.
func WithMaxHeaderListSize(s uint32) DialOption <span class="cov0" title="0">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov0" title="0">{
                o.copts.MaxHeaderListSize = &amp;s
        }</span>)
}

// WithDisableHealthCheck disables the LB channel health checking for all
// SubConns of this ClientConn.
//
// # Experimental
//
// Notice: This API is EXPERIMENTAL and may be changed or removed in a
// later release.
func WithDisableHealthCheck() DialOption <span class="cov0" title="0">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov0" title="0">{
                o.disableHealthCheck = true
        }</span>)
}

// withHealthCheckFunc replaces the default health check function with the
// provided one. It makes tests easier to change the health check function.
//
// For testing purpose only.
func withHealthCheckFunc(f internal.HealthChecker) DialOption <span class="cov0" title="0">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov0" title="0">{
                o.healthCheckFunc = f
        }</span>)
}

func defaultDialOptions() dialOptions <span class="cov8" title="1">{
        return dialOptions{
                healthCheckFunc: internal.HealthCheckFunc,
                copts: transport.ConnectOptions{
                        WriteBufferSize: defaultWriteBufSize,
                        ReadBufferSize:  defaultReadBufSize,
                        UseProxy:        true,
                },
        }
}</span>

// withGetMinConnectDeadline specifies the function that clientconn uses to
// get minConnectDeadline. This can be used to make connection attempts happen
// faster/slower.
//
// For testing purpose only.
func withMinConnectDeadline(f func() time.Duration) DialOption <span class="cov8" title="1">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov8" title="1">{
                o.minConnectTimeout = f
        }</span>)
}

// WithResolvers allows a list of resolver implementations to be registered
// locally with the ClientConn without needing to be globally registered via
// resolver.Register.  They will be matched against the scheme used for the
// current Dial only, and will take precedence over the global registry.
//
// # Experimental
//
// Notice: This API is EXPERIMENTAL and may be changed or removed in a
// later release.
func WithResolvers(rs ...resolver.Builder) DialOption <span class="cov8" title="1">{
        return newFuncDialOption(func(o *dialOptions) </span><span class="cov8" title="1">{
                o.resolvers = append(o.resolvers, rs...)
        }</span>)
}
</pre>
		
		<pre class="file" id="file61" style="display: none">/*
 *
 * Copyright 2018 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package proto defines the protobuf codec. Importing this package will
// register the codec.
package proto

import (
        "fmt"

        "github.com/golang/protobuf/proto"
        "google.golang.org/grpc/encoding"
)

// Name is the name registered for the proto compressor.
const Name = "proto"

func init() <span class="cov8" title="1">{
        encoding.RegisterCodec(codec{})
}</span>

// codec is a Codec implementation with protobuf. It is the default codec for gRPC.
type codec struct{}

func (codec) Marshal(v interface{}) ([]byte, error) <span class="cov8" title="1">{
        vv, ok := v.(proto.Message)
        if !ok </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to marshal, message is %T, want proto.Message", v)
        }</span>
        <span class="cov8" title="1">return proto.Marshal(vv)</span>
}

func (codec) Unmarshal(data []byte, v interface{}) error <span class="cov8" title="1">{
        vv, ok := v.(proto.Message)
        if !ok </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to unmarshal, message is %T, want proto.Message", v)
        }</span>
        <span class="cov8" title="1">return proto.Unmarshal(data, vv)</span>
}

func (codec) Name() string <span class="cov8" title="1">{
        return Name
}</span>
</pre>
		
		<pre class="file" id="file62" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package grpclog

import (
        "fmt"

        "google.golang.org/grpc/internal/grpclog"
)

// componentData records the settings for a component.
type componentData struct {
        name string
}

var cache = map[string]*componentData{}

func (c *componentData) InfoDepth(depth int, args ...interface{}) <span class="cov0" title="0">{
        args = append([]interface{}{"[" + string(c.name) + "]"}, args...)
        grpclog.InfoDepth(depth+1, args...)
}</span>

func (c *componentData) WarningDepth(depth int, args ...interface{}) <span class="cov0" title="0">{
        args = append([]interface{}{"[" + string(c.name) + "]"}, args...)
        grpclog.WarningDepth(depth+1, args...)
}</span>

func (c *componentData) ErrorDepth(depth int, args ...interface{}) <span class="cov0" title="0">{
        args = append([]interface{}{"[" + string(c.name) + "]"}, args...)
        grpclog.ErrorDepth(depth+1, args...)
}</span>

func (c *componentData) FatalDepth(depth int, args ...interface{}) <span class="cov0" title="0">{
        args = append([]interface{}{"[" + string(c.name) + "]"}, args...)
        grpclog.FatalDepth(depth+1, args...)
}</span>

func (c *componentData) Info(args ...interface{}) <span class="cov0" title="0">{
        c.InfoDepth(1, args...)
}</span>

func (c *componentData) Warning(args ...interface{}) <span class="cov0" title="0">{
        c.WarningDepth(1, args...)
}</span>

func (c *componentData) Error(args ...interface{}) <span class="cov0" title="0">{
        c.ErrorDepth(1, args...)
}</span>

func (c *componentData) Fatal(args ...interface{}) <span class="cov0" title="0">{
        c.FatalDepth(1, args...)
}</span>

func (c *componentData) Infof(format string, args ...interface{}) <span class="cov0" title="0">{
        c.InfoDepth(1, fmt.Sprintf(format, args...))
}</span>

func (c *componentData) Warningf(format string, args ...interface{}) <span class="cov0" title="0">{
        c.WarningDepth(1, fmt.Sprintf(format, args...))
}</span>

func (c *componentData) Errorf(format string, args ...interface{}) <span class="cov0" title="0">{
        c.ErrorDepth(1, fmt.Sprintf(format, args...))
}</span>

func (c *componentData) Fatalf(format string, args ...interface{}) <span class="cov0" title="0">{
        c.FatalDepth(1, fmt.Sprintf(format, args...))
}</span>

func (c *componentData) Infoln(args ...interface{}) <span class="cov0" title="0">{
        c.InfoDepth(1, args...)
}</span>

func (c *componentData) Warningln(args ...interface{}) <span class="cov0" title="0">{
        c.WarningDepth(1, args...)
}</span>

func (c *componentData) Errorln(args ...interface{}) <span class="cov0" title="0">{
        c.ErrorDepth(1, args...)
}</span>

func (c *componentData) Fatalln(args ...interface{}) <span class="cov0" title="0">{
        c.FatalDepth(1, args...)
}</span>

func (c *componentData) V(l int) bool <span class="cov0" title="0">{
        return V(l)
}</span>

// Component creates a new component and returns it for logging. If a component
// with the name already exists, nothing will be created and it will be
// returned. SetLoggerV2 will panic if it is called with a logger created by
// Component.
func Component(componentName string) DepthLoggerV2 <span class="cov0" title="0">{
        if cData, ok := cache[componentName]; ok </span><span class="cov0" title="0">{
                return cData
        }</span>
        <span class="cov0" title="0">c := &amp;componentData{componentName}
        cache[componentName] = c
        return c</span>
}
</pre>
		
		<pre class="file" id="file63" style="display: none">/*
 *
 * Copyright 2017 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package grpclog defines logging for grpc.
//
// All logs in transport and grpclb packages only go to verbose level 2.
// All logs in other packages in grpc are logged in spite of the verbosity level.
//
// In the default logger,
// severity level can be set by environment variable GRPC_GO_LOG_SEVERITY_LEVEL,
// verbosity level can be set by GRPC_GO_LOG_VERBOSITY_LEVEL.
package grpclog // import "google.golang.org/grpc/grpclog"

import (
        "os"

        "google.golang.org/grpc/internal/grpclog"
)

func init() <span class="cov8" title="1">{
        SetLoggerV2(newLoggerV2())
}</span>

// V reports whether verbosity level l is at least the requested verbose level.
func V(l int) bool <span class="cov0" title="0">{
        return grpclog.Logger.V(l)
}</span>

// Info logs to the INFO log.
func Info(args ...interface{}) <span class="cov8" title="1">{
        grpclog.Logger.Info(args...)
}</span>

// Infof logs to the INFO log. Arguments are handled in the manner of fmt.Printf.
func Infof(format string, args ...interface{}) <span class="cov0" title="0">{
        grpclog.Logger.Infof(format, args...)
}</span>

// Infoln logs to the INFO log. Arguments are handled in the manner of fmt.Println.
func Infoln(args ...interface{}) <span class="cov0" title="0">{
        grpclog.Logger.Infoln(args...)
}</span>

// Warning logs to the WARNING log.
func Warning(args ...interface{}) <span class="cov8" title="1">{
        grpclog.Logger.Warning(args...)
}</span>

// Warningf logs to the WARNING log. Arguments are handled in the manner of fmt.Printf.
func Warningf(format string, args ...interface{}) <span class="cov0" title="0">{
        grpclog.Logger.Warningf(format, args...)
}</span>

// Warningln logs to the WARNING log. Arguments are handled in the manner of fmt.Println.
func Warningln(args ...interface{}) <span class="cov0" title="0">{
        grpclog.Logger.Warningln(args...)
}</span>

// Error logs to the ERROR log.
func Error(args ...interface{}) <span class="cov8" title="1">{
        grpclog.Logger.Error(args...)
}</span>

// Errorf logs to the ERROR log. Arguments are handled in the manner of fmt.Printf.
func Errorf(format string, args ...interface{}) <span class="cov0" title="0">{
        grpclog.Logger.Errorf(format, args...)
}</span>

// Errorln logs to the ERROR log. Arguments are handled in the manner of fmt.Println.
func Errorln(args ...interface{}) <span class="cov0" title="0">{
        grpclog.Logger.Errorln(args...)
}</span>

// Fatal logs to the FATAL log. Arguments are handled in the manner of fmt.Print.
// It calls os.Exit() with exit code 1.
func Fatal(args ...interface{}) <span class="cov0" title="0">{
        grpclog.Logger.Fatal(args...)
        // Make sure fatal logs will exit.
        os.Exit(1)
}</span>

// Fatalf logs to the FATAL log. Arguments are handled in the manner of fmt.Printf.
// It calls os.Exit() with exit code 1.
func Fatalf(format string, args ...interface{}) <span class="cov0" title="0">{
        grpclog.Logger.Fatalf(format, args...)
        // Make sure fatal logs will exit.
        os.Exit(1)
}</span>

// Fatalln logs to the FATAL log. Arguments are handled in the manner of fmt.Println.
// It calle os.Exit()) with exit code 1.
func Fatalln(args ...interface{}) <span class="cov0" title="0">{
        grpclog.Logger.Fatalln(args...)
        // Make sure fatal logs will exit.
        os.Exit(1)
}</span>

// Print prints to the logger. Arguments are handled in the manner of fmt.Print.
//
// Deprecated: use Info.
func Print(args ...interface{}) <span class="cov0" title="0">{
        grpclog.Logger.Info(args...)
}</span>

// Printf prints to the logger. Arguments are handled in the manner of fmt.Printf.
//
// Deprecated: use Infof.
func Printf(format string, args ...interface{}) <span class="cov0" title="0">{
        grpclog.Logger.Infof(format, args...)
}</span>

// Println prints to the logger. Arguments are handled in the manner of fmt.Println.
//
// Deprecated: use Infoln.
func Println(args ...interface{}) <span class="cov0" title="0">{
        grpclog.Logger.Infoln(args...)
}</span>
</pre>
		
		<pre class="file" id="file64" style="display: none">/*
 *
 * Copyright 2015 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package grpclog

import "google.golang.org/grpc/internal/grpclog"

// Logger mimics golang's standard Logger as an interface.
//
// Deprecated: use LoggerV2.
type Logger interface {
        Fatal(args ...interface{})
        Fatalf(format string, args ...interface{})
        Fatalln(args ...interface{})
        Print(args ...interface{})
        Printf(format string, args ...interface{})
        Println(args ...interface{})
}

// SetLogger sets the logger that is used in grpc. Call only from
// init() functions.
//
// Deprecated: use SetLoggerV2.
func SetLogger(l Logger) <span class="cov0" title="0">{
        grpclog.Logger = &amp;loggerWrapper{Logger: l}
}</span>

// loggerWrapper wraps Logger into a LoggerV2.
type loggerWrapper struct {
        Logger
}

func (g *loggerWrapper) Info(args ...interface{}) <span class="cov0" title="0">{
        g.Logger.Print(args...)
}</span>

func (g *loggerWrapper) Infoln(args ...interface{}) <span class="cov0" title="0">{
        g.Logger.Println(args...)
}</span>

func (g *loggerWrapper) Infof(format string, args ...interface{}) <span class="cov0" title="0">{
        g.Logger.Printf(format, args...)
}</span>

func (g *loggerWrapper) Warning(args ...interface{}) <span class="cov0" title="0">{
        g.Logger.Print(args...)
}</span>

func (g *loggerWrapper) Warningln(args ...interface{}) <span class="cov0" title="0">{
        g.Logger.Println(args...)
}</span>

func (g *loggerWrapper) Warningf(format string, args ...interface{}) <span class="cov0" title="0">{
        g.Logger.Printf(format, args...)
}</span>

func (g *loggerWrapper) Error(args ...interface{}) <span class="cov0" title="0">{
        g.Logger.Print(args...)
}</span>

func (g *loggerWrapper) Errorln(args ...interface{}) <span class="cov0" title="0">{
        g.Logger.Println(args...)
}</span>

func (g *loggerWrapper) Errorf(format string, args ...interface{}) <span class="cov0" title="0">{
        g.Logger.Printf(format, args...)
}</span>

func (g *loggerWrapper) V(l int) bool <span class="cov0" title="0">{
        // Returns true for all verbose level.
        return true
}</span>
</pre>
		
		<pre class="file" id="file65" style="display: none">/*
 *
 * Copyright 2017 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package grpclog

import (
        "encoding/json"
        "fmt"
        "io"
        "io/ioutil"
        "log"
        "os"
        "strconv"
        "strings"

        "google.golang.org/grpc/internal/grpclog"
)

// LoggerV2 does underlying logging work for grpclog.
type LoggerV2 interface {
        // Info logs to INFO log. Arguments are handled in the manner of fmt.Print.
        Info(args ...interface{})
        // Infoln logs to INFO log. Arguments are handled in the manner of fmt.Println.
        Infoln(args ...interface{})
        // Infof logs to INFO log. Arguments are handled in the manner of fmt.Printf.
        Infof(format string, args ...interface{})
        // Warning logs to WARNING log. Arguments are handled in the manner of fmt.Print.
        Warning(args ...interface{})
        // Warningln logs to WARNING log. Arguments are handled in the manner of fmt.Println.
        Warningln(args ...interface{})
        // Warningf logs to WARNING log. Arguments are handled in the manner of fmt.Printf.
        Warningf(format string, args ...interface{})
        // Error logs to ERROR log. Arguments are handled in the manner of fmt.Print.
        Error(args ...interface{})
        // Errorln logs to ERROR log. Arguments are handled in the manner of fmt.Println.
        Errorln(args ...interface{})
        // Errorf logs to ERROR log. Arguments are handled in the manner of fmt.Printf.
        Errorf(format string, args ...interface{})
        // Fatal logs to ERROR log. Arguments are handled in the manner of fmt.Print.
        // gRPC ensures that all Fatal logs will exit with os.Exit(1).
        // Implementations may also call os.Exit() with a non-zero exit code.
        Fatal(args ...interface{})
        // Fatalln logs to ERROR log. Arguments are handled in the manner of fmt.Println.
        // gRPC ensures that all Fatal logs will exit with os.Exit(1).
        // Implementations may also call os.Exit() with a non-zero exit code.
        Fatalln(args ...interface{})
        // Fatalf logs to ERROR log. Arguments are handled in the manner of fmt.Printf.
        // gRPC ensures that all Fatal logs will exit with os.Exit(1).
        // Implementations may also call os.Exit() with a non-zero exit code.
        Fatalf(format string, args ...interface{})
        // V reports whether verbosity level l is at least the requested verbose level.
        V(l int) bool
}

// SetLoggerV2 sets logger that is used in grpc to a V2 logger.
// Not mutex-protected, should be called before any gRPC functions.
func SetLoggerV2(l LoggerV2) <span class="cov8" title="1">{
        if _, ok := l.(*componentData); ok </span><span class="cov0" title="0">{
                panic("cannot use component logger as grpclog logger")</span>
        }
        <span class="cov8" title="1">grpclog.Logger = l
        grpclog.DepthLogger, _ = l.(grpclog.DepthLoggerV2)</span>
}

const (
        // infoLog indicates Info severity.
        infoLog int = iota
        // warningLog indicates Warning severity.
        warningLog
        // errorLog indicates Error severity.
        errorLog
        // fatalLog indicates Fatal severity.
        fatalLog
)

// severityName contains the string representation of each severity.
var severityName = []string{
        infoLog:    "INFO",
        warningLog: "WARNING",
        errorLog:   "ERROR",
        fatalLog:   "FATAL",
}

// loggerT is the default logger used by grpclog.
type loggerT struct {
        m          []*log.Logger
        v          int
        jsonFormat bool
}

// NewLoggerV2 creates a loggerV2 with the provided writers.
// Fatal logs will be written to errorW, warningW, infoW, followed by exit(1).
// Error logs will be written to errorW, warningW and infoW.
// Warning logs will be written to warningW and infoW.
// Info logs will be written to infoW.
func NewLoggerV2(infoW, warningW, errorW io.Writer) LoggerV2 <span class="cov8" title="1">{
        return newLoggerV2WithConfig(infoW, warningW, errorW, loggerV2Config{})
}</span>

// NewLoggerV2WithVerbosity creates a loggerV2 with the provided writers and
// verbosity level.
func NewLoggerV2WithVerbosity(infoW, warningW, errorW io.Writer, v int) LoggerV2 <span class="cov0" title="0">{
        return newLoggerV2WithConfig(infoW, warningW, errorW, loggerV2Config{verbose: v})
}</span>

type loggerV2Config struct {
        verbose    int
        jsonFormat bool
}

func newLoggerV2WithConfig(infoW, warningW, errorW io.Writer, c loggerV2Config) LoggerV2 <span class="cov8" title="1">{
        var m []*log.Logger
        flag := log.LstdFlags
        if c.jsonFormat </span><span class="cov0" title="0">{
                flag = 0
        }</span>
        <span class="cov8" title="1">m = append(m, log.New(infoW, "", flag))
        m = append(m, log.New(io.MultiWriter(infoW, warningW), "", flag))
        ew := io.MultiWriter(infoW, warningW, errorW) // ew will be used for error and fatal.
        m = append(m, log.New(ew, "", flag))
        m = append(m, log.New(ew, "", flag))
        return &amp;loggerT{m: m, v: c.verbose, jsonFormat: c.jsonFormat}</span>
}

// newLoggerV2 creates a loggerV2 to be used as default logger.
// All logs are written to stderr.
func newLoggerV2() LoggerV2 <span class="cov8" title="1">{
        errorW := ioutil.Discard
        warningW := ioutil.Discard
        infoW := ioutil.Discard

        logLevel := os.Getenv("GRPC_GO_LOG_SEVERITY_LEVEL")
        switch logLevel </span>{
        case "", "ERROR", "error":<span class="cov8" title="1"> // If env is unset, set level to ERROR.
                errorW = os.Stderr</span>
        case "WARNING", "warning":<span class="cov0" title="0">
                warningW = os.Stderr</span>
        case "INFO", "info":<span class="cov0" title="0">
                infoW = os.Stderr</span>
        }

        <span class="cov8" title="1">var v int
        vLevel := os.Getenv("GRPC_GO_LOG_VERBOSITY_LEVEL")
        if vl, err := strconv.Atoi(vLevel); err == nil </span><span class="cov0" title="0">{
                v = vl
        }</span>

        <span class="cov8" title="1">jsonFormat := strings.EqualFold(os.Getenv("GRPC_GO_LOG_FORMATTER"), "json")

        return newLoggerV2WithConfig(infoW, warningW, errorW, loggerV2Config{
                verbose:    v,
                jsonFormat: jsonFormat,
        })</span>
}

func (g *loggerT) output(severity int, s string) <span class="cov8" title="1">{
        sevStr := severityName[severity]
        if !g.jsonFormat </span><span class="cov8" title="1">{
                g.m[severity].Output(2, fmt.Sprintf("%v: %v", sevStr, s))
                return
        }</span>
        // TODO: we can also include the logging component, but that needs more
        // (API) changes.
        <span class="cov0" title="0">b, _ := json.Marshal(map[string]string{
                "severity": sevStr,
                "message":  s,
        })
        g.m[severity].Output(2, string(b))</span>
}

func (g *loggerT) Info(args ...interface{}) <span class="cov8" title="1">{
        g.output(infoLog, fmt.Sprint(args...))
}</span>

func (g *loggerT) Infoln(args ...interface{}) <span class="cov0" title="0">{
        g.output(infoLog, fmt.Sprintln(args...))
}</span>

func (g *loggerT) Infof(format string, args ...interface{}) <span class="cov0" title="0">{
        g.output(infoLog, fmt.Sprintf(format, args...))
}</span>

func (g *loggerT) Warning(args ...interface{}) <span class="cov8" title="1">{
        g.output(warningLog, fmt.Sprint(args...))
}</span>

func (g *loggerT) Warningln(args ...interface{}) <span class="cov0" title="0">{
        g.output(warningLog, fmt.Sprintln(args...))
}</span>

func (g *loggerT) Warningf(format string, args ...interface{}) <span class="cov0" title="0">{
        g.output(warningLog, fmt.Sprintf(format, args...))
}</span>

func (g *loggerT) Error(args ...interface{}) <span class="cov8" title="1">{
        g.output(errorLog, fmt.Sprint(args...))
}</span>

func (g *loggerT) Errorln(args ...interface{}) <span class="cov0" title="0">{
        g.output(errorLog, fmt.Sprintln(args...))
}</span>

func (g *loggerT) Errorf(format string, args ...interface{}) <span class="cov0" title="0">{
        g.output(errorLog, fmt.Sprintf(format, args...))
}</span>

func (g *loggerT) Fatal(args ...interface{}) <span class="cov0" title="0">{
        g.output(fatalLog, fmt.Sprint(args...))
        os.Exit(1)
}</span>

func (g *loggerT) Fatalln(args ...interface{}) <span class="cov0" title="0">{
        g.output(fatalLog, fmt.Sprintln(args...))
        os.Exit(1)
}</span>

func (g *loggerT) Fatalf(format string, args ...interface{}) <span class="cov0" title="0">{
        g.output(fatalLog, fmt.Sprintf(format, args...))
        os.Exit(1)
}</span>

func (g *loggerT) V(l int) bool <span class="cov0" title="0">{
        return l &lt;= g.v
}</span>

// DepthLoggerV2 logs at a specified call frame. If a LoggerV2 also implements
// DepthLoggerV2, the below functions will be called with the appropriate stack
// depth set for trivial functions the logger may ignore.
//
// Experimental
//
// Notice: This type is EXPERIMENTAL and may be changed or removed in a
// later release.
type DepthLoggerV2 interface {
        LoggerV2
        // InfoDepth logs to INFO log at the specified depth. Arguments are handled in the manner of fmt.Println.
        InfoDepth(depth int, args ...interface{})
        // WarningDepth logs to WARNING log at the specified depth. Arguments are handled in the manner of fmt.Println.
        WarningDepth(depth int, args ...interface{})
        // ErrorDepth logs to ERROR log at the specified depth. Arguments are handled in the manner of fmt.Println.
        ErrorDepth(depth int, args ...interface{})
        // FatalDepth logs to FATAL log at the specified depth. Arguments are handled in the manner of fmt.Println.
        FatalDepth(depth int, args ...interface{})
}
</pre>
		
		<pre class="file" id="file66" style="display: none">/*
 *
 * Copyright 2018 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package health

import (
        "context"
        "fmt"
        "io"
        "time"

        "google.golang.org/grpc"
        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/connectivity"
        healthpb "google.golang.org/grpc/health/grpc_health_v1"
        "google.golang.org/grpc/internal"
        "google.golang.org/grpc/internal/backoff"
        "google.golang.org/grpc/status"
)

var (
        backoffStrategy = backoff.DefaultExponential
        backoffFunc     = func(ctx context.Context, retries int) bool <span class="cov0" title="0">{
                d := backoffStrategy.Backoff(retries)
                timer := time.NewTimer(d)
                select </span>{
                case &lt;-timer.C:<span class="cov0" title="0">
                        return true</span>
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        timer.Stop()
                        return false</span>
                }
        }
)

func init() <span class="cov8" title="1">{
        internal.HealthCheckFunc = clientHealthCheck
}</span>

const healthCheckMethod = "/grpc.health.v1.Health/Watch"

// This function implements the protocol defined at:
// https://github.com/grpc/grpc/blob/master/doc/health-checking.md
func clientHealthCheck(ctx context.Context, newStream func(string) (interface{}, error), setConnectivityState func(connectivity.State, error), service string) error <span class="cov8" title="1">{
        tryCnt := 0

retryConnection:
        for </span><span class="cov8" title="1">{
                // Backs off if the connection has failed in some way without receiving a message in the previous retry.
                if tryCnt &gt; 0 &amp;&amp; !backoffFunc(ctx, tryCnt-1) </span><span class="cov0" title="0">{
                        return nil
                }</span>
                <span class="cov8" title="1">tryCnt++

                if ctx.Err() != nil </span><span class="cov0" title="0">{
                        return nil
                }</span>
                <span class="cov8" title="1">setConnectivityState(connectivity.Connecting, nil)
                rawS, err := newStream(healthCheckMethod)
                if err != nil </span><span class="cov8" title="1">{
                        continue retryConnection</span>
                }

                <span class="cov8" title="1">s, ok := rawS.(grpc.ClientStream)
                // Ideally, this should never happen. But if it happens, the server is marked as healthy for LBing purposes.
                if !ok </span><span class="cov8" title="1">{
                        setConnectivityState(connectivity.Ready, nil)
                        return fmt.Errorf("newStream returned %v (type %T); want grpc.ClientStream", rawS, rawS)
                }</span>

                <span class="cov0" title="0">if err = s.SendMsg(&amp;healthpb.HealthCheckRequest{Service: service}); err != nil &amp;&amp; err != io.EOF </span><span class="cov0" title="0">{
                        // Stream should have been closed, so we can safely continue to create a new stream.
                        continue retryConnection</span>
                }
                <span class="cov0" title="0">s.CloseSend()

                resp := new(healthpb.HealthCheckResponse)
                for </span><span class="cov0" title="0">{
                        err = s.RecvMsg(resp)

                        // Reports healthy for the LBing purposes if health check is not implemented in the server.
                        if status.Code(err) == codes.Unimplemented </span><span class="cov0" title="0">{
                                setConnectivityState(connectivity.Ready, nil)
                                return err
                        }</span>

                        // Reports unhealthy if server's Watch method gives an error other than UNIMPLEMENTED.
                        <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                                setConnectivityState(connectivity.TransientFailure, fmt.Errorf("connection active but received health check RPC error: %v", err))
                                continue retryConnection</span>
                        }

                        // As a message has been received, removes the need for backoff for the next retry by resetting the try count.
                        <span class="cov0" title="0">tryCnt = 0
                        if resp.Status == healthpb.HealthCheckResponse_SERVING </span><span class="cov0" title="0">{
                                setConnectivityState(connectivity.Ready, nil)
                        }</span> else<span class="cov0" title="0"> {
                                setConnectivityState(connectivity.TransientFailure, fmt.Errorf("connection active but health check failed. status=%s", resp.Status))
                        }</span>
                }
        }
}
</pre>
		
		<pre class="file" id="file67" style="display: none">/*
 *
 * Copyright 2017 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package health provides a service that exposes server's health and it must be
// imported to enable support for client-side health checks.
package health

import (
        "context"
        "sync"

        "google.golang.org/grpc/codes"
        healthgrpc "google.golang.org/grpc/health/grpc_health_v1"
        healthpb "google.golang.org/grpc/health/grpc_health_v1"
        "google.golang.org/grpc/status"
)

// Server implements `service Health`.
type Server struct {
        healthgrpc.UnimplementedHealthServer
        mu sync.RWMutex
        // If shutdown is true, it's expected all serving status is NOT_SERVING, and
        // will stay in NOT_SERVING.
        shutdown bool
        // statusMap stores the serving status of the services this Server monitors.
        statusMap map[string]healthpb.HealthCheckResponse_ServingStatus
        updates   map[string]map[healthgrpc.Health_WatchServer]chan healthpb.HealthCheckResponse_ServingStatus
}

// NewServer returns a new Server.
func NewServer() *Server <span class="cov8" title="1">{
        return &amp;Server{
                statusMap: map[string]healthpb.HealthCheckResponse_ServingStatus{"": healthpb.HealthCheckResponse_SERVING},
                updates:   make(map[string]map[healthgrpc.Health_WatchServer]chan healthpb.HealthCheckResponse_ServingStatus),
        }
}</span>

// Check implements `service Health`.
func (s *Server) Check(ctx context.Context, in *healthpb.HealthCheckRequest) (*healthpb.HealthCheckResponse, error) <span class="cov0" title="0">{
        s.mu.RLock()
        defer s.mu.RUnlock()
        if servingStatus, ok := s.statusMap[in.Service]; ok </span><span class="cov0" title="0">{
                return &amp;healthpb.HealthCheckResponse{
                        Status: servingStatus,
                }, nil
        }</span>
        <span class="cov0" title="0">return nil, status.Error(codes.NotFound, "unknown service")</span>
}

// Watch implements `service Health`.
func (s *Server) Watch(in *healthpb.HealthCheckRequest, stream healthgrpc.Health_WatchServer) error <span class="cov0" title="0">{
        service := in.Service
        // update channel is used for getting service status updates.
        update := make(chan healthpb.HealthCheckResponse_ServingStatus, 1)
        s.mu.Lock()
        // Puts the initial status to the channel.
        if servingStatus, ok := s.statusMap[service]; ok </span><span class="cov0" title="0">{
                update &lt;- servingStatus
        }</span> else<span class="cov0" title="0"> {
                update &lt;- healthpb.HealthCheckResponse_SERVICE_UNKNOWN
        }</span>

        // Registers the update channel to the correct place in the updates map.
        <span class="cov0" title="0">if _, ok := s.updates[service]; !ok </span><span class="cov0" title="0">{
                s.updates[service] = make(map[healthgrpc.Health_WatchServer]chan healthpb.HealthCheckResponse_ServingStatus)
        }</span>
        <span class="cov0" title="0">s.updates[service][stream] = update
        defer func() </span><span class="cov0" title="0">{
                s.mu.Lock()
                delete(s.updates[service], stream)
                s.mu.Unlock()
        }</span>()
        <span class="cov0" title="0">s.mu.Unlock()

        var lastSentStatus healthpb.HealthCheckResponse_ServingStatus = -1
        for </span><span class="cov0" title="0">{
                select </span>{
                // Status updated. Sends the up-to-date status to the client.
                case servingStatus := &lt;-update:<span class="cov0" title="0">
                        if lastSentStatus == servingStatus </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        <span class="cov0" title="0">lastSentStatus = servingStatus
                        err := stream.Send(&amp;healthpb.HealthCheckResponse{Status: servingStatus})
                        if err != nil </span><span class="cov0" title="0">{
                                return status.Error(codes.Canceled, "Stream has ended.")
                        }</span>
                // Context done. Removes the update channel from the updates map.
                case &lt;-stream.Context().Done():<span class="cov0" title="0">
                        return status.Error(codes.Canceled, "Stream has ended.")</span>
                }
        }
}

// SetServingStatus is called when need to reset the serving status of a service
// or insert a new service entry into the statusMap.
func (s *Server) SetServingStatus(service string, servingStatus healthpb.HealthCheckResponse_ServingStatus) <span class="cov8" title="1">{
        s.mu.Lock()
        defer s.mu.Unlock()
        if s.shutdown </span><span class="cov8" title="1">{
                logger.Infof("health: status changing for %s to %v is ignored because health service is shutdown", service, servingStatus)
                return
        }</span>

        <span class="cov8" title="1">s.setServingStatusLocked(service, servingStatus)</span>
}

func (s *Server) setServingStatusLocked(service string, servingStatus healthpb.HealthCheckResponse_ServingStatus) <span class="cov8" title="1">{
        s.statusMap[service] = servingStatus
        for _, update := range s.updates[service] </span><span class="cov0" title="0">{
                // Clears previous updates, that are not sent to the client, from the channel.
                // This can happen if the client is not reading and the server gets flow control limited.
                select </span>{
                case &lt;-update:<span class="cov0" title="0"></span>
                default:<span class="cov0" title="0"></span>
                }
                // Puts the most recent update to the channel.
                <span class="cov0" title="0">update &lt;- servingStatus</span>
        }
}

// Shutdown sets all serving status to NOT_SERVING, and configures the server to
// ignore all future status changes.
//
// This changes serving status for all services. To set status for a particular
// services, call SetServingStatus().
func (s *Server) Shutdown() <span class="cov8" title="1">{
        s.mu.Lock()
        defer s.mu.Unlock()
        s.shutdown = true
        for service := range s.statusMap </span><span class="cov8" title="1">{
                s.setServingStatusLocked(service, healthpb.HealthCheckResponse_NOT_SERVING)
        }</span>
}

// Resume sets all serving status to SERVING, and configures the server to
// accept all future status changes.
//
// This changes serving status for all services. To set status for a particular
// services, call SetServingStatus().
func (s *Server) Resume() <span class="cov8" title="1">{
        s.mu.Lock()
        defer s.mu.Unlock()
        s.shutdown = false
        for service := range s.statusMap </span><span class="cov8" title="1">{
                s.setServingStatusLocked(service, healthpb.HealthCheckResponse_SERVING)
        }</span>
}
</pre>
		
		<pre class="file" id="file68" style="display: none">/*
 *
 * Copyright 2022 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package gracefulswitch implements a graceful switch load balancer.
package gracefulswitch

import (
        "errors"
        "fmt"
        "sync"

        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/balancer/base"
        "google.golang.org/grpc/connectivity"
        "google.golang.org/grpc/resolver"
)

var errBalancerClosed = errors.New("gracefulSwitchBalancer is closed")
var _ balancer.Balancer = (*Balancer)(nil)

// NewBalancer returns a graceful switch Balancer.
func NewBalancer(cc balancer.ClientConn, opts balancer.BuildOptions) *Balancer <span class="cov8" title="1">{
        return &amp;Balancer{
                cc:    cc,
                bOpts: opts,
        }
}</span>

// Balancer is a utility to gracefully switch from one balancer to
// a new balancer. It implements the balancer.Balancer interface.
type Balancer struct {
        bOpts balancer.BuildOptions
        cc    balancer.ClientConn

        // mu protects the following fields and all fields within balancerCurrent
        // and balancerPending. mu does not need to be held when calling into the
        // child balancers, as all calls into these children happen only as a direct
        // result of a call into the gracefulSwitchBalancer, which are also
        // guaranteed to be synchronous. There is one exception: an UpdateState call
        // from a child balancer when current and pending are populated can lead to
        // calling Close() on the current. To prevent that racing with an
        // UpdateSubConnState from the channel, we hold currentMu during Close and
        // UpdateSubConnState calls.
        mu              sync.Mutex
        balancerCurrent *balancerWrapper
        balancerPending *balancerWrapper
        closed          bool // set to true when this balancer is closed

        // currentMu must be locked before mu. This mutex guards against this
        // sequence of events: UpdateSubConnState() called, finds the
        // balancerCurrent, gives up lock, updateState comes in, causes Close() on
        // balancerCurrent before the UpdateSubConnState is called on the
        // balancerCurrent.
        currentMu sync.Mutex
}

// swap swaps out the current lb with the pending lb and updates the ClientConn.
// The caller must hold gsb.mu.
func (gsb *Balancer) swap() <span class="cov8" title="1">{
        gsb.cc.UpdateState(gsb.balancerPending.lastState)
        cur := gsb.balancerCurrent
        gsb.balancerCurrent = gsb.balancerPending
        gsb.balancerPending = nil
        go func() </span><span class="cov8" title="1">{
                gsb.currentMu.Lock()
                defer gsb.currentMu.Unlock()
                cur.Close()
        }</span>()
}

// Helper function that checks if the balancer passed in is current or pending.
// The caller must hold gsb.mu.
func (gsb *Balancer) balancerCurrentOrPending(bw *balancerWrapper) bool <span class="cov8" title="1">{
        return bw == gsb.balancerCurrent || bw == gsb.balancerPending
}</span>

// SwitchTo initializes the graceful switch process, which completes based on
// connectivity state changes on the current/pending balancer. Thus, the switch
// process is not complete when this method returns. This method must be called
// synchronously alongside the rest of the balancer.Balancer methods this
// Graceful Switch Balancer implements.
func (gsb *Balancer) SwitchTo(builder balancer.Builder) error <span class="cov8" title="1">{
        gsb.mu.Lock()
        if gsb.closed </span><span class="cov8" title="1">{
                gsb.mu.Unlock()
                return errBalancerClosed
        }</span>
        <span class="cov8" title="1">bw := &amp;balancerWrapper{
                gsb: gsb,
                lastState: balancer.State{
                        ConnectivityState: connectivity.Connecting,
                        Picker:            base.NewErrPicker(balancer.ErrNoSubConnAvailable),
                },
                subconns: make(map[balancer.SubConn]bool),
        }
        balToClose := gsb.balancerPending // nil if there is no pending balancer
        if gsb.balancerCurrent == nil </span><span class="cov8" title="1">{
                gsb.balancerCurrent = bw
        }</span> else<span class="cov8" title="1"> {
                gsb.balancerPending = bw
        }</span>
        <span class="cov8" title="1">gsb.mu.Unlock()
        balToClose.Close()
        // This function takes a builder instead of a balancer because builder.Build
        // can call back inline, and this utility needs to handle the callbacks.
        newBalancer := builder.Build(bw, gsb.bOpts)
        if newBalancer == nil </span><span class="cov0" title="0">{
                // This is illegal and should never happen; we clear the balancerWrapper
                // we were constructing if it happens to avoid a potential panic.
                gsb.mu.Lock()
                if gsb.balancerPending != nil </span><span class="cov0" title="0">{
                        gsb.balancerPending = nil
                }</span> else<span class="cov0" title="0"> {
                        gsb.balancerCurrent = nil
                }</span>
                <span class="cov0" title="0">gsb.mu.Unlock()
                return balancer.ErrBadResolverState</span>
        }

        // This write doesn't need to take gsb.mu because this field never gets read
        // or written to on any calls from the current or pending. Calls from grpc
        // to this balancer are guaranteed to be called synchronously, so this
        // bw.Balancer field will never be forwarded to until this SwitchTo()
        // function returns.
        <span class="cov8" title="1">bw.Balancer = newBalancer
        return nil</span>
}

// Returns nil if the graceful switch balancer is closed.
func (gsb *Balancer) latestBalancer() *balancerWrapper <span class="cov8" title="1">{
        gsb.mu.Lock()
        defer gsb.mu.Unlock()
        if gsb.balancerPending != nil </span><span class="cov8" title="1">{
                return gsb.balancerPending
        }</span>
        <span class="cov8" title="1">return gsb.balancerCurrent</span>
}

// UpdateClientConnState forwards the update to the latest balancer created.
func (gsb *Balancer) UpdateClientConnState(state balancer.ClientConnState) error <span class="cov8" title="1">{
        // The resolver data is only relevant to the most recent LB Policy.
        balToUpdate := gsb.latestBalancer()
        if balToUpdate == nil </span><span class="cov8" title="1">{
                return errBalancerClosed
        }</span>
        // Perform this call without gsb.mu to prevent deadlocks if the child calls
        // back into the channel. The latest balancer can never be closed during a
        // call from the channel, even without gsb.mu held.
        <span class="cov8" title="1">return balToUpdate.UpdateClientConnState(state)</span>
}

// ResolverError forwards the error to the latest balancer created.
func (gsb *Balancer) ResolverError(err error) <span class="cov8" title="1">{
        // The resolver data is only relevant to the most recent LB Policy.
        balToUpdate := gsb.latestBalancer()
        if balToUpdate == nil </span><span class="cov8" title="1">{
                return
        }</span>
        // Perform this call without gsb.mu to prevent deadlocks if the child calls
        // back into the channel. The latest balancer can never be closed during a
        // call from the channel, even without gsb.mu held.
        <span class="cov8" title="1">balToUpdate.ResolverError(err)</span>
}

// ExitIdle forwards the call to the latest balancer created.
//
// If the latest balancer does not support ExitIdle, the subConns are
// re-connected to manually.
func (gsb *Balancer) ExitIdle() <span class="cov8" title="1">{
        balToUpdate := gsb.latestBalancer()
        if balToUpdate == nil </span><span class="cov0" title="0">{
                return
        }</span>
        // There is no need to protect this read with a mutex, as the write to the
        // Balancer field happens in SwitchTo, which completes before this can be
        // called.
        <span class="cov8" title="1">if ei, ok := balToUpdate.Balancer.(balancer.ExitIdler); ok </span><span class="cov8" title="1">{
                ei.ExitIdle()
                return
        }</span>
        <span class="cov8" title="1">gsb.mu.Lock()
        defer gsb.mu.Unlock()
        for sc := range balToUpdate.subconns </span><span class="cov8" title="1">{
                sc.Connect()
        }</span>
}

// UpdateSubConnState forwards the update to the appropriate child.
func (gsb *Balancer) UpdateSubConnState(sc balancer.SubConn, state balancer.SubConnState) <span class="cov8" title="1">{
        gsb.currentMu.Lock()
        defer gsb.currentMu.Unlock()
        gsb.mu.Lock()
        // Forward update to the appropriate child.  Even if there is a pending
        // balancer, the current balancer should continue to get SubConn updates to
        // maintain the proper state while the pending is still connecting.
        var balToUpdate *balancerWrapper
        if gsb.balancerCurrent != nil &amp;&amp; gsb.balancerCurrent.subconns[sc] </span><span class="cov8" title="1">{
                balToUpdate = gsb.balancerCurrent
        }</span> else<span class="cov8" title="1"> if gsb.balancerPending != nil &amp;&amp; gsb.balancerPending.subconns[sc] </span><span class="cov8" title="1">{
                balToUpdate = gsb.balancerPending
        }</span>
        <span class="cov8" title="1">gsb.mu.Unlock()
        if balToUpdate == nil </span><span class="cov8" title="1">{
                // SubConn belonged to a stale lb policy that has not yet fully closed,
                // or the balancer was already closed.
                return
        }</span>
        <span class="cov8" title="1">balToUpdate.UpdateSubConnState(sc, state)</span>
}

// Close closes any active child balancers.
func (gsb *Balancer) Close() <span class="cov8" title="1">{
        gsb.mu.Lock()
        gsb.closed = true
        currentBalancerToClose := gsb.balancerCurrent
        gsb.balancerCurrent = nil
        pendingBalancerToClose := gsb.balancerPending
        gsb.balancerPending = nil
        gsb.mu.Unlock()

        currentBalancerToClose.Close()
        pendingBalancerToClose.Close()
}</span>

// balancerWrapper wraps a balancer.Balancer, and overrides some Balancer
// methods to help cleanup SubConns created by the wrapped balancer.
//
// It implements the balancer.ClientConn interface and is passed down in that
// capacity to the wrapped balancer. It maintains a set of subConns created by
// the wrapped balancer and calls from the latter to create/update/remove
// SubConns update this set before being forwarded to the parent ClientConn.
// State updates from the wrapped balancer can result in invocation of the
// graceful switch logic.
type balancerWrapper struct {
        balancer.Balancer
        gsb *Balancer

        lastState balancer.State
        subconns  map[balancer.SubConn]bool // subconns created by this balancer
}

func (bw *balancerWrapper) UpdateSubConnState(sc balancer.SubConn, state balancer.SubConnState) <span class="cov8" title="1">{
        if state.ConnectivityState == connectivity.Shutdown </span><span class="cov0" title="0">{
                bw.gsb.mu.Lock()
                delete(bw.subconns, sc)
                bw.gsb.mu.Unlock()
        }</span>
        // There is no need to protect this read with a mutex, as the write to the
        // Balancer field happens in SwitchTo, which completes before this can be
        // called.
        <span class="cov8" title="1">bw.Balancer.UpdateSubConnState(sc, state)</span>
}

// Close closes the underlying LB policy and removes the subconns it created. bw
// must not be referenced via balancerCurrent or balancerPending in gsb when
// called. gsb.mu must not be held.  Does not panic with a nil receiver.
func (bw *balancerWrapper) Close() <span class="cov8" title="1">{
        // before Close is called.
        if bw == nil </span><span class="cov8" title="1">{
                return
        }</span>
        // There is no need to protect this read with a mutex, as Close() is
        // impossible to be called concurrently with the write in SwitchTo(). The
        // callsites of Close() for this balancer in Graceful Switch Balancer will
        // never be called until SwitchTo() returns.
        <span class="cov8" title="1">bw.Balancer.Close()
        bw.gsb.mu.Lock()
        for sc := range bw.subconns </span><span class="cov8" title="1">{
                bw.gsb.cc.RemoveSubConn(sc)
        }</span>
        <span class="cov8" title="1">bw.gsb.mu.Unlock()</span>
}

func (bw *balancerWrapper) UpdateState(state balancer.State) <span class="cov8" title="1">{
        // Hold the mutex for this entire call to ensure it cannot occur
        // concurrently with other updateState() calls. This causes updates to
        // lastState and calls to cc.UpdateState to happen atomically.
        bw.gsb.mu.Lock()
        defer bw.gsb.mu.Unlock()
        bw.lastState = state

        if !bw.gsb.balancerCurrentOrPending(bw) </span><span class="cov8" title="1">{
                return
        }</span>

        <span class="cov8" title="1">if bw == bw.gsb.balancerCurrent </span><span class="cov8" title="1">{
                // In the case that the current balancer exits READY, and there is a pending
                // balancer, you can forward the pending balancer's cached State up to
                // ClientConn and swap the pending into the current. This is because there
                // is no reason to gracefully switch from and keep using the old policy as
                // the ClientConn is not connected to any backends.
                if state.ConnectivityState != connectivity.Ready &amp;&amp; bw.gsb.balancerPending != nil </span><span class="cov8" title="1">{
                        bw.gsb.swap()
                        return
                }</span>
                // Even if there is a pending balancer waiting to be gracefully switched to,
                // continue to forward current balancer updates to the Client Conn. Ignoring
                // state + picker from the current would cause undefined behavior/cause the
                // system to behave incorrectly from the current LB policies perspective.
                // Also, the current LB is still being used by grpc to choose SubConns per
                // RPC, and thus should use the most updated form of the current balancer.
                <span class="cov8" title="1">bw.gsb.cc.UpdateState(state)
                return</span>
        }
        // This method is now dealing with a state update from the pending balancer.
        // If the current balancer is currently in a state other than READY, the new
        // policy can be swapped into place immediately. This is because there is no
        // reason to gracefully switch from and keep using the old policy as the
        // ClientConn is not connected to any backends.
        <span class="cov8" title="1">if state.ConnectivityState != connectivity.Connecting || bw.gsb.balancerCurrent.lastState.ConnectivityState != connectivity.Ready </span><span class="cov8" title="1">{
                bw.gsb.swap()
        }</span>
}

func (bw *balancerWrapper) NewSubConn(addrs []resolver.Address, opts balancer.NewSubConnOptions) (balancer.SubConn, error) <span class="cov8" title="1">{
        bw.gsb.mu.Lock()
        if !bw.gsb.balancerCurrentOrPending(bw) </span><span class="cov8" title="1">{
                bw.gsb.mu.Unlock()
                return nil, fmt.Errorf("%T at address %p that called NewSubConn is deleted", bw, bw)
        }</span>
        <span class="cov8" title="1">bw.gsb.mu.Unlock()

        sc, err := bw.gsb.cc.NewSubConn(addrs, opts)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">bw.gsb.mu.Lock()
        if !bw.gsb.balancerCurrentOrPending(bw) </span><span class="cov0" title="0">{ // balancer was closed during this call
                bw.gsb.cc.RemoveSubConn(sc)
                bw.gsb.mu.Unlock()
                return nil, fmt.Errorf("%T at address %p that called NewSubConn is deleted", bw, bw)
        }</span>
        <span class="cov8" title="1">bw.subconns[sc] = true
        bw.gsb.mu.Unlock()
        return sc, nil</span>
}

func (bw *balancerWrapper) ResolveNow(opts resolver.ResolveNowOptions) <span class="cov0" title="0">{
        // Ignore ResolveNow requests from anything other than the most recent
        // balancer, because older balancers were already removed from the config.
        if bw != bw.gsb.latestBalancer() </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov0" title="0">bw.gsb.cc.ResolveNow(opts)</span>
}

func (bw *balancerWrapper) RemoveSubConn(sc balancer.SubConn) <span class="cov8" title="1">{
        bw.gsb.mu.Lock()
        if !bw.gsb.balancerCurrentOrPending(bw) </span><span class="cov0" title="0">{
                bw.gsb.mu.Unlock()
                return
        }</span>
        <span class="cov8" title="1">bw.gsb.mu.Unlock()
        bw.gsb.cc.RemoveSubConn(sc)</span>
}

func (bw *balancerWrapper) UpdateAddresses(sc balancer.SubConn, addrs []resolver.Address) <span class="cov8" title="1">{
        bw.gsb.mu.Lock()
        if !bw.gsb.balancerCurrentOrPending(bw) </span><span class="cov0" title="0">{
                bw.gsb.mu.Unlock()
                return
        }</span>
        <span class="cov8" title="1">bw.gsb.mu.Unlock()
        bw.gsb.cc.UpdateAddresses(sc, addrs)</span>
}

func (bw *balancerWrapper) Target() string <span class="cov0" title="0">{
        return bw.gsb.cc.Target()
}</span>
</pre>
		
		<pre class="file" id="file69" style="display: none">/*
 * Copyright 2019 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// Package balancergroup implements a utility struct to bind multiple balancers
// into one balancer.
package balancergroup

import (
        "fmt"
        "sync"
        "time"

        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/connectivity"
        "google.golang.org/grpc/internal/balancer/gracefulswitch"
        "google.golang.org/grpc/internal/cache"
        "google.golang.org/grpc/internal/grpclog"
        "google.golang.org/grpc/resolver"
)

// subBalancerWrapper is used to keep the configurations that will be used to start
// the underlying balancer. It can be called to start/stop the underlying
// balancer.
//
// When the config changes, it will pass the update to the underlying balancer
// if it exists.
//
// TODO: move to a separate file?
type subBalancerWrapper struct {
        // subBalancerWrapper is passed to the sub-balancer as a ClientConn
        // wrapper, only to keep the state and picker.  When sub-balancer is
        // restarted while in cache, the picker needs to be resent.
        //
        // It also contains the sub-balancer ID, so the parent balancer group can
        // keep track of SubConn/pickers and the sub-balancers they belong to. Some
        // of the actions are forwarded to the parent ClientConn with no change.
        // Some are forward to balancer group with the sub-balancer ID.
        balancer.ClientConn
        id    string
        group *BalancerGroup

        mu    sync.Mutex
        state balancer.State

        // The static part of sub-balancer. Keeps balancerBuilders and addresses.
        // To be used when restarting sub-balancer.
        builder balancer.Builder
        // Options to be passed to sub-balancer at the time of creation.
        buildOpts balancer.BuildOptions
        // ccState is a cache of the addresses/balancer config, so when the balancer
        // is restarted after close, it will get the previous update. It's a pointer
        // and is set to nil at init, so when the balancer is built for the first
        // time (not a restart), it won't receive an empty update. Note that this
        // isn't reset to nil when the underlying balancer is closed.
        ccState *balancer.ClientConnState
        // The dynamic part of sub-balancer. Only used when balancer group is
        // started. Gets cleared when sub-balancer is closed.
        balancer *gracefulswitch.Balancer
}

// UpdateState overrides balancer.ClientConn, to keep state and picker.
func (sbc *subBalancerWrapper) UpdateState(state balancer.State) <span class="cov8" title="1">{
        sbc.mu.Lock()
        sbc.state = state
        sbc.group.updateBalancerState(sbc.id, state)
        sbc.mu.Unlock()
}</span>

// NewSubConn overrides balancer.ClientConn, so balancer group can keep track of
// the relation between subconns and sub-balancers.
func (sbc *subBalancerWrapper) NewSubConn(addrs []resolver.Address, opts balancer.NewSubConnOptions) (balancer.SubConn, error) <span class="cov8" title="1">{
        return sbc.group.newSubConn(sbc, addrs, opts)
}</span>

func (sbc *subBalancerWrapper) updateBalancerStateWithCachedPicker() <span class="cov8" title="1">{
        sbc.mu.Lock()
        if sbc.state.Picker != nil </span><span class="cov8" title="1">{
                sbc.group.updateBalancerState(sbc.id, sbc.state)
        }</span>
        <span class="cov8" title="1">sbc.mu.Unlock()</span>
}

func (sbc *subBalancerWrapper) startBalancer() <span class="cov8" title="1">{
        if sbc.balancer == nil </span><span class="cov8" title="1">{
                sbc.balancer = gracefulswitch.NewBalancer(sbc, sbc.buildOpts)
        }</span>
        <span class="cov8" title="1">sbc.group.logger.Infof("Creating child policy of type %v", sbc.builder.Name())
        sbc.balancer.SwitchTo(sbc.builder)
        if sbc.ccState != nil </span><span class="cov8" title="1">{
                sbc.balancer.UpdateClientConnState(*sbc.ccState)
        }</span>
}

// exitIdle invokes the sub-balancer's ExitIdle method. Returns a boolean
// indicating whether or not the operation was completed.
func (sbc *subBalancerWrapper) exitIdle() (complete bool) <span class="cov8" title="1">{
        b := sbc.balancer
        if b == nil </span><span class="cov0" title="0">{
                return true
        }</span>
        <span class="cov8" title="1">b.ExitIdle()
        return true</span>
}

func (sbc *subBalancerWrapper) updateSubConnState(sc balancer.SubConn, state balancer.SubConnState) <span class="cov8" title="1">{
        b := sbc.balancer
        if b == nil </span><span class="cov0" title="0">{
                // This sub-balancer was closed. This can happen when EDS removes a
                // locality. The balancer for this locality was already closed, and the
                // SubConns are being deleted. But SubConn state change can still
                // happen.
                return
        }</span>
        <span class="cov8" title="1">b.UpdateSubConnState(sc, state)</span>
}

func (sbc *subBalancerWrapper) updateClientConnState(s balancer.ClientConnState) error <span class="cov8" title="1">{
        sbc.ccState = &amp;s
        b := sbc.balancer
        if b == nil </span><span class="cov8" title="1">{
                // This sub-balancer was closed. This should never happen because
                // sub-balancers are closed when the locality is removed from EDS, or
                // the balancer group is closed. There should be no further address
                // updates when either of this happened.
                //
                // This will be a common case with priority support, because a
                // sub-balancer (and the whole balancer group) could be closed because
                // it's the lower priority, but it can still get address updates.
                return nil
        }</span>
        <span class="cov8" title="1">return b.UpdateClientConnState(s)</span>
}

func (sbc *subBalancerWrapper) resolverError(err error) <span class="cov0" title="0">{
        b := sbc.balancer
        if b == nil </span><span class="cov0" title="0">{
                // This sub-balancer was closed. This should never happen because
                // sub-balancers are closed when the locality is removed from EDS, or
                // the balancer group is closed. There should be no further address
                // updates when either of this happened.
                //
                // This will be a common case with priority support, because a
                // sub-balancer (and the whole balancer group) could be closed because
                // it's the lower priority, but it can still get address updates.
                return
        }</span>
        <span class="cov0" title="0">b.ResolverError(err)</span>
}

func (sbc *subBalancerWrapper) gracefulSwitch(builder balancer.Builder) <span class="cov8" title="1">{
        sbc.builder = builder
        b := sbc.balancer
        // Even if you get an add and it persists builder but doesn't start
        // balancer, this would leave graceful switch being nil, in which we are
        // correctly overwriting with the recent builder here as well to use later.
        // The graceful switch balancer's presence is an invariant of whether the
        // balancer group is closed or not (if closed, nil, if started, present).
        if sbc.balancer != nil </span><span class="cov8" title="1">{
                sbc.group.logger.Infof("Switching child policy %v to type %v", sbc.id, sbc.builder.Name())
                b.SwitchTo(sbc.builder)
        }</span>
}

func (sbc *subBalancerWrapper) stopBalancer() <span class="cov8" title="1">{
        sbc.balancer.Close()
        sbc.balancer = nil
}</span>

// BalancerGroup takes a list of balancers, and make them into one balancer.
//
// Note that this struct doesn't implement balancer.Balancer, because it's not
// intended to be used directly as a balancer. It's expected to be used as a
// sub-balancer manager by a high level balancer.
//
// Updates from ClientConn are forwarded to sub-balancers
//  - service config update
//  - address update
//  - subConn state change
//     - find the corresponding balancer and forward
//
// Actions from sub-balances are forwarded to parent ClientConn
//  - new/remove SubConn
//  - picker update and health states change
//     - sub-pickers are sent to an aggregator provided by the parent, which
//     will group them into a group-picker. The aggregated connectivity state is
//     also handled by the aggregator.
//  - resolveNow
//
// Sub-balancers are only built when the balancer group is started. If the
// balancer group is closed, the sub-balancers are also closed. And it's
// guaranteed that no updates will be sent to parent ClientConn from a closed
// balancer group.
type BalancerGroup struct {
        cc        balancer.ClientConn
        buildOpts balancer.BuildOptions
        logger    *grpclog.PrefixLogger

        // stateAggregator is where the state/picker updates will be sent to. It's
        // provided by the parent balancer, to build a picker with all the
        // sub-pickers.
        stateAggregator BalancerStateAggregator

        // outgoingMu guards all operations in the direction:
        // ClientConn--&gt;Sub-balancer. Including start, stop, resolver updates and
        // SubConn state changes.
        //
        // The corresponding boolean outgoingStarted is used to stop further updates
        // to sub-balancers after they are closed.
        outgoingMu         sync.Mutex
        outgoingStarted    bool
        idToBalancerConfig map[string]*subBalancerWrapper
        // Cache for sub-balancers when they are removed.
        balancerCache *cache.TimeoutCache

        // incomingMu is to make sure this balancer group doesn't send updates to cc
        // after it's closed.
        //
        // We don't share the mutex to avoid deadlocks (e.g. a call to sub-balancer
        // may call back to balancer group inline. It causes deaclock if they
        // require the same mutex).
        //
        // We should never need to hold multiple locks at the same time in this
        // struct. The case where two locks are held can only happen when the
        // underlying balancer calls back into balancer group inline. So there's an
        // implicit lock acquisition order that outgoingMu is locked before
        // incomingMu.

        // incomingMu guards all operations in the direction:
        // Sub-balancer--&gt;ClientConn. Including NewSubConn, RemoveSubConn. It also
        // guards the map from SubConn to balancer ID, so updateSubConnState needs
        // to hold it shortly to find the sub-balancer to forward the update.
        //
        // UpdateState is called by the balancer state aggretator, and it will
        // decide when and whether to call.
        //
        // The corresponding boolean incomingStarted is used to stop further updates
        // from sub-balancers after they are closed.
        incomingMu      sync.Mutex
        incomingStarted bool // This boolean only guards calls back to ClientConn.
        scToSubBalancer map[balancer.SubConn]*subBalancerWrapper
}

// DefaultSubBalancerCloseTimeout is defined as a variable instead of const for
// testing.
//
// TODO: make it a parameter for New().
var DefaultSubBalancerCloseTimeout = 15 * time.Minute

// New creates a new BalancerGroup. Note that the BalancerGroup
// needs to be started to work.
func New(cc balancer.ClientConn, bOpts balancer.BuildOptions, stateAggregator BalancerStateAggregator, logger *grpclog.PrefixLogger) *BalancerGroup <span class="cov8" title="1">{
        return &amp;BalancerGroup{
                cc:              cc,
                buildOpts:       bOpts,
                logger:          logger,
                stateAggregator: stateAggregator,

                idToBalancerConfig: make(map[string]*subBalancerWrapper),
                balancerCache:      cache.NewTimeoutCache(DefaultSubBalancerCloseTimeout),
                scToSubBalancer:    make(map[balancer.SubConn]*subBalancerWrapper),
        }
}</span>

// Start starts the balancer group, including building all the sub-balancers,
// and send the existing addresses to them.
//
// A BalancerGroup can be closed and started later. When a BalancerGroup is
// closed, it can still receive address updates, which will be applied when
// restarted.
func (bg *BalancerGroup) Start() <span class="cov8" title="1">{
        bg.incomingMu.Lock()
        bg.incomingStarted = true
        bg.incomingMu.Unlock()

        bg.outgoingMu.Lock()
        if bg.outgoingStarted </span><span class="cov0" title="0">{
                bg.outgoingMu.Unlock()
                return
        }</span>

        <span class="cov8" title="1">for _, config := range bg.idToBalancerConfig </span><span class="cov8" title="1">{
                config.startBalancer()
        }</span>
        <span class="cov8" title="1">bg.outgoingStarted = true
        bg.outgoingMu.Unlock()</span>
}

// Add adds a balancer built by builder to the group, with given id.
func (bg *BalancerGroup) Add(id string, builder balancer.Builder) <span class="cov8" title="1">{
        // Store data in static map, and then check to see if bg is started.
        bg.outgoingMu.Lock()
        var sbc *subBalancerWrapper
        // If outgoingStarted is true, search in the cache. Otherwise, cache is
        // guaranteed to be empty, searching is unnecessary.
        if bg.outgoingStarted </span><span class="cov8" title="1">{
                if old, ok := bg.balancerCache.Remove(id); ok </span><span class="cov8" title="1">{
                        sbc, _ = old.(*subBalancerWrapper)
                        if sbc != nil &amp;&amp; sbc.builder != builder </span><span class="cov8" title="1">{
                                // If the sub-balancer in cache was built with a different
                                // balancer builder, don't use it, cleanup this old-balancer,
                                // and behave as sub-balancer is not found in cache.
                                //
                                // NOTE that this will also drop the cached addresses for this
                                // sub-balancer, which seems to be reasonable.
                                sbc.stopBalancer()
                                // cleanupSubConns must be done before the new balancer starts,
                                // otherwise new SubConns created by the new balancer might be
                                // removed by mistake.
                                bg.cleanupSubConns(sbc)
                                sbc = nil
                        }</span>
                }
        }
        <span class="cov8" title="1">if sbc == nil </span><span class="cov8" title="1">{
                sbc = &amp;subBalancerWrapper{
                        ClientConn: bg.cc,
                        id:         id,
                        group:      bg,
                        builder:    builder,
                        buildOpts:  bg.buildOpts,
                }
                if bg.outgoingStarted </span><span class="cov8" title="1">{
                        // Only start the balancer if bg is started. Otherwise, we only keep the
                        // static data.
                        sbc.startBalancer()
                }</span>
        } else<span class="cov8" title="1"> {
                // When brining back a sub-balancer from cache, re-send the cached
                // picker and state.
                sbc.updateBalancerStateWithCachedPicker()
        }</span>
        <span class="cov8" title="1">bg.idToBalancerConfig[id] = sbc
        bg.outgoingMu.Unlock()</span>
}

// UpdateBuilder updates the builder for a current child, starting the Graceful
// Switch process for that child.
func (bg *BalancerGroup) UpdateBuilder(id string, builder balancer.Builder) <span class="cov8" title="1">{
        bg.outgoingMu.Lock()
        // This does not deal with the balancer cache because this call should come
        // after an Add call for a given child balancer. If the child is removed,
        // the caller will call Add if the child balancer comes back which would
        // then deal with the balancer cache.
        sbc := bg.idToBalancerConfig[id]
        if sbc == nil </span><span class="cov0" title="0">{
                // simply ignore it if not present, don't error
                return
        }</span>
        <span class="cov8" title="1">sbc.gracefulSwitch(builder)
        bg.outgoingMu.Unlock()</span>
}

// Remove removes the balancer with id from the group.
//
// But doesn't close the balancer. The balancer is kept in a cache, and will be
// closed after timeout. Cleanup work (closing sub-balancer and removing
// subconns) will be done after timeout.
func (bg *BalancerGroup) Remove(id string) <span class="cov8" title="1">{
        bg.outgoingMu.Lock()
        if sbToRemove, ok := bg.idToBalancerConfig[id]; ok </span><span class="cov8" title="1">{
                if bg.outgoingStarted </span><span class="cov8" title="1">{
                        bg.balancerCache.Add(id, sbToRemove, func() </span><span class="cov8" title="1">{
                                // After timeout, when sub-balancer is removed from cache, need
                                // to close the underlying sub-balancer, and remove all its
                                // subconns.
                                bg.outgoingMu.Lock()
                                if bg.outgoingStarted </span><span class="cov8" title="1">{
                                        sbToRemove.stopBalancer()
                                }</span>
                                <span class="cov8" title="1">bg.outgoingMu.Unlock()
                                bg.cleanupSubConns(sbToRemove)</span>
                        })
                }
                <span class="cov8" title="1">delete(bg.idToBalancerConfig, id)</span>
        } else<span class="cov0" title="0"> {
                bg.logger.Infof("balancer group: trying to remove a non-existing locality from balancer group: %v", id)
        }</span>
        <span class="cov8" title="1">bg.outgoingMu.Unlock()</span>
}

// bg.remove(id) doesn't do cleanup for the sub-balancer. This function does
// cleanup after the timeout.
func (bg *BalancerGroup) cleanupSubConns(config *subBalancerWrapper) <span class="cov8" title="1">{
        bg.incomingMu.Lock()
        // Remove SubConns. This is only done after the balancer is
        // actually closed.
        //
        // NOTE: if NewSubConn is called by this (closed) balancer later, the
        // SubConn will be leaked. This shouldn't happen if the balancer
        // implementation is correct. To make sure this never happens, we need to
        // add another layer (balancer manager) between balancer group and the
        // sub-balancers.
        for sc, b := range bg.scToSubBalancer </span><span class="cov8" title="1">{
                if b == config </span><span class="cov8" title="1">{
                        delete(bg.scToSubBalancer, sc)
                }</span>
        }
        <span class="cov8" title="1">bg.incomingMu.Unlock()</span>
}

// connect attempts to connect to all subConns belonging to sb.
func (bg *BalancerGroup) connect(sb *subBalancerWrapper) <span class="cov0" title="0">{
        bg.incomingMu.Lock()
        for sc, b := range bg.scToSubBalancer </span><span class="cov0" title="0">{
                if b == sb </span><span class="cov0" title="0">{
                        sc.Connect()
                }</span>
        }
        <span class="cov0" title="0">bg.incomingMu.Unlock()</span>
}

// Following are actions from the parent grpc.ClientConn, forward to sub-balancers.

// UpdateSubConnState handles the state for the subconn. It finds the
// corresponding balancer and forwards the update.
func (bg *BalancerGroup) UpdateSubConnState(sc balancer.SubConn, state balancer.SubConnState) <span class="cov8" title="1">{
        bg.incomingMu.Lock()
        config, ok := bg.scToSubBalancer[sc]
        if !ok </span><span class="cov8" title="1">{
                bg.incomingMu.Unlock()
                return
        }</span>
        <span class="cov8" title="1">if state.ConnectivityState == connectivity.Shutdown </span><span class="cov0" title="0">{
                // Only delete sc from the map when state changed to Shutdown.
                delete(bg.scToSubBalancer, sc)
        }</span>
        <span class="cov8" title="1">bg.incomingMu.Unlock()

        bg.outgoingMu.Lock()
        config.updateSubConnState(sc, state)
        bg.outgoingMu.Unlock()</span>
}

// UpdateClientConnState handles ClientState (including balancer config and
// addresses) from resolver. It finds the balancer and forwards the update.
func (bg *BalancerGroup) UpdateClientConnState(id string, s balancer.ClientConnState) error <span class="cov8" title="1">{
        bg.outgoingMu.Lock()
        defer bg.outgoingMu.Unlock()
        if config, ok := bg.idToBalancerConfig[id]; ok </span><span class="cov8" title="1">{
                return config.updateClientConnState(s)
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// ResolverError forwards resolver errors to all sub-balancers.
func (bg *BalancerGroup) ResolverError(err error) <span class="cov0" title="0">{
        bg.outgoingMu.Lock()
        for _, config := range bg.idToBalancerConfig </span><span class="cov0" title="0">{
                config.resolverError(err)
        }</span>
        <span class="cov0" title="0">bg.outgoingMu.Unlock()</span>
}

// Following are actions from sub-balancers, forward to ClientConn.

// newSubConn: forward to ClientConn, and also create a map from sc to balancer,
// so state update will find the right balancer.
//
// One note about removing SubConn: only forward to ClientConn, but not delete
// from map. Delete sc from the map only when state changes to Shutdown. Since
// it's just forwarding the action, there's no need for a removeSubConn()
// wrapper function.
func (bg *BalancerGroup) newSubConn(config *subBalancerWrapper, addrs []resolver.Address, opts balancer.NewSubConnOptions) (balancer.SubConn, error) <span class="cov8" title="1">{
        // NOTE: if balancer with id was already removed, this should also return
        // error. But since we call balancer.stopBalancer when removing the balancer, this
        // shouldn't happen.
        bg.incomingMu.Lock()
        if !bg.incomingStarted </span><span class="cov0" title="0">{
                bg.incomingMu.Unlock()
                return nil, fmt.Errorf("NewSubConn is called after balancer group is closed")
        }</span>
        <span class="cov8" title="1">sc, err := bg.cc.NewSubConn(addrs, opts)
        if err != nil </span><span class="cov0" title="0">{
                bg.incomingMu.Unlock()
                return nil, err
        }</span>
        <span class="cov8" title="1">bg.scToSubBalancer[sc] = config
        bg.incomingMu.Unlock()
        return sc, nil</span>
}

// updateBalancerState: forward the new state to balancer state aggregator. The
// aggregator will create an aggregated picker and an aggregated connectivity
// state, then forward to ClientConn.
func (bg *BalancerGroup) updateBalancerState(id string, state balancer.State) <span class="cov8" title="1">{
        bg.logger.Infof("Balancer state update from locality %v, new state: %+v", id, state)

        // Send new state to the aggregator, without holding the incomingMu.
        // incomingMu is to protect all calls to the parent ClientConn, this update
        // doesn't necessary trigger a call to ClientConn, and should already be
        // protected by aggregator's mutex if necessary.
        if bg.stateAggregator != nil </span><span class="cov8" title="1">{
                bg.stateAggregator.UpdateState(id, state)
        }</span>
}

// Close closes the balancer. It stops sub-balancers, and removes the subconns.
// The BalancerGroup can be restarted later.
func (bg *BalancerGroup) Close() <span class="cov8" title="1">{
        bg.incomingMu.Lock()
        if bg.incomingStarted </span><span class="cov8" title="1">{
                bg.incomingStarted = false
                // Also remove all SubConns.
                for sc := range bg.scToSubBalancer </span><span class="cov8" title="1">{
                        bg.cc.RemoveSubConn(sc)
                        delete(bg.scToSubBalancer, sc)
                }</span>
        }
        <span class="cov8" title="1">bg.incomingMu.Unlock()

        // Clear(true) runs clear function to close sub-balancers in cache. It
        // must be called out of outgoing mutex.
        bg.balancerCache.Clear(true)

        bg.outgoingMu.Lock()
        if bg.outgoingStarted </span><span class="cov8" title="1">{
                bg.outgoingStarted = false
                for _, config := range bg.idToBalancerConfig </span><span class="cov8" title="1">{
                        config.stopBalancer()
                }</span>
        }
        <span class="cov8" title="1">bg.outgoingMu.Unlock()</span>
}

// ExitIdle should be invoked when the parent LB policy's ExitIdle is invoked.
// It will trigger this on all sub-balancers, or reconnect their subconns if
// not supported.
func (bg *BalancerGroup) ExitIdle() <span class="cov0" title="0">{
        bg.outgoingMu.Lock()
        for _, config := range bg.idToBalancerConfig </span><span class="cov0" title="0">{
                if !config.exitIdle() </span><span class="cov0" title="0">{
                        bg.connect(config)
                }</span>
        }
        <span class="cov0" title="0">bg.outgoingMu.Unlock()</span>
}

// ExitIdleOne instructs the sub-balancer `id` to exit IDLE state, if
// appropriate and possible.
func (bg *BalancerGroup) ExitIdleOne(id string) <span class="cov8" title="1">{
        bg.outgoingMu.Lock()
        if config := bg.idToBalancerConfig[id]; config != nil </span><span class="cov8" title="1">{
                if !config.exitIdle() </span><span class="cov0" title="0">{
                        bg.connect(config)
                }</span>
        }
        <span class="cov8" title="1">bg.outgoingMu.Unlock()</span>
}
</pre>
		
		<pre class="file" id="file70" style="display: none">/*
 *
 * Copyright 2018 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package binarylog implementation binary logging as defined in
// https://github.com/grpc/proposal/blob/master/A16-binary-logging.md.
package binarylog

import (
        "fmt"
        "os"

        "google.golang.org/grpc/grpclog"
        "google.golang.org/grpc/internal/grpcutil"
)

// Logger is the global binary logger. It can be used to get binary logger for
// each method.
type Logger interface {
        GetMethodLogger(methodName string) MethodLogger
}

// binLogger is the global binary logger for the binary. One of this should be
// built at init time from the configuration (environment variable or flags).
//
// It is used to get a methodLogger for each individual method.
var binLogger Logger

var grpclogLogger = grpclog.Component("binarylog")

// SetLogger sets the binary logger.
//
// Only call this at init time.
func SetLogger(l Logger) <span class="cov0" title="0">{
        binLogger = l
}</span>

// GetLogger gets the binary logger.
//
// Only call this at init time.
func GetLogger() Logger <span class="cov0" title="0">{
        return binLogger
}</span>

// GetMethodLogger returns the methodLogger for the given methodName.
//
// methodName should be in the format of "/service/method".
//
// Each methodLogger returned by this method is a new instance. This is to
// generate sequence id within the call.
func GetMethodLogger(methodName string) MethodLogger <span class="cov0" title="0">{
        if binLogger == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">return binLogger.GetMethodLogger(methodName)</span>
}

func init() <span class="cov8" title="1">{
        const envStr = "GRPC_BINARY_LOG_FILTER"
        configStr := os.Getenv(envStr)
        binLogger = NewLoggerFromConfigString(configStr)
}</span>

// MethodLoggerConfig contains the setting for logging behavior of a method
// logger. Currently, it contains the max length of header and message.
type MethodLoggerConfig struct {
        // Max length of header and message.
        Header, Message uint64
}

// LoggerConfig contains the config for loggers to create method loggers.
type LoggerConfig struct {
        All      *MethodLoggerConfig
        Services map[string]*MethodLoggerConfig
        Methods  map[string]*MethodLoggerConfig

        Blacklist map[string]struct{}
}

type logger struct {
        config LoggerConfig
}

// NewLoggerFromConfig builds a logger with the given LoggerConfig.
func NewLoggerFromConfig(config LoggerConfig) Logger <span class="cov0" title="0">{
        return &amp;logger{config: config}
}</span>

// newEmptyLogger creates an empty logger. The map fields need to be filled in
// using the set* functions.
func newEmptyLogger() *logger <span class="cov8" title="1">{
        return &amp;logger{}
}</span>

// Set method logger for "*".
func (l *logger) setDefaultMethodLogger(ml *MethodLoggerConfig) error <span class="cov8" title="1">{
        if l.config.All != nil </span><span class="cov8" title="1">{
                return fmt.Errorf("conflicting global rules found")
        }</span>
        <span class="cov8" title="1">l.config.All = ml
        return nil</span>
}

// Set method logger for "service/*".
//
// New methodLogger with same service overrides the old one.
func (l *logger) setServiceMethodLogger(service string, ml *MethodLoggerConfig) error <span class="cov8" title="1">{
        if _, ok := l.config.Services[service]; ok </span><span class="cov8" title="1">{
                return fmt.Errorf("conflicting service rules for service %v found", service)
        }</span>
        <span class="cov8" title="1">if l.config.Services == nil </span><span class="cov8" title="1">{
                l.config.Services = make(map[string]*MethodLoggerConfig)
        }</span>
        <span class="cov8" title="1">l.config.Services[service] = ml
        return nil</span>
}

// Set method logger for "service/method".
//
// New methodLogger with same method overrides the old one.
func (l *logger) setMethodMethodLogger(method string, ml *MethodLoggerConfig) error <span class="cov8" title="1">{
        if _, ok := l.config.Blacklist[method]; ok </span><span class="cov8" title="1">{
                return fmt.Errorf("conflicting blacklist rules for method %v found", method)
        }</span>
        <span class="cov8" title="1">if _, ok := l.config.Methods[method]; ok </span><span class="cov8" title="1">{
                return fmt.Errorf("conflicting method rules for method %v found", method)
        }</span>
        <span class="cov8" title="1">if l.config.Methods == nil </span><span class="cov8" title="1">{
                l.config.Methods = make(map[string]*MethodLoggerConfig)
        }</span>
        <span class="cov8" title="1">l.config.Methods[method] = ml
        return nil</span>
}

// Set blacklist method for "-service/method".
func (l *logger) setBlacklist(method string) error <span class="cov8" title="1">{
        if _, ok := l.config.Blacklist[method]; ok </span><span class="cov8" title="1">{
                return fmt.Errorf("conflicting blacklist rules for method %v found", method)
        }</span>
        <span class="cov8" title="1">if _, ok := l.config.Methods[method]; ok </span><span class="cov8" title="1">{
                return fmt.Errorf("conflicting method rules for method %v found", method)
        }</span>
        <span class="cov8" title="1">if l.config.Blacklist == nil </span><span class="cov8" title="1">{
                l.config.Blacklist = make(map[string]struct{})
        }</span>
        <span class="cov8" title="1">l.config.Blacklist[method] = struct{}{}
        return nil</span>
}

// getMethodLogger returns the methodLogger for the given methodName.
//
// methodName should be in the format of "/service/method".
//
// Each methodLogger returned by this method is a new instance. This is to
// generate sequence id within the call.
func (l *logger) GetMethodLogger(methodName string) MethodLogger <span class="cov8" title="1">{
        s, m, err := grpcutil.ParseMethod(methodName)
        if err != nil </span><span class="cov0" title="0">{
                grpclogLogger.Infof("binarylogging: failed to parse %q: %v", methodName, err)
                return nil
        }</span>
        <span class="cov8" title="1">if ml, ok := l.config.Methods[s+"/"+m]; ok </span><span class="cov8" title="1">{
                return newMethodLogger(ml.Header, ml.Message)
        }</span>
        <span class="cov8" title="1">if _, ok := l.config.Blacklist[s+"/"+m]; ok </span><span class="cov8" title="1">{
                return nil
        }</span>
        <span class="cov8" title="1">if ml, ok := l.config.Services[s]; ok </span><span class="cov8" title="1">{
                return newMethodLogger(ml.Header, ml.Message)
        }</span>
        <span class="cov8" title="1">if l.config.All == nil </span><span class="cov8" title="1">{
                return nil
        }</span>
        <span class="cov8" title="1">return newMethodLogger(l.config.All.Header, l.config.All.Message)</span>
}
</pre>
		
		<pre class="file" id="file71" style="display: none">/*
 *
 * Copyright 2018 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package binarylog

import (
        "errors"
        "fmt"
        "regexp"
        "strconv"
        "strings"
)

// NewLoggerFromConfigString reads the string and build a logger. It can be used
// to build a new logger and assign it to binarylog.Logger.
//
// Example filter config strings:
//  - "" Nothing will be logged
//  - "*" All headers and messages will be fully logged.
//  - "*{h}" Only headers will be logged.
//  - "*{m:256}" Only the first 256 bytes of each message will be logged.
//  - "Foo/*" Logs every method in service Foo
//  - "Foo/*,-Foo/Bar" Logs every method in service Foo except method /Foo/Bar
//  - "Foo/*,Foo/Bar{m:256}" Logs the first 256 bytes of each message in method
//    /Foo/Bar, logs all headers and messages in every other method in service
//    Foo.
//
// If two configs exist for one certain method or service, the one specified
// later overrides the previous config.
func NewLoggerFromConfigString(s string) Logger <span class="cov8" title="1">{
        if s == "" </span><span class="cov8" title="1">{
                return nil
        }</span>
        <span class="cov8" title="1">l := newEmptyLogger()
        methods := strings.Split(s, ",")
        for _, method := range methods </span><span class="cov8" title="1">{
                if err := l.fillMethodLoggerWithConfigString(method); err != nil </span><span class="cov8" title="1">{
                        grpclogLogger.Warningf("failed to parse binary log config: %v", err)
                        return nil
                }</span>
        }
        <span class="cov8" title="1">return l</span>
}

// fillMethodLoggerWithConfigString parses config, creates methodLogger and adds
// it to the right map in the logger.
func (l *logger) fillMethodLoggerWithConfigString(config string) error <span class="cov8" title="1">{
        // "" is invalid.
        if config == "" </span><span class="cov8" title="1">{
                return errors.New("empty string is not a valid method binary logging config")
        }</span>

        // "-service/method", blacklist, no * or {} allowed.
        <span class="cov8" title="1">if config[0] == '-' </span><span class="cov8" title="1">{
                s, m, suffix, err := parseMethodConfigAndSuffix(config[1:])
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("invalid config: %q, %v", config, err)
                }</span>
                <span class="cov8" title="1">if m == "*" </span><span class="cov8" title="1">{
                        return fmt.Errorf("invalid config: %q, %v", config, "* not allowed in blacklist config")
                }</span>
                <span class="cov8" title="1">if suffix != "" </span><span class="cov8" title="1">{
                        return fmt.Errorf("invalid config: %q, %v", config, "header/message limit not allowed in blacklist config")
                }</span>
                <span class="cov8" title="1">if err := l.setBlacklist(s + "/" + m); err != nil </span><span class="cov8" title="1">{
                        return fmt.Errorf("invalid config: %v", err)
                }</span>
                <span class="cov8" title="1">return nil</span>
        }

        // "*{h:256;m:256}"
        <span class="cov8" title="1">if config[0] == '*' </span><span class="cov8" title="1">{
                hdr, msg, err := parseHeaderMessageLengthConfig(config[1:])
                if err != nil </span><span class="cov8" title="1">{
                        return fmt.Errorf("invalid config: %q, %v", config, err)
                }</span>
                <span class="cov8" title="1">if err := l.setDefaultMethodLogger(&amp;MethodLoggerConfig{Header: hdr, Message: msg}); err != nil </span><span class="cov8" title="1">{
                        return fmt.Errorf("invalid config: %v", err)
                }</span>
                <span class="cov8" title="1">return nil</span>
        }

        <span class="cov8" title="1">s, m, suffix, err := parseMethodConfigAndSuffix(config)
        if err != nil </span><span class="cov8" title="1">{
                return fmt.Errorf("invalid config: %q, %v", config, err)
        }</span>
        <span class="cov8" title="1">hdr, msg, err := parseHeaderMessageLengthConfig(suffix)
        if err != nil </span><span class="cov8" title="1">{
                return fmt.Errorf("invalid header/message length config: %q, %v", suffix, err)
        }</span>
        <span class="cov8" title="1">if m == "*" </span><span class="cov8" title="1">{
                if err := l.setServiceMethodLogger(s, &amp;MethodLoggerConfig{Header: hdr, Message: msg}); err != nil </span><span class="cov8" title="1">{
                        return fmt.Errorf("invalid config: %v", err)
                }</span>
        } else<span class="cov8" title="1"> {
                if err := l.setMethodMethodLogger(s+"/"+m, &amp;MethodLoggerConfig{Header: hdr, Message: msg}); err != nil </span><span class="cov8" title="1">{
                        return fmt.Errorf("invalid config: %v", err)
                }</span>
        }
        <span class="cov8" title="1">return nil</span>
}

const (
        // TODO: this const is only used by env_config now. But could be useful for
        // other config. Move to binarylog.go if necessary.
        maxUInt = ^uint64(0)

        // For "p.s/m" plus any suffix. Suffix will be parsed again. See test for
        // expected output.
        longMethodConfigRegexpStr = `^([\w./]+)/((?:\w+)|[*])(.+)?$`

        // For suffix from above, "{h:123,m:123}". See test for expected output.
        optionalLengthRegexpStr      = `(?::(\d+))?` // Optional ":123".
        headerConfigRegexpStr        = `^{h` + optionalLengthRegexpStr + `}$`
        messageConfigRegexpStr       = `^{m` + optionalLengthRegexpStr + `}$`
        headerMessageConfigRegexpStr = `^{h` + optionalLengthRegexpStr + `;m` + optionalLengthRegexpStr + `}$`
)

var (
        longMethodConfigRegexp    = regexp.MustCompile(longMethodConfigRegexpStr)
        headerConfigRegexp        = regexp.MustCompile(headerConfigRegexpStr)
        messageConfigRegexp       = regexp.MustCompile(messageConfigRegexpStr)
        headerMessageConfigRegexp = regexp.MustCompile(headerMessageConfigRegexpStr)
)

// Turn "service/method{h;m}" into "service", "method", "{h;m}".
func parseMethodConfigAndSuffix(c string) (service, method, suffix string, _ error) <span class="cov8" title="1">{
        // Regexp result:
        //
        // in:  "p.s/m{h:123,m:123}",
        // out: []string{"p.s/m{h:123,m:123}", "p.s", "m", "{h:123,m:123}"},
        match := longMethodConfigRegexp.FindStringSubmatch(c)
        if match == nil </span><span class="cov8" title="1">{
                return "", "", "", fmt.Errorf("%q contains invalid substring", c)
        }</span>
        <span class="cov8" title="1">service = match[1]
        method = match[2]
        suffix = match[3]
        return</span>
}

// Turn "{h:123;m:345}" into 123, 345.
//
// Return maxUInt if length is unspecified.
func parseHeaderMessageLengthConfig(c string) (hdrLenStr, msgLenStr uint64, err error) <span class="cov8" title="1">{
        if c == "" </span><span class="cov8" title="1">{
                return maxUInt, maxUInt, nil
        }</span>
        // Header config only.
        <span class="cov8" title="1">if match := headerConfigRegexp.FindStringSubmatch(c); match != nil </span><span class="cov8" title="1">{
                if s := match[1]; s != "" </span><span class="cov8" title="1">{
                        hdrLenStr, err = strconv.ParseUint(s, 10, 64)
                        if err != nil </span><span class="cov0" title="0">{
                                return 0, 0, fmt.Errorf("failed to convert %q to uint", s)
                        }</span>
                        <span class="cov8" title="1">return hdrLenStr, 0, nil</span>
                }
                <span class="cov8" title="1">return maxUInt, 0, nil</span>
        }

        // Message config only.
        <span class="cov8" title="1">if match := messageConfigRegexp.FindStringSubmatch(c); match != nil </span><span class="cov8" title="1">{
                if s := match[1]; s != "" </span><span class="cov8" title="1">{
                        msgLenStr, err = strconv.ParseUint(s, 10, 64)
                        if err != nil </span><span class="cov0" title="0">{
                                return 0, 0, fmt.Errorf("failed to convert %q to uint", s)
                        }</span>
                        <span class="cov8" title="1">return 0, msgLenStr, nil</span>
                }
                <span class="cov8" title="1">return 0, maxUInt, nil</span>
        }

        // Header and message config both.
        <span class="cov8" title="1">if match := headerMessageConfigRegexp.FindStringSubmatch(c); match != nil </span><span class="cov8" title="1">{
                // Both hdr and msg are specified, but one or two of them might be empty.
                hdrLenStr = maxUInt
                msgLenStr = maxUInt
                if s := match[1]; s != "" </span><span class="cov8" title="1">{
                        hdrLenStr, err = strconv.ParseUint(s, 10, 64)
                        if err != nil </span><span class="cov0" title="0">{
                                return 0, 0, fmt.Errorf("failed to convert %q to uint", s)
                        }</span>
                }
                <span class="cov8" title="1">if s := match[2]; s != "" </span><span class="cov8" title="1">{
                        msgLenStr, err = strconv.ParseUint(s, 10, 64)
                        if err != nil </span><span class="cov0" title="0">{
                                return 0, 0, fmt.Errorf("failed to convert %q to uint", s)
                        }</span>
                }
                <span class="cov8" title="1">return hdrLenStr, msgLenStr, nil</span>
        }
        <span class="cov8" title="1">return 0, 0, fmt.Errorf("%q contains invalid substring", c)</span>
}
</pre>
		
		<pre class="file" id="file72" style="display: none">/*
 *
 * Copyright 2018 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package binarylog

import (
        "net"
        "strings"
        "sync/atomic"
        "time"

        "github.com/golang/protobuf/proto"
        "github.com/golang/protobuf/ptypes"
        pb "google.golang.org/grpc/binarylog/grpc_binarylog_v1"
        "google.golang.org/grpc/metadata"
        "google.golang.org/grpc/status"
)

type callIDGenerator struct {
        id uint64
}

func (g *callIDGenerator) next() uint64 <span class="cov8" title="1">{
        id := atomic.AddUint64(&amp;g.id, 1)
        return id
}</span>

// reset is for testing only, and doesn't need to be thread safe.
func (g *callIDGenerator) reset() <span class="cov8" title="1">{
        g.id = 0
}</span>

var idGen callIDGenerator

// MethodLogger is the sub-logger for each method.
type MethodLogger interface {
        Log(LogEntryConfig)
}

type methodLogger struct {
        headerMaxLen, messageMaxLen uint64

        callID          uint64
        idWithinCallGen *callIDGenerator

        sink Sink // TODO(blog): make this plugable.
}

func newMethodLogger(h, m uint64) *methodLogger <span class="cov8" title="1">{
        return &amp;methodLogger{
                headerMaxLen:  h,
                messageMaxLen: m,

                callID:          idGen.next(),
                idWithinCallGen: &amp;callIDGenerator{},

                sink: DefaultSink, // TODO(blog): make it plugable.
        }
}</span>

// Build is an internal only method for building the proto message out of the
// input event. It's made public to enable other library to reuse as much logic
// in methodLogger as possible.
func (ml *methodLogger) Build(c LogEntryConfig) *pb.GrpcLogEntry <span class="cov8" title="1">{
        m := c.toProto()
        timestamp, _ := ptypes.TimestampProto(time.Now())
        m.Timestamp = timestamp
        m.CallId = ml.callID
        m.SequenceIdWithinCall = ml.idWithinCallGen.next()

        switch pay := m.Payload.(type) </span>{
        case *pb.GrpcLogEntry_ClientHeader:<span class="cov8" title="1">
                m.PayloadTruncated = ml.truncateMetadata(pay.ClientHeader.GetMetadata())</span>
        case *pb.GrpcLogEntry_ServerHeader:<span class="cov8" title="1">
                m.PayloadTruncated = ml.truncateMetadata(pay.ServerHeader.GetMetadata())</span>
        case *pb.GrpcLogEntry_Message:<span class="cov8" title="1">
                m.PayloadTruncated = ml.truncateMessage(pay.Message)</span>
        }
        <span class="cov8" title="1">return m</span>
}

// Log creates a proto binary log entry, and logs it to the sink.
func (ml *methodLogger) Log(c LogEntryConfig) <span class="cov8" title="1">{
        ml.sink.Write(ml.Build(c))
}</span>

func (ml *methodLogger) truncateMetadata(mdPb *pb.Metadata) (truncated bool) <span class="cov8" title="1">{
        if ml.headerMaxLen == maxUInt </span><span class="cov8" title="1">{
                return false
        }</span>
        <span class="cov8" title="1">var (
                bytesLimit = ml.headerMaxLen
                index      int
        )
        // At the end of the loop, index will be the first entry where the total
        // size is greater than the limit:
        //
        // len(entry[:index]) &lt;= ml.hdr &amp;&amp; len(entry[:index+1]) &gt; ml.hdr.
        for ; index &lt; len(mdPb.Entry); index++ </span><span class="cov8" title="1">{
                entry := mdPb.Entry[index]
                if entry.Key == "grpc-trace-bin" </span><span class="cov8" title="1">{
                        // "grpc-trace-bin" is a special key. It's kept in the log entry,
                        // but not counted towards the size limit.
                        continue</span>
                }
                <span class="cov8" title="1">currentEntryLen := uint64(len(entry.Value))
                if currentEntryLen &gt; bytesLimit </span><span class="cov8" title="1">{
                        break</span>
                }
                <span class="cov8" title="1">bytesLimit -= currentEntryLen</span>
        }
        <span class="cov8" title="1">truncated = index &lt; len(mdPb.Entry)
        mdPb.Entry = mdPb.Entry[:index]
        return truncated</span>
}

func (ml *methodLogger) truncateMessage(msgPb *pb.Message) (truncated bool) <span class="cov8" title="1">{
        if ml.messageMaxLen == maxUInt </span><span class="cov8" title="1">{
                return false
        }</span>
        <span class="cov8" title="1">if ml.messageMaxLen &gt;= uint64(len(msgPb.Data)) </span><span class="cov8" title="1">{
                return false
        }</span>
        <span class="cov8" title="1">msgPb.Data = msgPb.Data[:ml.messageMaxLen]
        return true</span>
}

// LogEntryConfig represents the configuration for binary log entry.
type LogEntryConfig interface {
        toProto() *pb.GrpcLogEntry
}

// ClientHeader configs the binary log entry to be a ClientHeader entry.
type ClientHeader struct {
        OnClientSide bool
        Header       metadata.MD
        MethodName   string
        Authority    string
        Timeout      time.Duration
        // PeerAddr is required only when it's on server side.
        PeerAddr net.Addr
}

func (c *ClientHeader) toProto() *pb.GrpcLogEntry <span class="cov8" title="1">{
        // This function doesn't need to set all the fields (e.g. seq ID). The Log
        // function will set the fields when necessary.
        clientHeader := &amp;pb.ClientHeader{
                Metadata:   mdToMetadataProto(c.Header),
                MethodName: c.MethodName,
                Authority:  c.Authority,
        }
        if c.Timeout &gt; 0 </span><span class="cov8" title="1">{
                clientHeader.Timeout = ptypes.DurationProto(c.Timeout)
        }</span>
        <span class="cov8" title="1">ret := &amp;pb.GrpcLogEntry{
                Type: pb.GrpcLogEntry_EVENT_TYPE_CLIENT_HEADER,
                Payload: &amp;pb.GrpcLogEntry_ClientHeader{
                        ClientHeader: clientHeader,
                },
        }
        if c.OnClientSide </span><span class="cov0" title="0">{
                ret.Logger = pb.GrpcLogEntry_LOGGER_CLIENT
        }</span> else<span class="cov8" title="1"> {
                ret.Logger = pb.GrpcLogEntry_LOGGER_SERVER
        }</span>
        <span class="cov8" title="1">if c.PeerAddr != nil </span><span class="cov8" title="1">{
                ret.Peer = addrToProto(c.PeerAddr)
        }</span>
        <span class="cov8" title="1">return ret</span>
}

// ServerHeader configs the binary log entry to be a ServerHeader entry.
type ServerHeader struct {
        OnClientSide bool
        Header       metadata.MD
        // PeerAddr is required only when it's on client side.
        PeerAddr net.Addr
}

func (c *ServerHeader) toProto() *pb.GrpcLogEntry <span class="cov8" title="1">{
        ret := &amp;pb.GrpcLogEntry{
                Type: pb.GrpcLogEntry_EVENT_TYPE_SERVER_HEADER,
                Payload: &amp;pb.GrpcLogEntry_ServerHeader{
                        ServerHeader: &amp;pb.ServerHeader{
                                Metadata: mdToMetadataProto(c.Header),
                        },
                },
        }
        if c.OnClientSide </span><span class="cov8" title="1">{
                ret.Logger = pb.GrpcLogEntry_LOGGER_CLIENT
        }</span> else<span class="cov0" title="0"> {
                ret.Logger = pb.GrpcLogEntry_LOGGER_SERVER
        }</span>
        <span class="cov8" title="1">if c.PeerAddr != nil </span><span class="cov8" title="1">{
                ret.Peer = addrToProto(c.PeerAddr)
        }</span>
        <span class="cov8" title="1">return ret</span>
}

// ClientMessage configs the binary log entry to be a ClientMessage entry.
type ClientMessage struct {
        OnClientSide bool
        // Message can be a proto.Message or []byte. Other messages formats are not
        // supported.
        Message interface{}
}

func (c *ClientMessage) toProto() *pb.GrpcLogEntry <span class="cov8" title="1">{
        var (
                data []byte
                err  error
        )
        if m, ok := c.Message.(proto.Message); ok </span><span class="cov8" title="1">{
                data, err = proto.Marshal(m)
                if err != nil </span><span class="cov0" title="0">{
                        grpclogLogger.Infof("binarylogging: failed to marshal proto message: %v", err)
                }</span>
        } else<span class="cov0" title="0"> if b, ok := c.Message.([]byte); ok </span><span class="cov0" title="0">{
                data = b
        }</span> else<span class="cov0" title="0"> {
                grpclogLogger.Infof("binarylogging: message to log is neither proto.message nor []byte")
        }</span>
        <span class="cov8" title="1">ret := &amp;pb.GrpcLogEntry{
                Type: pb.GrpcLogEntry_EVENT_TYPE_CLIENT_MESSAGE,
                Payload: &amp;pb.GrpcLogEntry_Message{
                        Message: &amp;pb.Message{
                                Length: uint32(len(data)),
                                Data:   data,
                        },
                },
        }
        if c.OnClientSide </span><span class="cov8" title="1">{
                ret.Logger = pb.GrpcLogEntry_LOGGER_CLIENT
        }</span> else<span class="cov0" title="0"> {
                ret.Logger = pb.GrpcLogEntry_LOGGER_SERVER
        }</span>
        <span class="cov8" title="1">return ret</span>
}

// ServerMessage configs the binary log entry to be a ServerMessage entry.
type ServerMessage struct {
        OnClientSide bool
        // Message can be a proto.Message or []byte. Other messages formats are not
        // supported.
        Message interface{}
}

func (c *ServerMessage) toProto() *pb.GrpcLogEntry <span class="cov8" title="1">{
        var (
                data []byte
                err  error
        )
        if m, ok := c.Message.(proto.Message); ok </span><span class="cov8" title="1">{
                data, err = proto.Marshal(m)
                if err != nil </span><span class="cov0" title="0">{
                        grpclogLogger.Infof("binarylogging: failed to marshal proto message: %v", err)
                }</span>
        } else<span class="cov0" title="0"> if b, ok := c.Message.([]byte); ok </span><span class="cov0" title="0">{
                data = b
        }</span> else<span class="cov0" title="0"> {
                grpclogLogger.Infof("binarylogging: message to log is neither proto.message nor []byte")
        }</span>
        <span class="cov8" title="1">ret := &amp;pb.GrpcLogEntry{
                Type: pb.GrpcLogEntry_EVENT_TYPE_SERVER_MESSAGE,
                Payload: &amp;pb.GrpcLogEntry_Message{
                        Message: &amp;pb.Message{
                                Length: uint32(len(data)),
                                Data:   data,
                        },
                },
        }
        if c.OnClientSide </span><span class="cov0" title="0">{
                ret.Logger = pb.GrpcLogEntry_LOGGER_CLIENT
        }</span> else<span class="cov8" title="1"> {
                ret.Logger = pb.GrpcLogEntry_LOGGER_SERVER
        }</span>
        <span class="cov8" title="1">return ret</span>
}

// ClientHalfClose configs the binary log entry to be a ClientHalfClose entry.
type ClientHalfClose struct {
        OnClientSide bool
}

func (c *ClientHalfClose) toProto() *pb.GrpcLogEntry <span class="cov8" title="1">{
        ret := &amp;pb.GrpcLogEntry{
                Type:    pb.GrpcLogEntry_EVENT_TYPE_CLIENT_HALF_CLOSE,
                Payload: nil, // No payload here.
        }
        if c.OnClientSide </span><span class="cov0" title="0">{
                ret.Logger = pb.GrpcLogEntry_LOGGER_CLIENT
        }</span> else<span class="cov8" title="1"> {
                ret.Logger = pb.GrpcLogEntry_LOGGER_SERVER
        }</span>
        <span class="cov8" title="1">return ret</span>
}

// ServerTrailer configs the binary log entry to be a ServerTrailer entry.
type ServerTrailer struct {
        OnClientSide bool
        Trailer      metadata.MD
        // Err is the status error.
        Err error
        // PeerAddr is required only when it's on client side and the RPC is trailer
        // only.
        PeerAddr net.Addr
}

func (c *ServerTrailer) toProto() *pb.GrpcLogEntry <span class="cov8" title="1">{
        st, ok := status.FromError(c.Err)
        if !ok </span><span class="cov0" title="0">{
                grpclogLogger.Info("binarylogging: error in trailer is not a status error")
        }</span>
        <span class="cov8" title="1">var (
                detailsBytes []byte
                err          error
        )
        stProto := st.Proto()
        if stProto != nil &amp;&amp; len(stProto.Details) != 0 </span><span class="cov0" title="0">{
                detailsBytes, err = proto.Marshal(stProto)
                if err != nil </span><span class="cov0" title="0">{
                        grpclogLogger.Infof("binarylogging: failed to marshal status proto: %v", err)
                }</span>
        }
        <span class="cov8" title="1">ret := &amp;pb.GrpcLogEntry{
                Type: pb.GrpcLogEntry_EVENT_TYPE_SERVER_TRAILER,
                Payload: &amp;pb.GrpcLogEntry_Trailer{
                        Trailer: &amp;pb.Trailer{
                                Metadata:      mdToMetadataProto(c.Trailer),
                                StatusCode:    uint32(st.Code()),
                                StatusMessage: st.Message(),
                                StatusDetails: detailsBytes,
                        },
                },
        }
        if c.OnClientSide </span><span class="cov8" title="1">{
                ret.Logger = pb.GrpcLogEntry_LOGGER_CLIENT
        }</span> else<span class="cov0" title="0"> {
                ret.Logger = pb.GrpcLogEntry_LOGGER_SERVER
        }</span>
        <span class="cov8" title="1">if c.PeerAddr != nil </span><span class="cov8" title="1">{
                ret.Peer = addrToProto(c.PeerAddr)
        }</span>
        <span class="cov8" title="1">return ret</span>
}

// Cancel configs the binary log entry to be a Cancel entry.
type Cancel struct {
        OnClientSide bool
}

func (c *Cancel) toProto() *pb.GrpcLogEntry <span class="cov8" title="1">{
        ret := &amp;pb.GrpcLogEntry{
                Type:    pb.GrpcLogEntry_EVENT_TYPE_CANCEL,
                Payload: nil,
        }
        if c.OnClientSide </span><span class="cov8" title="1">{
                ret.Logger = pb.GrpcLogEntry_LOGGER_CLIENT
        }</span> else<span class="cov0" title="0"> {
                ret.Logger = pb.GrpcLogEntry_LOGGER_SERVER
        }</span>
        <span class="cov8" title="1">return ret</span>
}

// metadataKeyOmit returns whether the metadata entry with this key should be
// omitted.
func metadataKeyOmit(key string) bool <span class="cov8" title="1">{
        switch key </span>{
        case "lb-token", ":path", ":authority", "content-encoding", "content-type", "user-agent", "te":<span class="cov8" title="1">
                return true</span>
        case "grpc-trace-bin":<span class="cov0" title="0"> // grpc-trace-bin is special because it's visiable to users.
                return false</span>
        }
        <span class="cov8" title="1">return strings.HasPrefix(key, "grpc-")</span>
}

func mdToMetadataProto(md metadata.MD) *pb.Metadata <span class="cov8" title="1">{
        ret := &amp;pb.Metadata{}
        for k, vv := range md </span><span class="cov8" title="1">{
                if metadataKeyOmit(k) </span><span class="cov8" title="1">{
                        continue</span>
                }
                <span class="cov8" title="1">for _, v := range vv </span><span class="cov8" title="1">{
                        ret.Entry = append(ret.Entry,
                                &amp;pb.MetadataEntry{
                                        Key:   k,
                                        Value: []byte(v),
                                },
                        )
                }</span>
        }
        <span class="cov8" title="1">return ret</span>
}

func addrToProto(addr net.Addr) *pb.Address <span class="cov8" title="1">{
        ret := &amp;pb.Address{}
        switch a := addr.(type) </span>{
        case *net.TCPAddr:<span class="cov8" title="1">
                if a.IP.To4() != nil </span><span class="cov8" title="1">{
                        ret.Type = pb.Address_TYPE_IPV4
                }</span> else<span class="cov8" title="1"> if a.IP.To16() != nil </span><span class="cov8" title="1">{
                        ret.Type = pb.Address_TYPE_IPV6
                }</span> else<span class="cov0" title="0"> {
                        ret.Type = pb.Address_TYPE_UNKNOWN
                        // Do not set address and port fields.
                        break</span>
                }
                <span class="cov8" title="1">ret.Address = a.IP.String()
                ret.IpPort = uint32(a.Port)</span>
        case *net.UnixAddr:<span class="cov0" title="0">
                ret.Type = pb.Address_TYPE_UNIX
                ret.Address = a.String()</span>
        default:<span class="cov0" title="0">
                ret.Type = pb.Address_TYPE_UNKNOWN</span>
        }
        <span class="cov8" title="1">return ret</span>
}
</pre>
		
		<pre class="file" id="file73" style="display: none">/*
 *
 * Copyright 2018 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package binarylog

import (
        "bufio"
        "encoding/binary"
        "io"
        "sync"
        "time"

        "github.com/golang/protobuf/proto"
        pb "google.golang.org/grpc/binarylog/grpc_binarylog_v1"
)

var (
        // DefaultSink is the sink where the logs will be written to. It's exported
        // for the binarylog package to update.
        DefaultSink Sink = &amp;noopSink{} // TODO(blog): change this default (file in /tmp).
)

// Sink writes log entry into the binary log sink.
//
// sink is a copy of the exported binarylog.Sink, to avoid circular dependency.
type Sink interface {
        // Write will be called to write the log entry into the sink.
        //
        // It should be thread-safe so it can be called in parallel.
        Write(*pb.GrpcLogEntry) error
        // Close will be called when the Sink is replaced by a new Sink.
        Close() error
}

type noopSink struct{}

func (ns *noopSink) Write(*pb.GrpcLogEntry) error <span class="cov0" title="0">{ return nil }</span>
func (ns *noopSink) Close() error                 <span class="cov0" title="0">{ return nil }</span>

// newWriterSink creates a binary log sink with the given writer.
//
// Write() marshals the proto message and writes it to the given writer. Each
// message is prefixed with a 4 byte big endian unsigned integer as the length.
//
// No buffer is done, Close() doesn't try to close the writer.
func newWriterSink(w io.Writer) Sink <span class="cov8" title="1">{
        return &amp;writerSink{out: w}
}</span>

type writerSink struct {
        out io.Writer
}

func (ws *writerSink) Write(e *pb.GrpcLogEntry) error <span class="cov8" title="1">{
        b, err := proto.Marshal(e)
        if err != nil </span><span class="cov0" title="0">{
                grpclogLogger.Errorf("binary logging: failed to marshal proto message: %v", err)
                return err
        }</span>
        <span class="cov8" title="1">hdr := make([]byte, 4)
        binary.BigEndian.PutUint32(hdr, uint32(len(b)))
        if _, err := ws.out.Write(hdr); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov8" title="1">if _, err := ws.out.Write(b); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov8" title="1">return nil</span>
}

func (ws *writerSink) Close() error <span class="cov0" title="0">{ return nil }</span>

type bufferedSink struct {
        mu             sync.Mutex
        closer         io.Closer
        out            Sink          // out is built on buf.
        buf            *bufio.Writer // buf is kept for flush.
        flusherStarted bool

        writeTicker *time.Ticker
        done        chan struct{}
}

func (fs *bufferedSink) Write(e *pb.GrpcLogEntry) error <span class="cov0" title="0">{
        fs.mu.Lock()
        defer fs.mu.Unlock()
        if !fs.flusherStarted </span><span class="cov0" title="0">{
                // Start the write loop when Write is called.
                fs.startFlushGoroutine()
                fs.flusherStarted = true
        }</span>
        <span class="cov0" title="0">if err := fs.out.Write(e); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov0" title="0">return nil</span>
}

const (
        bufFlushDuration = 60 * time.Second
)

func (fs *bufferedSink) startFlushGoroutine() <span class="cov0" title="0">{
        fs.writeTicker = time.NewTicker(bufFlushDuration)
        go func() </span><span class="cov0" title="0">{
                for </span><span class="cov0" title="0">{
                        select </span>{
                        case &lt;-fs.done:<span class="cov0" title="0">
                                return</span>
                        case &lt;-fs.writeTicker.C:<span class="cov0" title="0"></span>
                        }
                        <span class="cov0" title="0">fs.mu.Lock()
                        if err := fs.buf.Flush(); err != nil </span><span class="cov0" title="0">{
                                grpclogLogger.Warningf("failed to flush to Sink: %v", err)
                        }</span>
                        <span class="cov0" title="0">fs.mu.Unlock()</span>
                }
        }()
}

func (fs *bufferedSink) Close() error <span class="cov0" title="0">{
        fs.mu.Lock()
        defer fs.mu.Unlock()
        if fs.writeTicker != nil </span><span class="cov0" title="0">{
                fs.writeTicker.Stop()
        }</span>
        <span class="cov0" title="0">close(fs.done)
        if err := fs.buf.Flush(); err != nil </span><span class="cov0" title="0">{
                grpclogLogger.Warningf("failed to flush to Sink: %v", err)
        }</span>
        <span class="cov0" title="0">if err := fs.closer.Close(); err != nil </span><span class="cov0" title="0">{
                grpclogLogger.Warningf("failed to close the underlying WriterCloser: %v", err)
        }</span>
        <span class="cov0" title="0">if err := fs.out.Close(); err != nil </span><span class="cov0" title="0">{
                grpclogLogger.Warningf("failed to close the Sink: %v", err)
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// NewBufferedSink creates a binary log sink with the given WriteCloser.
//
// Write() marshals the proto message and writes it to the given writer. Each
// message is prefixed with a 4 byte big endian unsigned integer as the length.
//
// Content is kept in a buffer, and is flushed every 60 seconds.
//
// Close closes the WriteCloser.
func NewBufferedSink(o io.WriteCloser) Sink <span class="cov0" title="0">{
        bufW := bufio.NewWriter(o)
        return &amp;bufferedSink{
                closer: o,
                out:    newWriterSink(bufW),
                buf:    bufW,
                done:   make(chan struct{}),
        }
}</span>
</pre>
		
		<pre class="file" id="file74" style="display: none">/*
 * Copyright 2019 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package buffer provides an implementation of an unbounded buffer.
package buffer

import "sync"

// Unbounded is an implementation of an unbounded buffer which does not use
// extra goroutines. This is typically used for passing updates from one entity
// to another within gRPC.
//
// All methods on this type are thread-safe and don't block on anything except
// the underlying mutex used for synchronization.
//
// Unbounded supports values of any type to be stored in it by using a channel
// of `interface{}`. This means that a call to Put() incurs an extra memory
// allocation, and also that users need a type assertion while reading. For
// performance critical code paths, using Unbounded is strongly discouraged and
// defining a new type specific implementation of this buffer is preferred. See
// internal/transport/transport.go for an example of this.
type Unbounded struct {
        c       chan interface{}
        mu      sync.Mutex
        backlog []interface{}
}

// NewUnbounded returns a new instance of Unbounded.
func NewUnbounded() *Unbounded <span class="cov8" title="1">{
        return &amp;Unbounded{c: make(chan interface{}, 1)}
}</span>

// Put adds t to the unbounded buffer.
func (b *Unbounded) Put(t interface{}) <span class="cov8" title="1">{
        b.mu.Lock()
        if len(b.backlog) == 0 </span><span class="cov8" title="1">{
                select </span>{
                case b.c &lt;- t:<span class="cov8" title="1">
                        b.mu.Unlock()
                        return</span>
                default:<span class="cov8" title="1"></span>
                }
        }
        <span class="cov8" title="1">b.backlog = append(b.backlog, t)
        b.mu.Unlock()</span>
}

// Load sends the earliest buffered data, if any, onto the read channel
// returned by Get(). Users are expected to call this every time they read a
// value from the read channel.
func (b *Unbounded) Load() <span class="cov8" title="1">{
        b.mu.Lock()
        if len(b.backlog) &gt; 0 </span><span class="cov8" title="1">{
                select </span>{
                case b.c &lt;- b.backlog[0]:<span class="cov8" title="1">
                        b.backlog[0] = nil
                        b.backlog = b.backlog[1:]</span>
                default:<span class="cov8" title="1"></span>
                }
        }
        <span class="cov8" title="1">b.mu.Unlock()</span>
}

// Get returns a read channel on which values added to the buffer, via Put(),
// are sent on.
//
// Upon reading a value from this channel, users are expected to call Load() to
// send the next buffered value onto the channel if there is any.
func (b *Unbounded) Get() &lt;-chan interface{} <span class="cov8" title="1">{
        return b.c
}</span>
</pre>
		
		<pre class="file" id="file75" style="display: none">/*
 * Copyright 2019 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// Package cache implements caches to be used in gRPC.
package cache

import (
        "sync"
        "time"
)

type cacheEntry struct {
        item interface{}
        // Note that to avoid deadlocks (potentially caused by lock ordering),
        // callback can only be called without holding cache's mutex.
        callback func()
        timer    *time.Timer
        // deleted is set to true in Remove() when the call to timer.Stop() fails.
        // This can happen when the timer in the cache entry fires around the same
        // time that timer.stop() is called in Remove().
        deleted bool
}

// TimeoutCache is a cache with items to be deleted after a timeout.
type TimeoutCache struct {
        mu      sync.Mutex
        timeout time.Duration
        cache   map[interface{}]*cacheEntry
}

// NewTimeoutCache creates a TimeoutCache with the given timeout.
func NewTimeoutCache(timeout time.Duration) *TimeoutCache <span class="cov8" title="1">{
        return &amp;TimeoutCache{
                timeout: timeout,
                cache:   make(map[interface{}]*cacheEntry),
        }
}</span>

// Add adds an item to the cache, with the specified callback to be called when
// the item is removed from the cache upon timeout. If the item is removed from
// the cache using a call to Remove before the timeout expires, the callback
// will not be called.
//
// If the Add was successful, it returns (newly added item, true). If there is
// an existing entry for the specified key, the cache entry is not be updated
// with the specified item and it returns (existing item, false).
func (c *TimeoutCache) Add(key, item interface{}, callback func()) (interface{}, bool) <span class="cov8" title="1">{
        c.mu.Lock()
        defer c.mu.Unlock()
        if e, ok := c.cache[key]; ok </span><span class="cov0" title="0">{
                return e.item, false
        }</span>

        <span class="cov8" title="1">entry := &amp;cacheEntry{
                item:     item,
                callback: callback,
        }
        entry.timer = time.AfterFunc(c.timeout, func() </span><span class="cov8" title="1">{
                c.mu.Lock()
                if entry.deleted </span><span class="cov8" title="1">{
                        c.mu.Unlock()
                        // Abort the delete since this has been taken care of in Remove().
                        return
                }</span>
                <span class="cov8" title="1">delete(c.cache, key)
                c.mu.Unlock()
                entry.callback()</span>
        })
        <span class="cov8" title="1">c.cache[key] = entry
        return item, true</span>
}

// Remove the item with the key from the cache.
//
// If the specified key exists in the cache, it returns (item associated with
// key, true) and the callback associated with the item is guaranteed to be not
// called. If the given key is not found in the cache, it returns (nil, false)
func (c *TimeoutCache) Remove(key interface{}) (item interface{}, ok bool) <span class="cov8" title="1">{
        c.mu.Lock()
        defer c.mu.Unlock()
        entry, ok := c.removeInternal(key)
        if !ok </span><span class="cov0" title="0">{
                return nil, false
        }</span>
        <span class="cov8" title="1">return entry.item, true</span>
}

// removeInternal removes and returns the item with key.
//
// caller must hold c.mu.
func (c *TimeoutCache) removeInternal(key interface{}) (*cacheEntry, bool) <span class="cov8" title="1">{
        entry, ok := c.cache[key]
        if !ok </span><span class="cov0" title="0">{
                return nil, false
        }</span>
        <span class="cov8" title="1">delete(c.cache, key)
        if !entry.timer.Stop() </span><span class="cov8" title="1">{
                // If stop was not successful, the timer has fired (this can only happen
                // in a race). But the deleting function is blocked on c.mu because the
                // mutex was held by the caller of this function.
                //
                // Set deleted to true to abort the deleting function. When the lock is
                // released, the delete function will acquire the lock, check the value
                // of deleted and return.
                entry.deleted = true
        }</span>
        <span class="cov8" title="1">return entry, true</span>
}

// Clear removes all entries, and runs the callbacks if runCallback is true.
func (c *TimeoutCache) Clear(runCallback bool) <span class="cov8" title="1">{
        var entries []*cacheEntry
        c.mu.Lock()
        for key := range c.cache </span><span class="cov8" title="1">{
                if e, ok := c.removeInternal(key); ok </span><span class="cov8" title="1">{
                        entries = append(entries, e)
                }</span>
        }
        <span class="cov8" title="1">c.mu.Unlock()

        if !runCallback </span><span class="cov8" title="1">{
                return
        }</span>

        // removeInternal removes entries from cache, and also stops the timer, so
        // the callback is guaranteed to be not called. If runCallback is true,
        // manual execute all callbacks.
        <span class="cov8" title="1">for _, entry := range entries </span><span class="cov8" title="1">{
                entry.callback()
        }</span>
}
</pre>
		
		<pre class="file" id="file76" style="display: none">/*
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package credentials

import (
        "context"
)

// requestInfoKey is a struct to be used as the key to store RequestInfo in a
// context.
type requestInfoKey struct{}

// NewRequestInfoContext creates a context with ri.
func NewRequestInfoContext(ctx context.Context, ri interface{}) context.Context <span class="cov0" title="0">{
        return context.WithValue(ctx, requestInfoKey{}, ri)
}</span>

// RequestInfoFromContext extracts the RequestInfo from ctx.
func RequestInfoFromContext(ctx context.Context) interface{} <span class="cov0" title="0">{
        return ctx.Value(requestInfoKey{})
}</span>

// clientHandshakeInfoKey is a struct used as the key to store
// ClientHandshakeInfo in a context.
type clientHandshakeInfoKey struct{}

// ClientHandshakeInfoFromContext extracts the ClientHandshakeInfo from ctx.
func ClientHandshakeInfoFromContext(ctx context.Context) interface{} <span class="cov0" title="0">{
        return ctx.Value(clientHandshakeInfoKey{})
}</span>

// NewClientHandshakeInfoContext creates a context with chi.
func NewClientHandshakeInfoContext(ctx context.Context, chi interface{}) context.Context <span class="cov0" title="0">{
        return context.WithValue(ctx, clientHandshakeInfoKey{}, chi)
}</span>
</pre>
		
		<pre class="file" id="file77" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package credentials defines APIs for parsing SPIFFE ID.
//
// All APIs in this package are experimental.
package credentials

import (
        "crypto/tls"
        "crypto/x509"
        "net/url"

        "google.golang.org/grpc/grpclog"
)

var logger = grpclog.Component("credentials")

// SPIFFEIDFromState parses the SPIFFE ID from State. If the SPIFFE ID format
// is invalid, return nil with warning.
func SPIFFEIDFromState(state tls.ConnectionState) *url.URL <span class="cov8" title="1">{
        if len(state.PeerCertificates) == 0 || len(state.PeerCertificates[0].URIs) == 0 </span><span class="cov8" title="1">{
                return nil
        }</span>
        <span class="cov8" title="1">return SPIFFEIDFromCert(state.PeerCertificates[0])</span>
}

// SPIFFEIDFromCert parses the SPIFFE ID from x509.Certificate. If the SPIFFE
// ID format is invalid, return nil with warning.
func SPIFFEIDFromCert(cert *x509.Certificate) *url.URL <span class="cov8" title="1">{
        if cert == nil || cert.URIs == nil </span><span class="cov8" title="1">{
                return nil
        }</span>
        <span class="cov8" title="1">var spiffeID *url.URL
        for _, uri := range cert.URIs </span><span class="cov8" title="1">{
                if uri == nil || uri.Scheme != "spiffe" || uri.Opaque != "" || (uri.User != nil &amp;&amp; uri.User.Username() != "") </span><span class="cov8" title="1">{
                        continue</span>
                }
                // From this point, we assume the uri is intended for a SPIFFE ID.
                <span class="cov8" title="1">if len(uri.String()) &gt; 2048 </span><span class="cov8" title="1">{
                        logger.Warning("invalid SPIFFE ID: total ID length larger than 2048 bytes")
                        return nil
                }</span>
                <span class="cov8" title="1">if len(uri.Host) == 0 || len(uri.Path) == 0 </span><span class="cov8" title="1">{
                        logger.Warning("invalid SPIFFE ID: domain or workload ID is empty")
                        return nil
                }</span>
                <span class="cov8" title="1">if len(uri.Host) &gt; 255 </span><span class="cov8" title="1">{
                        logger.Warning("invalid SPIFFE ID: domain length larger than 255 characters")
                        return nil
                }</span>
                // A valid SPIFFE certificate can only have exactly one URI SAN field.
                <span class="cov8" title="1">if len(cert.URIs) &gt; 1 </span><span class="cov8" title="1">{
                        logger.Warning("invalid SPIFFE ID: multiple URI SANs")
                        return nil
                }</span>
                <span class="cov8" title="1">spiffeID = uri</span>
        }
        <span class="cov8" title="1">return spiffeID</span>
}
</pre>
		
		<pre class="file" id="file78" style="display: none">/*
 *
 * Copyright 2018 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package credentials

import (
        "net"
        "syscall"
)

type sysConn = syscall.Conn

// syscallConn keeps reference of rawConn to support syscall.Conn for channelz.
// SyscallConn() (the method in interface syscall.Conn) is explicitly
// implemented on this type,
//
// Interface syscall.Conn is implemented by most net.Conn implementations (e.g.
// TCPConn, UnixConn), but is not part of net.Conn interface. So wrapper conns
// that embed net.Conn don't implement syscall.Conn. (Side note: tls.Conn
// doesn't embed net.Conn, so even if syscall.Conn is part of net.Conn, it won't
// help here).
type syscallConn struct {
        net.Conn
        // sysConn is a type alias of syscall.Conn. It's necessary because the name
        // `Conn` collides with `net.Conn`.
        sysConn
}

// WrapSyscallConn tries to wrap rawConn and newConn into a net.Conn that
// implements syscall.Conn. rawConn will be used to support syscall, and newConn
// will be used for read/write.
//
// This function returns newConn if rawConn doesn't implement syscall.Conn.
func WrapSyscallConn(rawConn, newConn net.Conn) net.Conn <span class="cov8" title="1">{
        sysConn, ok := rawConn.(syscall.Conn)
        if !ok </span><span class="cov8" title="1">{
                return newConn
        }</span>
        <span class="cov8" title="1">return &amp;syscallConn{
                Conn:    newConn,
                sysConn: sysConn,
        }</span>
}
</pre>
		
		<pre class="file" id="file79" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package credentials

import (
        "crypto/tls"
)

const alpnProtoStrH2 = "h2"

// AppendH2ToNextProtos appends h2 to next protos.
func AppendH2ToNextProtos(ps []string) []string <span class="cov8" title="1">{
        for _, p := range ps </span><span class="cov8" title="1">{
                if p == alpnProtoStrH2 </span><span class="cov8" title="1">{
                        return ps
                }</span>
        }
        <span class="cov8" title="1">ret := make([]string, 0, len(ps)+1)
        ret = append(ret, ps...)
        return append(ret, alpnProtoStrH2)</span>
}

// CloneTLSConfig returns a shallow clone of the exported
// fields of cfg, ignoring the unexported sync.Once, which
// contains a mutex and must not be copied.
//
// If cfg is nil, a new zero tls.Config is returned.
//
// TODO: inline this function if possible.
func CloneTLSConfig(cfg *tls.Config) *tls.Config <span class="cov0" title="0">{
        if cfg == nil </span><span class="cov0" title="0">{
                return &amp;tls.Config{}
        }</span>

        <span class="cov0" title="0">return cfg.Clone()</span>
}
</pre>
		
		<pre class="file" id="file80" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package xds contains non-user facing functionality of the xds credentials.
package xds

import (
        "context"
        "crypto/tls"
        "crypto/x509"
        "errors"
        "fmt"
        "strings"
        "sync"

        "google.golang.org/grpc/attributes"
        "google.golang.org/grpc/credentials/tls/certprovider"
        "google.golang.org/grpc/internal"
        "google.golang.org/grpc/internal/xds/matcher"
        "google.golang.org/grpc/resolver"
)

func init() <span class="cov8" title="1">{
        internal.GetXDSHandshakeInfoForTesting = GetHandshakeInfo
}</span>

// handshakeAttrKey is the type used as the key to store HandshakeInfo in
// the Attributes field of resolver.Address.
type handshakeAttrKey struct{}

// Equal reports whether the handshake info structs are identical (have the
// same pointer).  This is sufficient as all subconns from one CDS balancer use
// the same one.
func (hi *HandshakeInfo) Equal(o interface{}) bool <span class="cov0" title="0">{
        oh, ok := o.(*HandshakeInfo)
        return ok &amp;&amp; oh == hi
}</span>

// SetHandshakeInfo returns a copy of addr in which the Attributes field is
// updated with hInfo.
func SetHandshakeInfo(addr resolver.Address, hInfo *HandshakeInfo) resolver.Address <span class="cov0" title="0">{
        addr.Attributes = addr.Attributes.WithValue(handshakeAttrKey{}, hInfo)
        return addr
}</span>

// GetHandshakeInfo returns a pointer to the HandshakeInfo stored in attr.
func GetHandshakeInfo(attr *attributes.Attributes) *HandshakeInfo <span class="cov0" title="0">{
        v := attr.Value(handshakeAttrKey{})
        hi, _ := v.(*HandshakeInfo)
        return hi
}</span>

// HandshakeInfo wraps all the security configuration required by client and
// server handshake methods in xds credentials. The xDS implementation will be
// responsible for populating these fields.
//
// Safe for concurrent access.
type HandshakeInfo struct {
        mu                sync.Mutex
        rootProvider      certprovider.Provider
        identityProvider  certprovider.Provider
        sanMatchers       []matcher.StringMatcher // Only on the client side.
        requireClientCert bool                    // Only on server side.
}

// SetRootCertProvider updates the root certificate provider.
func (hi *HandshakeInfo) SetRootCertProvider(root certprovider.Provider) <span class="cov0" title="0">{
        hi.mu.Lock()
        hi.rootProvider = root
        hi.mu.Unlock()
}</span>

// SetIdentityCertProvider updates the identity certificate provider.
func (hi *HandshakeInfo) SetIdentityCertProvider(identity certprovider.Provider) <span class="cov0" title="0">{
        hi.mu.Lock()
        hi.identityProvider = identity
        hi.mu.Unlock()
}</span>

// SetSANMatchers updates the list of SAN matchers.
func (hi *HandshakeInfo) SetSANMatchers(sanMatchers []matcher.StringMatcher) <span class="cov8" title="1">{
        hi.mu.Lock()
        hi.sanMatchers = sanMatchers
        hi.mu.Unlock()
}</span>

// SetRequireClientCert updates whether a client cert is required during the
// ServerHandshake(). A value of true indicates that we are performing mTLS.
func (hi *HandshakeInfo) SetRequireClientCert(require bool) <span class="cov0" title="0">{
        hi.mu.Lock()
        hi.requireClientCert = require
        hi.mu.Unlock()
}</span>

// UseFallbackCreds returns true when fallback credentials are to be used based
// on the contents of the HandshakeInfo.
func (hi *HandshakeInfo) UseFallbackCreds() bool <span class="cov0" title="0">{
        if hi == nil </span><span class="cov0" title="0">{
                return true
        }</span>

        <span class="cov0" title="0">hi.mu.Lock()
        defer hi.mu.Unlock()
        return hi.identityProvider == nil &amp;&amp; hi.rootProvider == nil</span>
}

// GetSANMatchersForTesting returns the SAN matchers stored in HandshakeInfo.
// To be used only for testing purposes.
func (hi *HandshakeInfo) GetSANMatchersForTesting() []matcher.StringMatcher <span class="cov0" title="0">{
        hi.mu.Lock()
        defer hi.mu.Unlock()
        return append([]matcher.StringMatcher{}, hi.sanMatchers...)
}</span>

// ClientSideTLSConfig constructs a tls.Config to be used in a client-side
// handshake based on the contents of the HandshakeInfo.
func (hi *HandshakeInfo) ClientSideTLSConfig(ctx context.Context) (*tls.Config, error) <span class="cov0" title="0">{
        hi.mu.Lock()
        // On the client side, rootProvider is mandatory. IdentityProvider is
        // optional based on whether the client is doing TLS or mTLS.
        if hi.rootProvider == nil </span><span class="cov0" title="0">{
                return nil, errors.New("xds: CertificateProvider to fetch trusted roots is missing, cannot perform TLS handshake. Please check configuration on the management server")
        }</span>
        // Since the call to KeyMaterial() can block, we read the providers under
        // the lock but call the actual function after releasing the lock.
        <span class="cov0" title="0">rootProv, idProv := hi.rootProvider, hi.identityProvider
        hi.mu.Unlock()

        // InsecureSkipVerify needs to be set to true because we need to perform
        // custom verification to check the SAN on the received certificate.
        // Currently the Go stdlib does complete verification of the cert (which
        // includes hostname verification) or none. We are forced to go with the
        // latter and perform the normal cert validation ourselves.
        cfg := &amp;tls.Config{
                InsecureSkipVerify: true,
                NextProtos:         []string{"h2"},
        }

        km, err := rootProv.KeyMaterial(ctx)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("xds: fetching trusted roots from CertificateProvider failed: %v", err)
        }</span>
        <span class="cov0" title="0">cfg.RootCAs = km.Roots

        if idProv != nil </span><span class="cov0" title="0">{
                km, err := idProv.KeyMaterial(ctx)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("xds: fetching identity certificates from CertificateProvider failed: %v", err)
                }</span>
                <span class="cov0" title="0">cfg.Certificates = km.Certs</span>
        }
        <span class="cov0" title="0">return cfg, nil</span>
}

// ServerSideTLSConfig constructs a tls.Config to be used in a server-side
// handshake based on the contents of the HandshakeInfo.
func (hi *HandshakeInfo) ServerSideTLSConfig(ctx context.Context) (*tls.Config, error) <span class="cov0" title="0">{
        cfg := &amp;tls.Config{
                ClientAuth: tls.NoClientCert,
                NextProtos: []string{"h2"},
        }
        hi.mu.Lock()
        // On the server side, identityProvider is mandatory. RootProvider is
        // optional based on whether the server is doing TLS or mTLS.
        if hi.identityProvider == nil </span><span class="cov0" title="0">{
                return nil, errors.New("xds: CertificateProvider to fetch identity certificate is missing, cannot perform TLS handshake. Please check configuration on the management server")
        }</span>
        // Since the call to KeyMaterial() can block, we read the providers under
        // the lock but call the actual function after releasing the lock.
        <span class="cov0" title="0">rootProv, idProv := hi.rootProvider, hi.identityProvider
        if hi.requireClientCert </span><span class="cov0" title="0">{
                cfg.ClientAuth = tls.RequireAndVerifyClientCert
        }</span>
        <span class="cov0" title="0">hi.mu.Unlock()

        // identityProvider is mandatory on the server side.
        km, err := idProv.KeyMaterial(ctx)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("xds: fetching identity certificates from CertificateProvider failed: %v", err)
        }</span>
        <span class="cov0" title="0">cfg.Certificates = km.Certs

        if rootProv != nil </span><span class="cov0" title="0">{
                km, err := rootProv.KeyMaterial(ctx)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("xds: fetching trusted roots from CertificateProvider failed: %v", err)
                }</span>
                <span class="cov0" title="0">cfg.ClientCAs = km.Roots</span>
        }
        <span class="cov0" title="0">return cfg, nil</span>
}

// MatchingSANExists returns true if the SANs contained in cert match the
// criteria enforced by the list of SAN matchers in HandshakeInfo.
//
// If the list of SAN matchers in the HandshakeInfo is empty, this function
// returns true for all input certificates.
func (hi *HandshakeInfo) MatchingSANExists(cert *x509.Certificate) bool <span class="cov8" title="1">{
        hi.mu.Lock()
        defer hi.mu.Unlock()
        if len(hi.sanMatchers) == 0 </span><span class="cov8" title="1">{
                return true
        }</span>

        // SANs can be specified in any of these four fields on the parsed cert.
        <span class="cov8" title="1">for _, san := range cert.DNSNames </span><span class="cov8" title="1">{
                if hi.matchSAN(san, true) </span><span class="cov8" title="1">{
                        return true
                }</span>
        }
        <span class="cov8" title="1">for _, san := range cert.EmailAddresses </span><span class="cov8" title="1">{
                if hi.matchSAN(san, false) </span><span class="cov8" title="1">{
                        return true
                }</span>
        }
        <span class="cov8" title="1">for _, san := range cert.IPAddresses </span><span class="cov8" title="1">{
                if hi.matchSAN(san.String(), false) </span><span class="cov8" title="1">{
                        return true
                }</span>
        }
        <span class="cov8" title="1">for _, san := range cert.URIs </span><span class="cov8" title="1">{
                if hi.matchSAN(san.String(), false) </span><span class="cov8" title="1">{
                        return true
                }</span>
        }
        <span class="cov8" title="1">return false</span>
}

// Caller must hold mu.
func (hi *HandshakeInfo) matchSAN(san string, isDNS bool) bool <span class="cov8" title="1">{
        for _, matcher := range hi.sanMatchers </span><span class="cov8" title="1">{
                if em := matcher.ExactMatch(); em != "" &amp;&amp; isDNS </span><span class="cov8" title="1">{
                        // This is a special case which is documented in the xDS protos.
                        // If the DNS SAN is a wildcard entry, and the match criteria is
                        // `exact`, then we need to perform DNS wildcard matching
                        // instead of regular string comparison.
                        if dnsMatch(em, san) </span><span class="cov8" title="1">{
                                return true
                        }</span>
                        <span class="cov8" title="1">continue</span>
                }
                <span class="cov8" title="1">if matcher.Match(san) </span><span class="cov8" title="1">{
                        return true
                }</span>
        }
        <span class="cov8" title="1">return false</span>
}

// dnsMatch implements a DNS wildcard matching algorithm based on RFC2828 and
// grpc-java's implementation in `OkHostnameVerifier` class.
//
// NOTE: Here the `host` argument is the one from the set of string matchers in
// the xDS proto and the `san` argument is a DNS SAN from the certificate, and
// this is the one which can potentially contain a wildcard pattern.
func dnsMatch(host, san string) bool <span class="cov8" title="1">{
        // Add trailing "." and turn them into absolute domain names.
        if !strings.HasSuffix(host, ".") </span><span class="cov8" title="1">{
                host += "."
        }</span>
        <span class="cov8" title="1">if !strings.HasSuffix(san, ".") </span><span class="cov8" title="1">{
                san += "."
        }</span>
        // Domain names are case-insensitive.
        <span class="cov8" title="1">host = strings.ToLower(host)
        san = strings.ToLower(san)

        // If san does not contain a wildcard, do exact match.
        if !strings.Contains(san, "*") </span><span class="cov8" title="1">{
                return host == san
        }</span>

        // Wildcard dns matching rules
        // - '*' is only permitted in the left-most label and must be the only
        //   character in that label. For example, *.example.com is permitted, while
        //   *a.example.com, a*.example.com, a*b.example.com, a.*.example.com are
        //   not permitted.
        // - '*' matches a single domain name component. For example, *.example.com
        //   matches test.example.com but does not match sub.test.example.com.
        // - Wildcard patterns for single-label domain names are not permitted.
        <span class="cov8" title="1">if san == "*." || !strings.HasPrefix(san, "*.") || strings.Contains(san[1:], "*") </span><span class="cov8" title="1">{
                return false
        }</span>
        // Optimization: at this point, we know that the san contains a '*' and
        // is the first domain component of san. So, the host name must be at
        // least as long as the san to be able to match.
        <span class="cov8" title="1">if len(host) &lt; len(san) </span><span class="cov8" title="1">{
                return false
        }</span>
        // Hostname must end with the non-wildcard portion of san.
        <span class="cov8" title="1">if !strings.HasSuffix(host, san[1:]) </span><span class="cov8" title="1">{
                return false
        }</span>
        // At this point we know that the hostName and san share the same suffix
        // (the non-wildcard portion of san). Now, we just need to make sure
        // that the '*' does not match across domain components.
        <span class="cov8" title="1">hostPrefix := strings.TrimSuffix(host, san[1:])
        return !strings.Contains(hostPrefix, ".")</span>
}

// NewHandshakeInfo returns a new instance of HandshakeInfo with the given root
// and identity certificate providers.
func NewHandshakeInfo(root, identity certprovider.Provider) *HandshakeInfo <span class="cov8" title="1">{
        return &amp;HandshakeInfo{rootProvider: root, identityProvider: identity}
}</span>
</pre>
		
		<pre class="file" id="file81" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package googlecloud contains internal helpful functions for google cloud.
package googlecloud

import (
        "runtime"
        "strings"
        "sync"

        "google.golang.org/grpc/grpclog"
        internalgrpclog "google.golang.org/grpc/internal/grpclog"
)

const logPrefix = "[googlecloud]"

var (
        vmOnGCEOnce sync.Once
        vmOnGCE     bool

        logger = internalgrpclog.NewPrefixLogger(grpclog.Component("googlecloud"), logPrefix)
)

// OnGCE returns whether the client is running on GCE.
//
// It provides similar functionality as metadata.OnGCE from the cloud library
// package. We keep this to avoid depending on the cloud library module.
func OnGCE() bool <span class="cov0" title="0">{
        vmOnGCEOnce.Do(func() </span><span class="cov0" title="0">{
                mf, err := manufacturer()
                if err != nil </span><span class="cov0" title="0">{
                        logger.Infof("failed to read manufacturer, setting onGCE=false: %v")
                        return
                }</span>
                <span class="cov0" title="0">vmOnGCE = isRunningOnGCE(mf, runtime.GOOS)</span>
        })
        <span class="cov0" title="0">return vmOnGCE</span>
}

// isRunningOnGCE checks whether the local system, without doing a network request, is
// running on GCP.
func isRunningOnGCE(manufacturer []byte, goos string) bool <span class="cov8" title="1">{
        name := string(manufacturer)
        switch goos </span>{
        case "linux":<span class="cov8" title="1">
                name = strings.TrimSpace(name)
                return name == "Google" || name == "Google Compute Engine"</span>
        case "windows":<span class="cov8" title="1">
                name = strings.Replace(name, " ", "", -1)
                name = strings.Replace(name, "\n", "", -1)
                name = strings.Replace(name, "\r", "", -1)
                return name == "Google"</span>
        default:<span class="cov0" title="0">
                return false</span>
        }
}
</pre>
		
		<pre class="file" id="file82" style="display: none">//go:build !(linux || windows)
// +build !linux,!windows

/*
 *
 * Copyright 2022 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package googlecloud

func manufacturer() ([]byte, error) <span class="cov0" title="0">{
        return nil, nil
}</span>
</pre>
		
		<pre class="file" id="file83" style="display: none">/*
 *
 * Copyright 2018 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package grpcsync implements additional synchronization primitives built upon
// the sync package.
package grpcsync

import (
        "sync"
        "sync/atomic"
)

// Event represents a one-time event that may occur in the future.
type Event struct {
        fired int32
        c     chan struct{}
        o     sync.Once
}

// Fire causes e to complete.  It is safe to call multiple times, and
// concurrently.  It returns true iff this call to Fire caused the signaling
// channel returned by Done to close.
func (e *Event) Fire() bool <span class="cov8" title="1">{
        ret := false
        e.o.Do(func() </span><span class="cov8" title="1">{
                atomic.StoreInt32(&amp;e.fired, 1)
                close(e.c)
                ret = true
        }</span>)
        <span class="cov8" title="1">return ret</span>
}

// Done returns a channel that will be closed when Fire is called.
func (e *Event) Done() &lt;-chan struct{} <span class="cov8" title="1">{
        return e.c
}</span>

// HasFired returns true if Fire has been called.
func (e *Event) HasFired() bool <span class="cov8" title="1">{
        return atomic.LoadInt32(&amp;e.fired) == 1
}</span>

// NewEvent returns a new, ready-to-use Event.
func NewEvent() *Event <span class="cov8" title="1">{
        return &amp;Event{c: make(chan struct{})}
}</span>
</pre>
		
		<pre class="file" id="file84" style="display: none">/*
 *
 * Copyright 2018 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package grpctest implements testing helpers.
package grpctest

import (
        "reflect"
        "strings"
        "sync/atomic"
        "testing"

        "google.golang.org/grpc/internal/leakcheck"
)

var lcFailed uint32

type errorer struct {
        t *testing.T
}

func (e errorer) Errorf(format string, args ...interface{}) <span class="cov0" title="0">{
        atomic.StoreUint32(&amp;lcFailed, 1)
        e.t.Errorf(format, args...)
}</span>

// Tester is an implementation of the x interface parameter to
// grpctest.RunSubTests with default Setup and Teardown behavior. Setup updates
// the tlogger and Teardown performs a leak check. Embed in a struct with tests
// defined to use.
type Tester struct{}

// Setup updates the tlogger.
func (Tester) Setup(t *testing.T) <span class="cov8" title="1">{
        TLogger.Update(t)
}</span>

// Teardown performs a leak check.
func (Tester) Teardown(t *testing.T) <span class="cov8" title="1">{
        if atomic.LoadUint32(&amp;lcFailed) == 1 </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov8" title="1">leakcheck.Check(errorer{t: t})
        if atomic.LoadUint32(&amp;lcFailed) == 1 </span><span class="cov0" title="0">{
                t.Log("Leak check disabled for future tests")
        }</span>
        <span class="cov8" title="1">TLogger.EndTest(t)</span>
}

func getTestFunc(t *testing.T, xv reflect.Value, name string) func(*testing.T) <span class="cov8" title="1">{
        if m := xv.MethodByName(name); m.IsValid() </span><span class="cov8" title="1">{
                if f, ok := m.Interface().(func(*testing.T)); ok </span><span class="cov8" title="1">{
                        return f
                }</span>
                // Method exists but has the wrong type signature.
                <span class="cov0" title="0">t.Fatalf("grpctest: function %v has unexpected signature (%T)", name, m.Interface())</span>
        }
        <span class="cov8" title="1">return func(*testing.T) </span>{<span class="cov8" title="1">}</span>
}

// RunSubTests runs all "Test___" functions that are methods of x as subtests
// of the current test.  If x contains methods "Setup(*testing.T)" or
// "Teardown(*testing.T)", those are run before or after each of the test
// functions, respectively.
//
// For example usage, see example_test.go.  Run it using:
//     $ go test -v -run TestExample .
//
// To run a specific test/subtest:
//     $ go test -v -run 'TestExample/^Something$' .
func RunSubTests(t *testing.T, x interface{}) <span class="cov8" title="1">{
        xt := reflect.TypeOf(x)
        xv := reflect.ValueOf(x)

        setup := getTestFunc(t, xv, "Setup")
        teardown := getTestFunc(t, xv, "Teardown")

        for i := 0; i &lt; xt.NumMethod(); i++ </span><span class="cov8" title="1">{
                methodName := xt.Method(i).Name
                if !strings.HasPrefix(methodName, "Test") </span><span class="cov8" title="1">{
                        continue</span>
                }
                <span class="cov8" title="1">tfunc := getTestFunc(t, xv, methodName)
                t.Run(strings.TrimPrefix(methodName, "Test"), func(t *testing.T) </span><span class="cov8" title="1">{
                        // Run leakcheck in t.Cleanup() to guarantee it is run even if tfunc
                        // or setup uses t.Fatal().
                        //
                        // Note that a defer would run before t.Cleanup, so if a goroutine
                        // is closed by a test's t.Cleanup, a deferred leakcheck would fail.
                        t.Cleanup(func() </span><span class="cov8" title="1">{ teardown(t) }</span>)
                        <span class="cov8" title="1">setup(t)
                        tfunc(t)</span>
                })
        }
}
</pre>
		
		<pre class="file" id="file85" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package grpctest

import (
        "errors"
        "fmt"
        "os"
        "path"
        "regexp"
        "runtime"
        "strconv"
        "sync"
        "testing"
        "time"

        "google.golang.org/grpc/grpclog"
)

// TLogger serves as the grpclog logger and is the interface through which
// expected errors are declared in tests.
var TLogger *tLogger

const callingFrame = 4

type logType int

func (l logType) String() string <span class="cov8" title="1">{
        switch l </span>{
        case infoLog:<span class="cov8" title="1">
                return "INFO"</span>
        case warningLog:<span class="cov8" title="1">
                return "WARNING"</span>
        case errorLog:<span class="cov8" title="1">
                return "ERROR"</span>
        case fatalLog:<span class="cov0" title="0">
                return "FATAL"</span>
        }
        <span class="cov0" title="0">return "UNKNOWN"</span>
}

const (
        infoLog logType = iota
        warningLog
        errorLog
        fatalLog
)

type tLogger struct {
        v           int
        initialized bool

        mu     sync.Mutex // guards t, start, and errors
        t      *testing.T
        start  time.Time
        errors map[*regexp.Regexp]int
}

func init() <span class="cov8" title="1">{
        TLogger = &amp;tLogger{errors: map[*regexp.Regexp]int{}}
        vLevel := os.Getenv("GRPC_GO_LOG_VERBOSITY_LEVEL")
        if vl, err := strconv.Atoi(vLevel); err == nil </span><span class="cov0" title="0">{
                TLogger.v = vl
        }</span>
}

// getCallingPrefix returns the &lt;file:line&gt; at the given depth from the stack.
func getCallingPrefix(depth int) (string, error) <span class="cov8" title="1">{
        _, file, line, ok := runtime.Caller(depth)
        if !ok </span><span class="cov0" title="0">{
                return "", errors.New("frame request out-of-bounds")
        }</span>
        <span class="cov8" title="1">return fmt.Sprintf("%s:%d", path.Base(file), line), nil</span>
}

// log logs the message with the specified parameters to the tLogger.
func (g *tLogger) log(ltype logType, depth int, format string, args ...interface{}) <span class="cov8" title="1">{
        g.mu.Lock()
        defer g.mu.Unlock()
        prefix, err := getCallingPrefix(callingFrame + depth)
        if err != nil </span><span class="cov0" title="0">{
                g.t.Error(err)
                return
        }</span>
        <span class="cov8" title="1">args = append([]interface{}{ltype.String() + " " + prefix}, args...)
        args = append(args, fmt.Sprintf(" (t=+%s)", time.Since(g.start)))

        if format == "" </span><span class="cov8" title="1">{
                switch ltype </span>{
                case errorLog:<span class="cov8" title="1">
                        // fmt.Sprintln is used rather than fmt.Sprint because t.Log uses fmt.Sprintln behavior.
                        if g.expected(fmt.Sprintln(args...)) </span><span class="cov8" title="1">{
                                g.t.Log(args...)
                        }</span> else<span class="cov0" title="0"> {
                                g.t.Error(args...)
                        }</span>
                case fatalLog:<span class="cov0" title="0">
                        panic(fmt.Sprint(args...))</span>
                default:<span class="cov8" title="1">
                        g.t.Log(args...)</span>
                }
        } else<span class="cov8" title="1"> {
                // Add formatting directives for the callingPrefix and timeSuffix.
                format = "%v " + format + "%s"
                switch ltype </span>{
                case errorLog:<span class="cov8" title="1">
                        if g.expected(fmt.Sprintf(format, args...)) </span><span class="cov8" title="1">{
                                g.t.Logf(format, args...)
                        }</span> else<span class="cov0" title="0"> {
                                g.t.Errorf(format, args...)
                        }</span>
                case fatalLog:<span class="cov0" title="0">
                        panic(fmt.Sprintf(format, args...))</span>
                default:<span class="cov8" title="1">
                        g.t.Logf(format, args...)</span>
                }
        }
}

// Update updates the testing.T that the testing logger logs to. Should be done
// before every test. It also initializes the tLogger if it has not already.
func (g *tLogger) Update(t *testing.T) <span class="cov8" title="1">{
        g.mu.Lock()
        defer g.mu.Unlock()
        if !g.initialized </span><span class="cov8" title="1">{
                grpclog.SetLoggerV2(TLogger)
                g.initialized = true
        }</span>
        <span class="cov8" title="1">g.t = t
        g.start = time.Now()
        g.errors = map[*regexp.Regexp]int{}</span>
}

// ExpectError declares an error to be expected. For the next test, the first
// error log matching the expression (using FindString) will not cause the test
// to fail. "For the next test" includes all the time until the next call to
// Update(). Note that if an expected error is not encountered, this will cause
// the test to fail.
func (g *tLogger) ExpectError(expr string) <span class="cov8" title="1">{
        g.ExpectErrorN(expr, 1)
}</span>

// ExpectErrorN declares an error to be expected n times.
func (g *tLogger) ExpectErrorN(expr string, n int) <span class="cov8" title="1">{
        g.mu.Lock()
        defer g.mu.Unlock()
        re, err := regexp.Compile(expr)
        if err != nil </span><span class="cov0" title="0">{
                g.t.Error(err)
                return
        }</span>
        <span class="cov8" title="1">g.errors[re] += n</span>
}

// EndTest checks if expected errors were not encountered.
func (g *tLogger) EndTest(t *testing.T) <span class="cov8" title="1">{
        g.mu.Lock()
        defer g.mu.Unlock()
        for re, count := range g.errors </span><span class="cov0" title="0">{
                if count &gt; 0 </span><span class="cov0" title="0">{
                        t.Errorf("Expected error '%v' not encountered", re.String())
                }</span>
        }
        <span class="cov8" title="1">g.errors = map[*regexp.Regexp]int{}</span>
}

// expected determines if the error string is protected or not.
func (g *tLogger) expected(s string) bool <span class="cov8" title="1">{
        for re, count := range g.errors </span><span class="cov8" title="1">{
                if re.FindStringIndex(s) != nil </span><span class="cov8" title="1">{
                        g.errors[re]--
                        if count &lt;= 1 </span><span class="cov8" title="1">{
                                delete(g.errors, re)
                        }</span>
                        <span class="cov8" title="1">return true</span>
                }
        }
        <span class="cov0" title="0">return false</span>
}

func (g *tLogger) Info(args ...interface{}) <span class="cov8" title="1">{
        g.log(infoLog, 0, "", args...)
}</span>

func (g *tLogger) Infoln(args ...interface{}) <span class="cov8" title="1">{
        g.log(infoLog, 0, "", args...)
}</span>

func (g *tLogger) Infof(format string, args ...interface{}) <span class="cov8" title="1">{
        g.log(infoLog, 0, format, args...)
}</span>

func (g *tLogger) InfoDepth(depth int, args ...interface{}) <span class="cov8" title="1">{
        g.log(infoLog, depth, "", args...)
}</span>

func (g *tLogger) Warning(args ...interface{}) <span class="cov8" title="1">{
        g.log(warningLog, 0, "", args...)
}</span>

func (g *tLogger) Warningln(args ...interface{}) <span class="cov8" title="1">{
        g.log(warningLog, 0, "", args...)
}</span>

func (g *tLogger) Warningf(format string, args ...interface{}) <span class="cov8" title="1">{
        g.log(warningLog, 0, format, args...)
}</span>

func (g *tLogger) WarningDepth(depth int, args ...interface{}) <span class="cov8" title="1">{
        g.log(warningLog, depth, "", args...)
}</span>

func (g *tLogger) Error(args ...interface{}) <span class="cov8" title="1">{
        g.log(errorLog, 0, "", args...)
}</span>

func (g *tLogger) Errorln(args ...interface{}) <span class="cov8" title="1">{
        g.log(errorLog, 0, "", args...)
}</span>

func (g *tLogger) Errorf(format string, args ...interface{}) <span class="cov8" title="1">{
        g.log(errorLog, 0, format, args...)
}</span>

func (g *tLogger) ErrorDepth(depth int, args ...interface{}) <span class="cov0" title="0">{
        g.log(errorLog, depth, "", args...)
}</span>

func (g *tLogger) Fatal(args ...interface{}) <span class="cov0" title="0">{
        g.log(fatalLog, 0, "", args...)
}</span>

func (g *tLogger) Fatalln(args ...interface{}) <span class="cov0" title="0">{
        g.log(fatalLog, 0, "", args...)
}</span>

func (g *tLogger) Fatalf(format string, args ...interface{}) <span class="cov0" title="0">{
        g.log(fatalLog, 0, format, args...)
}</span>

func (g *tLogger) FatalDepth(depth int, args ...interface{}) <span class="cov0" title="0">{
        g.log(fatalLog, depth, "", args...)
}</span>

func (g *tLogger) V(l int) bool <span class="cov0" title="0">{
        return l &lt;= g.v
}</span>
</pre>
		
		<pre class="file" id="file86" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package grpcutil

import (
        "strconv"
        "time"
)

const maxTimeoutValue int64 = 100000000 - 1

// div does integer division and round-up the result. Note that this is
// equivalent to (d+r-1)/r but has less chance to overflow.
func div(d, r time.Duration) int64 <span class="cov8" title="1">{
        if d%r &gt; 0 </span><span class="cov8" title="1">{
                return int64(d/r + 1)
        }</span>
        <span class="cov8" title="1">return int64(d / r)</span>
}

// EncodeDuration encodes the duration to the format grpc-timeout header
// accepts.
//
// https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md#requests
func EncodeDuration(t time.Duration) string <span class="cov8" title="1">{
        // TODO: This is simplistic and not bandwidth efficient. Improve it.
        if t &lt;= 0 </span><span class="cov0" title="0">{
                return "0n"
        }</span>
        <span class="cov8" title="1">if d := div(t, time.Nanosecond); d &lt;= maxTimeoutValue </span><span class="cov8" title="1">{
                return strconv.FormatInt(d, 10) + "n"
        }</span>
        <span class="cov8" title="1">if d := div(t, time.Microsecond); d &lt;= maxTimeoutValue </span><span class="cov8" title="1">{
                return strconv.FormatInt(d, 10) + "u"
        }</span>
        <span class="cov8" title="1">if d := div(t, time.Millisecond); d &lt;= maxTimeoutValue </span><span class="cov8" title="1">{
                return strconv.FormatInt(d, 10) + "m"
        }</span>
        <span class="cov8" title="1">if d := div(t, time.Second); d &lt;= maxTimeoutValue </span><span class="cov8" title="1">{
                return strconv.FormatInt(d, 10) + "S"
        }</span>
        <span class="cov8" title="1">if d := div(t, time.Minute); d &lt;= maxTimeoutValue </span><span class="cov8" title="1">{
                return strconv.FormatInt(d, 10) + "M"
        }</span>
        // Note that maxTimeoutValue * time.Hour &gt; MaxInt64.
        <span class="cov8" title="1">return strconv.FormatInt(div(t, time.Hour), 10) + "H"</span>
}
</pre>
		
		<pre class="file" id="file87" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package grpcutil

import (
        "context"

        "google.golang.org/grpc/metadata"
)

type mdExtraKey struct{}

// WithExtraMetadata creates a new context with incoming md attached.
func WithExtraMetadata(ctx context.Context, md metadata.MD) context.Context <span class="cov0" title="0">{
        return context.WithValue(ctx, mdExtraKey{}, md)
}</span>

// ExtraMetadata returns the incoming metadata in ctx if it exists.  The
// returned MD should not be modified. Writing to it may cause races.
// Modification should be made to copies of the returned MD.
func ExtraMetadata(ctx context.Context) (md metadata.MD, ok bool) <span class="cov0" title="0">{
        md, ok = ctx.Value(mdExtraKey{}).(metadata.MD)
        return
}</span>
</pre>
		
		<pre class="file" id="file88" style="display: none">/*
 *
 * Copyright 2018 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package grpcutil

import (
        "errors"
        "strings"
)

// ParseMethod splits service and method from the input. It expects format
// "/service/method".
//
func ParseMethod(methodName string) (service, method string, _ error) <span class="cov8" title="1">{
        if !strings.HasPrefix(methodName, "/") </span><span class="cov8" title="1">{
                return "", "", errors.New("invalid method name: should start with /")
        }</span>
        <span class="cov8" title="1">methodName = methodName[1:]

        pos := strings.LastIndex(methodName, "/")
        if pos &lt; 0 </span><span class="cov8" title="1">{
                return "", "", errors.New("invalid method name: suffix /method is missing")
        }</span>
        <span class="cov8" title="1">return methodName[:pos], methodName[pos+1:], nil</span>
}

// baseContentType is the base content-type for gRPC.  This is a valid
// content-type on it's own, but can also include a content-subtype such as
// "proto" as a suffix after "+" or ";".  See
// https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md#requests
// for more details.
const baseContentType = "application/grpc"

// ContentSubtype returns the content-subtype for the given content-type.  The
// given content-type must be a valid content-type that starts with
// "application/grpc". A content-subtype will follow "application/grpc" after a
// "+" or ";". See
// https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md#requests for
// more details.
//
// If contentType is not a valid content-type for gRPC, the boolean
// will be false, otherwise true. If content-type == "application/grpc",
// "application/grpc+", or "application/grpc;", the boolean will be true,
// but no content-subtype will be returned.
//
// contentType is assumed to be lowercase already.
func ContentSubtype(contentType string) (string, bool) <span class="cov8" title="1">{
        if contentType == baseContentType </span><span class="cov8" title="1">{
                return "", true
        }</span>
        <span class="cov8" title="1">if !strings.HasPrefix(contentType, baseContentType) </span><span class="cov8" title="1">{
                return "", false
        }</span>
        // guaranteed since != baseContentType and has baseContentType prefix
        <span class="cov8" title="1">switch contentType[len(baseContentType)] </span>{
        case '+', ';':<span class="cov8" title="1">
                // this will return true for "application/grpc+" or "application/grpc;"
                // which the previous validContentType function tested to be valid, so we
                // just say that no content-subtype is specified in this case
                return contentType[len(baseContentType)+1:], true</span>
        default:<span class="cov8" title="1">
                return "", false</span>
        }
}

// ContentType builds full content type with the given sub-type.
//
// contentSubtype is assumed to be lowercase
func ContentType(contentSubtype string) string <span class="cov0" title="0">{
        if contentSubtype == "" </span><span class="cov0" title="0">{
                return baseContentType
        }</span>
        <span class="cov0" title="0">return baseContentType + "+" + contentSubtype</span>
}
</pre>
		
		<pre class="file" id="file89" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package grpcutil

import "regexp"

// FullMatchWithRegex returns whether the full text matches the regex provided.
func FullMatchWithRegex(re *regexp.Regexp, text string) bool <span class="cov8" title="1">{
        if len(text) == 0 </span><span class="cov8" title="1">{
                return re.MatchString(text)
        }</span>
        <span class="cov8" title="1">re.Longest()
        rem := re.FindString(text)
        return len(rem) == len(text)</span>
}
</pre>
		
		<pre class="file" id="file90" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package hierarchy contains functions to set and get hierarchy string from
// addresses.
//
// This package is experimental.
package hierarchy

import (
        "google.golang.org/grpc/resolver"
)

type pathKeyType string

const pathKey = pathKeyType("grpc.internal.address.hierarchical_path")

type pathValue []string

func (p pathValue) Equal(o interface{}) bool <span class="cov8" title="1">{
        op, ok := o.(pathValue)
        if !ok </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov8" title="1">if len(op) != len(p) </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov8" title="1">for i, v := range p </span><span class="cov0" title="0">{
                if v != op[i] </span><span class="cov0" title="0">{
                        return false
                }</span>
        }
        <span class="cov8" title="1">return true</span>
}

// Get returns the hierarchical path of addr.
func Get(addr resolver.Address) []string <span class="cov8" title="1">{
        attrs := addr.BalancerAttributes
        if attrs == nil </span><span class="cov8" title="1">{
                return nil
        }</span>
        <span class="cov8" title="1">path, _ := attrs.Value(pathKey).(pathValue)
        return ([]string)(path)</span>
}

// Set overrides the hierarchical path in addr with path.
func Set(addr resolver.Address, path []string) resolver.Address <span class="cov8" title="1">{
        addr.BalancerAttributes = addr.BalancerAttributes.WithValue(pathKey, pathValue(path))
        return addr
}</span>

// Group splits a slice of addresses into groups based on
// the first hierarchy path. The first hierarchy path will be removed from the
// result.
//
// Input:
// [
//   {addr0, path: [p0, wt0]}
//   {addr1, path: [p0, wt1]}
//   {addr2, path: [p1, wt2]}
//   {addr3, path: [p1, wt3]}
// ]
//
// Addresses will be split into p0/p1, and the p0/p1 will be removed from the
// path.
//
// Output:
// {
//   p0: [
//     {addr0, path: [wt0]},
//     {addr1, path: [wt1]},
//   ],
//   p1: [
//     {addr2, path: [wt2]},
//     {addr3, path: [wt3]},
//   ],
// }
//
// If hierarchical path is not set, or has no path in it, the address is
// dropped.
func Group(addrs []resolver.Address) map[string][]resolver.Address <span class="cov8" title="1">{
        ret := make(map[string][]resolver.Address)
        for _, addr := range addrs </span><span class="cov8" title="1">{
                oldPath := Get(addr)
                if len(oldPath) == 0 </span><span class="cov8" title="1">{
                        continue</span>
                }
                <span class="cov8" title="1">curPath := oldPath[0]
                newPath := oldPath[1:]
                newAddr := Set(addr, newPath)
                ret[curPath] = append(ret[curPath], newAddr)</span>
        }
        <span class="cov8" title="1">return ret</span>
}
</pre>
		
		<pre class="file" id="file91" style="display: none">/*
 *
 * Copyright 2017 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package leakcheck contains functions to check leaked goroutines.
//
// Call "defer leakcheck.Check(t)" at the beginning of tests.
package leakcheck

import (
        "runtime"
        "sort"
        "strings"
        "time"
)

var goroutinesToIgnore = []string{
        "testing.Main(",
        "testing.tRunner(",
        "testing.(*M).",
        "runtime.goexit",
        "created by runtime.gc",
        "created by runtime/trace.Start",
        "interestingGoroutines",
        "runtime.MHeap_Scavenger",
        "signal.signal_recv",
        "sigterm.handler",
        "runtime_mcall",
        "(*loggingT).flushDaemon",
        "goroutine in C code",
        // Ignore the http read/write goroutines. gce metadata.OnGCE() was leaking
        // these, root cause unknown.
        //
        // https://github.com/grpc/grpc-go/issues/5171
        // https://github.com/grpc/grpc-go/issues/5173
        "created by net/http.(*Transport).dialConn",
}

// RegisterIgnoreGoroutine appends s into the ignore goroutine list. The
// goroutines whose stack trace contains s will not be identified as leaked
// goroutines. Not thread-safe, only call this function in init().
func RegisterIgnoreGoroutine(s string) <span class="cov8" title="1">{
        goroutinesToIgnore = append(goroutinesToIgnore, s)
}</span>

func ignore(g string) bool <span class="cov8" title="1">{
        sl := strings.SplitN(g, "\n", 2)
        if len(sl) != 2 </span><span class="cov0" title="0">{
                return true
        }</span>
        <span class="cov8" title="1">stack := strings.TrimSpace(sl[1])
        if strings.HasPrefix(stack, "testing.RunTests") </span><span class="cov0" title="0">{
                return true
        }</span>

        <span class="cov8" title="1">if stack == "" </span><span class="cov0" title="0">{
                return true
        }</span>

        <span class="cov8" title="1">for _, s := range goroutinesToIgnore </span><span class="cov8" title="1">{
                if strings.Contains(stack, s) </span><span class="cov8" title="1">{
                        return true
                }</span>
        }

        <span class="cov8" title="1">return false</span>
}

// interestingGoroutines returns all goroutines we care about for the purpose of
// leak checking. It excludes testing or runtime ones.
func interestingGoroutines() (gs []string) <span class="cov8" title="1">{
        buf := make([]byte, 2&lt;&lt;20)
        buf = buf[:runtime.Stack(buf, true)]
        for _, g := range strings.Split(string(buf), "\n\n") </span><span class="cov8" title="1">{
                if !ignore(g) </span><span class="cov8" title="1">{
                        gs = append(gs, g)
                }</span>
        }
        <span class="cov8" title="1">sort.Strings(gs)
        return</span>
}

// Errorfer is the interface that wraps the Errorf method. It's a subset of
// testing.TB to make it easy to use Check.
type Errorfer interface {
        Errorf(format string, args ...interface{})
}

func check(efer Errorfer, timeout time.Duration) <span class="cov8" title="1">{
        // Loop, waiting for goroutines to shut down.
        // Wait up to timeout, but finish as quickly as possible.
        deadline := time.Now().Add(timeout)
        var leaked []string
        for time.Now().Before(deadline) </span><span class="cov8" title="1">{
                if leaked = interestingGoroutines(); len(leaked) == 0 </span><span class="cov8" title="1">{
                        return
                }</span>
                <span class="cov8" title="1">time.Sleep(50 * time.Millisecond)</span>
        }
        <span class="cov8" title="1">for _, g := range leaked </span><span class="cov8" title="1">{
                efer.Errorf("Leaked goroutine: %v", g)
        }</span>
}

// Check looks at the currently-running goroutines and checks if there are any
// interesting (created by gRPC) goroutines leaked. It waits up to 10 seconds
// in the error cases.
func Check(efer Errorfer) <span class="cov0" title="0">{
        check(efer, 10*time.Second)
}</span>
</pre>
		
		<pre class="file" id="file92" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package metadata contains functions to set and get metadata from addresses.
//
// This package is experimental.
package metadata

import (
        "fmt"
        "strings"

        "google.golang.org/grpc/metadata"
        "google.golang.org/grpc/resolver"
)

type mdKeyType string

const mdKey = mdKeyType("grpc.internal.address.metadata")

type mdValue metadata.MD

func (m mdValue) Equal(o interface{}) bool <span class="cov0" title="0">{
        om, ok := o.(mdValue)
        if !ok </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov0" title="0">if len(m) != len(om) </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov0" title="0">for k, v := range m </span><span class="cov0" title="0">{
                ov := om[k]
                if len(ov) != len(v) </span><span class="cov0" title="0">{
                        return false
                }</span>
                <span class="cov0" title="0">for i, ve := range v </span><span class="cov0" title="0">{
                        if ov[i] != ve </span><span class="cov0" title="0">{
                                return false
                        }</span>
                }
        }
        <span class="cov0" title="0">return true</span>
}

// Get returns the metadata of addr.
func Get(addr resolver.Address) metadata.MD <span class="cov8" title="1">{
        attrs := addr.Attributes
        if attrs == nil </span><span class="cov8" title="1">{
                return nil
        }</span>
        <span class="cov8" title="1">md, _ := attrs.Value(mdKey).(mdValue)
        return metadata.MD(md)</span>
}

// Set sets (overrides) the metadata in addr.
//
// When a SubConn is created with this address, the RPCs sent on it will all
// have this metadata.
func Set(addr resolver.Address, md metadata.MD) resolver.Address <span class="cov8" title="1">{
        addr.Attributes = addr.Attributes.WithValue(mdKey, mdValue(md))
        return addr
}</span>

// Validate returns an error if the input md contains invalid keys or values.
//
// If the header is not a pseudo-header, the following items are checked:
// - header names must contain one or more characters from this set [0-9 a-z _ - .].
// - if the header-name ends with a "-bin" suffix, no validation of the header value is performed.
// - otherwise, the header value must contain one or more characters from the set [%x20-%x7E].
func Validate(md metadata.MD) error <span class="cov8" title="1">{
        for k, vals := range md </span><span class="cov8" title="1">{
                // pseudo-header will be ignored
                if k[0] == ':' </span><span class="cov0" title="0">{
                        continue</span>
                }
                // check key, for i that saving a conversion if not using for range
                <span class="cov8" title="1">for i := 0; i &lt; len(k); i++ </span><span class="cov8" title="1">{
                        r := k[i]
                        if !(r &gt;= 'a' &amp;&amp; r &lt;= 'z') &amp;&amp; !(r &gt;= '0' &amp;&amp; r &lt;= '9') &amp;&amp; r != '.' &amp;&amp; r != '-' &amp;&amp; r != '_' </span><span class="cov8" title="1">{
                                return fmt.Errorf("header key %q contains illegal characters not in [0-9a-z-_.]", k)
                        }</span>
                }
                <span class="cov8" title="1">if strings.HasSuffix(k, "-bin") </span><span class="cov8" title="1">{
                        continue</span>
                }
                // check value
                <span class="cov8" title="1">for _, val := range vals </span><span class="cov8" title="1">{
                        if hasNotPrintable(val) </span><span class="cov8" title="1">{
                                return fmt.Errorf("header key %q contains value with non-printable ASCII characters", k)
                        }</span>
                }
        }
        <span class="cov8" title="1">return nil</span>
}

// hasNotPrintable return true if msg contains any characters which are not in %x20-%x7E
func hasNotPrintable(msg string) bool <span class="cov8" title="1">{
        // for i that saving a conversion if not using for range
        for i := 0; i &lt; len(msg); i++ </span><span class="cov8" title="1">{
                if msg[i] &lt; 0x20 || msg[i] &gt; 0x7E </span><span class="cov8" title="1">{
                        return true
                }</span>
        }
        <span class="cov0" title="0">return false</span>
}
</pre>
		
		<pre class="file" id="file93" style="display: none">/*
 *
 * Copyright 2019 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package buffer provides a high-performant lock free implementation of a
// circular buffer used by the profiling code.
package buffer

import (
        "errors"
        "math/bits"
        "runtime"
        "sync"
        "sync/atomic"
        "unsafe"
)

type queue struct {
        // An array of pointers as references to the items stored in this queue.
        arr []unsafe.Pointer
        // The maximum number of elements this queue may store before it wraps around
        // and overwrites older values. Must be an exponent of 2.
        size uint32
        // Always size - 1. A bitwise AND is performed with this mask in place of a
        // modulo operation by the Push operation.
        mask uint32
        // Each Push operation into this queue increments the acquired counter before
        // proceeding forwarding with the actual write to arr. This counter is also
        // used by the Drain operation's drainWait subroutine to wait for all pushes
        // to complete.
        acquired uint32 // Accessed atomically.
        // After the completion of a Push operation, the written counter is
        // incremented. Also used by drainWait to wait for all pushes to complete.
        written uint32
}

// Allocates and returns a new *queue. size needs to be a exponent of two.
func newQueue(size uint32) *queue <span class="cov8" title="1">{
        return &amp;queue{
                arr:  make([]unsafe.Pointer, size),
                size: size,
                mask: size - 1,
        }
}</span>

// drainWait blocks the caller until all Pushes on this queue are complete.
func (q *queue) drainWait() <span class="cov8" title="1">{
        for atomic.LoadUint32(&amp;q.acquired) != atomic.LoadUint32(&amp;q.written) </span><span class="cov0" title="0">{
                runtime.Gosched()
        }</span>
}

// A queuePair has two queues. At any given time, Pushes go into the queue
// referenced by queuePair.q. The active queue gets switched when there's a
// drain operation on the circular buffer.
type queuePair struct {
        q0 unsafe.Pointer
        q1 unsafe.Pointer
        q  unsafe.Pointer
}

// Allocates and returns a new *queuePair with its internal queues allocated.
func newQueuePair(size uint32) *queuePair <span class="cov8" title="1">{
        qp := &amp;queuePair{}
        qp.q0 = unsafe.Pointer(newQueue(size))
        qp.q1 = unsafe.Pointer(newQueue(size))
        qp.q = qp.q0
        return qp
}</span>

// Switches the current queue for future Pushes to proceed to the other queue
// so that there's no blocking in Push. Returns a pointer to the old queue that
// was in place before the switch.
func (qp *queuePair) switchQueues() *queue <span class="cov8" title="1">{
        // Even though we have mutual exclusion across drainers (thanks to mu.Lock in
        // drain), Push operations may access qp.q whilst we're writing to it.
        if atomic.CompareAndSwapPointer(&amp;qp.q, qp.q0, qp.q1) </span><span class="cov8" title="1">{
                return (*queue)(qp.q0)
        }</span>

        <span class="cov8" title="1">atomic.CompareAndSwapPointer(&amp;qp.q, qp.q1, qp.q0)
        return (*queue)(qp.q1)</span>
}

// In order to not have expensive modulo operations, we require the maximum
// number of elements in the circular buffer (N) to be an exponent of two to
// use a bitwise AND mask. Since a CircularBuffer is a collection of queuePairs
// (see below), we need to divide N; since exponents of two are only divisible
// by other exponents of two, we use floorCPUCount number of queuePairs within
// each CircularBuffer.
//
// Floor of the number of CPUs (and not the ceiling) was found to the be the
// optimal number through experiments.
func floorCPUCount() uint32 <span class="cov8" title="1">{
        floorExponent := bits.Len32(uint32(runtime.NumCPU())) - 1
        if floorExponent &lt; 0 </span><span class="cov0" title="0">{
                floorExponent = 0
        }</span>
        <span class="cov8" title="1">return 1 &lt;&lt; uint32(floorExponent)</span>
}

var numCircularBufferPairs = floorCPUCount()

// CircularBuffer is a lock-free data structure that supports Push and Drain
// operations.
//
// Note that CircularBuffer is built for performance more than reliability.
// That is, some Push operations may fail without retries in some situations
// (such as during a Drain operation). Order of pushes is not maintained
// either; that is, if A was pushed before B, the Drain operation may return an
// array with B before A. These restrictions are acceptable within gRPC's
// profiling, but if your use-case does not permit these relaxed constraints
// or if performance is not a primary concern, you should probably use a
// lock-based data structure such as internal/buffer.UnboundedBuffer.
type CircularBuffer struct {
        drainMutex sync.Mutex
        qp         []*queuePair
        // qpn is an monotonically incrementing counter that's used to determine
        // which queuePair a Push operation should write to. This approach's
        // performance was found to be better than writing to a random queue.
        qpn    uint32
        qpMask uint32
}

var errInvalidCircularBufferSize = errors.New("buffer size is not an exponent of two")

// NewCircularBuffer allocates a circular buffer of size size and returns a
// reference to the struct. Only circular buffers of size 2^k are allowed
// (saves us from having to do expensive modulo operations).
func NewCircularBuffer(size uint32) (*CircularBuffer, error) <span class="cov8" title="1">{
        if size&amp;(size-1) != 0 </span><span class="cov0" title="0">{
                return nil, errInvalidCircularBufferSize
        }</span>

        <span class="cov8" title="1">n := numCircularBufferPairs
        if size/numCircularBufferPairs &lt; 8 </span><span class="cov0" title="0">{
                // If each circular buffer is going to hold less than a very small number
                // of items (let's say 8), using multiple circular buffers is very likely
                // wasteful. Instead, fallback to one circular buffer holding everything.
                n = 1
        }</span>

        <span class="cov8" title="1">cb := &amp;CircularBuffer{
                qp:     make([]*queuePair, n),
                qpMask: n - 1,
        }

        for i := uint32(0); i &lt; n; i++ </span><span class="cov8" title="1">{
                cb.qp[i] = newQueuePair(size / n)
        }</span>

        <span class="cov8" title="1">return cb, nil</span>
}

// Push pushes an element in to the circular buffer. Guaranteed to complete in
// a finite number of steps (also lock-free). Does not guarantee that push
// order will be retained. Does not guarantee that the operation will succeed
// if a Drain operation concurrently begins execution.
func (cb *CircularBuffer) Push(x interface{}) <span class="cov8" title="1">{
        n := atomic.AddUint32(&amp;cb.qpn, 1) &amp; cb.qpMask
        qptr := atomic.LoadPointer(&amp;cb.qp[n].q)
        q := (*queue)(qptr)

        acquired := atomic.AddUint32(&amp;q.acquired, 1) - 1

        // If true, it means that we have incremented acquired before any queuePair
        // was switched, and therefore before any drainWait completion. Therefore, it
        // is safe to proceed with the Push operation on this queue. Otherwise, it
        // means that a Drain operation has begun execution, but we don't know how
        // far along the process it is. If it is past the drainWait check, it is not
        // safe to proceed with the Push operation. We choose to drop this sample
        // entirely instead of retrying, as retrying may potentially send the Push
        // operation into a spin loop (we want to guarantee completion of the Push
        // operation within a finite time). Before exiting, we increment written so
        // that any existing drainWaits can proceed.
        if atomic.LoadPointer(&amp;cb.qp[n].q) != qptr </span><span class="cov0" title="0">{
                atomic.AddUint32(&amp;q.written, 1)
                return
        }</span>

        // At this point, we're definitely writing to the right queue. That is, one
        // of the following is true:
        //   1. No drainer is in execution on this queue.
        //   2. A drainer is in execution on this queue and it is waiting at the
        //      acquired == written barrier.
        //
        // Let's say two Pushes A and B happen on the same queue. Say A and B are
        // q.size apart; i.e. they get the same index. That is,
        //
        //   index_A = index_B
        //   acquired_A + q.size = acquired_B
        //
        // We say "B has wrapped around A" when this happens. In this case, since A
        // occurred before B, B's Push should be the final value. However, we
        // accommodate A being the final value because wrap-arounds are extremely
        // rare and accounting for them requires an additional counter and a
        // significant performance penalty. Note that the below approach never leads
        // to any data corruption.
        <span class="cov8" title="1">index := acquired &amp; q.mask
        atomic.StorePointer(&amp;q.arr[index], unsafe.Pointer(&amp;x))

        // Allows any drainWait checks to proceed.
        atomic.AddUint32(&amp;q.written, 1)</span>
}

// Dereferences non-nil pointers from arr into result. Range of elements from
// arr that are copied is [from, to). Assumes that the result slice is already
// allocated and is large enough to hold all the elements that might be copied.
// Also assumes mutual exclusion on the array of pointers.
func dereferenceAppend(result []interface{}, arr []unsafe.Pointer, from, to uint32) []interface{} <span class="cov8" title="1">{
        for i := from; i &lt; to; i++ </span><span class="cov8" title="1">{
                // We have mutual exclusion on arr, there's no need for atomics.
                x := (*interface{})(arr[i])
                if x != nil </span><span class="cov8" title="1">{
                        result = append(result, *x)
                }</span>
        }
        <span class="cov8" title="1">return result</span>
}

// Drain allocates and returns an array of things Pushed in to the circular
// buffer. Push order is not maintained; that is, if B was Pushed after A,
// drain may return B at a lower index than A in the returned array.
func (cb *CircularBuffer) Drain() []interface{} <span class="cov8" title="1">{
        cb.drainMutex.Lock()

        qs := make([]*queue, len(cb.qp))
        for i := 0; i &lt; len(cb.qp); i++ </span><span class="cov8" title="1">{
                qs[i] = cb.qp[i].switchQueues()
        }</span>

        <span class="cov8" title="1">var wg sync.WaitGroup
        wg.Add(len(qs))
        for i := 0; i &lt; len(qs); i++ </span><span class="cov8" title="1">{
                go func(qi int) </span><span class="cov8" title="1">{
                        qs[qi].drainWait()
                        wg.Done()
                }</span>(i)
        }
        <span class="cov8" title="1">wg.Wait()

        result := make([]interface{}, 0)
        for i := 0; i &lt; len(qs); i++ </span><span class="cov8" title="1">{
                if acquired := atomic.LoadUint32(&amp;qs[i].acquired); acquired &lt; qs[i].size </span><span class="cov8" title="1">{
                        result = dereferenceAppend(result, qs[i].arr, 0, acquired)
                }</span> else<span class="cov8" title="1"> {
                        result = dereferenceAppend(result, qs[i].arr, 0, qs[i].size)
                }</span>
        }

        <span class="cov8" title="1">for i := 0; i &lt; len(qs); i++ </span><span class="cov8" title="1">{
                atomic.StoreUint32(&amp;qs[i].acquired, 0)
                atomic.StoreUint32(&amp;qs[i].written, 0)
        }</span>

        <span class="cov8" title="1">cb.drainMutex.Unlock()
        return result</span>
}
</pre>
		
		<pre class="file" id="file94" style="display: none">//go:build !grpcgoid
// +build !grpcgoid

/*
 *
 * Copyright 2019 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package profiling

// This dummy function always returns 0. In some modified dev environments,
// this may be replaced with a call to a function in a modified Go runtime that
// retrieves the goroutine ID efficiently. See goid_modified.go for a different
// version of goId that requires a grpcgoid build tag to compile.
func goid() int64 <span class="cov8" title="1">{
        return 0
}</span>
</pre>
		
		<pre class="file" id="file95" style="display: none">/*
 *
 * Copyright 2019 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package profiling contains two logical components: buffer.go and
// profiling.go. The former implements a circular buffer (a.k.a. ring buffer)
// in a lock-free manner using atomics. This ring buffer is used by
// profiling.go to store various statistics. For example, StreamStats is a
// circular buffer of Stat objects, each of which is comprised of Timers.
//
// This abstraction is designed to accommodate more stats in the future; for
// example, if one wants to profile the load balancing layer, which is
// independent of RPC queries, a separate CircularBuffer can be used.
//
// Note that the circular buffer simply takes any interface{}. In the future,
// more types of measurements (such as the number of memory allocations) could
// be measured, which might require a different type of object being pushed
// into the circular buffer.
package profiling

import (
        "errors"
        "sync"
        "sync/atomic"
        "time"

        "google.golang.org/grpc/internal/profiling/buffer"
)

// 0 or 1 representing profiling off and on, respectively. Use IsEnabled and
// Enable to get and set this in a safe manner.
var profilingEnabled uint32

// IsEnabled returns whether or not profiling is enabled.
func IsEnabled() bool <span class="cov0" title="0">{
        return atomic.LoadUint32(&amp;profilingEnabled) &gt; 0
}</span>

// Enable turns profiling on and off.
//
// Note that it is impossible to enable profiling for one server and leave it
// turned off for another. This is intentional and by design -- if the status
// of profiling was server-specific, clients wouldn't be able to profile
// themselves. As a result, Enable turns profiling on and off for all servers
// and clients in the binary. Each stat will be, however, tagged with whether
// it's a client stat or a server stat; so you should be able to filter for the
// right type of stats in post-processing.
func Enable(enabled bool) <span class="cov0" title="0">{
        if enabled </span><span class="cov0" title="0">{
                atomic.StoreUint32(&amp;profilingEnabled, 1)
        }</span> else<span class="cov0" title="0"> {
                atomic.StoreUint32(&amp;profilingEnabled, 0)
        }</span>
}

// A Timer represents the wall-clock beginning and ending of a logical
// operation.
type Timer struct {
        // Tags is a comma-separated list of strings (usually forward-slash-separated
        // hierarchical strings) used to categorize a Timer.
        Tags string
        // Begin marks the beginning of this timer. The timezone is unspecified, but
        // must use the same timezone as End; this is so shave off the small, but
        // non-zero time required to convert to a standard timezone such as UTC.
        Begin time.Time
        // End marks the end of a timer.
        End time.Time
        // Each Timer must be started and ended within the same goroutine; GoID
        // captures this goroutine ID. The Go runtime does not typically expose this
        // information, so this is set to zero in the typical case. However, a
        // trivial patch to the runtime package can make this field useful. See
        // goid_modified.go in this package for more details.
        GoID int64
}

// NewTimer creates and returns a new Timer object. This is useful when you
// don't already have a Stat object to associate this Timer with; for example,
// before the context of a new RPC query is created, a Timer may be needed to
// measure transport-related operations.
//
// Use AppendTimer to append the returned Timer to a Stat.
func NewTimer(tags string) *Timer <span class="cov8" title="1">{
        return &amp;Timer{
                Tags:  tags,
                Begin: time.Now(),
                GoID:  goid(),
        }
}</span>

// Egress sets the End field of a timer to the current time.
func (timer *Timer) Egress() <span class="cov8" title="1">{
        if timer == nil </span><span class="cov0" title="0">{
                return
        }</span>

        <span class="cov8" title="1">timer.End = time.Now()</span>
}

// A Stat is a collection of Timers that represent timing information for
// different components within this Stat. For example, a Stat may be used to
// reference the entire lifetime of an RPC request, with Timers within it
// representing different components such as encoding, compression, and
// transport.
//
// The user is expected to use the included helper functions to do operations
// on the Stat such as creating or appending a new timer. Direct operations on
// the Stat's exported fields (which are exported for encoding reasons) may
// lead to data races.
type Stat struct {
        // Tags is a comma-separated list of strings used to categorize a Stat.
        Tags string
        // Stats may also need to store other unstructured information specific to
        // this stat. For example, a StreamStat will use these bytes to encode the
        // connection ID and stream ID for each RPC to uniquely identify it. The
        // encoding that must be used is unspecified.
        Metadata []byte
        // A collection of *Timers and a mutex for append operations on the slice.
        mu     sync.Mutex
        Timers []*Timer
}

// A power of two that's large enough to hold all timers within an average RPC
// request (defined to be a unary request) without any reallocation. A typical
// unary RPC creates 80-100 timers for various things. While this number is
// purely anecdotal and may change in the future as the resolution of profiling
// increases or decreases, it serves as a good estimate for what the initial
// allocation size should be.
const defaultStatAllocatedTimers int32 = 128

// NewStat creates and returns a new Stat object.
func NewStat(tags string) *Stat <span class="cov8" title="1">{
        return &amp;Stat{
                Tags:   tags,
                Timers: make([]*Timer, 0, defaultStatAllocatedTimers),
        }
}</span>

// NewTimer creates a Timer object within the given stat if stat is non-nil.
// The value passed in tags will be attached to the newly created Timer.
// NewTimer also automatically sets the Begin value of the Timer to the current
// time. The user is expected to call stat.Egress with the returned index as
// argument to mark the end.
func (stat *Stat) NewTimer(tags string) *Timer <span class="cov8" title="1">{
        if stat == nil </span><span class="cov0" title="0">{
                return nil
        }</span>

        <span class="cov8" title="1">timer := &amp;Timer{
                Tags:  tags,
                GoID:  goid(),
                Begin: time.Now(),
        }
        stat.mu.Lock()
        stat.Timers = append(stat.Timers, timer)
        stat.mu.Unlock()
        return timer</span>
}

// AppendTimer appends a given Timer object to the internal slice of timers. A
// deep copy of the timer is made (i.e. no reference is retained to this
// pointer) and the user is expected to lose their reference to the timer to
// allow the Timer object to be garbage collected.
func (stat *Stat) AppendTimer(timer *Timer) <span class="cov8" title="1">{
        if stat == nil || timer == nil </span><span class="cov0" title="0">{
                return
        }</span>

        <span class="cov8" title="1">stat.mu.Lock()
        stat.Timers = append(stat.Timers, timer)
        stat.mu.Unlock()</span>
}

// statsInitialized is 0 before InitStats has been called. Changed to 1 by
// exactly one call to InitStats.
var statsInitialized int32

// Stats for the last defaultStreamStatsBufsize RPCs will be stored in memory.
// This is can be configured by the registering server at profiling service
// initialization with google.golang.org/grpc/profiling/service.ProfilingConfig
const defaultStreamStatsSize uint32 = 16 &lt;&lt; 10

// StreamStats is a CircularBuffer containing data from the last N RPC calls
// served, where N is set by the user. This will contain both server stats and
// client stats (but each stat will be tagged with whether it's a server or a
// client in its Tags).
var StreamStats *buffer.CircularBuffer

var errAlreadyInitialized = errors.New("profiling may be initialized at most once")

// InitStats initializes all the relevant Stat objects. Must be called exactly
// once per lifetime of a process; calls after the first one will return an
// error.
func InitStats(streamStatsSize uint32) error <span class="cov0" title="0">{
        var err error
        if !atomic.CompareAndSwapInt32(&amp;statsInitialized, 0, 1) </span><span class="cov0" title="0">{
                return errAlreadyInitialized
        }</span>

        <span class="cov0" title="0">if streamStatsSize == 0 </span><span class="cov0" title="0">{
                streamStatsSize = defaultStreamStatsSize
        }</span>

        <span class="cov0" title="0">StreamStats, err = buffer.NewCircularBuffer(streamStatsSize)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        <span class="cov0" title="0">return nil</span>
}
</pre>
		
		<pre class="file" id="file96" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package resolver provides internal resolver-related functionality.
package resolver

import (
        "context"
        "sync"

        "google.golang.org/grpc/internal/serviceconfig"
        "google.golang.org/grpc/metadata"
        "google.golang.org/grpc/resolver"
)

// ConfigSelector controls what configuration to use for every RPC.
type ConfigSelector interface {
        // Selects the configuration for the RPC, or terminates it using the error.
        // This error will be converted by the gRPC library to a status error with
        // code UNKNOWN if it is not returned as a status error.
        SelectConfig(RPCInfo) (*RPCConfig, error)
}

// RPCInfo contains RPC information needed by a ConfigSelector.
type RPCInfo struct {
        // Context is the user's context for the RPC and contains headers and
        // application timeout.  It is passed for interception purposes and for
        // efficiency reasons.  SelectConfig should not be blocking.
        Context context.Context
        Method  string // i.e. "/Service/Method"
}

// RPCConfig describes the configuration to use for each RPC.
type RPCConfig struct {
        // The context to use for the remainder of the RPC; can pass info to LB
        // policy or affect timeout or metadata.
        Context      context.Context
        MethodConfig serviceconfig.MethodConfig // configuration to use for this RPC
        OnCommitted  func()                     // Called when the RPC has been committed (retries no longer possible)
        Interceptor  ClientInterceptor
}

// ClientStream is the same as grpc.ClientStream, but defined here for circular
// dependency reasons.
type ClientStream interface {
        // Header returns the header metadata received from the server if there
        // is any. It blocks if the metadata is not ready to read.
        Header() (metadata.MD, error)
        // Trailer returns the trailer metadata from the server, if there is any.
        // It must only be called after stream.CloseAndRecv has returned, or
        // stream.Recv has returned a non-nil error (including io.EOF).
        Trailer() metadata.MD
        // CloseSend closes the send direction of the stream. It closes the stream
        // when non-nil error is met. It is also not safe to call CloseSend
        // concurrently with SendMsg.
        CloseSend() error
        // Context returns the context for this stream.
        //
        // It should not be called until after Header or RecvMsg has returned. Once
        // called, subsequent client-side retries are disabled.
        Context() context.Context
        // SendMsg is generally called by generated code. On error, SendMsg aborts
        // the stream. If the error was generated by the client, the status is
        // returned directly; otherwise, io.EOF is returned and the status of
        // the stream may be discovered using RecvMsg.
        //
        // SendMsg blocks until:
        //   - There is sufficient flow control to schedule m with the transport, or
        //   - The stream is done, or
        //   - The stream breaks.
        //
        // SendMsg does not wait until the message is received by the server. An
        // untimely stream closure may result in lost messages. To ensure delivery,
        // users should ensure the RPC completed successfully using RecvMsg.
        //
        // It is safe to have a goroutine calling SendMsg and another goroutine
        // calling RecvMsg on the same stream at the same time, but it is not safe
        // to call SendMsg on the same stream in different goroutines. It is also
        // not safe to call CloseSend concurrently with SendMsg.
        SendMsg(m interface{}) error
        // RecvMsg blocks until it receives a message into m or the stream is
        // done. It returns io.EOF when the stream completes successfully. On
        // any other error, the stream is aborted and the error contains the RPC
        // status.
        //
        // It is safe to have a goroutine calling SendMsg and another goroutine
        // calling RecvMsg on the same stream at the same time, but it is not
        // safe to call RecvMsg on the same stream in different goroutines.
        RecvMsg(m interface{}) error
}

// ClientInterceptor is an interceptor for gRPC client streams.
type ClientInterceptor interface {
        // NewStream produces a ClientStream for an RPC which may optionally use
        // the provided function to produce a stream for delegation.  Note:
        // RPCInfo.Context should not be used (will be nil).
        //
        // done is invoked when the RPC is finished using its connection, or could
        // not be assigned a connection.  RPC operations may still occur on
        // ClientStream after done is called, since the interceptor is invoked by
        // application-layer operations.  done must never be nil when called.
        NewStream(ctx context.Context, ri RPCInfo, done func(), newStream func(ctx context.Context, done func()) (ClientStream, error)) (ClientStream, error)
}

// ServerInterceptor is an interceptor for incoming RPC's on gRPC server side.
type ServerInterceptor interface {
        // AllowRPC checks if an incoming RPC is allowed to proceed based on
        // information about connection RPC was received on, and HTTP Headers. This
        // information will be piped into context.
        AllowRPC(ctx context.Context) error // TODO: Make this a real interceptor for filters such as rate limiting.
}

type csKeyType string

const csKey = csKeyType("grpc.internal.resolver.configSelector")

// SetConfigSelector sets the config selector in state and returns the new
// state.
func SetConfigSelector(state resolver.State, cs ConfigSelector) resolver.State <span class="cov0" title="0">{
        state.Attributes = state.Attributes.WithValue(csKey, cs)
        return state
}</span>

// GetConfigSelector retrieves the config selector from state, if present, and
// returns it or nil if absent.
func GetConfigSelector(state resolver.State) ConfigSelector <span class="cov0" title="0">{
        cs, _ := state.Attributes.Value(csKey).(ConfigSelector)
        return cs
}</span>

// SafeConfigSelector allows for safe switching of ConfigSelector
// implementations such that previous values are guaranteed to not be in use
// when UpdateConfigSelector returns.
type SafeConfigSelector struct {
        mu sync.RWMutex
        cs ConfigSelector
}

// UpdateConfigSelector swaps to the provided ConfigSelector and blocks until
// all uses of the previous ConfigSelector have completed.
func (scs *SafeConfigSelector) UpdateConfigSelector(cs ConfigSelector) <span class="cov8" title="1">{
        scs.mu.Lock()
        defer scs.mu.Unlock()
        scs.cs = cs
}</span>

// SelectConfig defers to the current ConfigSelector in scs.
func (scs *SafeConfigSelector) SelectConfig(r RPCInfo) (*RPCConfig, error) <span class="cov8" title="1">{
        scs.mu.RLock()
        defer scs.mu.RUnlock()
        return scs.cs.SelectConfig(r)
}</span>
</pre>
		
		<pre class="file" id="file97" style="display: none">/*
 *
 * Copyright 2018 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package dns implements a dns resolver to be installed as the default resolver
// in grpc.
package dns

import (
        "context"
        "encoding/json"
        "errors"
        "fmt"
        "net"
        "os"
        "strconv"
        "strings"
        "sync"
        "time"

        grpclbstate "google.golang.org/grpc/balancer/grpclb/state"
        "google.golang.org/grpc/grpclog"
        "google.golang.org/grpc/internal/backoff"
        "google.golang.org/grpc/internal/envconfig"
        "google.golang.org/grpc/internal/grpcrand"
        "google.golang.org/grpc/resolver"
        "google.golang.org/grpc/serviceconfig"
)

// EnableSRVLookups controls whether the DNS resolver attempts to fetch gRPCLB
// addresses from SRV records.  Must not be changed after init time.
var EnableSRVLookups = false

var logger = grpclog.Component("dns")

// Globals to stub out in tests. TODO: Perhaps these two can be combined into a
// single variable for testing the resolver?
var (
        newTimer           = time.NewTimer
        newTimerDNSResRate = time.NewTimer
)

func init() <span class="cov8" title="1">{
        resolver.Register(NewBuilder())
}</span>

const (
        defaultPort       = "443"
        defaultDNSSvrPort = "53"
        golang            = "GO"
        // txtPrefix is the prefix string to be prepended to the host name for txt record lookup.
        txtPrefix = "_grpc_config."
        // In DNS, service config is encoded in a TXT record via the mechanism
        // described in RFC-1464 using the attribute name grpc_config.
        txtAttribute = "grpc_config="
)

var (
        errMissingAddr = errors.New("dns resolver: missing address")

        // Addresses ending with a colon that is supposed to be the separator
        // between host and port is not allowed.  E.g. "::" is a valid address as
        // it is an IPv6 address (host only) and "[::]:" is invalid as it ends with
        // a colon as the host and port separator
        errEndsWithColon = errors.New("dns resolver: missing port after port-separator colon")
)

var (
        defaultResolver netResolver = net.DefaultResolver
        // To prevent excessive re-resolution, we enforce a rate limit on DNS
        // resolution requests.
        minDNSResRate = 30 * time.Second
)

var customAuthorityDialler = func(authority string) func(ctx context.Context, network, address string) (net.Conn, error) <span class="cov0" title="0">{
        return func(ctx context.Context, network, address string) (net.Conn, error) </span><span class="cov0" title="0">{
                var dialer net.Dialer
                return dialer.DialContext(ctx, network, authority)
        }</span>
}

var customAuthorityResolver = func(authority string) (netResolver, error) <span class="cov8" title="1">{
        host, port, err := parseTarget(authority, defaultDNSSvrPort)
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>

        <span class="cov8" title="1">authorityWithPort := net.JoinHostPort(host, port)

        return &amp;net.Resolver{
                PreferGo: true,
                Dial:     customAuthorityDialler(authorityWithPort),
        }, nil</span>
}

// NewBuilder creates a dnsBuilder which is used to factory DNS resolvers.
func NewBuilder() resolver.Builder <span class="cov8" title="1">{
        return &amp;dnsBuilder{}
}</span>

type dnsBuilder struct{}

// Build creates and starts a DNS resolver that watches the name resolution of the target.
func (b *dnsBuilder) Build(target resolver.Target, cc resolver.ClientConn, opts resolver.BuildOptions) (resolver.Resolver, error) <span class="cov8" title="1">{
        host, port, err := parseTarget(target.Endpoint, defaultPort)
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>

        // IP address.
        <span class="cov8" title="1">if ipAddr, ok := formatIP(host); ok </span><span class="cov8" title="1">{
                addr := []resolver.Address{{Addr: ipAddr + ":" + port}}
                cc.UpdateState(resolver.State{Addresses: addr})
                return deadResolver{}, nil
        }</span>

        // DNS address (non-IP).
        <span class="cov8" title="1">ctx, cancel := context.WithCancel(context.Background())
        d := &amp;dnsResolver{
                host:                 host,
                port:                 port,
                ctx:                  ctx,
                cancel:               cancel,
                cc:                   cc,
                rn:                   make(chan struct{}, 1),
                disableServiceConfig: opts.DisableServiceConfig,
        }

        if target.Authority == "" </span><span class="cov8" title="1">{
                d.resolver = defaultResolver
        }</span> else<span class="cov8" title="1"> {
                d.resolver, err = customAuthorityResolver(target.Authority)
                if err != nil </span><span class="cov8" title="1">{
                        return nil, err
                }</span>
        }

        <span class="cov8" title="1">d.wg.Add(1)
        go d.watcher()
        return d, nil</span>
}

// Scheme returns the naming scheme of this resolver builder, which is "dns".
func (b *dnsBuilder) Scheme() string <span class="cov8" title="1">{
        return "dns"
}</span>

type netResolver interface {
        LookupHost(ctx context.Context, host string) (addrs []string, err error)
        LookupSRV(ctx context.Context, service, proto, name string) (cname string, addrs []*net.SRV, err error)
        LookupTXT(ctx context.Context, name string) (txts []string, err error)
}

// deadResolver is a resolver that does nothing.
type deadResolver struct{}

func (deadResolver) ResolveNow(resolver.ResolveNowOptions) {<span class="cov8" title="1">}</span>

func (deadResolver) Close() {<span class="cov8" title="1">}</span>

// dnsResolver watches for the name resolution update for a non-IP target.
type dnsResolver struct {
        host     string
        port     string
        resolver netResolver
        ctx      context.Context
        cancel   context.CancelFunc
        cc       resolver.ClientConn
        // rn channel is used by ResolveNow() to force an immediate resolution of the target.
        rn chan struct{}
        // wg is used to enforce Close() to return after the watcher() goroutine has finished.
        // Otherwise, data race will be possible. [Race Example] in dns_resolver_test we
        // replace the real lookup functions with mocked ones to facilitate testing.
        // If Close() doesn't wait for watcher() goroutine finishes, race detector sometimes
        // will warns lookup (READ the lookup function pointers) inside watcher() goroutine
        // has data race with replaceNetFunc (WRITE the lookup function pointers).
        wg                   sync.WaitGroup
        disableServiceConfig bool
}

// ResolveNow invoke an immediate resolution of the target that this dnsResolver watches.
func (d *dnsResolver) ResolveNow(resolver.ResolveNowOptions) <span class="cov8" title="1">{
        select </span>{
        case d.rn &lt;- struct{}{}:<span class="cov8" title="1"></span>
        default:<span class="cov8" title="1"></span>
        }
}

// Close closes the dnsResolver.
func (d *dnsResolver) Close() <span class="cov8" title="1">{
        d.cancel()
        d.wg.Wait()
}</span>

func (d *dnsResolver) watcher() <span class="cov8" title="1">{
        defer d.wg.Done()
        backoffIndex := 1
        for </span><span class="cov8" title="1">{
                state, err := d.lookup()
                if err != nil </span><span class="cov8" title="1">{
                        // Report error to the underlying grpc.ClientConn.
                        d.cc.ReportError(err)
                }</span> else<span class="cov8" title="1"> {
                        err = d.cc.UpdateState(*state)
                }</span>

                <span class="cov8" title="1">var timer *time.Timer
                if err == nil </span><span class="cov8" title="1">{
                        // Success resolving, wait for the next ResolveNow. However, also wait 30 seconds at the very least
                        // to prevent constantly re-resolving.
                        backoffIndex = 1
                        timer = newTimerDNSResRate(minDNSResRate)
                        select </span>{
                        case &lt;-d.ctx.Done():<span class="cov8" title="1">
                                timer.Stop()
                                return</span>
                        case &lt;-d.rn:<span class="cov8" title="1"></span>
                        }
                } else<span class="cov8" title="1"> {
                        // Poll on an error found in DNS Resolver or an error received from ClientConn.
                        timer = newTimer(backoff.DefaultExponential.Backoff(backoffIndex))
                        backoffIndex++
                }</span>
                <span class="cov8" title="1">select </span>{
                case &lt;-d.ctx.Done():<span class="cov8" title="1">
                        timer.Stop()
                        return</span>
                case &lt;-timer.C:<span class="cov8" title="1"></span>
                }
        }
}

func (d *dnsResolver) lookupSRV() ([]resolver.Address, error) <span class="cov8" title="1">{
        if !EnableSRVLookups </span><span class="cov8" title="1">{
                return nil, nil
        }</span>
        <span class="cov8" title="1">var newAddrs []resolver.Address
        _, srvs, err := d.resolver.LookupSRV(d.ctx, "grpclb", "tcp", d.host)
        if err != nil </span><span class="cov8" title="1">{
                err = handleDNSError(err, "SRV") // may become nil
                return nil, err
        }</span>
        <span class="cov8" title="1">for _, s := range srvs </span><span class="cov8" title="1">{
                lbAddrs, err := d.resolver.LookupHost(d.ctx, s.Target)
                if err != nil </span><span class="cov0" title="0">{
                        err = handleDNSError(err, "A") // may become nil
                        if err == nil </span><span class="cov0" title="0">{
                                // If there are other SRV records, look them up and ignore this
                                // one that does not exist.
                                continue</span>
                        }
                        <span class="cov0" title="0">return nil, err</span>
                }
                <span class="cov8" title="1">for _, a := range lbAddrs </span><span class="cov8" title="1">{
                        ip, ok := formatIP(a)
                        if !ok </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("dns: error parsing A record IP address %v", a)
                        }</span>
                        <span class="cov8" title="1">addr := ip + ":" + strconv.Itoa(int(s.Port))
                        newAddrs = append(newAddrs, resolver.Address{Addr: addr, ServerName: s.Target})</span>
                }
        }
        <span class="cov8" title="1">return newAddrs, nil</span>
}

func handleDNSError(err error, lookupType string) error <span class="cov8" title="1">{
        if dnsErr, ok := err.(*net.DNSError); ok &amp;&amp; !dnsErr.IsTimeout &amp;&amp; !dnsErr.IsTemporary </span><span class="cov8" title="1">{
                // Timeouts and temporary errors should be communicated to gRPC to
                // attempt another DNS query (with backoff).  Other errors should be
                // suppressed (they may represent the absence of a TXT record).
                return nil
        }</span>
        <span class="cov8" title="1">if err != nil </span><span class="cov8" title="1">{
                err = fmt.Errorf("dns: %v record lookup error: %v", lookupType, err)
                logger.Info(err)
        }</span>
        <span class="cov8" title="1">return err</span>
}

func (d *dnsResolver) lookupTXT() *serviceconfig.ParseResult <span class="cov8" title="1">{
        ss, err := d.resolver.LookupTXT(d.ctx, txtPrefix+d.host)
        if err != nil </span><span class="cov8" title="1">{
                if envconfig.TXTErrIgnore </span><span class="cov8" title="1">{
                        return nil
                }</span>
                <span class="cov8" title="1">if err = handleDNSError(err, "TXT"); err != nil </span><span class="cov8" title="1">{
                        return &amp;serviceconfig.ParseResult{Err: err}
                }</span>
                <span class="cov0" title="0">return nil</span>
        }
        <span class="cov8" title="1">var res string
        for _, s := range ss </span><span class="cov8" title="1">{
                res += s
        }</span>

        // TXT record must have "grpc_config=" attribute in order to be used as service config.
        <span class="cov8" title="1">if !strings.HasPrefix(res, txtAttribute) </span><span class="cov0" title="0">{
                logger.Warningf("dns: TXT record %v missing %v attribute", res, txtAttribute)
                // This is not an error; it is the equivalent of not having a service config.
                return nil
        }</span>
        <span class="cov8" title="1">sc := canaryingSC(strings.TrimPrefix(res, txtAttribute))
        return d.cc.ParseServiceConfig(sc)</span>
}

func (d *dnsResolver) lookupHost() ([]resolver.Address, error) <span class="cov8" title="1">{
        addrs, err := d.resolver.LookupHost(d.ctx, d.host)
        if err != nil </span><span class="cov8" title="1">{
                err = handleDNSError(err, "A")
                return nil, err
        }</span>
        <span class="cov8" title="1">newAddrs := make([]resolver.Address, 0, len(addrs))
        for _, a := range addrs </span><span class="cov8" title="1">{
                ip, ok := formatIP(a)
                if !ok </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("dns: error parsing A record IP address %v", a)
                }</span>
                <span class="cov8" title="1">addr := ip + ":" + d.port
                newAddrs = append(newAddrs, resolver.Address{Addr: addr})</span>
        }
        <span class="cov8" title="1">return newAddrs, nil</span>
}

func (d *dnsResolver) lookup() (*resolver.State, error) <span class="cov8" title="1">{
        srv, srvErr := d.lookupSRV()
        addrs, hostErr := d.lookupHost()
        if hostErr != nil &amp;&amp; (srvErr != nil || len(srv) == 0) </span><span class="cov8" title="1">{
                return nil, hostErr
        }</span>

        <span class="cov8" title="1">state := resolver.State{Addresses: addrs}
        if len(srv) &gt; 0 </span><span class="cov8" title="1">{
                state = grpclbstate.Set(state, &amp;grpclbstate.State{BalancerAddresses: srv})
        }</span>
        <span class="cov8" title="1">if !d.disableServiceConfig </span><span class="cov8" title="1">{
                state.ServiceConfig = d.lookupTXT()
        }</span>
        <span class="cov8" title="1">return &amp;state, nil</span>
}

// formatIP returns ok = false if addr is not a valid textual representation of an IP address.
// If addr is an IPv4 address, return the addr and ok = true.
// If addr is an IPv6 address, return the addr enclosed in square brackets and ok = true.
func formatIP(addr string) (addrIP string, ok bool) <span class="cov8" title="1">{
        ip := net.ParseIP(addr)
        if ip == nil </span><span class="cov8" title="1">{
                return "", false
        }</span>
        <span class="cov8" title="1">if ip.To4() != nil </span><span class="cov8" title="1">{
                return addr, true
        }</span>
        <span class="cov8" title="1">return "[" + addr + "]", true</span>
}

// parseTarget takes the user input target string and default port, returns formatted host and port info.
// If target doesn't specify a port, set the port to be the defaultPort.
// If target is in IPv6 format and host-name is enclosed in square brackets, brackets
// are stripped when setting the host.
// examples:
// target: "www.google.com" defaultPort: "443" returns host: "www.google.com", port: "443"
// target: "ipv4-host:80" defaultPort: "443" returns host: "ipv4-host", port: "80"
// target: "[ipv6-host]" defaultPort: "443" returns host: "ipv6-host", port: "443"
// target: ":80" defaultPort: "443" returns host: "localhost", port: "80"
func parseTarget(target, defaultPort string) (host, port string, err error) <span class="cov8" title="1">{
        if target == "" </span><span class="cov8" title="1">{
                return "", "", errMissingAddr
        }</span>
        <span class="cov8" title="1">if ip := net.ParseIP(target); ip != nil </span><span class="cov8" title="1">{
                // target is an IPv4 or IPv6(without brackets) address
                return target, defaultPort, nil
        }</span>
        <span class="cov8" title="1">if host, port, err = net.SplitHostPort(target); err == nil </span><span class="cov8" title="1">{
                if port == "" </span><span class="cov8" title="1">{
                        // If the port field is empty (target ends with colon), e.g. "[::1]:", this is an error.
                        return "", "", errEndsWithColon
                }</span>
                // target has port, i.e ipv4-host:port, [ipv6-host]:port, host-name:port
                <span class="cov8" title="1">if host == "" </span><span class="cov8" title="1">{
                        // Keep consistent with net.Dial(): If the host is empty, as in ":80", the local system is assumed.
                        host = "localhost"
                }</span>
                <span class="cov8" title="1">return host, port, nil</span>
        }
        <span class="cov8" title="1">if host, port, err = net.SplitHostPort(target + ":" + defaultPort); err == nil </span><span class="cov8" title="1">{
                // target doesn't have port
                return host, port, nil
        }</span>
        <span class="cov8" title="1">return "", "", fmt.Errorf("invalid target address %v, error info: %v", target, err)</span>
}

type rawChoice struct {
        ClientLanguage *[]string        `json:"clientLanguage,omitempty"`
        Percentage     *int             `json:"percentage,omitempty"`
        ClientHostName *[]string        `json:"clientHostName,omitempty"`
        ServiceConfig  *json.RawMessage `json:"serviceConfig,omitempty"`
}

func containsString(a *[]string, b string) bool <span class="cov8" title="1">{
        if a == nil </span><span class="cov8" title="1">{
                return true
        }</span>
        <span class="cov8" title="1">for _, c := range *a </span><span class="cov8" title="1">{
                if c == b </span><span class="cov8" title="1">{
                        return true
                }</span>
        }
        <span class="cov8" title="1">return false</span>
}

func chosenByPercentage(a *int) bool <span class="cov8" title="1">{
        if a == nil </span><span class="cov8" title="1">{
                return true
        }</span>
        <span class="cov8" title="1">return grpcrand.Intn(100)+1 &lt;= *a</span>
}

func canaryingSC(js string) string <span class="cov8" title="1">{
        if js == "" </span><span class="cov0" title="0">{
                return ""
        }</span>
        <span class="cov8" title="1">var rcs []rawChoice
        err := json.Unmarshal([]byte(js), &amp;rcs)
        if err != nil </span><span class="cov0" title="0">{
                logger.Warningf("dns: error parsing service config json: %v", err)
                return ""
        }</span>
        <span class="cov8" title="1">cliHostname, err := os.Hostname()
        if err != nil </span><span class="cov0" title="0">{
                logger.Warningf("dns: error getting client hostname: %v", err)
                return ""
        }</span>
        <span class="cov8" title="1">var sc string
        for _, c := range rcs </span><span class="cov8" title="1">{
                if !containsString(c.ClientLanguage, golang) ||
                        !chosenByPercentage(c.Percentage) ||
                        !containsString(c.ClientHostName, cliHostname) ||
                        c.ServiceConfig == nil </span><span class="cov8" title="1">{
                        continue</span>
                }
                <span class="cov8" title="1">sc = string(*c.ServiceConfig)
                break</span>
        }
        <span class="cov8" title="1">return sc</span>
}
</pre>
		
		<pre class="file" id="file98" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package serviceconfig contains utility functions to parse service config.
package serviceconfig

import (
        "encoding/json"
        "fmt"
        "time"

        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/grpclog"
        externalserviceconfig "google.golang.org/grpc/serviceconfig"
)

var logger = grpclog.Component("core")

// BalancerConfig wraps the name and config associated with one load balancing
// policy. It corresponds to a single entry of the loadBalancingConfig field
// from ServiceConfig.
//
// It implements the json.Unmarshaler interface.
//
// https://github.com/grpc/grpc-proto/blob/54713b1e8bc6ed2d4f25fb4dff527842150b91b2/grpc/service_config/service_config.proto#L247
type BalancerConfig struct {
        Name   string
        Config externalserviceconfig.LoadBalancingConfig
}

type intermediateBalancerConfig []map[string]json.RawMessage

// MarshalJSON implements the json.Marshaler interface.
//
// It marshals the balancer and config into a length-1 slice
// ([]map[string]config).
func (bc *BalancerConfig) MarshalJSON() ([]byte, error) <span class="cov8" title="1">{
        if bc.Config == nil </span><span class="cov8" title="1">{
                // If config is nil, return empty config `{}`.
                return []byte(fmt.Sprintf(`[{%q: %v}]`, bc.Name, "{}")), nil
        }</span>
        <span class="cov8" title="1">c, err := json.Marshal(bc.Config)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return []byte(fmt.Sprintf(`[{%q: %s}]`, bc.Name, c)), nil</span>
}

// UnmarshalJSON implements the json.Unmarshaler interface.
//
// ServiceConfig contains a list of loadBalancingConfigs, each with a name and
// config. This method iterates through that list in order, and stops at the
// first policy that is supported.
// - If the config for the first supported policy is invalid, the whole service
//   config is invalid.
// - If the list doesn't contain any supported policy, the whole service config
//   is invalid.
func (bc *BalancerConfig) UnmarshalJSON(b []byte) error <span class="cov8" title="1">{
        var ir intermediateBalancerConfig
        err := json.Unmarshal(b, &amp;ir)
        if err != nil </span><span class="cov8" title="1">{
                return err
        }</span>

        <span class="cov8" title="1">var names []string
        for i, lbcfg := range ir </span><span class="cov8" title="1">{
                if len(lbcfg) != 1 </span><span class="cov8" title="1">{
                        return fmt.Errorf("invalid loadBalancingConfig: entry %v does not contain exactly 1 policy/config pair: %q", i, lbcfg)
                }</span>

                <span class="cov8" title="1">var (
                        name    string
                        jsonCfg json.RawMessage
                )
                // Get the key:value pair from the map. We have already made sure that
                // the map contains a single entry.
                for name, jsonCfg = range lbcfg </span>{<span class="cov8" title="1">
                }</span>

                <span class="cov8" title="1">names = append(names, name)
                builder := balancer.Get(name)
                if builder == nil </span><span class="cov8" title="1">{
                        // If the balancer is not registered, move on to the next config.
                        // This is not an error.
                        continue</span>
                }
                <span class="cov8" title="1">bc.Name = name

                parser, ok := builder.(balancer.ConfigParser)
                if !ok </span><span class="cov8" title="1">{
                        if string(jsonCfg) != "{}" </span><span class="cov8" title="1">{
                                logger.Warningf("non-empty balancer configuration %q, but balancer does not implement ParseConfig", string(jsonCfg))
                        }</span>
                        // Stop at this, though the builder doesn't support parsing config.
                        <span class="cov8" title="1">return nil</span>
                }

                <span class="cov8" title="1">cfg, err := parser.ParseConfig(jsonCfg)
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("error parsing loadBalancingConfig for policy %q: %v", name, err)
                }</span>
                <span class="cov8" title="1">bc.Config = cfg
                return nil</span>
        }
        // This is reached when the for loop iterates over all entries, but didn't
        // return. This means we had a loadBalancingConfig slice but did not
        // encounter a registered policy. The config is considered invalid in this
        // case.
        <span class="cov8" title="1">return fmt.Errorf("invalid loadBalancingConfig: no supported policies found in %v", names)</span>
}

// MethodConfig defines the configuration recommended by the service providers for a
// particular method.
type MethodConfig struct {
        // WaitForReady indicates whether RPCs sent to this method should wait until
        // the connection is ready by default (!failfast). The value specified via the
        // gRPC client API will override the value set here.
        WaitForReady *bool
        // Timeout is the default timeout for RPCs sent to this method. The actual
        // deadline used will be the minimum of the value specified here and the value
        // set by the application via the gRPC client API.  If either one is not set,
        // then the other will be used.  If neither is set, then the RPC has no deadline.
        Timeout *time.Duration
        // MaxReqSize is the maximum allowed payload size for an individual request in a
        // stream (client-&gt;server) in bytes. The size which is measured is the serialized
        // payload after per-message compression (but before stream compression) in bytes.
        // The actual value used is the minimum of the value specified here and the value set
        // by the application via the gRPC client API. If either one is not set, then the other
        // will be used.  If neither is set, then the built-in default is used.
        MaxReqSize *int
        // MaxRespSize is the maximum allowed payload size for an individual response in a
        // stream (server-&gt;client) in bytes.
        MaxRespSize *int
        // RetryPolicy configures retry options for the method.
        RetryPolicy *RetryPolicy
}

// RetryPolicy defines the go-native version of the retry policy defined by the
// service config here:
// https://github.com/grpc/proposal/blob/master/A6-client-retries.md#integration-with-service-config
type RetryPolicy struct {
        // MaxAttempts is the maximum number of attempts, including the original RPC.
        //
        // This field is required and must be two or greater.
        MaxAttempts int

        // Exponential backoff parameters. The initial retry attempt will occur at
        // random(0, initialBackoff). In general, the nth attempt will occur at
        // random(0,
        //   min(initialBackoff*backoffMultiplier**(n-1), maxBackoff)).
        //
        // These fields are required and must be greater than zero.
        InitialBackoff    time.Duration
        MaxBackoff        time.Duration
        BackoffMultiplier float64

        // The set of status codes which may be retried.
        //
        // Status codes are specified as strings, e.g., "UNAVAILABLE".
        //
        // This field is required and must be non-empty.
        // Note: a set is used to store this for easy lookup.
        RetryableStatusCodes map[codes.Code]bool
}
</pre>
		
		<pre class="file" id="file99" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package testutils

import (
        "context"
        "errors"
        "fmt"
        "testing"

        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/connectivity"
        "google.golang.org/grpc/resolver"
)

// TestSubConnsCount is the number of TestSubConns initialized as part of
// package init.
const TestSubConnsCount = 16

// testingLogger wraps the logging methods from testing.T.
type testingLogger interface {
        Log(args ...interface{})
        Logf(format string, args ...interface{})
}

// TestSubConns contains a list of SubConns to be used in tests.
var TestSubConns []*TestSubConn

func init() <span class="cov8" title="1">{
        for i := 0; i &lt; TestSubConnsCount; i++ </span><span class="cov8" title="1">{
                TestSubConns = append(TestSubConns, &amp;TestSubConn{
                        id:        fmt.Sprintf("sc%d", i),
                        ConnectCh: make(chan struct{}, 1),
                })
        }</span>
}

// TestSubConn implements the SubConn interface, to be used in tests.
type TestSubConn struct {
        id        string
        ConnectCh chan struct{}
}

// UpdateAddresses is a no-op.
func (tsc *TestSubConn) UpdateAddresses([]resolver.Address) {<span class="cov0" title="0">}</span>

// Connect is a no-op.
func (tsc *TestSubConn) Connect() <span class="cov0" title="0">{
        select </span>{
        case tsc.ConnectCh &lt;- struct{}{}:<span class="cov0" title="0"></span>
        default:<span class="cov0" title="0"></span>
        }
}

// String implements stringer to print human friendly error message.
func (tsc *TestSubConn) String() string <span class="cov0" title="0">{
        return tsc.id
}</span>

// TestClientConn is a mock balancer.ClientConn used in tests.
type TestClientConn struct {
        logger testingLogger

        NewSubConnAddrsCh      chan []resolver.Address // the last 10 []Address to create subconn.
        NewSubConnCh           chan balancer.SubConn   // the last 10 subconn created.
        RemoveSubConnCh        chan balancer.SubConn   // the last 10 subconn removed.
        UpdateAddressesAddrsCh chan []resolver.Address // last updated address via UpdateAddresses().

        NewPickerCh  chan balancer.Picker            // the last picker updated.
        NewStateCh   chan connectivity.State         // the last state.
        ResolveNowCh chan resolver.ResolveNowOptions // the last ResolveNow().

        subConnIdx int
}

// NewTestClientConn creates a TestClientConn.
func NewTestClientConn(t *testing.T) *TestClientConn <span class="cov0" title="0">{
        return &amp;TestClientConn{
                logger: t,

                NewSubConnAddrsCh:      make(chan []resolver.Address, 10),
                NewSubConnCh:           make(chan balancer.SubConn, 10),
                RemoveSubConnCh:        make(chan balancer.SubConn, 10),
                UpdateAddressesAddrsCh: make(chan []resolver.Address, 1),

                NewPickerCh:  make(chan balancer.Picker, 1),
                NewStateCh:   make(chan connectivity.State, 1),
                ResolveNowCh: make(chan resolver.ResolveNowOptions, 1),
        }
}</span>

// NewSubConn creates a new SubConn.
func (tcc *TestClientConn) NewSubConn(a []resolver.Address, o balancer.NewSubConnOptions) (balancer.SubConn, error) <span class="cov0" title="0">{
        sc := TestSubConns[tcc.subConnIdx]
        tcc.subConnIdx++

        tcc.logger.Logf("testClientConn: NewSubConn(%v, %+v) =&gt; %s", a, o, sc)
        select </span>{
        case tcc.NewSubConnAddrsCh &lt;- a:<span class="cov0" title="0"></span>
        default:<span class="cov0" title="0"></span>
        }

        <span class="cov0" title="0">select </span>{
        case tcc.NewSubConnCh &lt;- sc:<span class="cov0" title="0"></span>
        default:<span class="cov0" title="0"></span>
        }

        <span class="cov0" title="0">return sc, nil</span>
}

// RemoveSubConn removes the SubConn.
func (tcc *TestClientConn) RemoveSubConn(sc balancer.SubConn) <span class="cov0" title="0">{
        tcc.logger.Logf("testClientConn: RemoveSubConn(%s)", sc)
        select </span>{
        case tcc.RemoveSubConnCh &lt;- sc:<span class="cov0" title="0"></span>
        default:<span class="cov0" title="0"></span>
        }
}

// UpdateAddresses updates the addresses on the SubConn.
func (tcc *TestClientConn) UpdateAddresses(sc balancer.SubConn, addrs []resolver.Address) <span class="cov0" title="0">{
        tcc.logger.Logf("testClientConn: UpdateAddresses(%v, %+v)", sc, addrs)
        select </span>{
        case tcc.UpdateAddressesAddrsCh &lt;- addrs:<span class="cov0" title="0"></span>
        default:<span class="cov0" title="0"></span>
        }
}

// UpdateState updates connectivity state and picker.
func (tcc *TestClientConn) UpdateState(bs balancer.State) <span class="cov0" title="0">{
        tcc.logger.Logf("testClientConn: UpdateState(%v)", bs)
        select </span>{
        case &lt;-tcc.NewStateCh:<span class="cov0" title="0"></span>
        default:<span class="cov0" title="0"></span>
        }
        <span class="cov0" title="0">tcc.NewStateCh &lt;- bs.ConnectivityState

        select </span>{
        case &lt;-tcc.NewPickerCh:<span class="cov0" title="0"></span>
        default:<span class="cov0" title="0"></span>
        }
        <span class="cov0" title="0">tcc.NewPickerCh &lt;- bs.Picker</span>
}

// ResolveNow panics.
func (tcc *TestClientConn) ResolveNow(o resolver.ResolveNowOptions) <span class="cov0" title="0">{
        select </span>{
        case &lt;-tcc.ResolveNowCh:<span class="cov0" title="0"></span>
        default:<span class="cov0" title="0"></span>
        }
        <span class="cov0" title="0">tcc.ResolveNowCh &lt;- o</span>
}

// Target panics.
func (tcc *TestClientConn) Target() string <span class="cov0" title="0">{
        panic("not implemented")</span>
}

// WaitForErrPicker waits until an error picker is pushed to this ClientConn.
// Returns error if the provided context expires or a non-error picker is pushed
// to the ClientConn.
func (tcc *TestClientConn) WaitForErrPicker(ctx context.Context) error <span class="cov0" title="0">{
        select </span>{
        case &lt;-ctx.Done():<span class="cov0" title="0">
                return errors.New("timeout when waiting for an error picker")</span>
        case picker := &lt;-tcc.NewPickerCh:<span class="cov0" title="0">
                if _, perr := picker.Pick(balancer.PickInfo{}); perr == nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("balancer returned a picker which is not an error picker")
                }</span>
        }
        <span class="cov0" title="0">return nil</span>
}

// WaitForPickerWithErr waits until an error picker is pushed to this
// ClientConn with the error matching the wanted error.  Returns an error if
// the provided context expires, including the last received picker error (if
// any).
func (tcc *TestClientConn) WaitForPickerWithErr(ctx context.Context, want error) error <span class="cov0" title="0">{
        lastErr := errors.New("received no picker")
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        return fmt.Errorf("timeout when waiting for an error picker with %v; last picker error: %v", want, lastErr)</span>
                case picker := &lt;-tcc.NewPickerCh:<span class="cov0" title="0">
                        for i := 0; i &lt; 5; i++ </span><span class="cov0" title="0">{
                                if _, lastErr = picker.Pick(balancer.PickInfo{}); lastErr == nil || lastErr.Error() != want.Error() </span><span class="cov0" title="0">{
                                        break</span>
                                }
                                <span class="cov0" title="0">return nil</span>
                        }
                }
        }
}

// WaitForConnectivityState waits until the state pushed to this ClientConn
// matches the wanted state.  Returns an error if the provided context expires,
// including the last received state (if any).
func (tcc *TestClientConn) WaitForConnectivityState(ctx context.Context, want connectivity.State) error <span class="cov0" title="0">{
        var lastState connectivity.State = -1
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        return fmt.Errorf("timeout when waiting for state to be %s; last state: %s", want, lastState)</span>
                case s := &lt;-tcc.NewStateCh:<span class="cov0" title="0">
                        if s == want </span><span class="cov0" title="0">{
                                return nil
                        }</span>
                        <span class="cov0" title="0">lastState = s</span>
                }
        }
}

// WaitForRoundRobinPicker waits for a picker that passes IsRoundRobin.  Also
// drains the matching state channel and requires it to be READY (if an entry
// is pending) to be considered.  Returns an error if the provided context
// expires, including the last received error from IsRoundRobin or the picker
// (if any).
func (tcc *TestClientConn) WaitForRoundRobinPicker(ctx context.Context, want ...balancer.SubConn) error <span class="cov0" title="0">{
        lastErr := errors.New("received no picker")
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        return fmt.Errorf("timeout when waiting for round robin picker with %v; last error: %v", want, lastErr)</span>
                case p := &lt;-tcc.NewPickerCh:<span class="cov0" title="0">
                        s := connectivity.Ready
                        select </span>{
                        case s = &lt;-tcc.NewStateCh:<span class="cov0" title="0"></span>
                        default:<span class="cov0" title="0"></span>
                        }
                        <span class="cov0" title="0">if s != connectivity.Ready </span><span class="cov0" title="0">{
                                lastErr = fmt.Errorf("received state %v instead of ready", s)
                                break</span>
                        }
                        <span class="cov0" title="0">var pickerErr error
                        if err := IsRoundRobin(want, func() balancer.SubConn </span><span class="cov0" title="0">{
                                sc, err := p.Pick(balancer.PickInfo{})
                                if err != nil </span><span class="cov0" title="0">{
                                        pickerErr = err
                                }</span> else<span class="cov0" title="0"> if sc.Done != nil </span><span class="cov0" title="0">{
                                        sc.Done(balancer.DoneInfo{})
                                }</span>
                                <span class="cov0" title="0">return sc.SubConn</span>
                        }); pickerErr != nil <span class="cov0" title="0">{
                                lastErr = pickerErr
                                continue</span>
                        } else<span class="cov0" title="0"> if err != nil </span><span class="cov0" title="0">{
                                lastErr = err
                                continue</span>
                        }
                        <span class="cov0" title="0">return nil</span>
                }
        }
}

// WaitForPicker waits for a picker that results in f returning nil.  If the
// context expires, returns the last error returned by f (if any).
func (tcc *TestClientConn) WaitForPicker(ctx context.Context, f func(balancer.Picker) error) error <span class="cov0" title="0">{
        lastErr := errors.New("received no picker")
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        return fmt.Errorf("timeout when waiting for picker; last error: %v", lastErr)</span>
                case p := &lt;-tcc.NewPickerCh:<span class="cov0" title="0">
                        if err := f(p); err != nil </span><span class="cov0" title="0">{
                                lastErr = err
                                continue</span>
                        }
                        <span class="cov0" title="0">return nil</span>
                }
        }
}

// IsRoundRobin checks whether f's return value is roundrobin of elements from
// want. But it doesn't check for the order. Note that want can contain
// duplicate items, which makes it weight-round-robin.
//
// Step 1. the return values of f should form a permutation of all elements in
// want, but not necessary in the same order. E.g. if want is {a,a,b}, the check
// fails if f returns:
//  - {a,a,a}: third a is returned before b
//  - {a,b,b}: second b is returned before the second a
//
// If error is found in this step, the returned error contains only the first
// iteration until where it goes wrong.
//
// Step 2. the return values of f should be repetitions of the same permutation.
// E.g. if want is {a,a,b}, the check failes if f returns:
//  - {a,b,a,b,a,a}: though it satisfies step 1, the second iteration is not
//  repeating the first iteration.
//
// If error is found in this step, the returned error contains the first
// iteration + the second iteration until where it goes wrong.
func IsRoundRobin(want []balancer.SubConn, f func() balancer.SubConn) error <span class="cov0" title="0">{
        wantSet := make(map[balancer.SubConn]int) // SubConn -&gt; count, for weighted RR.
        for _, sc := range want </span><span class="cov0" title="0">{
                wantSet[sc]++
        }</span>

        // The first iteration: makes sure f's return values form a permutation of
        // elements in want.
        //
        // Also keep the returns values in a slice, so we can compare the order in
        // the second iteration.
        <span class="cov0" title="0">gotSliceFirstIteration := make([]balancer.SubConn, 0, len(want))
        for range want </span><span class="cov0" title="0">{
                got := f()
                gotSliceFirstIteration = append(gotSliceFirstIteration, got)
                wantSet[got]--
                if wantSet[got] &lt; 0 </span><span class="cov0" title="0">{
                        return fmt.Errorf("non-roundrobin want: %v, result: %v", want, gotSliceFirstIteration)
                }</span>
        }

        // The second iteration should repeat the first iteration.
        <span class="cov0" title="0">var gotSliceSecondIteration []balancer.SubConn
        for i := 0; i &lt; 2; i++ </span><span class="cov0" title="0">{
                for _, w := range gotSliceFirstIteration </span><span class="cov0" title="0">{
                        g := f()
                        gotSliceSecondIteration = append(gotSliceSecondIteration, g)
                        if w != g </span><span class="cov0" title="0">{
                                return fmt.Errorf("non-roundrobin, first iter: %v, second iter: %v", gotSliceFirstIteration, gotSliceSecondIteration)
                        }</span>
                }
        }

        <span class="cov0" title="0">return nil</span>
}

// ErrTestConstPicker is error returned by test const picker.
var ErrTestConstPicker = fmt.Errorf("const picker error")

// TestConstPicker is a const picker for tests.
type TestConstPicker struct {
        Err error
        SC  balancer.SubConn
}

// Pick returns the const SubConn or the error.
func (tcp *TestConstPicker) Pick(info balancer.PickInfo) (balancer.PickResult, error) <span class="cov0" title="0">{
        if tcp.Err != nil </span><span class="cov0" title="0">{
                return balancer.PickResult{}, tcp.Err
        }</span>
        <span class="cov0" title="0">return balancer.PickResult{SubConn: tcp.SC}, nil</span>
}
</pre>
		
		<pre class="file" id="file100" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package testutils

import (
        "context"
)

// DefaultChanBufferSize is the default buffer size of the underlying channel.
const DefaultChanBufferSize = 1

// Channel wraps a generic channel and provides a timed receive operation.
type Channel struct {
        ch chan interface{}
}

// Send sends value on the underlying channel.
func (c *Channel) Send(value interface{}) <span class="cov0" title="0">{
        c.ch &lt;- value
}</span>

// SendContext sends value on the underlying channel, or returns an error if
// the context expires.
func (c *Channel) SendContext(ctx context.Context, value interface{}) error <span class="cov0" title="0">{
        select </span>{
        case c.ch &lt;- value:<span class="cov0" title="0">
                return nil</span>
        case &lt;-ctx.Done():<span class="cov0" title="0">
                return ctx.Err()</span>
        }
}

// SendOrFail attempts to send value on the underlying channel.  Returns true
// if successful or false if the channel was full.
func (c *Channel) SendOrFail(value interface{}) bool <span class="cov0" title="0">{
        select </span>{
        case c.ch &lt;- value:<span class="cov0" title="0">
                return true</span>
        default:<span class="cov0" title="0">
                return false</span>
        }
}

// ReceiveOrFail returns the value on the underlying channel and true, or nil
// and false if the channel was empty.
func (c *Channel) ReceiveOrFail() (interface{}, bool) <span class="cov0" title="0">{
        select </span>{
        case got := &lt;-c.ch:<span class="cov0" title="0">
                return got, true</span>
        default:<span class="cov0" title="0">
                return nil, false</span>
        }
}

// Receive returns the value received on the underlying channel, or the error
// returned by ctx if it is closed or cancelled.
func (c *Channel) Receive(ctx context.Context) (interface{}, error) <span class="cov0" title="0">{
        select </span>{
        case &lt;-ctx.Done():<span class="cov0" title="0">
                return nil, ctx.Err()</span>
        case got := &lt;-c.ch:<span class="cov0" title="0">
                return got, nil</span>
        }
}

// Replace clears the value on the underlying channel, and sends the new value.
//
// It's expected to be used with a size-1 channel, to only keep the most
// up-to-date item. This method is inherently racy when invoked concurrently
// from multiple goroutines.
func (c *Channel) Replace(value interface{}) <span class="cov0" title="0">{
        for </span><span class="cov0" title="0">{
                select </span>{
                case c.ch &lt;- value:<span class="cov0" title="0">
                        return</span>
                case &lt;-c.ch:<span class="cov0" title="0"></span>
                }
        }
}

// NewChannel returns a new Channel.
func NewChannel() *Channel <span class="cov0" title="0">{
        return NewChannelWithSize(DefaultChanBufferSize)
}</span>

// NewChannelWithSize returns a new Channel with a buffer of bufSize.
func NewChannelWithSize(bufSize int) *Channel <span class="cov0" title="0">{
        return &amp;Channel{ch: make(chan interface{}, bufSize)}
}</span>
</pre>
		
		<pre class="file" id="file101" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package testutils

import (
        "context"
        "net/http"
        "time"
)

// DefaultHTTPRequestTimeout is the default timeout value for the amount of time
// this client waits for a response to be pushed on RespChan before it fails the
// Do() call.
const DefaultHTTPRequestTimeout = 1 * time.Second

// FakeHTTPClient helps mock out HTTP calls made by the code under test. It
// makes HTTP requests made by the code under test available through a channel,
// and makes it possible to inject various responses.
type FakeHTTPClient struct {
        // ReqChan exposes the HTTP.Request made by the code under test.
        ReqChan *Channel
        // RespChan is a channel on which this fake client accepts responses to be
        // sent to the code under test.
        RespChan *Channel
        // Err, if set, is returned by Do().
        Err error
        // RecvTimeout is the amount of the time this client waits for a response to
        // be pushed on RespChan before it fails the Do() call. If this field is
        // left unspecified, DefaultHTTPRequestTimeout is used.
        RecvTimeout time.Duration
}

// Do pushes req on ReqChan and returns the response available on RespChan.
func (fc *FakeHTTPClient) Do(req *http.Request) (*http.Response, error) <span class="cov0" title="0">{
        fc.ReqChan.Send(req)

        timeout := fc.RecvTimeout
        if timeout == 0 </span><span class="cov0" title="0">{
                timeout = DefaultHTTPRequestTimeout
        }</span>
        <span class="cov0" title="0">ctx, cancel := context.WithTimeout(context.Background(), timeout)
        defer cancel()
        val, err := fc.RespChan.Receive(ctx)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">return val.(*http.Response), fc.Err</span>
}
</pre>
		
		<pre class="file" id="file102" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package testutils

import "net"

// LocalTCPListener returns a net.Listener listening on local address and port.
func LocalTCPListener() (net.Listener, error) <span class="cov0" title="0">{
        return net.Listen("tcp", "localhost:0")
}</span>
</pre>
		
		<pre class="file" id="file103" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package testutils

import (
        "fmt"

        "github.com/golang/protobuf/proto"
        "github.com/golang/protobuf/ptypes"
        "google.golang.org/protobuf/types/known/anypb"
)

// MarshalAny is a convenience function to marshal protobuf messages into any
// protos. It will panic if the marshaling fails.
func MarshalAny(m proto.Message) *anypb.Any <span class="cov0" title="0">{
        a, err := ptypes.MarshalAny(m)
        if err != nil </span><span class="cov0" title="0">{
                panic(fmt.Sprintf("ptypes.MarshalAny(%+v) failed: %v", m, err))</span>
        }
        <span class="cov0" title="0">return a</span>
}
</pre>
		
		<pre class="file" id="file104" style="display: none">/*
 *
 * Copyright 2018 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package testutils contains testing helpers.
package testutils

import (
        "errors"
        "net"
        "time"
)

var errClosed = errors.New("closed")

type pipeAddr struct{}

func (p pipeAddr) Network() string <span class="cov0" title="0">{ return "pipe" }</span>
func (p pipeAddr) String() string  <span class="cov0" title="0">{ return "pipe" }</span>

// PipeListener is a listener with an unbuffered pipe. Each write will complete only once the other side reads. It
// should only be created using NewPipeListener.
type PipeListener struct {
        c    chan chan&lt;- net.Conn
        done chan struct{}
}

// NewPipeListener creates a new pipe listener.
func NewPipeListener() *PipeListener <span class="cov8" title="1">{
        return &amp;PipeListener{
                c:    make(chan chan&lt;- net.Conn),
                done: make(chan struct{}),
        }
}</span>

// Accept accepts a connection.
func (p *PipeListener) Accept() (net.Conn, error) <span class="cov8" title="1">{
        var connChan chan&lt;- net.Conn
        select </span>{
        case &lt;-p.done:<span class="cov8" title="1">
                return nil, errClosed</span>
        case connChan = &lt;-p.c:<span class="cov8" title="1">
                select </span>{
                case &lt;-p.done:<span class="cov0" title="0">
                        close(connChan)
                        return nil, errClosed</span>
                default:<span class="cov8" title="1"></span>
                }
        }
        <span class="cov8" title="1">c1, c2 := net.Pipe()
        connChan &lt;- c1
        close(connChan)
        return c2, nil</span>
}

// Close closes the listener.
func (p *PipeListener) Close() error <span class="cov8" title="1">{
        close(p.done)
        return nil
}</span>

// Addr returns a pipe addr.
func (p *PipeListener) Addr() net.Addr <span class="cov0" title="0">{
        return pipeAddr{}
}</span>

// Dialer dials a connection.
func (p *PipeListener) Dialer() func(string, time.Duration) (net.Conn, error) <span class="cov8" title="1">{
        return func(string, time.Duration) (net.Conn, error) </span><span class="cov8" title="1">{
                connChan := make(chan net.Conn)
                select </span>{
                case p.c &lt;- connChan:<span class="cov8" title="1"></span>
                case &lt;-p.done:<span class="cov8" title="1">
                        return nil, errClosed</span>
                }
                <span class="cov8" title="1">conn, ok := &lt;-connChan
                if !ok </span><span class="cov0" title="0">{
                        return nil, errClosed
                }</span>
                <span class="cov8" title="1">return conn, nil</span>
        }
}
</pre>
		
		<pre class="file" id="file105" style="display: none">/*
 *
 * Copyright 2019 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package testutils

import (
        "net"
        "sync"
)

type tempError struct{}

func (*tempError) Error() string <span class="cov0" title="0">{
        return "restartable listener temporary error"
}</span>
func (*tempError) Temporary() bool <span class="cov0" title="0">{
        return true
}</span>

// RestartableListener wraps a net.Listener and supports stopping and restarting
// the latter.
type RestartableListener struct {
        lis net.Listener

        mu      sync.Mutex
        stopped bool
        conns   []net.Conn
}

// NewRestartableListener returns a new RestartableListener wrapping l.
func NewRestartableListener(l net.Listener) *RestartableListener <span class="cov0" title="0">{
        return &amp;RestartableListener{lis: l}
}</span>

// Accept waits for and returns the next connection to the listener.
//
// If the listener is currently not accepting new connections, because `Stop`
// was called on it, the connection is immediately closed after accepting
// without any bytes being sent on it.
func (l *RestartableListener) Accept() (net.Conn, error) <span class="cov0" title="0">{
        conn, err := l.lis.Accept()
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov0" title="0">l.mu.Lock()
        defer l.mu.Unlock()
        if l.stopped </span><span class="cov0" title="0">{
                conn.Close()
                return nil, &amp;tempError{}
        }</span>
        <span class="cov0" title="0">l.conns = append(l.conns, conn)
        return conn, nil</span>
}

// Close closes the listener.
func (l *RestartableListener) Close() error <span class="cov0" title="0">{
        return l.lis.Close()
}</span>

// Addr returns the listener's network address.
func (l *RestartableListener) Addr() net.Addr <span class="cov0" title="0">{
        return l.lis.Addr()
}</span>

// Stop closes existing connections on the listener and prevents new connections
// from being accepted.
func (l *RestartableListener) Stop() <span class="cov0" title="0">{
        l.mu.Lock()
        l.stopped = true
        for _, conn := range l.conns </span><span class="cov0" title="0">{
                conn.Close()
        }</span>
        <span class="cov0" title="0">l.conns = nil
        l.mu.Unlock()</span>
}

// Restart gets a previously stopped listener to start accepting connections.
func (l *RestartableListener) Restart() <span class="cov0" title="0">{
        l.mu.Lock()
        l.stopped = false
        l.mu.Unlock()
}</span>
</pre>
		
		<pre class="file" id="file106" style="display: none">/*
 *
 * Copyright 2019 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package testutils

import (
        "github.com/golang/protobuf/proto"
        "google.golang.org/grpc/status"
)

// StatusErrEqual returns true iff both err1 and err2 wrap status.Status errors
// and their underlying status protos are equal.
func StatusErrEqual(err1, err2 error) bool <span class="cov8" title="1">{
        status1, ok := status.FromError(err1)
        if !ok </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov8" title="1">status2, ok := status.FromError(err2)
        if !ok </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov8" title="1">return proto.Equal(status1.Proto(), status2.Proto())</span>
}
</pre>
		
		<pre class="file" id="file107" style="display: none">/*
 *
 * Copyright 2022 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package testutils

import (
        "net"
        "testing"
)

// ConnWrapper wraps a net.Conn and pushes on a channel when closed.
type ConnWrapper struct {
        net.Conn
        CloseCh *Channel
}

// Close closes the connection and sends a value on the close channel.
func (cw *ConnWrapper) Close() error <span class="cov0" title="0">{
        err := cw.Conn.Close()
        cw.CloseCh.Replace(nil)
        return err
}</span>

// ListenerWrapper wraps a net.Listener and the returned net.Conn.
//
// It pushes on a channel whenever it accepts a new connection.
type ListenerWrapper struct {
        net.Listener
        NewConnCh *Channel
}

// Accept wraps the Listener Accept and sends the accepted connection on a
// channel.
func (l *ListenerWrapper) Accept() (net.Conn, error) <span class="cov0" title="0">{
        c, err := l.Listener.Accept()
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">closeCh := NewChannel()
        conn := &amp;ConnWrapper{Conn: c, CloseCh: closeCh}
        l.NewConnCh.Send(conn)
        return conn, nil</span>
}

// NewListenerWrapper returns a ListenerWrapper.
func NewListenerWrapper(t *testing.T, lis net.Listener) *ListenerWrapper <span class="cov0" title="0">{
        if lis == nil </span><span class="cov0" title="0">{
                var err error
                lis, err = LocalTCPListener()
                if err != nil </span><span class="cov0" title="0">{
                        t.Fatal(err)
                }</span>
        }

        <span class="cov0" title="0">return &amp;ListenerWrapper{
                Listener:  lis,
                NewConnCh: NewChannel(),
        }</span>
}
</pre>
		
		<pre class="file" id="file108" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package testutils

import (
        "fmt"
        "sync"

        "google.golang.org/grpc/internal/wrr"
)

// testWRR is a deterministic WRR implementation.
//
// The real implementation does random WRR. testWRR makes the balancer behavior
// deterministic and easier to test.
//
// With {a: 2, b: 3}, the Next() results will be {a, a, b, b, b}.
type testWRR struct {
        itemsWithWeight []struct {
                item   interface{}
                weight int64
        }
        length int

        mu    sync.Mutex
        idx   int   // The index of the item that will be picked
        count int64 // The number of times the current item has been picked.
}

// NewTestWRR return a WRR for testing. It's deterministic instead of random.
func NewTestWRR() wrr.WRR <span class="cov0" title="0">{
        return &amp;testWRR{}
}</span>

func (twrr *testWRR) Add(item interface{}, weight int64) <span class="cov0" title="0">{
        twrr.itemsWithWeight = append(twrr.itemsWithWeight, struct {
                item   interface{}
                weight int64
        }{item: item, weight: weight})
        twrr.length++
}</span>

func (twrr *testWRR) Next() interface{} <span class="cov0" title="0">{
        twrr.mu.Lock()
        iww := twrr.itemsWithWeight[twrr.idx]
        twrr.count++
        if twrr.count &gt;= iww.weight </span><span class="cov0" title="0">{
                twrr.idx = (twrr.idx + 1) % twrr.length
                twrr.count = 0
        }</span>
        <span class="cov0" title="0">twrr.mu.Unlock()
        return iww.item</span>
}

func (twrr *testWRR) String() string <span class="cov0" title="0">{
        return fmt.Sprint(twrr.itemsWithWeight)
}</span>
</pre>
		
		<pre class="file" id="file109" style="display: none">/*
 *
 * Copyright 2017 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package transport

import (
        "sync"
        "time"
)

const (
        // bdpLimit is the maximum value the flow control windows will be increased
        // to.  TCP typically limits this to 4MB, but some systems go up to 16MB.
        // Since this is only a limit, it is safe to make it optimistic.
        bdpLimit = (1 &lt;&lt; 20) * 16
        // alpha is a constant factor used to keep a moving average
        // of RTTs.
        alpha = 0.9
        // If the current bdp sample is greater than or equal to
        // our beta * our estimated bdp and the current bandwidth
        // sample is the maximum bandwidth observed so far, we
        // increase our bbp estimate by a factor of gamma.
        beta = 0.66
        // To put our bdp to be smaller than or equal to twice the real BDP,
        // we should multiply our current sample with 4/3, however to round things out
        // we use 2 as the multiplication factor.
        gamma = 2
)

// Adding arbitrary data to ping so that its ack can be identified.
// Easter-egg: what does the ping message say?
var bdpPing = &amp;ping{data: [8]byte{2, 4, 16, 16, 9, 14, 7, 7}}

type bdpEstimator struct {
        // sentAt is the time when the ping was sent.
        sentAt time.Time

        mu sync.Mutex
        // bdp is the current bdp estimate.
        bdp uint32
        // sample is the number of bytes received in one measurement cycle.
        sample uint32
        // bwMax is the maximum bandwidth noted so far (bytes/sec).
        bwMax float64
        // bool to keep track of the beginning of a new measurement cycle.
        isSent bool
        // Callback to update the window sizes.
        updateFlowControl func(n uint32)
        // sampleCount is the number of samples taken so far.
        sampleCount uint64
        // round trip time (seconds)
        rtt float64
}

// timesnap registers the time bdp ping was sent out so that
// network rtt can be calculated when its ack is received.
// It is called (by controller) when the bdpPing is
// being written on the wire.
func (b *bdpEstimator) timesnap(d [8]byte) <span class="cov8" title="1">{
        if bdpPing.data != d </span><span class="cov8" title="1">{
                return
        }</span>
        <span class="cov8" title="1">b.sentAt = time.Now()</span>
}

// add adds bytes to the current sample for calculating bdp.
// It returns true only if a ping must be sent. This can be used
// by the caller (handleData) to make decision about batching
// a window update with it.
func (b *bdpEstimator) add(n uint32) bool <span class="cov8" title="1">{
        b.mu.Lock()
        defer b.mu.Unlock()
        if b.bdp == bdpLimit </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov8" title="1">if !b.isSent </span><span class="cov8" title="1">{
                b.isSent = true
                b.sample = n
                b.sentAt = time.Time{}
                b.sampleCount++
                return true
        }</span>
        <span class="cov8" title="1">b.sample += n
        return false</span>
}

// calculate is called when an ack for a bdp ping is received.
// Here we calculate the current bdp and bandwidth sample and
// decide if the flow control windows should go up.
func (b *bdpEstimator) calculate(d [8]byte) <span class="cov8" title="1">{
        // Check if the ping acked for was the bdp ping.
        if bdpPing.data != d </span><span class="cov8" title="1">{
                return
        }</span>
        <span class="cov8" title="1">b.mu.Lock()
        rttSample := time.Since(b.sentAt).Seconds()
        if b.sampleCount &lt; 10 </span><span class="cov8" title="1">{
                // Bootstrap rtt with an average of first 10 rtt samples.
                b.rtt += (rttSample - b.rtt) / float64(b.sampleCount)
        }</span> else<span class="cov8" title="1"> {
                // Heed to the recent past more.
                b.rtt += (rttSample - b.rtt) * float64(alpha)
        }</span>
        <span class="cov8" title="1">b.isSent = false
        // The number of bytes accumulated so far in the sample is smaller
        // than or equal to 1.5 times the real BDP on a saturated connection.
        bwCurrent := float64(b.sample) / (b.rtt * float64(1.5))
        if bwCurrent &gt; b.bwMax </span><span class="cov8" title="1">{
                b.bwMax = bwCurrent
        }</span>
        // If the current sample (which is smaller than or equal to the 1.5 times the real BDP) is
        // greater than or equal to 2/3rd our perceived bdp AND this is the maximum bandwidth seen so far, we
        // should update our perception of the network BDP.
        <span class="cov8" title="1">if float64(b.sample) &gt;= beta*float64(b.bdp) &amp;&amp; bwCurrent == b.bwMax &amp;&amp; b.bdp != bdpLimit </span><span class="cov8" title="1">{
                sampleFloat := float64(b.sample)
                b.bdp = uint32(gamma * sampleFloat)
                if b.bdp &gt; bdpLimit </span><span class="cov0" title="0">{
                        b.bdp = bdpLimit
                }</span>
                <span class="cov8" title="1">bdp := b.bdp
                b.mu.Unlock()
                b.updateFlowControl(bdp)
                return</span>
        }
        <span class="cov8" title="1">b.mu.Unlock()</span>
}
</pre>
		
		<pre class="file" id="file110" style="display: none">/*
 *
 * Copyright 2014 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package transport

import (
        "bytes"
        "errors"
        "fmt"
        "runtime"
        "strconv"
        "sync"
        "sync/atomic"

        "golang.org/x/net/http2"
        "golang.org/x/net/http2/hpack"
        "google.golang.org/grpc/internal/grpcutil"
        "google.golang.org/grpc/status"
)

var updateHeaderTblSize = func(e *hpack.Encoder, v uint32) <span class="cov0" title="0">{
        e.SetMaxDynamicTableSizeLimit(v)
}</span>

type itemNode struct {
        it   interface{}
        next *itemNode
}

type itemList struct {
        head *itemNode
        tail *itemNode
}

func (il *itemList) enqueue(i interface{}) <span class="cov8" title="1">{
        n := &amp;itemNode{it: i}
        if il.tail == nil </span><span class="cov8" title="1">{
                il.head, il.tail = n, n
                return
        }</span>
        <span class="cov8" title="1">il.tail.next = n
        il.tail = n</span>
}

// peek returns the first item in the list without removing it from the
// list.
func (il *itemList) peek() interface{} <span class="cov8" title="1">{
        return il.head.it
}</span>

func (il *itemList) dequeue() interface{} <span class="cov8" title="1">{
        if il.head == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">i := il.head.it
        il.head = il.head.next
        if il.head == nil </span><span class="cov8" title="1">{
                il.tail = nil
        }</span>
        <span class="cov8" title="1">return i</span>
}

func (il *itemList) dequeueAll() *itemNode <span class="cov8" title="1">{
        h := il.head
        il.head, il.tail = nil, nil
        return h
}</span>

func (il *itemList) isEmpty() bool <span class="cov8" title="1">{
        return il.head == nil
}</span>

// The following defines various control items which could flow through
// the control buffer of transport. They represent different aspects of
// control tasks, e.g., flow control, settings, streaming resetting, etc.

// maxQueuedTransportResponseFrames is the most queued "transport response"
// frames we will buffer before preventing new reads from occurring on the
// transport.  These are control frames sent in response to client requests,
// such as RST_STREAM due to bad headers or settings acks.
const maxQueuedTransportResponseFrames = 50

type cbItem interface {
        isTransportResponseFrame() bool
}

// registerStream is used to register an incoming stream with loopy writer.
type registerStream struct {
        streamID uint32
        wq       *writeQuota
}

func (*registerStream) isTransportResponseFrame() bool <span class="cov8" title="1">{ return false }</span>

// headerFrame is also used to register stream on the client-side.
type headerFrame struct {
        streamID   uint32
        hf         []hpack.HeaderField
        endStream  bool               // Valid on server side.
        initStream func(uint32) error // Used only on the client side.
        onWrite    func()
        wq         *writeQuota    // write quota for the stream created.
        cleanup    *cleanupStream // Valid on the server side.
        onOrphaned func(error)    // Valid on client-side
}

func (h *headerFrame) isTransportResponseFrame() bool <span class="cov8" title="1">{
        return h.cleanup != nil &amp;&amp; h.cleanup.rst // Results in a RST_STREAM
}</span>

type cleanupStream struct {
        streamID uint32
        rst      bool
        rstCode  http2.ErrCode
        onWrite  func()
}

func (c *cleanupStream) isTransportResponseFrame() bool <span class="cov8" title="1">{ return c.rst }</span> // Results in a RST_STREAM

type earlyAbortStream struct {
        httpStatus     uint32
        streamID       uint32
        contentSubtype string
        status         *status.Status
        rst            bool
}

func (*earlyAbortStream) isTransportResponseFrame() bool <span class="cov8" title="1">{ return false }</span>

type dataFrame struct {
        streamID  uint32
        endStream bool
        h         []byte
        d         []byte
        // onEachWrite is called every time
        // a part of d is written out.
        onEachWrite func()
}

func (*dataFrame) isTransportResponseFrame() bool <span class="cov8" title="1">{ return false }</span>

type incomingWindowUpdate struct {
        streamID  uint32
        increment uint32
}

func (*incomingWindowUpdate) isTransportResponseFrame() bool <span class="cov8" title="1">{ return false }</span>

type outgoingWindowUpdate struct {
        streamID  uint32
        increment uint32
}

func (*outgoingWindowUpdate) isTransportResponseFrame() bool <span class="cov8" title="1">{
        return false // window updates are throttled by thresholds
}</span>

type incomingSettings struct {
        ss []http2.Setting
}

func (*incomingSettings) isTransportResponseFrame() bool <span class="cov8" title="1">{ return true }</span> // Results in a settings ACK

type outgoingSettings struct {
        ss []http2.Setting
}

func (*outgoingSettings) isTransportResponseFrame() bool <span class="cov8" title="1">{ return false }</span>

type incomingGoAway struct {
}

func (*incomingGoAway) isTransportResponseFrame() bool <span class="cov8" title="1">{ return false }</span>

type goAway struct {
        code      http2.ErrCode
        debugData []byte
        headsUp   bool
        closeConn bool
}

func (*goAway) isTransportResponseFrame() bool <span class="cov8" title="1">{ return false }</span>

type ping struct {
        ack  bool
        data [8]byte
}

func (*ping) isTransportResponseFrame() bool <span class="cov8" title="1">{ return true }</span>

type outFlowControlSizeRequest struct {
        resp chan uint32
}

func (*outFlowControlSizeRequest) isTransportResponseFrame() bool <span class="cov0" title="0">{ return false }</span>

type outStreamState int

const (
        active outStreamState = iota
        empty
        waitingOnStreamQuota
)

type outStream struct {
        id               uint32
        state            outStreamState
        itl              *itemList
        bytesOutStanding int
        wq               *writeQuota

        next *outStream
        prev *outStream
}

func (s *outStream) deleteSelf() <span class="cov8" title="1">{
        if s.prev != nil </span><span class="cov8" title="1">{
                s.prev.next = s.next
        }</span>
        <span class="cov8" title="1">if s.next != nil </span><span class="cov8" title="1">{
                s.next.prev = s.prev
        }</span>
        <span class="cov8" title="1">s.next, s.prev = nil, nil</span>
}

type outStreamList struct {
        // Following are sentinel objects that mark the
        // beginning and end of the list. They do not
        // contain any item lists. All valid objects are
        // inserted in between them.
        // This is needed so that an outStream object can
        // deleteSelf() in O(1) time without knowing which
        // list it belongs to.
        head *outStream
        tail *outStream
}

func newOutStreamList() *outStreamList <span class="cov8" title="1">{
        head, tail := new(outStream), new(outStream)
        head.next = tail
        tail.prev = head
        return &amp;outStreamList{
                head: head,
                tail: tail,
        }
}</span>

func (l *outStreamList) enqueue(s *outStream) <span class="cov8" title="1">{
        e := l.tail.prev
        e.next = s
        s.prev = e
        s.next = l.tail
        l.tail.prev = s
}</span>

// remove from the beginning of the list.
func (l *outStreamList) dequeue() *outStream <span class="cov8" title="1">{
        b := l.head.next
        if b == l.tail </span><span class="cov8" title="1">{
                return nil
        }</span>
        <span class="cov8" title="1">b.deleteSelf()
        return b</span>
}

// controlBuffer is a way to pass information to loopy.
// Information is passed as specific struct types called control frames.
// A control frame not only represents data, messages or headers to be sent out
// but can also be used to instruct loopy to update its internal state.
// It shouldn't be confused with an HTTP2 frame, although some of the control frames
// like dataFrame and headerFrame do go out on wire as HTTP2 frames.
type controlBuffer struct {
        ch              chan struct{}
        done            &lt;-chan struct{}
        mu              sync.Mutex
        consumerWaiting bool
        list            *itemList
        err             error

        // transportResponseFrames counts the number of queued items that represent
        // the response of an action initiated by the peer.  trfChan is created
        // when transportResponseFrames &gt;= maxQueuedTransportResponseFrames and is
        // closed and nilled when transportResponseFrames drops below the
        // threshold.  Both fields are protected by mu.
        transportResponseFrames int
        trfChan                 atomic.Value // chan struct{}
}

func newControlBuffer(done &lt;-chan struct{}) *controlBuffer <span class="cov8" title="1">{
        return &amp;controlBuffer{
                ch:   make(chan struct{}, 1),
                list: &amp;itemList{},
                done: done,
        }
}</span>

// throttle blocks if there are too many incomingSettings/cleanupStreams in the
// controlbuf.
func (c *controlBuffer) throttle() <span class="cov8" title="1">{
        ch, _ := c.trfChan.Load().(chan struct{})
        if ch != nil </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ch:<span class="cov0" title="0"></span>
                case &lt;-c.done:<span class="cov0" title="0"></span>
                }
        }
}

func (c *controlBuffer) put(it cbItem) error <span class="cov8" title="1">{
        _, err := c.executeAndPut(nil, it)
        return err
}</span>

func (c *controlBuffer) executeAndPut(f func(it interface{}) bool, it cbItem) (bool, error) <span class="cov8" title="1">{
        var wakeUp bool
        c.mu.Lock()
        if c.err != nil </span><span class="cov8" title="1">{
                c.mu.Unlock()
                return false, c.err
        }</span>
        <span class="cov8" title="1">if f != nil </span><span class="cov8" title="1">{
                if !f(it) </span><span class="cov8" title="1">{ // f wasn't successful
                        c.mu.Unlock()
                        return false, nil
                }</span>
        }
        <span class="cov8" title="1">if c.consumerWaiting </span><span class="cov8" title="1">{
                wakeUp = true
                c.consumerWaiting = false
        }</span>
        <span class="cov8" title="1">c.list.enqueue(it)
        if it.isTransportResponseFrame() </span><span class="cov8" title="1">{
                c.transportResponseFrames++
                if c.transportResponseFrames == maxQueuedTransportResponseFrames </span><span class="cov0" title="0">{
                        // We are adding the frame that puts us over the threshold; create
                        // a throttling channel.
                        c.trfChan.Store(make(chan struct{}))
                }</span>
        }
        <span class="cov8" title="1">c.mu.Unlock()
        if wakeUp </span><span class="cov8" title="1">{
                select </span>{
                case c.ch &lt;- struct{}{}:<span class="cov8" title="1"></span>
                default:<span class="cov0" title="0"></span>
                }
        }
        <span class="cov8" title="1">return true, nil</span>
}

// Note argument f should never be nil.
func (c *controlBuffer) execute(f func(it interface{}) bool, it interface{}) (bool, error) <span class="cov8" title="1">{
        c.mu.Lock()
        if c.err != nil </span><span class="cov0" title="0">{
                c.mu.Unlock()
                return false, c.err
        }</span>
        <span class="cov8" title="1">if !f(it) </span><span class="cov0" title="0">{ // f wasn't successful
                c.mu.Unlock()
                return false, nil
        }</span>
        <span class="cov8" title="1">c.mu.Unlock()
        return true, nil</span>
}

func (c *controlBuffer) get(block bool) (interface{}, error) <span class="cov8" title="1">{
        for </span><span class="cov8" title="1">{
                c.mu.Lock()
                if c.err != nil </span><span class="cov8" title="1">{
                        c.mu.Unlock()
                        return nil, c.err
                }</span>
                <span class="cov8" title="1">if !c.list.isEmpty() </span><span class="cov8" title="1">{
                        h := c.list.dequeue().(cbItem)
                        if h.isTransportResponseFrame() </span><span class="cov8" title="1">{
                                if c.transportResponseFrames == maxQueuedTransportResponseFrames </span><span class="cov0" title="0">{
                                        // We are removing the frame that put us over the
                                        // threshold; close and clear the throttling channel.
                                        ch := c.trfChan.Load().(chan struct{})
                                        close(ch)
                                        c.trfChan.Store((chan struct{})(nil))
                                }</span>
                                <span class="cov8" title="1">c.transportResponseFrames--</span>
                        }
                        <span class="cov8" title="1">c.mu.Unlock()
                        return h, nil</span>
                }
                <span class="cov8" title="1">if !block </span><span class="cov8" title="1">{
                        c.mu.Unlock()
                        return nil, nil
                }</span>
                <span class="cov8" title="1">c.consumerWaiting = true
                c.mu.Unlock()
                select </span>{
                case &lt;-c.ch:<span class="cov8" title="1"></span>
                case &lt;-c.done:<span class="cov8" title="1">
                        return nil, ErrConnClosing</span>
                }
        }
}

func (c *controlBuffer) finish() <span class="cov8" title="1">{
        c.mu.Lock()
        if c.err != nil </span><span class="cov8" title="1">{
                c.mu.Unlock()
                return
        }</span>
        <span class="cov8" title="1">c.err = ErrConnClosing
        // There may be headers for streams in the control buffer.
        // These streams need to be cleaned out since the transport
        // is still not aware of these yet.
        for head := c.list.dequeueAll(); head != nil; head = head.next </span><span class="cov8" title="1">{
                hdr, ok := head.it.(*headerFrame)
                if !ok </span><span class="cov8" title="1">{
                        continue</span>
                }
                <span class="cov8" title="1">if hdr.onOrphaned != nil </span><span class="cov8" title="1">{ // It will be nil on the server-side.
                        hdr.onOrphaned(ErrConnClosing)
                }</span>
        }
        // In case throttle() is currently in flight, it needs to be unblocked.
        // Otherwise, the transport may not close, since the transport is closed by
        // the reader encountering the connection error.
        <span class="cov8" title="1">ch, _ := c.trfChan.Load().(chan struct{})
        if ch != nil </span><span class="cov0" title="0">{
                close(ch)
        }</span>
        <span class="cov8" title="1">c.trfChan.Store((chan struct{})(nil))
        c.mu.Unlock()</span>
}

type side int

const (
        clientSide side = iota
        serverSide
)

// Loopy receives frames from the control buffer.
// Each frame is handled individually; most of the work done by loopy goes
// into handling data frames. Loopy maintains a queue of active streams, and each
// stream maintains a queue of data frames; as loopy receives data frames
// it gets added to the queue of the relevant stream.
// Loopy goes over this list of active streams by processing one node every iteration,
// thereby closely resemebling to a round-robin scheduling over all streams. While
// processing a stream, loopy writes out data bytes from this stream capped by the min
// of http2MaxFrameLen, connection-level flow control and stream-level flow control.
type loopyWriter struct {
        side      side
        cbuf      *controlBuffer
        sendQuota uint32
        oiws      uint32 // outbound initial window size.
        // estdStreams is map of all established streams that are not cleaned-up yet.
        // On client-side, this is all streams whose headers were sent out.
        // On server-side, this is all streams whose headers were received.
        estdStreams map[uint32]*outStream // Established streams.
        // activeStreams is a linked-list of all streams that have data to send and some
        // stream-level flow control quota.
        // Each of these streams internally have a list of data items(and perhaps trailers
        // on the server-side) to be sent out.
        activeStreams *outStreamList
        framer        *framer
        hBuf          *bytes.Buffer  // The buffer for HPACK encoding.
        hEnc          *hpack.Encoder // HPACK encoder.
        bdpEst        *bdpEstimator
        draining      bool

        // Side-specific handlers
        ssGoAwayHandler func(*goAway) (bool, error)
}

func newLoopyWriter(s side, fr *framer, cbuf *controlBuffer, bdpEst *bdpEstimator) *loopyWriter <span class="cov8" title="1">{
        var buf bytes.Buffer
        l := &amp;loopyWriter{
                side:          s,
                cbuf:          cbuf,
                sendQuota:     defaultWindowSize,
                oiws:          defaultWindowSize,
                estdStreams:   make(map[uint32]*outStream),
                activeStreams: newOutStreamList(),
                framer:        fr,
                hBuf:          &amp;buf,
                hEnc:          hpack.NewEncoder(&amp;buf),
                bdpEst:        bdpEst,
        }
        return l
}</span>

const minBatchSize = 1000

// run should be run in a separate goroutine.
// It reads control frames from controlBuf and processes them by:
// 1. Updating loopy's internal state, or/and
// 2. Writing out HTTP2 frames on the wire.
//
// Loopy keeps all active streams with data to send in a linked-list.
// All streams in the activeStreams linked-list must have both:
// 1. Data to send, and
// 2. Stream level flow control quota available.
//
// In each iteration of run loop, other than processing the incoming control
// frame, loopy calls processData, which processes one node from the activeStreams linked-list.
// This results in writing of HTTP2 frames into an underlying write buffer.
// When there's no more control frames to read from controlBuf, loopy flushes the write buffer.
// As an optimization, to increase the batch size for each flush, loopy yields the processor, once
// if the batch size is too low to give stream goroutines a chance to fill it up.
func (l *loopyWriter) run() (err error) <span class="cov8" title="1">{
        defer func() </span><span class="cov8" title="1">{
                if err == ErrConnClosing </span><span class="cov8" title="1">{
                        // Don't log ErrConnClosing as error since it happens
                        // 1. When the connection is closed by some other known issue.
                        // 2. User closed the connection.
                        // 3. A graceful close of connection.
                        if logger.V(logLevel) </span><span class="cov0" title="0">{
                                logger.Infof("transport: loopyWriter.run returning. %v", err)
                        }</span>
                        <span class="cov8" title="1">err = nil</span>
                }
        }()
        <span class="cov8" title="1">for </span><span class="cov8" title="1">{
                it, err := l.cbuf.get(true)
                if err != nil </span><span class="cov8" title="1">{
                        return err
                }</span>
                <span class="cov8" title="1">if err = l.handle(it); err != nil </span><span class="cov8" title="1">{
                        return err
                }</span>
                <span class="cov8" title="1">if _, err = l.processData(); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov8" title="1">gosched := true
        hasdata:
                for </span><span class="cov8" title="1">{
                        it, err := l.cbuf.get(false)
                        if err != nil </span><span class="cov8" title="1">{
                                return err
                        }</span>
                        <span class="cov8" title="1">if it != nil </span><span class="cov8" title="1">{
                                if err = l.handle(it); err != nil </span><span class="cov8" title="1">{
                                        return err
                                }</span>
                                <span class="cov8" title="1">if _, err = l.processData(); err != nil </span><span class="cov0" title="0">{
                                        return err
                                }</span>
                                <span class="cov8" title="1">continue hasdata</span>
                        }
                        <span class="cov8" title="1">isEmpty, err := l.processData()
                        if err != nil </span><span class="cov0" title="0">{
                                return err
                        }</span>
                        <span class="cov8" title="1">if !isEmpty </span><span class="cov8" title="1">{
                                continue hasdata</span>
                        }
                        <span class="cov8" title="1">if gosched </span><span class="cov8" title="1">{
                                gosched = false
                                if l.framer.writer.offset &lt; minBatchSize </span><span class="cov8" title="1">{
                                        runtime.Gosched()
                                        continue hasdata</span>
                                }
                        }
                        <span class="cov8" title="1">l.framer.writer.Flush()
                        break hasdata</span>

                }
        }
}

func (l *loopyWriter) outgoingWindowUpdateHandler(w *outgoingWindowUpdate) error <span class="cov8" title="1">{
        return l.framer.fr.WriteWindowUpdate(w.streamID, w.increment)
}</span>

func (l *loopyWriter) incomingWindowUpdateHandler(w *incomingWindowUpdate) error <span class="cov8" title="1">{
        // Otherwise update the quota.
        if w.streamID == 0 </span><span class="cov8" title="1">{
                l.sendQuota += w.increment
                return nil
        }</span>
        // Find the stream and update it.
        <span class="cov8" title="1">if str, ok := l.estdStreams[w.streamID]; ok </span><span class="cov8" title="1">{
                str.bytesOutStanding -= int(w.increment)
                if strQuota := int(l.oiws) - str.bytesOutStanding; strQuota &gt; 0 &amp;&amp; str.state == waitingOnStreamQuota </span><span class="cov8" title="1">{
                        str.state = active
                        l.activeStreams.enqueue(str)
                        return nil
                }</span>
        }
        <span class="cov8" title="1">return nil</span>
}

func (l *loopyWriter) outgoingSettingsHandler(s *outgoingSettings) error <span class="cov8" title="1">{
        return l.framer.fr.WriteSettings(s.ss...)
}</span>

func (l *loopyWriter) incomingSettingsHandler(s *incomingSettings) error <span class="cov8" title="1">{
        if err := l.applySettings(s.ss); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov8" title="1">return l.framer.fr.WriteSettingsAck()</span>
}

func (l *loopyWriter) registerStreamHandler(h *registerStream) error <span class="cov8" title="1">{
        str := &amp;outStream{
                id:    h.streamID,
                state: empty,
                itl:   &amp;itemList{},
                wq:    h.wq,
        }
        l.estdStreams[h.streamID] = str
        return nil
}</span>

func (l *loopyWriter) headerHandler(h *headerFrame) error <span class="cov8" title="1">{
        if l.side == serverSide </span><span class="cov8" title="1">{
                str, ok := l.estdStreams[h.streamID]
                if !ok </span><span class="cov0" title="0">{
                        if logger.V(logLevel) </span><span class="cov0" title="0">{
                                logger.Warningf("transport: loopy doesn't recognize the stream: %d", h.streamID)
                        }</span>
                        <span class="cov0" title="0">return nil</span>
                }
                // Case 1.A: Server is responding back with headers.
                <span class="cov8" title="1">if !h.endStream </span><span class="cov8" title="1">{
                        return l.writeHeader(h.streamID, h.endStream, h.hf, h.onWrite)
                }</span>
                // else:  Case 1.B: Server wants to close stream.

                <span class="cov8" title="1">if str.state != empty </span><span class="cov8" title="1">{ // either active or waiting on stream quota.
                        // add it str's list of items.
                        str.itl.enqueue(h)
                        return nil
                }</span>
                <span class="cov8" title="1">if err := l.writeHeader(h.streamID, h.endStream, h.hf, h.onWrite); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov8" title="1">return l.cleanupStreamHandler(h.cleanup)</span>
        }
        // Case 2: Client wants to originate stream.
        <span class="cov8" title="1">str := &amp;outStream{
                id:    h.streamID,
                state: empty,
                itl:   &amp;itemList{},
                wq:    h.wq,
        }
        str.itl.enqueue(h)
        return l.originateStream(str)</span>
}

func (l *loopyWriter) originateStream(str *outStream) error <span class="cov8" title="1">{
        hdr := str.itl.dequeue().(*headerFrame)
        if err := hdr.initStream(str.id); err != nil </span><span class="cov8" title="1">{
                if err == ErrConnClosing </span><span class="cov0" title="0">{
                        return err
                }</span>
                // Other errors(errStreamDrain) need not close transport.
                <span class="cov8" title="1">return nil</span>
        }
        <span class="cov8" title="1">if err := l.writeHeader(str.id, hdr.endStream, hdr.hf, hdr.onWrite); err != nil </span><span class="cov8" title="1">{
                return err
        }</span>
        <span class="cov8" title="1">l.estdStreams[str.id] = str
        return nil</span>
}

func (l *loopyWriter) writeHeader(streamID uint32, endStream bool, hf []hpack.HeaderField, onWrite func()) error <span class="cov8" title="1">{
        if onWrite != nil </span><span class="cov8" title="1">{
                onWrite()
        }</span>
        <span class="cov8" title="1">l.hBuf.Reset()
        for _, f := range hf </span><span class="cov8" title="1">{
                if err := l.hEnc.WriteField(f); err != nil </span><span class="cov0" title="0">{
                        if logger.V(logLevel) </span><span class="cov0" title="0">{
                                logger.Warningf("transport: loopyWriter.writeHeader encountered error while encoding headers: %v", err)
                        }</span>
                }
        }
        <span class="cov8" title="1">var (
                err               error
                endHeaders, first bool
        )
        first = true
        for !endHeaders </span><span class="cov8" title="1">{
                size := l.hBuf.Len()
                if size &gt; http2MaxFrameLen </span><span class="cov0" title="0">{
                        size = http2MaxFrameLen
                }</span> else<span class="cov8" title="1"> {
                        endHeaders = true
                }</span>
                <span class="cov8" title="1">if first </span><span class="cov8" title="1">{
                        first = false
                        err = l.framer.fr.WriteHeaders(http2.HeadersFrameParam{
                                StreamID:      streamID,
                                BlockFragment: l.hBuf.Next(size),
                                EndStream:     endStream,
                                EndHeaders:    endHeaders,
                        })
                }</span> else<span class="cov0" title="0"> {
                        err = l.framer.fr.WriteContinuation(
                                streamID,
                                endHeaders,
                                l.hBuf.Next(size),
                        )
                }</span>
                <span class="cov8" title="1">if err != nil </span><span class="cov8" title="1">{
                        return err
                }</span>
        }
        <span class="cov8" title="1">return nil</span>
}

func (l *loopyWriter) preprocessData(df *dataFrame) error <span class="cov8" title="1">{
        str, ok := l.estdStreams[df.streamID]
        if !ok </span><span class="cov8" title="1">{
                return nil
        }</span>
        // If we got data for a stream it means that
        // stream was originated and the headers were sent out.
        <span class="cov8" title="1">str.itl.enqueue(df)
        if str.state == empty </span><span class="cov8" title="1">{
                str.state = active
                l.activeStreams.enqueue(str)
        }</span>
        <span class="cov8" title="1">return nil</span>
}

func (l *loopyWriter) pingHandler(p *ping) error <span class="cov8" title="1">{
        if !p.ack </span><span class="cov8" title="1">{
                l.bdpEst.timesnap(p.data)
        }</span>
        <span class="cov8" title="1">return l.framer.fr.WritePing(p.ack, p.data)</span>

}

func (l *loopyWriter) outFlowControlSizeRequestHandler(o *outFlowControlSizeRequest) error <span class="cov0" title="0">{
        o.resp &lt;- l.sendQuota
        return nil
}</span>

func (l *loopyWriter) cleanupStreamHandler(c *cleanupStream) error <span class="cov8" title="1">{
        c.onWrite()
        if str, ok := l.estdStreams[c.streamID]; ok </span><span class="cov8" title="1">{
                // On the server side it could be a trailers-only response or
                // a RST_STREAM before stream initialization thus the stream might
                // not be established yet.
                delete(l.estdStreams, c.streamID)
                str.deleteSelf()
        }</span>
        <span class="cov8" title="1">if c.rst </span><span class="cov8" title="1">{ // If RST_STREAM needs to be sent.
                if err := l.framer.fr.WriteRSTStream(c.streamID, c.rstCode); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
        }
        <span class="cov8" title="1">if l.side == clientSide &amp;&amp; l.draining &amp;&amp; len(l.estdStreams) == 0 </span><span class="cov8" title="1">{
                return ErrConnClosing
        }</span>
        <span class="cov8" title="1">return nil</span>
}

func (l *loopyWriter) earlyAbortStreamHandler(eas *earlyAbortStream) error <span class="cov8" title="1">{
        if l.side == clientSide </span><span class="cov0" title="0">{
                return errors.New("earlyAbortStream not handled on client")
        }</span>
        // In case the caller forgets to set the http status, default to 200.
        <span class="cov8" title="1">if eas.httpStatus == 0 </span><span class="cov0" title="0">{
                eas.httpStatus = 200
        }</span>
        <span class="cov8" title="1">headerFields := []hpack.HeaderField{
                {Name: ":status", Value: strconv.Itoa(int(eas.httpStatus))},
                {Name: "content-type", Value: grpcutil.ContentType(eas.contentSubtype)},
                {Name: "grpc-status", Value: strconv.Itoa(int(eas.status.Code()))},
                {Name: "grpc-message", Value: encodeGrpcMessage(eas.status.Message())},
        }

        if err := l.writeHeader(eas.streamID, true, headerFields, nil); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov8" title="1">if eas.rst </span><span class="cov8" title="1">{
                if err := l.framer.fr.WriteRSTStream(eas.streamID, http2.ErrCodeNo); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
        }
        <span class="cov8" title="1">return nil</span>
}

func (l *loopyWriter) incomingGoAwayHandler(*incomingGoAway) error <span class="cov8" title="1">{
        if l.side == clientSide </span><span class="cov8" title="1">{
                l.draining = true
                if len(l.estdStreams) == 0 </span><span class="cov0" title="0">{
                        return ErrConnClosing
                }</span>
        }
        <span class="cov8" title="1">return nil</span>
}

func (l *loopyWriter) goAwayHandler(g *goAway) error <span class="cov8" title="1">{
        // Handling of outgoing GoAway is very specific to side.
        if l.ssGoAwayHandler != nil </span><span class="cov8" title="1">{
                draining, err := l.ssGoAwayHandler(g)
                if err != nil </span><span class="cov8" title="1">{
                        return err
                }</span>
                <span class="cov8" title="1">l.draining = draining</span>
        }
        <span class="cov8" title="1">return nil</span>
}

func (l *loopyWriter) handle(i interface{}) error <span class="cov8" title="1">{
        switch i := i.(type) </span>{
        case *incomingWindowUpdate:<span class="cov8" title="1">
                return l.incomingWindowUpdateHandler(i)</span>
        case *outgoingWindowUpdate:<span class="cov8" title="1">
                return l.outgoingWindowUpdateHandler(i)</span>
        case *incomingSettings:<span class="cov8" title="1">
                return l.incomingSettingsHandler(i)</span>
        case *outgoingSettings:<span class="cov8" title="1">
                return l.outgoingSettingsHandler(i)</span>
        case *headerFrame:<span class="cov8" title="1">
                return l.headerHandler(i)</span>
        case *registerStream:<span class="cov8" title="1">
                return l.registerStreamHandler(i)</span>
        case *cleanupStream:<span class="cov8" title="1">
                return l.cleanupStreamHandler(i)</span>
        case *earlyAbortStream:<span class="cov8" title="1">
                return l.earlyAbortStreamHandler(i)</span>
        case *incomingGoAway:<span class="cov8" title="1">
                return l.incomingGoAwayHandler(i)</span>
        case *dataFrame:<span class="cov8" title="1">
                return l.preprocessData(i)</span>
        case *ping:<span class="cov8" title="1">
                return l.pingHandler(i)</span>
        case *goAway:<span class="cov8" title="1">
                return l.goAwayHandler(i)</span>
        case *outFlowControlSizeRequest:<span class="cov0" title="0">
                return l.outFlowControlSizeRequestHandler(i)</span>
        default:<span class="cov0" title="0">
                return fmt.Errorf("transport: unknown control message type %T", i)</span>
        }
}

func (l *loopyWriter) applySettings(ss []http2.Setting) error <span class="cov8" title="1">{
        for _, s := range ss </span><span class="cov8" title="1">{
                switch s.ID </span>{
                case http2.SettingInitialWindowSize:<span class="cov8" title="1">
                        o := l.oiws
                        l.oiws = s.Val
                        if o &lt; l.oiws </span><span class="cov8" title="1">{
                                // If the new limit is greater make all depleted streams active.
                                for _, stream := range l.estdStreams </span><span class="cov8" title="1">{
                                        if stream.state == waitingOnStreamQuota </span><span class="cov8" title="1">{
                                                stream.state = active
                                                l.activeStreams.enqueue(stream)
                                        }</span>
                                }
                        }
                case http2.SettingHeaderTableSize:<span class="cov8" title="1">
                        updateHeaderTblSize(l.hEnc, s.Val)</span>
                }
        }
        <span class="cov8" title="1">return nil</span>
}

// processData removes the first stream from active streams, writes out at most 16KB
// of its data and then puts it at the end of activeStreams if there's still more data
// to be sent and stream has some stream-level flow control.
func (l *loopyWriter) processData() (bool, error) <span class="cov8" title="1">{
        if l.sendQuota == 0 </span><span class="cov8" title="1">{
                return true, nil
        }</span>
        <span class="cov8" title="1">str := l.activeStreams.dequeue() // Remove the first stream.
        if str == nil </span><span class="cov8" title="1">{
                return true, nil
        }</span>
        <span class="cov8" title="1">dataItem := str.itl.peek().(*dataFrame) // Peek at the first data item this stream.
        // A data item is represented by a dataFrame, since it later translates into
        // multiple HTTP2 data frames.
        // Every dataFrame has two buffers; h that keeps grpc-message header and d that is acutal data.
        // As an optimization to keep wire traffic low, data from d is copied to h to make as big as the
        // maximum possilbe HTTP2 frame size.

        if len(dataItem.h) == 0 &amp;&amp; len(dataItem.d) == 0 </span><span class="cov8" title="1">{ // Empty data frame
                // Client sends out empty data frame with endStream = true
                if err := l.framer.fr.WriteData(dataItem.streamID, dataItem.endStream, nil); err != nil </span><span class="cov0" title="0">{
                        return false, err
                }</span>
                <span class="cov8" title="1">str.itl.dequeue() // remove the empty data item from stream
                if str.itl.isEmpty() </span><span class="cov8" title="1">{
                        str.state = empty
                }</span> else<span class="cov0" title="0"> if trailer, ok := str.itl.peek().(*headerFrame); ok </span><span class="cov0" title="0">{ // the next item is trailers.
                        if err := l.writeHeader(trailer.streamID, trailer.endStream, trailer.hf, trailer.onWrite); err != nil </span><span class="cov0" title="0">{
                                return false, err
                        }</span>
                        <span class="cov0" title="0">if err := l.cleanupStreamHandler(trailer.cleanup); err != nil </span><span class="cov0" title="0">{
                                return false, nil
                        }</span>
                } else<span class="cov0" title="0"> {
                        l.activeStreams.enqueue(str)
                }</span>
                <span class="cov8" title="1">return false, nil</span>
        }
        <span class="cov8" title="1">var (
                buf []byte
        )
        // Figure out the maximum size we can send
        maxSize := http2MaxFrameLen
        if strQuota := int(l.oiws) - str.bytesOutStanding; strQuota &lt;= 0 </span><span class="cov0" title="0">{ // stream-level flow control.
                str.state = waitingOnStreamQuota
                return false, nil
        }</span> else<span class="cov8" title="1"> if maxSize &gt; strQuota </span><span class="cov8" title="1">{
                maxSize = strQuota
        }</span>
        <span class="cov8" title="1">if maxSize &gt; int(l.sendQuota) </span><span class="cov8" title="1">{ // connection-level flow control.
                maxSize = int(l.sendQuota)
        }</span>
        // Compute how much of the header and data we can send within quota and max frame length
        <span class="cov8" title="1">hSize := min(maxSize, len(dataItem.h))
        dSize := min(maxSize-hSize, len(dataItem.d))
        if hSize != 0 </span><span class="cov8" title="1">{
                if dSize == 0 </span><span class="cov0" title="0">{
                        buf = dataItem.h
                }</span> else<span class="cov8" title="1"> {
                        // We can add some data to grpc message header to distribute bytes more equally across frames.
                        // Copy on the stack to avoid generating garbage
                        var localBuf [http2MaxFrameLen]byte
                        copy(localBuf[:hSize], dataItem.h)
                        copy(localBuf[hSize:], dataItem.d[:dSize])
                        buf = localBuf[:hSize+dSize]
                }</span>
        } else<span class="cov8" title="1"> {
                buf = dataItem.d
        }</span>

        <span class="cov8" title="1">size := hSize + dSize

        // Now that outgoing flow controls are checked we can replenish str's write quota
        str.wq.replenish(size)
        var endStream bool
        // If this is the last data message on this stream and all of it can be written in this iteration.
        if dataItem.endStream &amp;&amp; len(dataItem.h)+len(dataItem.d) &lt;= size </span><span class="cov8" title="1">{
                endStream = true
        }</span>
        <span class="cov8" title="1">if dataItem.onEachWrite != nil </span><span class="cov8" title="1">{
                dataItem.onEachWrite()
        }</span>
        <span class="cov8" title="1">if err := l.framer.fr.WriteData(dataItem.streamID, endStream, buf[:size]); err != nil </span><span class="cov0" title="0">{
                return false, err
        }</span>
        <span class="cov8" title="1">str.bytesOutStanding += size
        l.sendQuota -= uint32(size)
        dataItem.h = dataItem.h[hSize:]
        dataItem.d = dataItem.d[dSize:]

        if len(dataItem.h) == 0 &amp;&amp; len(dataItem.d) == 0 </span><span class="cov8" title="1">{ // All the data from that message was written out.
                str.itl.dequeue()
        }</span>
        <span class="cov8" title="1">if str.itl.isEmpty() </span><span class="cov8" title="1">{
                str.state = empty
        }</span> else<span class="cov8" title="1"> if trailer, ok := str.itl.peek().(*headerFrame); ok </span><span class="cov8" title="1">{ // The next item is trailers.
                if err := l.writeHeader(trailer.streamID, trailer.endStream, trailer.hf, trailer.onWrite); err != nil </span><span class="cov0" title="0">{
                        return false, err
                }</span>
                <span class="cov8" title="1">if err := l.cleanupStreamHandler(trailer.cleanup); err != nil </span><span class="cov0" title="0">{
                        return false, err
                }</span>
        } else<span class="cov8" title="1"> if int(l.oiws)-str.bytesOutStanding &lt;= 0 </span><span class="cov8" title="1">{ // Ran out of stream quota.
                str.state = waitingOnStreamQuota
        }</span> else<span class="cov8" title="1"> { // Otherwise add it back to the list of active streams.
                l.activeStreams.enqueue(str)
        }</span>
        <span class="cov8" title="1">return false, nil</span>
}

func min(a, b int) int <span class="cov8" title="1">{
        if a &lt; b </span><span class="cov8" title="1">{
                return a
        }</span>
        <span class="cov8" title="1">return b</span>
}
</pre>
		
		<pre class="file" id="file111" style="display: none">/*
 *
 * Copyright 2014 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package transport

import (
        "fmt"
        "math"
        "sync"
        "sync/atomic"
)

// writeQuota is a soft limit on the amount of data a stream can
// schedule before some of it is written out.
type writeQuota struct {
        quota int32
        // get waits on read from when quota goes less than or equal to zero.
        // replenish writes on it when quota goes positive again.
        ch chan struct{}
        // done is triggered in error case.
        done &lt;-chan struct{}
        // replenish is called by loopyWriter to give quota back to.
        // It is implemented as a field so that it can be updated
        // by tests.
        replenish func(n int)
}

func newWriteQuota(sz int32, done &lt;-chan struct{}) *writeQuota <span class="cov8" title="1">{
        w := &amp;writeQuota{
                quota: sz,
                ch:    make(chan struct{}, 1),
                done:  done,
        }
        w.replenish = w.realReplenish
        return w
}</span>

func (w *writeQuota) get(sz int32) error <span class="cov8" title="1">{
        for </span><span class="cov8" title="1">{
                if atomic.LoadInt32(&amp;w.quota) &gt; 0 </span><span class="cov8" title="1">{
                        atomic.AddInt32(&amp;w.quota, -sz)
                        return nil
                }</span>
                <span class="cov8" title="1">select </span>{
                case &lt;-w.ch:<span class="cov0" title="0">
                        continue</span>
                case &lt;-w.done:<span class="cov8" title="1">
                        return errStreamDone</span>
                }
        }
}

func (w *writeQuota) realReplenish(n int) <span class="cov8" title="1">{
        sz := int32(n)
        a := atomic.AddInt32(&amp;w.quota, sz)
        b := a - sz
        if b &lt;= 0 &amp;&amp; a &gt; 0 </span><span class="cov8" title="1">{
                select </span>{
                case w.ch &lt;- struct{}{}:<span class="cov8" title="1"></span>
                default:<span class="cov8" title="1"></span>
                }
        }
}

type trInFlow struct {
        limit               uint32
        unacked             uint32
        effectiveWindowSize uint32
}

func (f *trInFlow) newLimit(n uint32) uint32 <span class="cov8" title="1">{
        d := n - f.limit
        f.limit = n
        f.updateEffectiveWindowSize()
        return d
}</span>

func (f *trInFlow) onData(n uint32) uint32 <span class="cov8" title="1">{
        f.unacked += n
        if f.unacked &gt;= f.limit/4 </span><span class="cov8" title="1">{
                w := f.unacked
                f.unacked = 0
                f.updateEffectiveWindowSize()
                return w
        }</span>
        <span class="cov8" title="1">f.updateEffectiveWindowSize()
        return 0</span>
}

func (f *trInFlow) reset() uint32 <span class="cov8" title="1">{
        w := f.unacked
        f.unacked = 0
        f.updateEffectiveWindowSize()
        return w
}</span>

func (f *trInFlow) updateEffectiveWindowSize() <span class="cov8" title="1">{
        atomic.StoreUint32(&amp;f.effectiveWindowSize, f.limit-f.unacked)
}</span>

func (f *trInFlow) getSize() uint32 <span class="cov0" title="0">{
        return atomic.LoadUint32(&amp;f.effectiveWindowSize)
}</span>

// TODO(mmukhi): Simplify this code.
// inFlow deals with inbound flow control
type inFlow struct {
        mu sync.Mutex
        // The inbound flow control limit for pending data.
        limit uint32
        // pendingData is the overall data which have been received but not been
        // consumed by applications.
        pendingData uint32
        // The amount of data the application has consumed but grpc has not sent
        // window update for them. Used to reduce window update frequency.
        pendingUpdate uint32
        // delta is the extra window update given by receiver when an application
        // is reading data bigger in size than the inFlow limit.
        delta uint32
}

// newLimit updates the inflow window to a new value n.
// It assumes that n is always greater than the old limit.
func (f *inFlow) newLimit(n uint32) <span class="cov8" title="1">{
        f.mu.Lock()
        f.limit = n
        f.mu.Unlock()
}</span>

func (f *inFlow) maybeAdjust(n uint32) uint32 <span class="cov8" title="1">{
        if n &gt; uint32(math.MaxInt32) </span><span class="cov0" title="0">{
                n = uint32(math.MaxInt32)
        }</span>
        <span class="cov8" title="1">f.mu.Lock()
        defer f.mu.Unlock()
        // estSenderQuota is the receiver's view of the maximum number of bytes the sender
        // can send without a window update.
        estSenderQuota := int32(f.limit - (f.pendingData + f.pendingUpdate))
        // estUntransmittedData is the maximum number of bytes the sends might not have put
        // on the wire yet. A value of 0 or less means that we have already received all or
        // more bytes than the application is requesting to read.
        estUntransmittedData := int32(n - f.pendingData) // Casting into int32 since it could be negative.
        // This implies that unless we send a window update, the sender won't be able to send all the bytes
        // for this message. Therefore we must send an update over the limit since there's an active read
        // request from the application.
        if estUntransmittedData &gt; estSenderQuota </span><span class="cov8" title="1">{
                // Sender's window shouldn't go more than 2^31 - 1 as specified in the HTTP spec.
                if f.limit+n &gt; maxWindowSize </span><span class="cov0" title="0">{
                        f.delta = maxWindowSize - f.limit
                }</span> else<span class="cov8" title="1"> {
                        // Send a window update for the whole message and not just the difference between
                        // estUntransmittedData and estSenderQuota. This will be helpful in case the message
                        // is padded; We will fallback on the current available window(at least a 1/4th of the limit).
                        f.delta = n
                }</span>
                <span class="cov8" title="1">return f.delta</span>
        }
        <span class="cov8" title="1">return 0</span>
}

// onData is invoked when some data frame is received. It updates pendingData.
func (f *inFlow) onData(n uint32) error <span class="cov8" title="1">{
        f.mu.Lock()
        f.pendingData += n
        if f.pendingData+f.pendingUpdate &gt; f.limit+f.delta </span><span class="cov8" title="1">{
                limit := f.limit
                rcvd := f.pendingData + f.pendingUpdate
                f.mu.Unlock()
                return fmt.Errorf("received %d-bytes data exceeding the limit %d bytes", rcvd, limit)
        }</span>
        <span class="cov8" title="1">f.mu.Unlock()
        return nil</span>
}

// onRead is invoked when the application reads the data. It returns the window size
// to be sent to the peer.
func (f *inFlow) onRead(n uint32) uint32 <span class="cov8" title="1">{
        f.mu.Lock()
        if f.pendingData == 0 </span><span class="cov0" title="0">{
                f.mu.Unlock()
                return 0
        }</span>
        <span class="cov8" title="1">f.pendingData -= n
        if n &gt; f.delta </span><span class="cov8" title="1">{
                n -= f.delta
                f.delta = 0
        }</span> else<span class="cov8" title="1"> {
                f.delta -= n
                n = 0
        }</span>
        <span class="cov8" title="1">f.pendingUpdate += n
        if f.pendingUpdate &gt;= f.limit/4 </span><span class="cov8" title="1">{
                wu := f.pendingUpdate
                f.pendingUpdate = 0
                f.mu.Unlock()
                return wu
        }</span>
        <span class="cov8" title="1">f.mu.Unlock()
        return 0</span>
}
</pre>
		
		<pre class="file" id="file112" style="display: none">/*
 *
 * Copyright 2016 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// This file is the implementation of a gRPC server using HTTP/2 which
// uses the standard Go http2 Server implementation (via the
// http.Handler interface), rather than speaking low-level HTTP/2
// frames itself. It is the implementation of *grpc.Server.ServeHTTP.

package transport

import (
        "bytes"
        "context"
        "errors"
        "fmt"
        "io"
        "net"
        "net/http"
        "strings"
        "sync"
        "time"

        "github.com/golang/protobuf/proto"
        "golang.org/x/net/http2"
        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/credentials"
        "google.golang.org/grpc/internal/grpcutil"
        "google.golang.org/grpc/metadata"
        "google.golang.org/grpc/peer"
        "google.golang.org/grpc/stats"
        "google.golang.org/grpc/status"
)

// NewServerHandlerTransport returns a ServerTransport handling gRPC
// from inside an http.Handler. It requires that the http Server
// supports HTTP/2.
func NewServerHandlerTransport(w http.ResponseWriter, r *http.Request, stats []stats.Handler) (ServerTransport, error) <span class="cov8" title="1">{
        if r.ProtoMajor != 2 </span><span class="cov8" title="1">{
                return nil, errors.New("gRPC requires HTTP/2")
        }</span>
        <span class="cov8" title="1">if r.Method != "POST" </span><span class="cov8" title="1">{
                return nil, errors.New("invalid gRPC request method")
        }</span>
        <span class="cov8" title="1">contentType := r.Header.Get("Content-Type")
        // TODO: do we assume contentType is lowercase? we did before
        contentSubtype, validContentType := grpcutil.ContentSubtype(contentType)
        if !validContentType </span><span class="cov8" title="1">{
                return nil, errors.New("invalid gRPC request content-type")
        }</span>
        <span class="cov8" title="1">if _, ok := w.(http.Flusher); !ok </span><span class="cov8" title="1">{
                return nil, errors.New("gRPC requires a ResponseWriter supporting http.Flusher")
        }</span>

        <span class="cov8" title="1">st := &amp;serverHandlerTransport{
                rw:             w,
                req:            r,
                closedCh:       make(chan struct{}),
                writes:         make(chan func()),
                contentType:    contentType,
                contentSubtype: contentSubtype,
                stats:          stats,
        }

        if v := r.Header.Get("grpc-timeout"); v != "" </span><span class="cov8" title="1">{
                to, err := decodeTimeout(v)
                if err != nil </span><span class="cov8" title="1">{
                        return nil, status.Errorf(codes.Internal, "malformed time-out: %v", err)
                }</span>
                <span class="cov8" title="1">st.timeoutSet = true
                st.timeout = to</span>
        }

        <span class="cov8" title="1">metakv := []string{"content-type", contentType}
        if r.Host != "" </span><span class="cov0" title="0">{
                metakv = append(metakv, ":authority", r.Host)
        }</span>
        <span class="cov8" title="1">for k, vv := range r.Header </span><span class="cov8" title="1">{
                k = strings.ToLower(k)
                if isReservedHeader(k) &amp;&amp; !isWhitelistedHeader(k) </span><span class="cov8" title="1">{
                        continue</span>
                }
                <span class="cov8" title="1">for _, v := range vv </span><span class="cov8" title="1">{
                        v, err := decodeMetadataHeader(k, v)
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, status.Errorf(codes.Internal, "malformed binary metadata: %v", err)
                        }</span>
                        <span class="cov8" title="1">metakv = append(metakv, k, v)</span>
                }
        }
        <span class="cov8" title="1">st.headerMD = metadata.Pairs(metakv...)

        return st, nil</span>
}

// serverHandlerTransport is an implementation of ServerTransport
// which replies to exactly one gRPC request (exactly one HTTP request),
// using the net/http.Handler interface. This http.Handler is guaranteed
// at this point to be speaking over HTTP/2, so it's able to speak valid
// gRPC.
type serverHandlerTransport struct {
        rw         http.ResponseWriter
        req        *http.Request
        timeoutSet bool
        timeout    time.Duration

        headerMD metadata.MD

        closeOnce sync.Once
        closedCh  chan struct{} // closed on Close

        // writes is a channel of code to run serialized in the
        // ServeHTTP (HandleStreams) goroutine. The channel is closed
        // when WriteStatus is called.
        writes chan func()

        // block concurrent WriteStatus calls
        // e.g. grpc/(*serverStream).SendMsg/RecvMsg
        writeStatusMu sync.Mutex

        // we just mirror the request content-type
        contentType string
        // we store both contentType and contentSubtype so we don't keep recreating them
        // TODO make sure this is consistent across handler_server and http2_server
        contentSubtype string

        stats []stats.Handler
}

func (ht *serverHandlerTransport) Close() <span class="cov8" title="1">{
        ht.closeOnce.Do(ht.closeCloseChanOnce)
}</span>

func (ht *serverHandlerTransport) closeCloseChanOnce() <span class="cov8" title="1">{ close(ht.closedCh) }</span>

func (ht *serverHandlerTransport) RemoteAddr() net.Addr <span class="cov8" title="1">{ return strAddr(ht.req.RemoteAddr) }</span>

// strAddr is a net.Addr backed by either a TCP "ip:port" string, or
// the empty string if unknown.
type strAddr string

func (a strAddr) Network() string <span class="cov0" title="0">{
        if a != "" </span><span class="cov0" title="0">{
                // Per the documentation on net/http.Request.RemoteAddr, if this is
                // set, it's set to the IP:port of the peer (hence, TCP):
                // https://golang.org/pkg/net/http/#Request
                //
                // If we want to support Unix sockets later, we can
                // add our own grpc-specific convention within the
                // grpc codebase to set RemoteAddr to a different
                // format, or probably better: we can attach it to the
                // context and use that from serverHandlerTransport.RemoteAddr.
                return "tcp"
        }</span>
        <span class="cov0" title="0">return ""</span>
}

func (a strAddr) String() string <span class="cov0" title="0">{ return string(a) }</span>

// do runs fn in the ServeHTTP goroutine.
func (ht *serverHandlerTransport) do(fn func()) error <span class="cov8" title="1">{
        select </span>{
        case &lt;-ht.closedCh:<span class="cov8" title="1">
                return ErrConnClosing</span>
        case ht.writes &lt;- fn:<span class="cov8" title="1">
                return nil</span>
        }
}

func (ht *serverHandlerTransport) WriteStatus(s *Stream, st *status.Status) error <span class="cov8" title="1">{
        ht.writeStatusMu.Lock()
        defer ht.writeStatusMu.Unlock()

        headersWritten := s.updateHeaderSent()
        err := ht.do(func() </span><span class="cov8" title="1">{
                if !headersWritten </span><span class="cov8" title="1">{
                        ht.writePendingHeaders(s)
                }</span>

                // And flush, in case no header or body has been sent yet.
                // This forces a separation of headers and trailers if this is the
                // first call (for example, in end2end tests's TestNoService).
                <span class="cov8" title="1">ht.rw.(http.Flusher).Flush()

                h := ht.rw.Header()
                h.Set("Grpc-Status", fmt.Sprintf("%d", st.Code()))
                if m := st.Message(); m != "" </span><span class="cov8" title="1">{
                        h.Set("Grpc-Message", encodeGrpcMessage(m))
                }</span>

                <span class="cov8" title="1">if p := st.Proto(); p != nil &amp;&amp; len(p.Details) &gt; 0 </span><span class="cov8" title="1">{
                        stBytes, err := proto.Marshal(p)
                        if err != nil </span><span class="cov0" title="0">{
                                // TODO: return error instead, when callers are able to handle it.
                                panic(err)</span>
                        }

                        <span class="cov8" title="1">h.Set("Grpc-Status-Details-Bin", encodeBinHeader(stBytes))</span>
                }

                <span class="cov8" title="1">if md := s.Trailer(); len(md) &gt; 0 </span><span class="cov8" title="1">{
                        for k, vv := range md </span><span class="cov8" title="1">{
                                // Clients don't tolerate reading restricted headers after some non restricted ones were sent.
                                if isReservedHeader(k) </span><span class="cov0" title="0">{
                                        continue</span>
                                }
                                <span class="cov8" title="1">for _, v := range vv </span><span class="cov8" title="1">{
                                        // http2 ResponseWriter mechanism to send undeclared Trailers after
                                        // the headers have possibly been written.
                                        h.Add(http2.TrailerPrefix+k, encodeMetadataHeader(k, v))
                                }</span>
                        }
                }
        })

        <span class="cov8" title="1">if err == nil </span><span class="cov8" title="1">{ // transport has not been closed
                // Note: The trailer fields are compressed with hpack after this call returns.
                // No WireLength field is set here.
                for _, sh := range ht.stats </span><span class="cov0" title="0">{
                        sh.HandleRPC(s.Context(), &amp;stats.OutTrailer{
                                Trailer: s.trailer.Copy(),
                        })
                }</span>
        }
        <span class="cov8" title="1">ht.Close()
        return err</span>
}

// writePendingHeaders sets common and custom headers on the first
// write call (Write, WriteHeader, or WriteStatus)
func (ht *serverHandlerTransport) writePendingHeaders(s *Stream) <span class="cov8" title="1">{
        ht.writeCommonHeaders(s)
        ht.writeCustomHeaders(s)
}</span>

// writeCommonHeaders sets common headers on the first write
// call (Write, WriteHeader, or WriteStatus).
func (ht *serverHandlerTransport) writeCommonHeaders(s *Stream) <span class="cov8" title="1">{
        h := ht.rw.Header()
        h["Date"] = nil // suppress Date to make tests happy; TODO: restore
        h.Set("Content-Type", ht.contentType)

        // Predeclare trailers we'll set later in WriteStatus (after the body).
        // This is a SHOULD in the HTTP RFC, and the way you add (known)
        // Trailers per the net/http.ResponseWriter contract.
        // See https://golang.org/pkg/net/http/#ResponseWriter
        // and https://golang.org/pkg/net/http/#example_ResponseWriter_trailers
        h.Add("Trailer", "Grpc-Status")
        h.Add("Trailer", "Grpc-Message")
        h.Add("Trailer", "Grpc-Status-Details-Bin")

        if s.sendCompress != "" </span><span class="cov0" title="0">{
                h.Set("Grpc-Encoding", s.sendCompress)
        }</span>
}

// writeCustomHeaders sets custom headers set on the stream via SetHeader
// on the first write call (Write, WriteHeader, or WriteStatus).
func (ht *serverHandlerTransport) writeCustomHeaders(s *Stream) <span class="cov8" title="1">{
        h := ht.rw.Header()

        s.hdrMu.Lock()
        for k, vv := range s.header </span><span class="cov8" title="1">{
                if isReservedHeader(k) </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov8" title="1">for _, v := range vv </span><span class="cov8" title="1">{
                        h.Add(k, encodeMetadataHeader(k, v))
                }</span>
        }

        <span class="cov8" title="1">s.hdrMu.Unlock()</span>
}

func (ht *serverHandlerTransport) Write(s *Stream, hdr []byte, data []byte, opts *Options) error <span class="cov8" title="1">{
        headersWritten := s.updateHeaderSent()
        return ht.do(func() </span><span class="cov0" title="0">{
                if !headersWritten </span><span class="cov0" title="0">{
                        ht.writePendingHeaders(s)
                }</span>
                <span class="cov0" title="0">ht.rw.Write(hdr)
                ht.rw.Write(data)
                ht.rw.(http.Flusher).Flush()</span>
        })
}

func (ht *serverHandlerTransport) WriteHeader(s *Stream, md metadata.MD) error <span class="cov8" title="1">{
        if err := s.SetHeader(md); err != nil </span><span class="cov8" title="1">{
                return err
        }</span>

        <span class="cov8" title="1">headersWritten := s.updateHeaderSent()
        err := ht.do(func() </span><span class="cov8" title="1">{
                if !headersWritten </span><span class="cov8" title="1">{
                        ht.writePendingHeaders(s)
                }</span>

                <span class="cov8" title="1">ht.rw.WriteHeader(200)
                ht.rw.(http.Flusher).Flush()</span>
        })

        <span class="cov8" title="1">if err == nil </span><span class="cov8" title="1">{
                for _, sh := range ht.stats </span><span class="cov0" title="0">{
                        // Note: The header fields are compressed with hpack after this call returns.
                        // No WireLength field is set here.
                        sh.HandleRPC(s.Context(), &amp;stats.OutHeader{
                                Header:      md.Copy(),
                                Compression: s.sendCompress,
                        })
                }</span>
        }
        <span class="cov8" title="1">return err</span>
}

func (ht *serverHandlerTransport) HandleStreams(startStream func(*Stream), traceCtx func(context.Context, string) context.Context) <span class="cov8" title="1">{
        // With this transport type there will be exactly 1 stream: this HTTP request.

        ctx := ht.req.Context()
        var cancel context.CancelFunc
        if ht.timeoutSet </span><span class="cov8" title="1">{
                ctx, cancel = context.WithTimeout(ctx, ht.timeout)
        }</span> else<span class="cov8" title="1"> {
                ctx, cancel = context.WithCancel(ctx)
        }</span>

        // requestOver is closed when the status has been written via WriteStatus.
        <span class="cov8" title="1">requestOver := make(chan struct{})
        go func() </span><span class="cov8" title="1">{
                select </span>{
                case &lt;-requestOver:<span class="cov8" title="1"></span>
                case &lt;-ht.closedCh:<span class="cov8" title="1"></span>
                case &lt;-ht.req.Context().Done():<span class="cov0" title="0"></span>
                }
                <span class="cov8" title="1">cancel()
                ht.Close()</span>
        }()

        <span class="cov8" title="1">req := ht.req

        s := &amp;Stream{
                id:             0, // irrelevant
                requestRead:    func(int) </span>{<span class="cov0" title="0">}</span>,
                cancel:         cancel,
                buf:            newRecvBuffer(),
                st:             ht,
                method:         req.URL.Path,
                recvCompress:   req.Header.Get("grpc-encoding"),
                contentSubtype: ht.contentSubtype,
        }
        <span class="cov8" title="1">pr := &amp;peer.Peer{
                Addr: ht.RemoteAddr(),
        }
        if req.TLS != nil </span><span class="cov0" title="0">{
                pr.AuthInfo = credentials.TLSInfo{State: *req.TLS, CommonAuthInfo: credentials.CommonAuthInfo{SecurityLevel: credentials.PrivacyAndIntegrity}}
        }</span>
        <span class="cov8" title="1">ctx = metadata.NewIncomingContext(ctx, ht.headerMD)
        s.ctx = peer.NewContext(ctx, pr)
        for _, sh := range ht.stats </span><span class="cov0" title="0">{
                s.ctx = sh.TagRPC(s.ctx, &amp;stats.RPCTagInfo{FullMethodName: s.method})
                inHeader := &amp;stats.InHeader{
                        FullMethod:  s.method,
                        RemoteAddr:  ht.RemoteAddr(),
                        Compression: s.recvCompress,
                }
                sh.HandleRPC(s.ctx, inHeader)
        }</span>
        <span class="cov8" title="1">s.trReader = &amp;transportReader{
                reader:        &amp;recvBufferReader{ctx: s.ctx, ctxDone: s.ctx.Done(), recv: s.buf, freeBuffer: func(*bytes.Buffer) </span>{<span class="cov0" title="0">}</span>},
                windowHandler: func(int) {<span class="cov0" title="0">}</span>,
        }

        // readerDone is closed when the Body.Read-ing goroutine exits.
        <span class="cov8" title="1">readerDone := make(chan struct{})
        go func() </span><span class="cov8" title="1">{
                defer close(readerDone)

                // TODO: minimize garbage, optimize recvBuffer code/ownership
                const readSize = 8196
                for buf := make([]byte, readSize); ; </span><span class="cov8" title="1">{
                        n, err := req.Body.Read(buf)
                        if n &gt; 0 </span><span class="cov0" title="0">{
                                s.buf.put(recvMsg{buffer: bytes.NewBuffer(buf[:n:n])})
                                buf = buf[n:]
                        }</span>
                        <span class="cov8" title="1">if err != nil </span><span class="cov8" title="1">{
                                s.buf.put(recvMsg{err: mapRecvMsgError(err)})
                                return
                        }</span>
                        <span class="cov0" title="0">if len(buf) == 0 </span><span class="cov0" title="0">{
                                buf = make([]byte, readSize)
                        }</span>
                }
        }()

        // startStream is provided by the *grpc.Server's serveStreams.
        // It starts a goroutine serving s and exits immediately.
        // The goroutine that is started is the one that then calls
        // into ht, calling WriteHeader, Write, WriteStatus, Close, etc.
        <span class="cov8" title="1">startStream(s)

        ht.runStream()
        close(requestOver)

        // Wait for reading goroutine to finish.
        req.Body.Close()
        &lt;-readerDone</span>
}

func (ht *serverHandlerTransport) runStream() <span class="cov8" title="1">{
        for </span><span class="cov8" title="1">{
                select </span>{
                case fn := &lt;-ht.writes:<span class="cov8" title="1">
                        fn()</span>
                case &lt;-ht.closedCh:<span class="cov8" title="1">
                        return</span>
                }
        }
}

func (ht *serverHandlerTransport) IncrMsgSent() {<span class="cov0" title="0">}</span>

func (ht *serverHandlerTransport) IncrMsgRecv() {<span class="cov0" title="0">}</span>

func (ht *serverHandlerTransport) Drain() <span class="cov0" title="0">{
        panic("Drain() is not implemented")</span>
}

// mapRecvMsgError returns the non-nil err into the appropriate
// error value as expected by callers of *grpc.parser.recvMsg.
// In particular, in can only be:
//   * io.EOF
//   * io.ErrUnexpectedEOF
//   * of type transport.ConnectionError
//   * an error from the status package
func mapRecvMsgError(err error) error <span class="cov8" title="1">{
        if err == io.EOF || err == io.ErrUnexpectedEOF </span><span class="cov8" title="1">{
                return err
        }</span>
        <span class="cov8" title="1">if se, ok := err.(http2.StreamError); ok </span><span class="cov0" title="0">{
                if code, ok := http2ErrConvTab[se.Code]; ok </span><span class="cov0" title="0">{
                        return status.Error(code, se.Error())
                }</span>
        }
        <span class="cov8" title="1">if strings.Contains(err.Error(), "body closed by handler") </span><span class="cov0" title="0">{
                return status.Error(codes.Canceled, err.Error())
        }</span>
        <span class="cov8" title="1">return connectionErrorf(true, err, err.Error())</span>
}
</pre>
		
		<pre class="file" id="file113" style="display: none">/*
 *
 * Copyright 2014 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package transport

import (
        "context"
        "fmt"
        "io"
        "math"
        "net"
        "net/http"
        "path/filepath"
        "strconv"
        "strings"
        "sync"
        "sync/atomic"
        "time"

        "golang.org/x/net/http2"
        "golang.org/x/net/http2/hpack"
        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/credentials"
        "google.golang.org/grpc/internal/channelz"
        icredentials "google.golang.org/grpc/internal/credentials"
        "google.golang.org/grpc/internal/grpcutil"
        imetadata "google.golang.org/grpc/internal/metadata"
        "google.golang.org/grpc/internal/syscall"
        "google.golang.org/grpc/internal/transport/networktype"
        "google.golang.org/grpc/keepalive"
        "google.golang.org/grpc/metadata"
        "google.golang.org/grpc/peer"
        "google.golang.org/grpc/resolver"
        "google.golang.org/grpc/stats"
        "google.golang.org/grpc/status"
)

// clientConnectionCounter counts the number of connections a client has
// initiated (equal to the number of http2Clients created). Must be accessed
// atomically.
var clientConnectionCounter uint64

// http2Client implements the ClientTransport interface with HTTP2.
type http2Client struct {
        lastRead   int64 // Keep this field 64-bit aligned. Accessed atomically.
        ctx        context.Context
        cancel     context.CancelFunc
        ctxDone    &lt;-chan struct{} // Cache the ctx.Done() chan.
        userAgent  string
        md         metadata.MD
        conn       net.Conn // underlying communication channel
        loopy      *loopyWriter
        remoteAddr net.Addr
        localAddr  net.Addr
        authInfo   credentials.AuthInfo // auth info about the connection

        readerDone chan struct{} // sync point to enable testing.
        writerDone chan struct{} // sync point to enable testing.
        // goAway is closed to notify the upper layer (i.e., addrConn.transportMonitor)
        // that the server sent GoAway on this transport.
        goAway chan struct{}

        framer *framer
        // controlBuf delivers all the control related tasks (e.g., window
        // updates, reset streams, and various settings) to the controller.
        // Do not access controlBuf with mu held.
        controlBuf *controlBuffer
        fc         *trInFlow
        // The scheme used: https if TLS is on, http otherwise.
        scheme string

        isSecure bool

        perRPCCreds []credentials.PerRPCCredentials

        kp               keepalive.ClientParameters
        keepaliveEnabled bool

        statsHandlers []stats.Handler

        initialWindowSize int32

        // configured by peer through SETTINGS_MAX_HEADER_LIST_SIZE
        maxSendHeaderListSize *uint32

        bdpEst *bdpEstimator
        // onPrefaceReceipt is a callback that client transport calls upon
        // receiving server preface to signal that a succefull HTTP2
        // connection was established.
        onPrefaceReceipt func()

        maxConcurrentStreams  uint32
        streamQuota           int64
        streamsQuotaAvailable chan struct{}
        waitingStreams        uint32
        nextID                uint32

        // Do not access controlBuf with mu held.
        mu            sync.Mutex // guard the following variables
        state         transportState
        activeStreams map[uint32]*Stream
        // prevGoAway ID records the Last-Stream-ID in the previous GOAway frame.
        prevGoAwayID uint32
        // goAwayReason records the http2.ErrCode and debug data received with the
        // GoAway frame.
        goAwayReason GoAwayReason
        // goAwayDebugMessage contains a detailed human readable string about a
        // GoAway frame, useful for error messages.
        goAwayDebugMessage string
        // A condition variable used to signal when the keepalive goroutine should
        // go dormant. The condition for dormancy is based on the number of active
        // streams and the `PermitWithoutStream` keepalive client parameter. And
        // since the number of active streams is guarded by the above mutex, we use
        // the same for this condition variable as well.
        kpDormancyCond *sync.Cond
        // A boolean to track whether the keepalive goroutine is dormant or not.
        // This is checked before attempting to signal the above condition
        // variable.
        kpDormant bool

        // Fields below are for channelz metric collection.
        channelzID *channelz.Identifier
        czData     *channelzData

        onGoAway func(GoAwayReason)
        onClose  func()

        bufferPool *bufferPool

        connectionID uint64
}

func dial(ctx context.Context, fn func(context.Context, string) (net.Conn, error), addr resolver.Address, useProxy bool, grpcUA string) (net.Conn, error) <span class="cov8" title="1">{
        address := addr.Addr
        networkType, ok := networktype.Get(addr)
        if fn != nil </span><span class="cov8" title="1">{
                // Special handling for unix scheme with custom dialer. Back in the day,
                // we did not have a unix resolver and therefore targets with a unix
                // scheme would end up using the passthrough resolver. So, user's used a
                // custom dialer in this case and expected the original dial target to
                // be passed to the custom dialer. Now, we have a unix resolver. But if
                // a custom dialer is specified, we want to retain the old behavior in
                // terms of the address being passed to the custom dialer.
                if networkType == "unix" &amp;&amp; !strings.HasPrefix(address, "\x00") </span><span class="cov0" title="0">{
                        // Supported unix targets are either "unix://absolute-path" or
                        // "unix:relative-path".
                        if filepath.IsAbs(address) </span><span class="cov0" title="0">{
                                return fn(ctx, "unix://"+address)
                        }</span>
                        <span class="cov0" title="0">return fn(ctx, "unix:"+address)</span>
                }
                <span class="cov8" title="1">return fn(ctx, address)</span>
        }
        <span class="cov8" title="1">if !ok </span><span class="cov8" title="1">{
                networkType, address = parseDialTarget(address)
        }</span>
        <span class="cov8" title="1">if networkType == "tcp" &amp;&amp; useProxy </span><span class="cov0" title="0">{
                return proxyDial(ctx, address, grpcUA)
        }</span>
        <span class="cov8" title="1">return (&amp;net.Dialer{}).DialContext(ctx, networkType, address)</span>
}

func isTemporary(err error) bool <span class="cov0" title="0">{
        switch err := err.(type) </span>{
        case interface {
                Temporary() bool
        }:<span class="cov0" title="0">
                return err.Temporary()</span>
        case interface {
                Timeout() bool
        }:<span class="cov0" title="0">
                // Timeouts may be resolved upon retry, and are thus treated as
                // temporary.
                return err.Timeout()</span>
        }
        <span class="cov0" title="0">return true</span>
}

// newHTTP2Client constructs a connected ClientTransport to addr based on HTTP2
// and starts to receive messages on it. Non-nil error returns if construction
// fails.
func newHTTP2Client(connectCtx, ctx context.Context, addr resolver.Address, opts ConnectOptions, onPrefaceReceipt func(), onGoAway func(GoAwayReason), onClose func()) (_ *http2Client, err error) <span class="cov8" title="1">{
        scheme := "http"
        ctx, cancel := context.WithCancel(ctx)
        defer func() </span><span class="cov8" title="1">{
                if err != nil </span><span class="cov0" title="0">{
                        cancel()
                }</span>
        }()

        // gRPC, resolver, balancer etc. can specify arbitrary data in the
        // Attributes field of resolver.Address, which is shoved into connectCtx
        // and passed to the dialer and credential handshaker. This makes it possible for
        // address specific arbitrary data to reach custom dialers and credential handshakers.
        <span class="cov8" title="1">connectCtx = icredentials.NewClientHandshakeInfoContext(connectCtx, credentials.ClientHandshakeInfo{Attributes: addr.Attributes})

        conn, err := dial(connectCtx, opts.Dialer, addr, opts.UseProxy, opts.UserAgent)
        if err != nil </span><span class="cov0" title="0">{
                if opts.FailOnNonTempDialError </span><span class="cov0" title="0">{
                        return nil, connectionErrorf(isTemporary(err), err, "transport: error while dialing: %v", err)
                }</span>
                <span class="cov0" title="0">return nil, connectionErrorf(true, err, "transport: Error while dialing %v", err)</span>
        }
        // Any further errors will close the underlying connection
        <span class="cov8" title="1">defer func(conn net.Conn) </span><span class="cov8" title="1">{
                if err != nil </span><span class="cov0" title="0">{
                        conn.Close()
                }</span>
        }(conn)
        <span class="cov8" title="1">kp := opts.KeepaliveParams
        // Validate keepalive parameters.
        if kp.Time == 0 </span><span class="cov8" title="1">{
                kp.Time = defaultClientKeepaliveTime
        }</span>
        <span class="cov8" title="1">if kp.Timeout == 0 </span><span class="cov8" title="1">{
                kp.Timeout = defaultClientKeepaliveTimeout
        }</span>
        <span class="cov8" title="1">keepaliveEnabled := false
        if kp.Time != infinity </span><span class="cov8" title="1">{
                if err = syscall.SetTCPUserTimeout(conn, kp.Timeout); err != nil </span><span class="cov0" title="0">{
                        return nil, connectionErrorf(false, err, "transport: failed to set TCP_USER_TIMEOUT: %v", err)
                }</span>
                <span class="cov8" title="1">keepaliveEnabled = true</span>
        }
        <span class="cov8" title="1">var (
                isSecure bool
                authInfo credentials.AuthInfo
        )
        transportCreds := opts.TransportCredentials
        perRPCCreds := opts.PerRPCCredentials

        if b := opts.CredsBundle; b != nil </span><span class="cov0" title="0">{
                if t := b.TransportCredentials(); t != nil </span><span class="cov0" title="0">{
                        transportCreds = t
                }</span>
                <span class="cov0" title="0">if t := b.PerRPCCredentials(); t != nil </span><span class="cov0" title="0">{
                        perRPCCreds = append(perRPCCreds, t)
                }</span>
        }
        <span class="cov8" title="1">if transportCreds != nil </span><span class="cov8" title="1">{
                rawConn := conn
                // Pull the deadline from the connectCtx, which will be used for
                // timeouts in the authentication protocol handshake. Can ignore the
                // boolean as the deadline will return the zero value, which will make
                // the conn not timeout on I/O operations.
                deadline, _ := connectCtx.Deadline()
                rawConn.SetDeadline(deadline)
                conn, authInfo, err = transportCreds.ClientHandshake(connectCtx, addr.ServerName, rawConn)
                rawConn.SetDeadline(time.Time{})
                if err != nil </span><span class="cov0" title="0">{
                        return nil, connectionErrorf(isTemporary(err), err, "transport: authentication handshake failed: %v", err)
                }</span>
                <span class="cov8" title="1">for _, cd := range perRPCCreds </span><span class="cov0" title="0">{
                        if cd.RequireTransportSecurity() </span><span class="cov0" title="0">{
                                if ci, ok := authInfo.(interface {
                                        GetCommonAuthInfo() credentials.CommonAuthInfo
                                }); ok </span><span class="cov0" title="0">{
                                        secLevel := ci.GetCommonAuthInfo().SecurityLevel
                                        if secLevel != credentials.InvalidSecurityLevel &amp;&amp; secLevel &lt; credentials.PrivacyAndIntegrity </span><span class="cov0" title="0">{
                                                return nil, connectionErrorf(true, nil, "transport: cannot send secure credentials on an insecure connection")
                                        }</span>
                                }
                        }
                }
                <span class="cov8" title="1">isSecure = true
                if transportCreds.Info().SecurityProtocol == "tls" </span><span class="cov0" title="0">{
                        scheme = "https"
                }</span>
        }
        <span class="cov8" title="1">dynamicWindow := true
        icwz := int32(initialWindowSize)
        if opts.InitialConnWindowSize &gt;= defaultWindowSize </span><span class="cov8" title="1">{
                icwz = opts.InitialConnWindowSize
                dynamicWindow = false
        }</span>
        <span class="cov8" title="1">writeBufSize := opts.WriteBufferSize
        readBufSize := opts.ReadBufferSize
        maxHeaderListSize := defaultClientMaxHeaderListSize
        if opts.MaxHeaderListSize != nil </span><span class="cov0" title="0">{
                maxHeaderListSize = *opts.MaxHeaderListSize
        }</span>
        <span class="cov8" title="1">t := &amp;http2Client{
                ctx:                   ctx,
                ctxDone:               ctx.Done(), // Cache Done chan.
                cancel:                cancel,
                userAgent:             opts.UserAgent,
                conn:                  conn,
                remoteAddr:            conn.RemoteAddr(),
                localAddr:             conn.LocalAddr(),
                authInfo:              authInfo,
                readerDone:            make(chan struct{}),
                writerDone:            make(chan struct{}),
                goAway:                make(chan struct{}),
                framer:                newFramer(conn, writeBufSize, readBufSize, maxHeaderListSize),
                fc:                    &amp;trInFlow{limit: uint32(icwz)},
                scheme:                scheme,
                activeStreams:         make(map[uint32]*Stream),
                isSecure:              isSecure,
                perRPCCreds:           perRPCCreds,
                kp:                    kp,
                statsHandlers:         opts.StatsHandlers,
                initialWindowSize:     initialWindowSize,
                onPrefaceReceipt:      onPrefaceReceipt,
                nextID:                1,
                maxConcurrentStreams:  defaultMaxStreamsClient,
                streamQuota:           defaultMaxStreamsClient,
                streamsQuotaAvailable: make(chan struct{}, 1),
                czData:                new(channelzData),
                onGoAway:              onGoAway,
                onClose:               onClose,
                keepaliveEnabled:      keepaliveEnabled,
                bufferPool:            newBufferPool(),
        }

        if md, ok := addr.Metadata.(*metadata.MD); ok </span><span class="cov0" title="0">{
                t.md = *md
        }</span> else<span class="cov8" title="1"> if md := imetadata.Get(addr); md != nil </span><span class="cov0" title="0">{
                t.md = md
        }</span>
        <span class="cov8" title="1">t.controlBuf = newControlBuffer(t.ctxDone)
        if opts.InitialWindowSize &gt;= defaultWindowSize </span><span class="cov8" title="1">{
                t.initialWindowSize = opts.InitialWindowSize
                dynamicWindow = false
        }</span>
        <span class="cov8" title="1">if dynamicWindow </span><span class="cov8" title="1">{
                t.bdpEst = &amp;bdpEstimator{
                        bdp:               initialWindowSize,
                        updateFlowControl: t.updateFlowControl,
                }
        }</span>
        <span class="cov8" title="1">for _, sh := range t.statsHandlers </span><span class="cov0" title="0">{
                t.ctx = sh.TagConn(t.ctx, &amp;stats.ConnTagInfo{
                        RemoteAddr: t.remoteAddr,
                        LocalAddr:  t.localAddr,
                })
                connBegin := &amp;stats.ConnBegin{
                        Client: true,
                }
                sh.HandleConn(t.ctx, connBegin)
        }</span>
        <span class="cov8" title="1">t.channelzID, err = channelz.RegisterNormalSocket(t, opts.ChannelzParentID, fmt.Sprintf("%s -&gt; %s", t.localAddr, t.remoteAddr))
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">if t.keepaliveEnabled </span><span class="cov8" title="1">{
                t.kpDormancyCond = sync.NewCond(&amp;t.mu)
                go t.keepalive()
        }</span>
        // Start the reader goroutine for incoming message. Each transport has
        // a dedicated goroutine which reads HTTP2 frame from network. Then it
        // dispatches the frame to the corresponding stream entity.
        <span class="cov8" title="1">go t.reader()

        // Send connection preface to server.
        n, err := t.conn.Write(clientPreface)
        if err != nil </span><span class="cov0" title="0">{
                err = connectionErrorf(true, err, "transport: failed to write client preface: %v", err)
                t.Close(err)
                return nil, err
        }</span>
        <span class="cov8" title="1">if n != len(clientPreface) </span><span class="cov0" title="0">{
                err = connectionErrorf(true, nil, "transport: preface mismatch, wrote %d bytes; want %d", n, len(clientPreface))
                t.Close(err)
                return nil, err
        }</span>
        <span class="cov8" title="1">var ss []http2.Setting

        if t.initialWindowSize != defaultWindowSize </span><span class="cov8" title="1">{
                ss = append(ss, http2.Setting{
                        ID:  http2.SettingInitialWindowSize,
                        Val: uint32(t.initialWindowSize),
                })
        }</span>
        <span class="cov8" title="1">if opts.MaxHeaderListSize != nil </span><span class="cov0" title="0">{
                ss = append(ss, http2.Setting{
                        ID:  http2.SettingMaxHeaderListSize,
                        Val: *opts.MaxHeaderListSize,
                })
        }</span>
        <span class="cov8" title="1">err = t.framer.fr.WriteSettings(ss...)
        if err != nil </span><span class="cov0" title="0">{
                err = connectionErrorf(true, err, "transport: failed to write initial settings frame: %v", err)
                t.Close(err)
                return nil, err
        }</span>
        // Adjust the connection flow control window if needed.
        <span class="cov8" title="1">if delta := uint32(icwz - defaultWindowSize); delta &gt; 0 </span><span class="cov8" title="1">{
                if err := t.framer.fr.WriteWindowUpdate(0, delta); err != nil </span><span class="cov0" title="0">{
                        err = connectionErrorf(true, err, "transport: failed to write window update: %v", err)
                        t.Close(err)
                        return nil, err
                }</span>
        }

        <span class="cov8" title="1">t.connectionID = atomic.AddUint64(&amp;clientConnectionCounter, 1)

        if err := t.framer.writer.Flush(); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">go func() </span><span class="cov8" title="1">{
                t.loopy = newLoopyWriter(clientSide, t.framer, t.controlBuf, t.bdpEst)
                err := t.loopy.run()
                if err != nil </span><span class="cov8" title="1">{
                        if logger.V(logLevel) </span><span class="cov0" title="0">{
                                logger.Errorf("transport: loopyWriter.run returning. Err: %v", err)
                        }</span>
                }
                // Do not close the transport.  Let reader goroutine handle it since
                // there might be data in the buffers.
                <span class="cov8" title="1">t.conn.Close()
                t.controlBuf.finish()
                close(t.writerDone)</span>
        }()
        <span class="cov8" title="1">return t, nil</span>
}

func (t *http2Client) newStream(ctx context.Context, callHdr *CallHdr) *Stream <span class="cov8" title="1">{
        // TODO(zhaoq): Handle uint32 overflow of Stream.id.
        s := &amp;Stream{
                ct:             t,
                done:           make(chan struct{}),
                method:         callHdr.Method,
                sendCompress:   callHdr.SendCompress,
                buf:            newRecvBuffer(),
                headerChan:     make(chan struct{}),
                contentSubtype: callHdr.ContentSubtype,
                doneFunc:       callHdr.DoneFunc,
        }
        s.wq = newWriteQuota(defaultWriteQuota, s.done)
        s.requestRead = func(n int) </span><span class="cov8" title="1">{
                t.adjustWindow(s, uint32(n))
        }</span>
        // The client side stream context should have exactly the same life cycle with the user provided context.
        // That means, s.ctx should be read-only. And s.ctx is done iff ctx is done.
        // So we use the original context here instead of creating a copy.
        <span class="cov8" title="1">s.ctx = ctx
        s.trReader = &amp;transportReader{
                reader: &amp;recvBufferReader{
                        ctx:     s.ctx,
                        ctxDone: s.ctx.Done(),
                        recv:    s.buf,
                        closeStream: func(err error) </span><span class="cov0" title="0">{
                                t.CloseStream(s, err)
                        }</span>,
                        freeBuffer: t.bufferPool.put,
                },
                windowHandler: func(n int) <span class="cov8" title="1">{
                        t.updateWindow(s, uint32(n))
                }</span>,
        }
        <span class="cov8" title="1">return s</span>
}

func (t *http2Client) getPeer() *peer.Peer <span class="cov8" title="1">{
        return &amp;peer.Peer{
                Addr:     t.remoteAddr,
                AuthInfo: t.authInfo,
        }
}</span>

func (t *http2Client) createHeaderFields(ctx context.Context, callHdr *CallHdr) ([]hpack.HeaderField, error) <span class="cov8" title="1">{
        aud := t.createAudience(callHdr)
        ri := credentials.RequestInfo{
                Method:   callHdr.Method,
                AuthInfo: t.authInfo,
        }
        ctxWithRequestInfo := icredentials.NewRequestInfoContext(ctx, ri)
        authData, err := t.getTrAuthData(ctxWithRequestInfo, aud)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">callAuthData, err := t.getCallAuthData(ctxWithRequestInfo, aud, callHdr)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        // TODO(mmukhi): Benchmark if the performance gets better if count the metadata and other header fields
        // first and create a slice of that exact size.
        // Make the slice of certain predictable size to reduce allocations made by append.
        <span class="cov8" title="1">hfLen := 7 // :method, :scheme, :path, :authority, content-type, user-agent, te
        hfLen += len(authData) + len(callAuthData)
        headerFields := make([]hpack.HeaderField, 0, hfLen)
        headerFields = append(headerFields, hpack.HeaderField{Name: ":method", Value: "POST"})
        headerFields = append(headerFields, hpack.HeaderField{Name: ":scheme", Value: t.scheme})
        headerFields = append(headerFields, hpack.HeaderField{Name: ":path", Value: callHdr.Method})
        headerFields = append(headerFields, hpack.HeaderField{Name: ":authority", Value: callHdr.Host})
        headerFields = append(headerFields, hpack.HeaderField{Name: "content-type", Value: grpcutil.ContentType(callHdr.ContentSubtype)})
        headerFields = append(headerFields, hpack.HeaderField{Name: "user-agent", Value: t.userAgent})
        headerFields = append(headerFields, hpack.HeaderField{Name: "te", Value: "trailers"})
        if callHdr.PreviousAttempts &gt; 0 </span><span class="cov0" title="0">{
                headerFields = append(headerFields, hpack.HeaderField{Name: "grpc-previous-rpc-attempts", Value: strconv.Itoa(callHdr.PreviousAttempts)})
        }</span>

        <span class="cov8" title="1">if callHdr.SendCompress != "" </span><span class="cov0" title="0">{
                headerFields = append(headerFields, hpack.HeaderField{Name: "grpc-encoding", Value: callHdr.SendCompress})
                headerFields = append(headerFields, hpack.HeaderField{Name: "grpc-accept-encoding", Value: callHdr.SendCompress})
        }</span>
        <span class="cov8" title="1">if dl, ok := ctx.Deadline(); ok </span><span class="cov8" title="1">{
                // Send out timeout regardless its value. The server can detect timeout context by itself.
                // TODO(mmukhi): Perhaps this field should be updated when actually writing out to the wire.
                timeout := time.Until(dl)
                headerFields = append(headerFields, hpack.HeaderField{Name: "grpc-timeout", Value: grpcutil.EncodeDuration(timeout)})
        }</span>
        <span class="cov8" title="1">for k, v := range authData </span><span class="cov0" title="0">{
                headerFields = append(headerFields, hpack.HeaderField{Name: k, Value: encodeMetadataHeader(k, v)})
        }</span>
        <span class="cov8" title="1">for k, v := range callAuthData </span><span class="cov0" title="0">{
                headerFields = append(headerFields, hpack.HeaderField{Name: k, Value: encodeMetadataHeader(k, v)})
        }</span>
        <span class="cov8" title="1">if b := stats.OutgoingTags(ctx); b != nil </span><span class="cov0" title="0">{
                headerFields = append(headerFields, hpack.HeaderField{Name: "grpc-tags-bin", Value: encodeBinHeader(b)})
        }</span>
        <span class="cov8" title="1">if b := stats.OutgoingTrace(ctx); b != nil </span><span class="cov0" title="0">{
                headerFields = append(headerFields, hpack.HeaderField{Name: "grpc-trace-bin", Value: encodeBinHeader(b)})
        }</span>

        <span class="cov8" title="1">if md, added, ok := metadata.FromOutgoingContextRaw(ctx); ok </span><span class="cov0" title="0">{
                var k string
                for k, vv := range md </span><span class="cov0" title="0">{
                        // HTTP doesn't allow you to set pseudoheaders after non pseudoheaders were set.
                        if isReservedHeader(k) </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        <span class="cov0" title="0">for _, v := range vv </span><span class="cov0" title="0">{
                                headerFields = append(headerFields, hpack.HeaderField{Name: k, Value: encodeMetadataHeader(k, v)})
                        }</span>
                }
                <span class="cov0" title="0">for _, vv := range added </span><span class="cov0" title="0">{
                        for i, v := range vv </span><span class="cov0" title="0">{
                                if i%2 == 0 </span><span class="cov0" title="0">{
                                        k = strings.ToLower(v)
                                        continue</span>
                                }
                                // HTTP doesn't allow you to set pseudoheaders after non pseudoheaders were set.
                                <span class="cov0" title="0">if isReservedHeader(k) </span><span class="cov0" title="0">{
                                        continue</span>
                                }
                                <span class="cov0" title="0">headerFields = append(headerFields, hpack.HeaderField{Name: k, Value: encodeMetadataHeader(k, v)})</span>
                        }
                }
        }
        <span class="cov8" title="1">for k, vv := range t.md </span><span class="cov0" title="0">{
                if isReservedHeader(k) </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov0" title="0">for _, v := range vv </span><span class="cov0" title="0">{
                        headerFields = append(headerFields, hpack.HeaderField{Name: k, Value: encodeMetadataHeader(k, v)})
                }</span>
        }
        <span class="cov8" title="1">return headerFields, nil</span>
}

func (t *http2Client) createAudience(callHdr *CallHdr) string <span class="cov8" title="1">{
        // Create an audience string only if needed.
        if len(t.perRPCCreds) == 0 &amp;&amp; callHdr.Creds == nil </span><span class="cov8" title="1">{
                return ""
        }</span>
        // Construct URI required to get auth request metadata.
        // Omit port if it is the default one.
        <span class="cov0" title="0">host := strings.TrimSuffix(callHdr.Host, ":443")
        pos := strings.LastIndex(callHdr.Method, "/")
        if pos == -1 </span><span class="cov0" title="0">{
                pos = len(callHdr.Method)
        }</span>
        <span class="cov0" title="0">return "https://" + host + callHdr.Method[:pos]</span>
}

func (t *http2Client) getTrAuthData(ctx context.Context, audience string) (map[string]string, error) <span class="cov8" title="1">{
        if len(t.perRPCCreds) == 0 </span><span class="cov8" title="1">{
                return nil, nil
        }</span>
        <span class="cov0" title="0">authData := map[string]string{}
        for _, c := range t.perRPCCreds </span><span class="cov0" title="0">{
                data, err := c.GetRequestMetadata(ctx, audience)
                if err != nil </span><span class="cov0" title="0">{
                        if _, ok := status.FromError(err); ok </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>

                        <span class="cov0" title="0">return nil, status.Errorf(codes.Unauthenticated, "transport: per-RPC creds failed due to error: %v", err)</span>
                }
                <span class="cov0" title="0">for k, v := range data </span><span class="cov0" title="0">{
                        // Capital header names are illegal in HTTP/2.
                        k = strings.ToLower(k)
                        authData[k] = v
                }</span>
        }
        <span class="cov0" title="0">return authData, nil</span>
}

func (t *http2Client) getCallAuthData(ctx context.Context, audience string, callHdr *CallHdr) (map[string]string, error) <span class="cov8" title="1">{
        var callAuthData map[string]string
        // Check if credentials.PerRPCCredentials were provided via call options.
        // Note: if these credentials are provided both via dial options and call
        // options, then both sets of credentials will be applied.
        if callCreds := callHdr.Creds; callCreds != nil </span><span class="cov0" title="0">{
                if callCreds.RequireTransportSecurity() </span><span class="cov0" title="0">{
                        ri, _ := credentials.RequestInfoFromContext(ctx)
                        if !t.isSecure || credentials.CheckSecurityLevel(ri.AuthInfo, credentials.PrivacyAndIntegrity) != nil </span><span class="cov0" title="0">{
                                return nil, status.Error(codes.Unauthenticated, "transport: cannot send secure credentials on an insecure connection")
                        }</span>
                }
                <span class="cov0" title="0">data, err := callCreds.GetRequestMetadata(ctx, audience)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, status.Errorf(codes.Internal, "transport: %v", err)
                }</span>
                <span class="cov0" title="0">callAuthData = make(map[string]string, len(data))
                for k, v := range data </span><span class="cov0" title="0">{
                        // Capital header names are illegal in HTTP/2
                        k = strings.ToLower(k)
                        callAuthData[k] = v
                }</span>
        }
        <span class="cov8" title="1">return callAuthData, nil</span>
}

// NewStreamError wraps an error and reports additional information.  Typically
// NewStream errors result in transparent retry, as they mean nothing went onto
// the wire.  However, there are two notable exceptions:
//
// 1. If the stream headers violate the max header list size allowed by the
//    server.  It's possible this could succeed on another transport, even if
//    it's unlikely, but do not transparently retry.
// 2. If the credentials errored when requesting their headers.  In this case,
//    it's possible a retry can fix the problem, but indefinitely transparently
//    retrying is not appropriate as it is likely the credentials, if they can
//    eventually succeed, would need I/O to do so.
type NewStreamError struct {
        Err error

        AllowTransparentRetry bool
}

func (e NewStreamError) Error() string <span class="cov8" title="1">{
        return e.Err.Error()
}</span>

// NewStream creates a stream and registers it into the transport as "active"
// streams.  All non-nil errors returned will be *NewStreamError.
func (t *http2Client) NewStream(ctx context.Context, callHdr *CallHdr) (*Stream, error) <span class="cov8" title="1">{
        ctx = peer.NewContext(ctx, t.getPeer())
        headerFields, err := t.createHeaderFields(ctx, callHdr)
        if err != nil </span><span class="cov0" title="0">{
                return nil, &amp;NewStreamError{Err: err, AllowTransparentRetry: false}
        }</span>
        <span class="cov8" title="1">s := t.newStream(ctx, callHdr)
        cleanup := func(err error) </span><span class="cov8" title="1">{
                if s.swapState(streamDone) == streamDone </span><span class="cov0" title="0">{
                        // If it was already done, return.
                        return
                }</span>
                // The stream was unprocessed by the server.
                <span class="cov8" title="1">atomic.StoreUint32(&amp;s.unprocessed, 1)
                s.write(recvMsg{err: err})
                close(s.done)
                // If headerChan isn't closed, then close it.
                if atomic.CompareAndSwapUint32(&amp;s.headerChanClosed, 0, 1) </span><span class="cov8" title="1">{
                        close(s.headerChan)
                }</span>
        }
        <span class="cov8" title="1">hdr := &amp;headerFrame{
                hf:        headerFields,
                endStream: false,
                initStream: func(id uint32) error </span><span class="cov8" title="1">{
                        t.mu.Lock()
                        if state := t.state; state != reachable </span><span class="cov8" title="1">{
                                t.mu.Unlock()
                                // Do a quick cleanup.
                                err := error(errStreamDrain)
                                if state == closing </span><span class="cov0" title="0">{
                                        err = ErrConnClosing
                                }</span>
                                <span class="cov8" title="1">cleanup(err)
                                return err</span>
                        }
                        <span class="cov8" title="1">if channelz.IsOn() </span><span class="cov0" title="0">{
                                atomic.AddInt64(&amp;t.czData.streamsStarted, 1)
                                atomic.StoreInt64(&amp;t.czData.lastStreamCreatedTime, time.Now().UnixNano())
                        }</span>
                        // If the keepalive goroutine has gone dormant, wake it up.
                        <span class="cov8" title="1">if t.kpDormant </span><span class="cov8" title="1">{
                                t.kpDormancyCond.Signal()
                        }</span>
                        <span class="cov8" title="1">t.mu.Unlock()
                        return nil</span>
                },
                onOrphaned: cleanup,
                wq:         s.wq,
        }
        <span class="cov8" title="1">firstTry := true
        var ch chan struct{}
        checkForStreamQuota := func(it interface{}) bool </span><span class="cov8" title="1">{
                if t.streamQuota &lt;= 0 </span><span class="cov8" title="1">{ // Can go negative if server decreases it.
                        if firstTry </span><span class="cov8" title="1">{
                                t.waitingStreams++
                        }</span>
                        <span class="cov8" title="1">ch = t.streamsQuotaAvailable
                        return false</span>
                }
                <span class="cov8" title="1">if !firstTry </span><span class="cov0" title="0">{
                        t.waitingStreams--
                }</span>
                <span class="cov8" title="1">t.streamQuota--
                h := it.(*headerFrame)
                h.streamID = t.nextID
                t.nextID += 2
                s.id = h.streamID
                s.fc = &amp;inFlow{limit: uint32(t.initialWindowSize)}
                t.mu.Lock()
                if t.activeStreams == nil </span><span class="cov0" title="0">{ // Can be niled from Close().
                        t.mu.Unlock()
                        return false // Don't create a stream if the transport is already closed.
                }</span>
                <span class="cov8" title="1">t.activeStreams[s.id] = s
                t.mu.Unlock()
                if t.streamQuota &gt; 0 &amp;&amp; t.waitingStreams &gt; 0 </span><span class="cov0" title="0">{
                        select </span>{
                        case t.streamsQuotaAvailable &lt;- struct{}{}:<span class="cov0" title="0"></span>
                        default:<span class="cov0" title="0"></span>
                        }
                }
                <span class="cov8" title="1">return true</span>
        }
        <span class="cov8" title="1">var hdrListSizeErr error
        checkForHeaderListSize := func(it interface{}) bool </span><span class="cov8" title="1">{
                if t.maxSendHeaderListSize == nil </span><span class="cov8" title="1">{
                        return true
                }</span>
                <span class="cov0" title="0">hdrFrame := it.(*headerFrame)
                var sz int64
                for _, f := range hdrFrame.hf </span><span class="cov0" title="0">{
                        if sz += int64(f.Size()); sz &gt; int64(*t.maxSendHeaderListSize) </span><span class="cov0" title="0">{
                                hdrListSizeErr = status.Errorf(codes.Internal, "header list size to send violates the maximum size (%d bytes) set by server", *t.maxSendHeaderListSize)
                                return false
                        }</span>
                }
                <span class="cov0" title="0">return true</span>
        }
        <span class="cov8" title="1">for </span><span class="cov8" title="1">{
                success, err := t.controlBuf.executeAndPut(func(it interface{}) bool </span><span class="cov8" title="1">{
                        return checkForHeaderListSize(it) &amp;&amp; checkForStreamQuota(it)
                }</span>, hdr)
                <span class="cov8" title="1">if err != nil </span><span class="cov8" title="1">{
                        // Connection closed.
                        return nil, &amp;NewStreamError{Err: err, AllowTransparentRetry: true}
                }</span>
                <span class="cov8" title="1">if success </span><span class="cov8" title="1">{
                        break</span>
                }
                <span class="cov8" title="1">if hdrListSizeErr != nil </span><span class="cov0" title="0">{
                        return nil, &amp;NewStreamError{Err: hdrListSizeErr}
                }</span>
                <span class="cov8" title="1">firstTry = false
                select </span>{
                case &lt;-ch:<span class="cov0" title="0"></span>
                case &lt;-ctx.Done():<span class="cov8" title="1">
                        return nil, &amp;NewStreamError{Err: ContextErr(ctx.Err())}</span>
                case &lt;-t.goAway:<span class="cov0" title="0">
                        return nil, &amp;NewStreamError{Err: errStreamDrain, AllowTransparentRetry: true}</span>
                case &lt;-t.ctx.Done():<span class="cov0" title="0">
                        return nil, &amp;NewStreamError{Err: ErrConnClosing, AllowTransparentRetry: true}</span>
                }
        }
        <span class="cov8" title="1">if len(t.statsHandlers) != 0 </span><span class="cov0" title="0">{
                header, ok := metadata.FromOutgoingContext(ctx)
                if ok </span><span class="cov0" title="0">{
                        header.Set("user-agent", t.userAgent)
                }</span> else<span class="cov0" title="0"> {
                        header = metadata.Pairs("user-agent", t.userAgent)
                }</span>
                <span class="cov0" title="0">for _, sh := range t.statsHandlers </span><span class="cov0" title="0">{
                        // Note: The header fields are compressed with hpack after this call returns.
                        // No WireLength field is set here.
                        // Note: Creating a new stats object to prevent pollution.
                        outHeader := &amp;stats.OutHeader{
                                Client:      true,
                                FullMethod:  callHdr.Method,
                                RemoteAddr:  t.remoteAddr,
                                LocalAddr:   t.localAddr,
                                Compression: callHdr.SendCompress,
                                Header:      header,
                        }
                        sh.HandleRPC(s.ctx, outHeader)
                }</span>
        }
        <span class="cov8" title="1">return s, nil</span>
}

// CloseStream clears the footprint of a stream when the stream is not needed any more.
// This must not be executed in reader's goroutine.
func (t *http2Client) CloseStream(s *Stream, err error) <span class="cov8" title="1">{
        var (
                rst     bool
                rstCode http2.ErrCode
        )
        if err != nil </span><span class="cov8" title="1">{
                rst = true
                rstCode = http2.ErrCodeCancel
        }</span>
        <span class="cov8" title="1">t.closeStream(s, err, rst, rstCode, status.Convert(err), nil, false)</span>
}

func (t *http2Client) closeStream(s *Stream, err error, rst bool, rstCode http2.ErrCode, st *status.Status, mdata map[string][]string, eosReceived bool) <span class="cov8" title="1">{
        // Set stream status to done.
        if s.swapState(streamDone) == streamDone </span><span class="cov8" title="1">{
                // If it was already done, return.  If multiple closeStream calls
                // happen simultaneously, wait for the first to finish.
                &lt;-s.done
                return
        }</span>
        // status and trailers can be updated here without any synchronization because the stream goroutine will
        // only read it after it sees an io.EOF error from read or write and we'll write those errors
        // only after updating this.
        <span class="cov8" title="1">s.status = st
        if len(mdata) &gt; 0 </span><span class="cov8" title="1">{
                s.trailer = mdata
        }</span>
        <span class="cov8" title="1">if err != nil </span><span class="cov8" title="1">{
                // This will unblock reads eventually.
                s.write(recvMsg{err: err})
        }</span>
        // If headerChan isn't closed, then close it.
        <span class="cov8" title="1">if atomic.CompareAndSwapUint32(&amp;s.headerChanClosed, 0, 1) </span><span class="cov8" title="1">{
                s.noHeaders = true
                close(s.headerChan)
        }</span>
        <span class="cov8" title="1">cleanup := &amp;cleanupStream{
                streamID: s.id,
                onWrite: func() </span><span class="cov8" title="1">{
                        t.mu.Lock()
                        if t.activeStreams != nil </span><span class="cov8" title="1">{
                                delete(t.activeStreams, s.id)
                        }</span>
                        <span class="cov8" title="1">t.mu.Unlock()
                        if channelz.IsOn() </span><span class="cov0" title="0">{
                                if eosReceived </span><span class="cov0" title="0">{
                                        atomic.AddInt64(&amp;t.czData.streamsSucceeded, 1)
                                }</span> else<span class="cov0" title="0"> {
                                        atomic.AddInt64(&amp;t.czData.streamsFailed, 1)
                                }</span>
                        }
                },
                rst:     rst,
                rstCode: rstCode,
        }
        <span class="cov8" title="1">addBackStreamQuota := func(interface{}) bool </span><span class="cov8" title="1">{
                t.streamQuota++
                if t.streamQuota &gt; 0 &amp;&amp; t.waitingStreams &gt; 0 </span><span class="cov8" title="1">{
                        select </span>{
                        case t.streamsQuotaAvailable &lt;- struct{}{}:<span class="cov8" title="1"></span>
                        default:<span class="cov0" title="0"></span>
                        }
                }
                <span class="cov8" title="1">return true</span>
        }
        <span class="cov8" title="1">t.controlBuf.executeAndPut(addBackStreamQuota, cleanup)
        // This will unblock write.
        close(s.done)
        if s.doneFunc != nil </span><span class="cov0" title="0">{
                s.doneFunc()
        }</span>
}

// Close kicks off the shutdown process of the transport. This should be called
// only once on a transport. Once it is called, the transport should not be
// accessed any more.
//
// This method blocks until the addrConn that initiated this transport is
// re-connected. This happens because t.onClose() begins reconnect logic at the
// addrConn level and blocks until the addrConn is successfully connected.
func (t *http2Client) Close(err error) <span class="cov8" title="1">{
        t.mu.Lock()
        // Make sure we only Close once.
        if t.state == closing </span><span class="cov8" title="1">{
                t.mu.Unlock()
                return
        }</span>
        // Call t.onClose before setting the state to closing to prevent the client
        // from attempting to create new streams ASAP.
        <span class="cov8" title="1">t.onClose()
        t.state = closing
        streams := t.activeStreams
        t.activeStreams = nil
        if t.kpDormant </span><span class="cov8" title="1">{
                // If the keepalive goroutine is blocked on this condition variable, we
                // should unblock it so that the goroutine eventually exits.
                t.kpDormancyCond.Signal()
        }</span>
        <span class="cov8" title="1">t.mu.Unlock()
        t.controlBuf.finish()
        t.cancel()
        t.conn.Close()
        channelz.RemoveEntry(t.channelzID)
        // Append info about previous goaways if there were any, since this may be important
        // for understanding the root cause for this connection to be closed.
        _, goAwayDebugMessage := t.GetGoAwayReason()

        var st *status.Status
        if len(goAwayDebugMessage) &gt; 0 </span><span class="cov8" title="1">{
                st = status.Newf(codes.Unavailable, "closing transport due to: %v, received prior goaway: %v", err, goAwayDebugMessage)
                err = st.Err()
        }</span> else<span class="cov8" title="1"> {
                st = status.New(codes.Unavailable, err.Error())
        }</span>

        // Notify all active streams.
        <span class="cov8" title="1">for _, s := range streams </span><span class="cov8" title="1">{
                t.closeStream(s, err, false, http2.ErrCodeNo, st, nil, false)
        }</span>
        <span class="cov8" title="1">for _, sh := range t.statsHandlers </span><span class="cov0" title="0">{
                connEnd := &amp;stats.ConnEnd{
                        Client: true,
                }
                sh.HandleConn(t.ctx, connEnd)
        }</span>
}

// GracefulClose sets the state to draining, which prevents new streams from
// being created and causes the transport to be closed when the last active
// stream is closed.  If there are no active streams, the transport is closed
// immediately.  This does nothing if the transport is already draining or
// closing.
func (t *http2Client) GracefulClose() <span class="cov8" title="1">{
        t.mu.Lock()
        // Make sure we move to draining only from active.
        if t.state == draining || t.state == closing </span><span class="cov0" title="0">{
                t.mu.Unlock()
                return
        }</span>
        <span class="cov8" title="1">t.state = draining
        active := len(t.activeStreams)
        t.mu.Unlock()
        if active == 0 </span><span class="cov0" title="0">{
                t.Close(ErrConnClosing)
                return
        }</span>
        <span class="cov8" title="1">t.controlBuf.put(&amp;incomingGoAway{})</span>
}

// Write formats the data into HTTP2 data frame(s) and sends it out. The caller
// should proceed only if Write returns nil.
func (t *http2Client) Write(s *Stream, hdr []byte, data []byte, opts *Options) error <span class="cov8" title="1">{
        if opts.Last </span><span class="cov8" title="1">{
                // If it's the last message, update stream state.
                if !s.compareAndSwapState(streamActive, streamWriteDone) </span><span class="cov0" title="0">{
                        return errStreamDone
                }</span>
        } else<span class="cov8" title="1"> if s.getState() != streamActive </span><span class="cov0" title="0">{
                return errStreamDone
        }</span>
        <span class="cov8" title="1">df := &amp;dataFrame{
                streamID:  s.id,
                endStream: opts.Last,
                h:         hdr,
                d:         data,
        }
        if hdr != nil || data != nil </span><span class="cov8" title="1">{ // If it's not an empty data frame, check quota.
                if err := s.wq.get(int32(len(hdr) + len(data))); err != nil </span><span class="cov8" title="1">{
                        return err
                }</span>
        }
        <span class="cov8" title="1">return t.controlBuf.put(df)</span>
}

func (t *http2Client) getStream(f http2.Frame) *Stream <span class="cov8" title="1">{
        t.mu.Lock()
        s := t.activeStreams[f.Header().StreamID]
        t.mu.Unlock()
        return s
}</span>

// adjustWindow sends out extra window update over the initial window size
// of stream if the application is requesting data larger in size than
// the window.
func (t *http2Client) adjustWindow(s *Stream, n uint32) <span class="cov8" title="1">{
        if w := s.fc.maybeAdjust(n); w &gt; 0 </span><span class="cov8" title="1">{
                t.controlBuf.put(&amp;outgoingWindowUpdate{streamID: s.id, increment: w})
        }</span>
}

// updateWindow adjusts the inbound quota for the stream.
// Window updates will be sent out when the cumulative quota
// exceeds the corresponding threshold.
func (t *http2Client) updateWindow(s *Stream, n uint32) <span class="cov8" title="1">{
        if w := s.fc.onRead(n); w &gt; 0 </span><span class="cov8" title="1">{
                t.controlBuf.put(&amp;outgoingWindowUpdate{streamID: s.id, increment: w})
        }</span>
}

// updateFlowControl updates the incoming flow control windows
// for the transport and the stream based on the current bdp
// estimation.
func (t *http2Client) updateFlowControl(n uint32) <span class="cov8" title="1">{
        updateIWS := func(interface{}) bool </span><span class="cov8" title="1">{
                t.initialWindowSize = int32(n)
                t.mu.Lock()
                for _, s := range t.activeStreams </span><span class="cov8" title="1">{
                        s.fc.newLimit(n)
                }</span>
                <span class="cov8" title="1">t.mu.Unlock()
                return true</span>
        }
        <span class="cov8" title="1">t.controlBuf.executeAndPut(updateIWS, &amp;outgoingWindowUpdate{streamID: 0, increment: t.fc.newLimit(n)})
        t.controlBuf.put(&amp;outgoingSettings{
                ss: []http2.Setting{
                        {
                                ID:  http2.SettingInitialWindowSize,
                                Val: n,
                        },
                },
        })</span>
}

func (t *http2Client) handleData(f *http2.DataFrame) <span class="cov8" title="1">{
        size := f.Header().Length
        var sendBDPPing bool
        if t.bdpEst != nil </span><span class="cov8" title="1">{
                sendBDPPing = t.bdpEst.add(size)
        }</span>
        // Decouple connection's flow control from application's read.
        // An update on connection's flow control should not depend on
        // whether user application has read the data or not. Such a
        // restriction is already imposed on the stream's flow control,
        // and therefore the sender will be blocked anyways.
        // Decoupling the connection flow control will prevent other
        // active(fast) streams from starving in presence of slow or
        // inactive streams.
        //
        <span class="cov8" title="1">if w := t.fc.onData(size); w &gt; 0 </span><span class="cov8" title="1">{
                t.controlBuf.put(&amp;outgoingWindowUpdate{
                        streamID:  0,
                        increment: w,
                })
        }</span>
        <span class="cov8" title="1">if sendBDPPing </span><span class="cov8" title="1">{
                // Avoid excessive ping detection (e.g. in an L7 proxy)
                // by sending a window update prior to the BDP ping.

                if w := t.fc.reset(); w &gt; 0 </span><span class="cov8" title="1">{
                        t.controlBuf.put(&amp;outgoingWindowUpdate{
                                streamID:  0,
                                increment: w,
                        })
                }</span>

                <span class="cov8" title="1">t.controlBuf.put(bdpPing)</span>
        }
        // Select the right stream to dispatch.
        <span class="cov8" title="1">s := t.getStream(f)
        if s == nil </span><span class="cov8" title="1">{
                return
        }</span>
        <span class="cov8" title="1">if size &gt; 0 </span><span class="cov8" title="1">{
                if err := s.fc.onData(size); err != nil </span><span class="cov8" title="1">{
                        t.closeStream(s, io.EOF, true, http2.ErrCodeFlowControl, status.New(codes.Internal, err.Error()), nil, false)
                        return
                }</span>
                <span class="cov8" title="1">if f.Header().Flags.Has(http2.FlagDataPadded) </span><span class="cov0" title="0">{
                        if w := s.fc.onRead(size - uint32(len(f.Data()))); w &gt; 0 </span><span class="cov0" title="0">{
                                t.controlBuf.put(&amp;outgoingWindowUpdate{s.id, w})
                        }</span>
                }
                // TODO(bradfitz, zhaoq): A copy is required here because there is no
                // guarantee f.Data() is consumed before the arrival of next frame.
                // Can this copy be eliminated?
                <span class="cov8" title="1">if len(f.Data()) &gt; 0 </span><span class="cov8" title="1">{
                        buffer := t.bufferPool.get()
                        buffer.Reset()
                        buffer.Write(f.Data())
                        s.write(recvMsg{buffer: buffer})
                }</span>
        }
        // The server has closed the stream without sending trailers.  Record that
        // the read direction is closed, and set the status appropriately.
        <span class="cov8" title="1">if f.StreamEnded() </span><span class="cov0" title="0">{
                t.closeStream(s, io.EOF, false, http2.ErrCodeNo, status.New(codes.Internal, "server closed the stream without sending trailers"), nil, true)
        }</span>
}

func (t *http2Client) handleRSTStream(f *http2.RSTStreamFrame) <span class="cov0" title="0">{
        s := t.getStream(f)
        if s == nil </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov0" title="0">if f.ErrCode == http2.ErrCodeRefusedStream </span><span class="cov0" title="0">{
                // The stream was unprocessed by the server.
                atomic.StoreUint32(&amp;s.unprocessed, 1)
        }</span>
        <span class="cov0" title="0">statusCode, ok := http2ErrConvTab[f.ErrCode]
        if !ok </span><span class="cov0" title="0">{
                if logger.V(logLevel) </span><span class="cov0" title="0">{
                        logger.Warningf("transport: http2Client.handleRSTStream found no mapped gRPC status for the received http2 error %v", f.ErrCode)
                }</span>
                <span class="cov0" title="0">statusCode = codes.Unknown</span>
        }
        <span class="cov0" title="0">if statusCode == codes.Canceled </span><span class="cov0" title="0">{
                if d, ok := s.ctx.Deadline(); ok &amp;&amp; !d.After(time.Now()) </span><span class="cov0" title="0">{
                        // Our deadline was already exceeded, and that was likely the cause
                        // of this cancelation.  Alter the status code accordingly.
                        statusCode = codes.DeadlineExceeded
                }</span>
        }
        <span class="cov0" title="0">t.closeStream(s, io.EOF, false, http2.ErrCodeNo, status.Newf(statusCode, "stream terminated by RST_STREAM with error code: %v", f.ErrCode), nil, false)</span>
}

func (t *http2Client) handleSettings(f *http2.SettingsFrame, isFirst bool) <span class="cov8" title="1">{
        if f.IsAck() </span><span class="cov8" title="1">{
                return
        }</span>
        <span class="cov8" title="1">var maxStreams *uint32
        var ss []http2.Setting
        var updateFuncs []func()
        f.ForeachSetting(func(s http2.Setting) error </span><span class="cov8" title="1">{
                switch s.ID </span>{
                case http2.SettingMaxConcurrentStreams:<span class="cov8" title="1">
                        maxStreams = new(uint32)
                        *maxStreams = s.Val</span>
                case http2.SettingMaxHeaderListSize:<span class="cov0" title="0">
                        updateFuncs = append(updateFuncs, func() </span><span class="cov0" title="0">{
                                t.maxSendHeaderListSize = new(uint32)
                                *t.maxSendHeaderListSize = s.Val
                        }</span>)
                default:<span class="cov8" title="1">
                        ss = append(ss, s)</span>
                }
                <span class="cov8" title="1">return nil</span>
        })
        <span class="cov8" title="1">if isFirst &amp;&amp; maxStreams == nil </span><span class="cov8" title="1">{
                maxStreams = new(uint32)
                *maxStreams = math.MaxUint32
        }</span>
        <span class="cov8" title="1">sf := &amp;incomingSettings{
                ss: ss,
        }
        if maxStreams != nil </span><span class="cov8" title="1">{
                updateStreamQuota := func() </span><span class="cov8" title="1">{
                        delta := int64(*maxStreams) - int64(t.maxConcurrentStreams)
                        t.maxConcurrentStreams = *maxStreams
                        t.streamQuota += delta
                        if delta &gt; 0 &amp;&amp; t.waitingStreams &gt; 0 </span><span class="cov0" title="0">{
                                close(t.streamsQuotaAvailable) // wake all of them up.
                                t.streamsQuotaAvailable = make(chan struct{}, 1)
                        }</span>
                }
                <span class="cov8" title="1">updateFuncs = append(updateFuncs, updateStreamQuota)</span>
        }
        <span class="cov8" title="1">t.controlBuf.executeAndPut(func(interface{}) bool </span><span class="cov8" title="1">{
                for _, f := range updateFuncs </span><span class="cov8" title="1">{
                        f()
                }</span>
                <span class="cov8" title="1">return true</span>
        }, sf)
}

func (t *http2Client) handlePing(f *http2.PingFrame) <span class="cov8" title="1">{
        if f.IsAck() </span><span class="cov8" title="1">{
                // Maybe it's a BDP ping.
                if t.bdpEst != nil </span><span class="cov8" title="1">{
                        t.bdpEst.calculate(f.Data)
                }</span>
                <span class="cov8" title="1">return</span>
        }
        <span class="cov8" title="1">pingAck := &amp;ping{ack: true}
        copy(pingAck.data[:], f.Data[:])
        t.controlBuf.put(pingAck)</span>
}

func (t *http2Client) handleGoAway(f *http2.GoAwayFrame) <span class="cov8" title="1">{
        t.mu.Lock()
        if t.state == closing </span><span class="cov0" title="0">{
                t.mu.Unlock()
                return
        }</span>
        <span class="cov8" title="1">if f.ErrCode == http2.ErrCodeEnhanceYourCalm </span><span class="cov8" title="1">{
                if logger.V(logLevel) </span><span class="cov0" title="0">{
                        logger.Infof("Client received GoAway with http2.ErrCodeEnhanceYourCalm.")
                }</span>
        }
        <span class="cov8" title="1">id := f.LastStreamID
        if id &gt; 0 &amp;&amp; id%2 == 0 </span><span class="cov0" title="0">{
                t.mu.Unlock()
                t.Close(connectionErrorf(true, nil, "received goaway with non-zero even-numbered numbered stream id: %v", id))
                return
        }</span>
        // A client can receive multiple GoAways from the server (see
        // https://github.com/grpc/grpc-go/issues/1387).  The idea is that the first
        // GoAway will be sent with an ID of MaxInt32 and the second GoAway will be
        // sent after an RTT delay with the ID of the last stream the server will
        // process.
        //
        // Therefore, when we get the first GoAway we don't necessarily close any
        // streams. While in case of second GoAway we close all streams created after
        // the GoAwayId. This way streams that were in-flight while the GoAway from
        // server was being sent don't get killed.
        <span class="cov8" title="1">select </span>{
        case &lt;-t.goAway:<span class="cov8" title="1"> // t.goAway has been closed (i.e.,multiple GoAways).
                // If there are multiple GoAways the first one should always have an ID greater than the following ones.
                if id &gt; t.prevGoAwayID </span><span class="cov0" title="0">{
                        t.mu.Unlock()
                        t.Close(connectionErrorf(true, nil, "received goaway with stream id: %v, which exceeds stream id of previous goaway: %v", id, t.prevGoAwayID))
                        return
                }</span>
        default:<span class="cov8" title="1">
                t.setGoAwayReason(f)
                close(t.goAway)
                defer t.controlBuf.put(&amp;incomingGoAway{}) // Defer as t.mu is currently held.
                // Notify the clientconn about the GOAWAY before we set the state to
                // draining, to allow the client to stop attempting to create streams
                // before disallowing new streams on this connection.
                t.onGoAway(t.goAwayReason)
                t.state = draining</span>
        }
        // All streams with IDs greater than the GoAwayId
        // and smaller than the previous GoAway ID should be killed.
        <span class="cov8" title="1">upperLimit := t.prevGoAwayID
        if upperLimit == 0 </span><span class="cov8" title="1">{ // This is the first GoAway Frame.
                upperLimit = math.MaxUint32 // Kill all streams after the GoAway ID.
        }</span>
        <span class="cov8" title="1">for streamID, stream := range t.activeStreams </span><span class="cov8" title="1">{
                if streamID &gt; id &amp;&amp; streamID &lt;= upperLimit </span><span class="cov0" title="0">{
                        // The stream was unprocessed by the server.
                        atomic.StoreUint32(&amp;stream.unprocessed, 1)
                        t.closeStream(stream, errStreamDrain, false, http2.ErrCodeNo, statusGoAway, nil, false)
                }</span>
        }
        <span class="cov8" title="1">t.prevGoAwayID = id
        active := len(t.activeStreams)
        t.mu.Unlock()
        if active == 0 </span><span class="cov8" title="1">{
                t.Close(connectionErrorf(true, nil, "received goaway and there are no active streams"))
        }</span>
}

// setGoAwayReason sets the value of t.goAwayReason based
// on the GoAway frame received.
// It expects a lock on transport's mutext to be held by
// the caller.
func (t *http2Client) setGoAwayReason(f *http2.GoAwayFrame) <span class="cov8" title="1">{
        t.goAwayReason = GoAwayNoReason
        switch f.ErrCode </span>{
        case http2.ErrCodeEnhanceYourCalm:<span class="cov8" title="1">
                if string(f.DebugData()) == "too_many_pings" </span><span class="cov8" title="1">{
                        t.goAwayReason = GoAwayTooManyPings
                }</span>
        }
        <span class="cov8" title="1">if len(f.DebugData()) == 0 </span><span class="cov8" title="1">{
                t.goAwayDebugMessage = fmt.Sprintf("code: %s", f.ErrCode)
        }</span> else<span class="cov8" title="1"> {
                t.goAwayDebugMessage = fmt.Sprintf("code: %s, debug data: %q", f.ErrCode, string(f.DebugData()))
        }</span>
}

func (t *http2Client) GetGoAwayReason() (GoAwayReason, string) <span class="cov8" title="1">{
        t.mu.Lock()
        defer t.mu.Unlock()
        return t.goAwayReason, t.goAwayDebugMessage
}</span>

func (t *http2Client) handleWindowUpdate(f *http2.WindowUpdateFrame) <span class="cov8" title="1">{
        t.controlBuf.put(&amp;incomingWindowUpdate{
                streamID:  f.Header().StreamID,
                increment: f.Increment,
        })
}</span>

// operateHeaders takes action on the decoded headers.
func (t *http2Client) operateHeaders(frame *http2.MetaHeadersFrame) <span class="cov8" title="1">{
        s := t.getStream(frame)
        if s == nil </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov8" title="1">endStream := frame.StreamEnded()
        atomic.StoreUint32(&amp;s.bytesReceived, 1)
        initialHeader := atomic.LoadUint32(&amp;s.headerChanClosed) == 0

        if !initialHeader &amp;&amp; !endStream </span><span class="cov0" title="0">{
                // As specified by gRPC over HTTP2, a HEADERS frame (and associated CONTINUATION frames) can only appear at the start or end of a stream. Therefore, second HEADERS frame must have EOS bit set.
                st := status.New(codes.Internal, "a HEADERS frame cannot appear in the middle of a stream")
                t.closeStream(s, st.Err(), true, http2.ErrCodeProtocol, st, nil, false)
                return
        }</span>

        // frame.Truncated is set to true when framer detects that the current header
        // list size hits MaxHeaderListSize limit.
        <span class="cov8" title="1">if frame.Truncated </span><span class="cov8" title="1">{
                se := status.New(codes.Internal, "peer header list size exceeded limit")
                t.closeStream(s, se.Err(), true, http2.ErrCodeFrameSize, se, nil, endStream)
                return
        }</span>

        <span class="cov8" title="1">var (
                // If a gRPC Response-Headers has already been received, then it means
                // that the peer is speaking gRPC and we are in gRPC mode.
                isGRPC         = !initialHeader
                mdata          = make(map[string][]string)
                contentTypeErr = "malformed header: missing HTTP content-type"
                grpcMessage    string
                statusGen      *status.Status
                recvCompress   string
                httpStatusCode *int
                httpStatusErr  string
                rawStatusCode  = codes.Unknown
                // headerError is set if an error is encountered while parsing the headers
                headerError string
        )

        if initialHeader </span><span class="cov8" title="1">{
                httpStatusErr = "malformed header: missing HTTP status"
        }</span>

        <span class="cov8" title="1">for _, hf := range frame.Fields </span><span class="cov8" title="1">{
                switch hf.Name </span>{
                case "content-type":<span class="cov8" title="1">
                        if _, validContentType := grpcutil.ContentSubtype(hf.Value); !validContentType </span><span class="cov8" title="1">{
                                contentTypeErr = fmt.Sprintf("transport: received unexpected content-type %q", hf.Value)
                                break</span>
                        }
                        <span class="cov8" title="1">contentTypeErr = ""
                        mdata[hf.Name] = append(mdata[hf.Name], hf.Value)
                        isGRPC = true</span>
                case "grpc-encoding":<span class="cov0" title="0">
                        recvCompress = hf.Value</span>
                case "grpc-status":<span class="cov8" title="1">
                        code, err := strconv.ParseInt(hf.Value, 10, 32)
                        if err != nil </span><span class="cov8" title="1">{
                                se := status.New(codes.Internal, fmt.Sprintf("transport: malformed grpc-status: %v", err))
                                t.closeStream(s, se.Err(), true, http2.ErrCodeProtocol, se, nil, endStream)
                                return
                        }</span>
                        <span class="cov8" title="1">rawStatusCode = codes.Code(uint32(code))</span>
                case "grpc-message":<span class="cov8" title="1">
                        grpcMessage = decodeGrpcMessage(hf.Value)</span>
                case "grpc-status-details-bin":<span class="cov0" title="0">
                        var err error
                        statusGen, err = decodeGRPCStatusDetails(hf.Value)
                        if err != nil </span><span class="cov0" title="0">{
                                headerError = fmt.Sprintf("transport: malformed grpc-status-details-bin: %v", err)
                        }</span>
                case ":status":<span class="cov8" title="1">
                        if hf.Value == "200" </span><span class="cov8" title="1">{
                                httpStatusErr = ""
                                statusCode := 200
                                httpStatusCode = &amp;statusCode
                                break</span>
                        }

                        <span class="cov8" title="1">c, err := strconv.ParseInt(hf.Value, 10, 32)
                        if err != nil </span><span class="cov8" title="1">{
                                se := status.New(codes.Internal, fmt.Sprintf("transport: malformed http-status: %v", err))
                                t.closeStream(s, se.Err(), true, http2.ErrCodeProtocol, se, nil, endStream)
                                return
                        }</span>
                        <span class="cov8" title="1">statusCode := int(c)
                        httpStatusCode = &amp;statusCode

                        httpStatusErr = fmt.Sprintf(
                                "unexpected HTTP status code received from server: %d (%s)",
                                statusCode,
                                http.StatusText(statusCode),
                        )</span>
                default:<span class="cov0" title="0">
                        if isReservedHeader(hf.Name) &amp;&amp; !isWhitelistedHeader(hf.Name) </span><span class="cov0" title="0">{
                                break</span>
                        }
                        <span class="cov0" title="0">v, err := decodeMetadataHeader(hf.Name, hf.Value)
                        if err != nil </span><span class="cov0" title="0">{
                                headerError = fmt.Sprintf("transport: malformed %s: %v", hf.Name, err)
                                logger.Warningf("Failed to decode metadata header (%q, %q): %v", hf.Name, hf.Value, err)
                                break</span>
                        }
                        <span class="cov0" title="0">mdata[hf.Name] = append(mdata[hf.Name], v)</span>
                }
        }

        <span class="cov8" title="1">if !isGRPC || httpStatusErr != "" </span><span class="cov8" title="1">{
                var code = codes.Internal // when header does not include HTTP status, return INTERNAL

                if httpStatusCode != nil </span><span class="cov8" title="1">{
                        var ok bool
                        code, ok = HTTPStatusConvTab[*httpStatusCode]
                        if !ok </span><span class="cov8" title="1">{
                                code = codes.Unknown
                        }</span>
                }
                <span class="cov8" title="1">var errs []string
                if httpStatusErr != "" </span><span class="cov8" title="1">{
                        errs = append(errs, httpStatusErr)
                }</span>
                <span class="cov8" title="1">if contentTypeErr != "" </span><span class="cov8" title="1">{
                        errs = append(errs, contentTypeErr)
                }</span>
                // Verify the HTTP response is a 200.
                <span class="cov8" title="1">se := status.New(code, strings.Join(errs, "; "))
                t.closeStream(s, se.Err(), true, http2.ErrCodeProtocol, se, nil, endStream)
                return</span>
        }

        <span class="cov8" title="1">if headerError != "" </span><span class="cov0" title="0">{
                se := status.New(codes.Internal, headerError)
                t.closeStream(s, se.Err(), true, http2.ErrCodeProtocol, se, nil, endStream)
                return
        }</span>

        <span class="cov8" title="1">isHeader := false

        // If headerChan hasn't been closed yet
        if atomic.CompareAndSwapUint32(&amp;s.headerChanClosed, 0, 1) </span><span class="cov8" title="1">{
                s.headerValid = true
                if !endStream </span><span class="cov8" title="1">{
                        // HEADERS frame block carries a Response-Headers.
                        isHeader = true
                        // These values can be set without any synchronization because
                        // stream goroutine will read it only after seeing a closed
                        // headerChan which we'll close after setting this.
                        s.recvCompress = recvCompress
                        if len(mdata) &gt; 0 </span><span class="cov8" title="1">{
                                s.header = mdata
                        }</span>
                } else<span class="cov8" title="1"> {
                        // HEADERS frame block carries a Trailers-Only.
                        s.noHeaders = true
                }</span>
                <span class="cov8" title="1">close(s.headerChan)</span>
        }

        <span class="cov8" title="1">for _, sh := range t.statsHandlers </span><span class="cov0" title="0">{
                if isHeader </span><span class="cov0" title="0">{
                        inHeader := &amp;stats.InHeader{
                                Client:      true,
                                WireLength:  int(frame.Header().Length),
                                Header:      metadata.MD(mdata).Copy(),
                                Compression: s.recvCompress,
                        }
                        sh.HandleRPC(s.ctx, inHeader)
                }</span> else<span class="cov0" title="0"> {
                        inTrailer := &amp;stats.InTrailer{
                                Client:     true,
                                WireLength: int(frame.Header().Length),
                                Trailer:    metadata.MD(mdata).Copy(),
                        }
                        sh.HandleRPC(s.ctx, inTrailer)
                }</span>
        }

        <span class="cov8" title="1">if !endStream </span><span class="cov8" title="1">{
                return
        }</span>

        <span class="cov8" title="1">if statusGen == nil </span><span class="cov8" title="1">{
                statusGen = status.New(rawStatusCode, grpcMessage)
        }</span>

        // if client received END_STREAM from server while stream was still active, send RST_STREAM
        <span class="cov8" title="1">rst := s.getState() == streamActive
        t.closeStream(s, io.EOF, rst, http2.ErrCodeNo, statusGen, mdata, true)</span>
}

// reader runs as a separate goroutine in charge of reading data from network
// connection.
//
// TODO(zhaoq): currently one reader per transport. Investigate whether this is
// optimal.
// TODO(zhaoq): Check the validity of the incoming frame sequence.
func (t *http2Client) reader() <span class="cov8" title="1">{
        defer close(t.readerDone)
        // Check the validity of server preface.
        frame, err := t.framer.fr.ReadFrame()
        if err != nil </span><span class="cov8" title="1">{
                err = connectionErrorf(true, err, "error reading server preface: %v", err)
                t.Close(err) // this kicks off resetTransport, so must be last before return
                return
        }</span>
        <span class="cov8" title="1">t.conn.SetReadDeadline(time.Time{}) // reset deadline once we get the settings frame (we didn't time out, yay!)
        if t.keepaliveEnabled </span><span class="cov8" title="1">{
                atomic.StoreInt64(&amp;t.lastRead, time.Now().UnixNano())
        }</span>
        <span class="cov8" title="1">sf, ok := frame.(*http2.SettingsFrame)
        if !ok </span><span class="cov0" title="0">{
                // this kicks off resetTransport, so must be last before return
                t.Close(connectionErrorf(true, nil, "initial http2 frame from server is not a settings frame: %T", frame))
                return
        }</span>
        <span class="cov8" title="1">t.onPrefaceReceipt()
        t.handleSettings(sf, true)

        // loop to keep reading incoming messages on this transport.
        for </span><span class="cov8" title="1">{
                t.controlBuf.throttle()
                frame, err := t.framer.fr.ReadFrame()
                if t.keepaliveEnabled </span><span class="cov8" title="1">{
                        atomic.StoreInt64(&amp;t.lastRead, time.Now().UnixNano())
                }</span>
                <span class="cov8" title="1">if err != nil </span><span class="cov8" title="1">{
                        // Abort an active stream if the http2.Framer returns a
                        // http2.StreamError. This can happen only if the server's response
                        // is malformed http2.
                        if se, ok := err.(http2.StreamError); ok </span><span class="cov0" title="0">{
                                t.mu.Lock()
                                s := t.activeStreams[se.StreamID]
                                t.mu.Unlock()
                                if s != nil </span><span class="cov0" title="0">{
                                        // use error detail to provide better err message
                                        code := http2ErrConvTab[se.Code]
                                        errorDetail := t.framer.fr.ErrorDetail()
                                        var msg string
                                        if errorDetail != nil </span><span class="cov0" title="0">{
                                                msg = errorDetail.Error()
                                        }</span> else<span class="cov0" title="0"> {
                                                msg = "received invalid frame"
                                        }</span>
                                        <span class="cov0" title="0">t.closeStream(s, status.Error(code, msg), true, http2.ErrCodeProtocol, status.New(code, msg), nil, false)</span>
                                }
                                <span class="cov0" title="0">continue</span>
                        } else<span class="cov8" title="1"> {
                                // Transport error.
                                t.Close(connectionErrorf(true, err, "error reading from server: %v", err))
                                return
                        }</span>
                }
                <span class="cov8" title="1">switch frame := frame.(type) </span>{
                case *http2.MetaHeadersFrame:<span class="cov8" title="1">
                        t.operateHeaders(frame)</span>
                case *http2.DataFrame:<span class="cov8" title="1">
                        t.handleData(frame)</span>
                case *http2.RSTStreamFrame:<span class="cov0" title="0">
                        t.handleRSTStream(frame)</span>
                case *http2.SettingsFrame:<span class="cov8" title="1">
                        t.handleSettings(frame, false)</span>
                case *http2.PingFrame:<span class="cov8" title="1">
                        t.handlePing(frame)</span>
                case *http2.GoAwayFrame:<span class="cov8" title="1">
                        t.handleGoAway(frame)</span>
                case *http2.WindowUpdateFrame:<span class="cov8" title="1">
                        t.handleWindowUpdate(frame)</span>
                default:<span class="cov0" title="0">
                        if logger.V(logLevel) </span><span class="cov0" title="0">{
                                logger.Errorf("transport: http2Client.reader got unhandled frame type %v.", frame)
                        }</span>
                }
        }
}

func minTime(a, b time.Duration) time.Duration <span class="cov8" title="1">{
        if a &lt; b </span><span class="cov8" title="1">{
                return a
        }</span>
        <span class="cov8" title="1">return b</span>
}

// keepalive running in a separate goroutine makes sure the connection is alive by sending pings.
func (t *http2Client) keepalive() <span class="cov8" title="1">{
        p := &amp;ping{data: [8]byte{}}
        // True iff a ping has been sent, and no data has been received since then.
        outstandingPing := false
        // Amount of time remaining before which we should receive an ACK for the
        // last sent ping.
        timeoutLeft := time.Duration(0)
        // Records the last value of t.lastRead before we go block on the timer.
        // This is required to check for read activity since then.
        prevNano := time.Now().UnixNano()
        timer := time.NewTimer(t.kp.Time)
        for </span><span class="cov8" title="1">{
                select </span>{
                case &lt;-timer.C:<span class="cov8" title="1">
                        lastRead := atomic.LoadInt64(&amp;t.lastRead)
                        if lastRead &gt; prevNano </span><span class="cov8" title="1">{
                                // There has been read activity since the last time we were here.
                                outstandingPing = false
                                // Next timer should fire at kp.Time seconds from lastRead time.
                                timer.Reset(time.Duration(lastRead) + t.kp.Time - time.Duration(time.Now().UnixNano()))
                                prevNano = lastRead
                                continue</span>
                        }
                        <span class="cov8" title="1">if outstandingPing &amp;&amp; timeoutLeft &lt;= 0 </span><span class="cov8" title="1">{
                                t.Close(connectionErrorf(true, nil, "keepalive ping failed to receive ACK within timeout"))
                                return
                        }</span>
                        <span class="cov8" title="1">t.mu.Lock()
                        if t.state == closing </span><span class="cov0" title="0">{
                                // If the transport is closing, we should exit from the
                                // keepalive goroutine here. If not, we could have a race
                                // between the call to Signal() from Close() and the call to
                                // Wait() here, whereby the keepalive goroutine ends up
                                // blocking on the condition variable which will never be
                                // signalled again.
                                t.mu.Unlock()
                                return
                        }</span>
                        <span class="cov8" title="1">if len(t.activeStreams) &lt; 1 &amp;&amp; !t.kp.PermitWithoutStream </span><span class="cov8" title="1">{
                                // If a ping was sent out previously (because there were active
                                // streams at that point) which wasn't acked and its timeout
                                // hadn't fired, but we got here and are about to go dormant,
                                // we should make sure that we unconditionally send a ping once
                                // we awaken.
                                outstandingPing = false
                                t.kpDormant = true
                                t.kpDormancyCond.Wait()
                        }</span>
                        <span class="cov8" title="1">t.kpDormant = false
                        t.mu.Unlock()

                        // We get here either because we were dormant and a new stream was
                        // created which unblocked the Wait() call, or because the
                        // keepalive timer expired. In both cases, we need to send a ping.
                        if !outstandingPing </span><span class="cov8" title="1">{
                                if channelz.IsOn() </span><span class="cov0" title="0">{
                                        atomic.AddInt64(&amp;t.czData.kpCount, 1)
                                }</span>
                                <span class="cov8" title="1">t.controlBuf.put(p)
                                timeoutLeft = t.kp.Timeout
                                outstandingPing = true</span>
                        }
                        // The amount of time to sleep here is the minimum of kp.Time and
                        // timeoutLeft. This will ensure that we wait only for kp.Time
                        // before sending out the next ping (for cases where the ping is
                        // acked).
                        <span class="cov8" title="1">sleepDuration := minTime(t.kp.Time, timeoutLeft)
                        timeoutLeft -= sleepDuration
                        timer.Reset(sleepDuration)</span>
                case &lt;-t.ctx.Done():<span class="cov8" title="1">
                        if !timer.Stop() </span><span class="cov0" title="0">{
                                &lt;-timer.C
                        }</span>
                        <span class="cov8" title="1">return</span>
                }
        }
}

func (t *http2Client) Error() &lt;-chan struct{} <span class="cov8" title="1">{
        return t.ctx.Done()
}</span>

func (t *http2Client) GoAway() &lt;-chan struct{} <span class="cov8" title="1">{
        return t.goAway
}</span>

func (t *http2Client) ChannelzMetric() *channelz.SocketInternalMetric <span class="cov0" title="0">{
        s := channelz.SocketInternalMetric{
                StreamsStarted:                  atomic.LoadInt64(&amp;t.czData.streamsStarted),
                StreamsSucceeded:                atomic.LoadInt64(&amp;t.czData.streamsSucceeded),
                StreamsFailed:                   atomic.LoadInt64(&amp;t.czData.streamsFailed),
                MessagesSent:                    atomic.LoadInt64(&amp;t.czData.msgSent),
                MessagesReceived:                atomic.LoadInt64(&amp;t.czData.msgRecv),
                KeepAlivesSent:                  atomic.LoadInt64(&amp;t.czData.kpCount),
                LastLocalStreamCreatedTimestamp: time.Unix(0, atomic.LoadInt64(&amp;t.czData.lastStreamCreatedTime)),
                LastMessageSentTimestamp:        time.Unix(0, atomic.LoadInt64(&amp;t.czData.lastMsgSentTime)),
                LastMessageReceivedTimestamp:    time.Unix(0, atomic.LoadInt64(&amp;t.czData.lastMsgRecvTime)),
                LocalFlowControlWindow:          int64(t.fc.getSize()),
                SocketOptions:                   channelz.GetSocketOption(t.conn),
                LocalAddr:                       t.localAddr,
                RemoteAddr:                      t.remoteAddr,
                // RemoteName :
        }
        if au, ok := t.authInfo.(credentials.ChannelzSecurityInfo); ok </span><span class="cov0" title="0">{
                s.Security = au.GetSecurityValue()
        }</span>
        <span class="cov0" title="0">s.RemoteFlowControlWindow = t.getOutFlowWindow()
        return &amp;s</span>
}

func (t *http2Client) RemoteAddr() net.Addr <span class="cov0" title="0">{ return t.remoteAddr }</span>

func (t *http2Client) IncrMsgSent() <span class="cov0" title="0">{
        atomic.AddInt64(&amp;t.czData.msgSent, 1)
        atomic.StoreInt64(&amp;t.czData.lastMsgSentTime, time.Now().UnixNano())
}</span>

func (t *http2Client) IncrMsgRecv() <span class="cov0" title="0">{
        atomic.AddInt64(&amp;t.czData.msgRecv, 1)
        atomic.StoreInt64(&amp;t.czData.lastMsgRecvTime, time.Now().UnixNano())
}</span>

func (t *http2Client) getOutFlowWindow() int64 <span class="cov0" title="0">{
        resp := make(chan uint32, 1)
        timer := time.NewTimer(time.Second)
        defer timer.Stop()
        t.controlBuf.put(&amp;outFlowControlSizeRequest{resp})
        select </span>{
        case sz := &lt;-resp:<span class="cov0" title="0">
                return int64(sz)</span>
        case &lt;-t.ctxDone:<span class="cov0" title="0">
                return -1</span>
        case &lt;-timer.C:<span class="cov0" title="0">
                return -2</span>
        }
}
</pre>
		
		<pre class="file" id="file114" style="display: none">/*
 *
 * Copyright 2014 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package transport

import (
        "bytes"
        "context"
        "fmt"
        "io"
        "math"
        "net"
        "net/http"
        "strconv"
        "sync"
        "sync/atomic"
        "time"

        "github.com/golang/protobuf/proto"
        "golang.org/x/net/http2"
        "golang.org/x/net/http2/hpack"
        "google.golang.org/grpc/internal/grpcutil"
        "google.golang.org/grpc/internal/syscall"

        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/credentials"
        "google.golang.org/grpc/internal/channelz"
        "google.golang.org/grpc/internal/grpcrand"
        "google.golang.org/grpc/keepalive"
        "google.golang.org/grpc/metadata"
        "google.golang.org/grpc/peer"
        "google.golang.org/grpc/stats"
        "google.golang.org/grpc/status"
        "google.golang.org/grpc/tap"
)

var (
        // ErrIllegalHeaderWrite indicates that setting header is illegal because of
        // the stream's state.
        ErrIllegalHeaderWrite = status.Error(codes.Internal, "transport: SendHeader called multiple times")
        // ErrHeaderListSizeLimitViolation indicates that the header list size is larger
        // than the limit set by peer.
        ErrHeaderListSizeLimitViolation = status.Error(codes.Internal, "transport: trying to send header list size larger than the limit set by peer")
)

// serverConnectionCounter counts the number of connections a server has seen
// (equal to the number of http2Servers created). Must be accessed atomically.
var serverConnectionCounter uint64

// http2Server implements the ServerTransport interface with HTTP2.
type http2Server struct {
        lastRead    int64 // Keep this field 64-bit aligned. Accessed atomically.
        ctx         context.Context
        done        chan struct{}
        conn        net.Conn
        loopy       *loopyWriter
        readerDone  chan struct{} // sync point to enable testing.
        writerDone  chan struct{} // sync point to enable testing.
        remoteAddr  net.Addr
        localAddr   net.Addr
        authInfo    credentials.AuthInfo // auth info about the connection
        inTapHandle tap.ServerInHandle
        framer      *framer
        // The max number of concurrent streams.
        maxStreams uint32
        // controlBuf delivers all the control related tasks (e.g., window
        // updates, reset streams, and various settings) to the controller.
        controlBuf *controlBuffer
        fc         *trInFlow
        stats      []stats.Handler
        // Keepalive and max-age parameters for the server.
        kp keepalive.ServerParameters
        // Keepalive enforcement policy.
        kep keepalive.EnforcementPolicy
        // The time instance last ping was received.
        lastPingAt time.Time
        // Number of times the client has violated keepalive ping policy so far.
        pingStrikes uint8
        // Flag to signify that number of ping strikes should be reset to 0.
        // This is set whenever data or header frames are sent.
        // 1 means yes.
        resetPingStrikes      uint32 // Accessed atomically.
        initialWindowSize     int32
        bdpEst                *bdpEstimator
        maxSendHeaderListSize *uint32

        mu sync.Mutex // guard the following

        // drainChan is initialized when Drain() is called the first time.
        // After which the server writes out the first GoAway(with ID 2^31-1) frame.
        // Then an independent goroutine will be launched to later send the second GoAway.
        // During this time we don't want to write another first GoAway(with ID 2^31 -1) frame.
        // Thus call to Drain() will be a no-op if drainChan is already initialized since draining is
        // already underway.
        drainChan     chan struct{}
        state         transportState
        activeStreams map[uint32]*Stream
        // idle is the time instant when the connection went idle.
        // This is either the beginning of the connection or when the number of
        // RPCs go down to 0.
        // When the connection is busy, this value is set to 0.
        idle time.Time

        // Fields below are for channelz metric collection.
        channelzID *channelz.Identifier
        czData     *channelzData
        bufferPool *bufferPool

        connectionID uint64

        // maxStreamMu guards the maximum stream ID
        // This lock may not be taken if mu is already held.
        maxStreamMu sync.Mutex
        maxStreamID uint32 // max stream ID ever seen
}

// NewServerTransport creates a http2 transport with conn and configuration
// options from config.
//
// It returns a non-nil transport and a nil error on success. On failure, it
// returns a nil transport and a non-nil error. For a special case where the
// underlying conn gets closed before the client preface could be read, it
// returns a nil transport and a nil error.
func NewServerTransport(conn net.Conn, config *ServerConfig) (_ ServerTransport, err error) <span class="cov8" title="1">{
        var authInfo credentials.AuthInfo
        rawConn := conn
        if config.Credentials != nil </span><span class="cov0" title="0">{
                var err error
                conn, authInfo, err = config.Credentials.ServerHandshake(rawConn)
                if err != nil </span><span class="cov0" title="0">{
                        // ErrConnDispatched means that the connection was dispatched away
                        // from gRPC; those connections should be left open. io.EOF means
                        // the connection was closed before handshaking completed, which can
                        // happen naturally from probers. Return these errors directly.
                        if err == credentials.ErrConnDispatched || err == io.EOF </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov0" title="0">return nil, connectionErrorf(false, err, "ServerHandshake(%q) failed: %v", rawConn.RemoteAddr(), err)</span>
                }
        }
        <span class="cov8" title="1">writeBufSize := config.WriteBufferSize
        readBufSize := config.ReadBufferSize
        maxHeaderListSize := defaultServerMaxHeaderListSize
        if config.MaxHeaderListSize != nil </span><span class="cov0" title="0">{
                maxHeaderListSize = *config.MaxHeaderListSize
        }</span>
        <span class="cov8" title="1">framer := newFramer(conn, writeBufSize, readBufSize, maxHeaderListSize)
        // Send initial settings as connection preface to client.
        isettings := []http2.Setting{{
                ID:  http2.SettingMaxFrameSize,
                Val: http2MaxFrameLen,
        }}
        // TODO(zhaoq): Have a better way to signal "no limit" because 0 is
        // permitted in the HTTP2 spec.
        maxStreams := config.MaxStreams
        if maxStreams == 0 </span><span class="cov8" title="1">{
                maxStreams = math.MaxUint32
        }</span> else<span class="cov8" title="1"> {
                isettings = append(isettings, http2.Setting{
                        ID:  http2.SettingMaxConcurrentStreams,
                        Val: maxStreams,
                })
        }</span>
        <span class="cov8" title="1">dynamicWindow := true
        iwz := int32(initialWindowSize)
        if config.InitialWindowSize &gt;= defaultWindowSize </span><span class="cov8" title="1">{
                iwz = config.InitialWindowSize
                dynamicWindow = false
        }</span>
        <span class="cov8" title="1">icwz := int32(initialWindowSize)
        if config.InitialConnWindowSize &gt;= defaultWindowSize </span><span class="cov8" title="1">{
                icwz = config.InitialConnWindowSize
                dynamicWindow = false
        }</span>
        <span class="cov8" title="1">if iwz != defaultWindowSize </span><span class="cov8" title="1">{
                isettings = append(isettings, http2.Setting{
                        ID:  http2.SettingInitialWindowSize,
                        Val: uint32(iwz)})
        }</span>
        <span class="cov8" title="1">if config.MaxHeaderListSize != nil </span><span class="cov0" title="0">{
                isettings = append(isettings, http2.Setting{
                        ID:  http2.SettingMaxHeaderListSize,
                        Val: *config.MaxHeaderListSize,
                })
        }</span>
        <span class="cov8" title="1">if config.HeaderTableSize != nil </span><span class="cov0" title="0">{
                isettings = append(isettings, http2.Setting{
                        ID:  http2.SettingHeaderTableSize,
                        Val: *config.HeaderTableSize,
                })
        }</span>
        <span class="cov8" title="1">if err := framer.fr.WriteSettings(isettings...); err != nil </span><span class="cov0" title="0">{
                return nil, connectionErrorf(false, err, "transport: %v", err)
        }</span>
        // Adjust the connection flow control window if needed.
        <span class="cov8" title="1">if delta := uint32(icwz - defaultWindowSize); delta &gt; 0 </span><span class="cov8" title="1">{
                if err := framer.fr.WriteWindowUpdate(0, delta); err != nil </span><span class="cov0" title="0">{
                        return nil, connectionErrorf(false, err, "transport: %v", err)
                }</span>
        }
        <span class="cov8" title="1">kp := config.KeepaliveParams
        if kp.MaxConnectionIdle == 0 </span><span class="cov8" title="1">{
                kp.MaxConnectionIdle = defaultMaxConnectionIdle
        }</span>
        <span class="cov8" title="1">if kp.MaxConnectionAge == 0 </span><span class="cov8" title="1">{
                kp.MaxConnectionAge = defaultMaxConnectionAge
        }</span>
        // Add a jitter to MaxConnectionAge.
        <span class="cov8" title="1">kp.MaxConnectionAge += getJitter(kp.MaxConnectionAge)
        if kp.MaxConnectionAgeGrace == 0 </span><span class="cov8" title="1">{
                kp.MaxConnectionAgeGrace = defaultMaxConnectionAgeGrace
        }</span>
        <span class="cov8" title="1">if kp.Time == 0 </span><span class="cov8" title="1">{
                kp.Time = defaultServerKeepaliveTime
        }</span>
        <span class="cov8" title="1">if kp.Timeout == 0 </span><span class="cov8" title="1">{
                kp.Timeout = defaultServerKeepaliveTimeout
        }</span>
        <span class="cov8" title="1">if kp.Time != infinity </span><span class="cov8" title="1">{
                if err = syscall.SetTCPUserTimeout(conn, kp.Timeout); err != nil </span><span class="cov0" title="0">{
                        return nil, connectionErrorf(false, err, "transport: failed to set TCP_USER_TIMEOUT: %v", err)
                }</span>
        }
        <span class="cov8" title="1">kep := config.KeepalivePolicy
        if kep.MinTime == 0 </span><span class="cov8" title="1">{
                kep.MinTime = defaultKeepalivePolicyMinTime
        }</span>

        <span class="cov8" title="1">done := make(chan struct{})
        t := &amp;http2Server{
                ctx:               setConnection(context.Background(), rawConn),
                done:              done,
                conn:              conn,
                remoteAddr:        conn.RemoteAddr(),
                localAddr:         conn.LocalAddr(),
                authInfo:          authInfo,
                framer:            framer,
                readerDone:        make(chan struct{}),
                writerDone:        make(chan struct{}),
                maxStreams:        maxStreams,
                inTapHandle:       config.InTapHandle,
                fc:                &amp;trInFlow{limit: uint32(icwz)},
                state:             reachable,
                activeStreams:     make(map[uint32]*Stream),
                stats:             config.StatsHandlers,
                kp:                kp,
                idle:              time.Now(),
                kep:               kep,
                initialWindowSize: iwz,
                czData:            new(channelzData),
                bufferPool:        newBufferPool(),
        }
        t.controlBuf = newControlBuffer(t.done)
        if dynamicWindow </span><span class="cov8" title="1">{
                t.bdpEst = &amp;bdpEstimator{
                        bdp:               initialWindowSize,
                        updateFlowControl: t.updateFlowControl,
                }
        }</span>
        <span class="cov8" title="1">for _, sh := range t.stats </span><span class="cov0" title="0">{
                t.ctx = sh.TagConn(t.ctx, &amp;stats.ConnTagInfo{
                        RemoteAddr: t.remoteAddr,
                        LocalAddr:  t.localAddr,
                })
                connBegin := &amp;stats.ConnBegin{}
                sh.HandleConn(t.ctx, connBegin)
        }</span>
        <span class="cov8" title="1">t.channelzID, err = channelz.RegisterNormalSocket(t, config.ChannelzParentID, fmt.Sprintf("%s -&gt; %s", t.remoteAddr, t.localAddr))
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov8" title="1">t.connectionID = atomic.AddUint64(&amp;serverConnectionCounter, 1)
        t.framer.writer.Flush()

        defer func() </span><span class="cov8" title="1">{
                if err != nil </span><span class="cov0" title="0">{
                        t.Close()
                }</span>
        }()

        // Check the validity of client preface.
        <span class="cov8" title="1">preface := make([]byte, len(clientPreface))
        if _, err := io.ReadFull(t.conn, preface); err != nil </span><span class="cov0" title="0">{
                // In deployments where a gRPC server runs behind a cloud load balancer
                // which performs regular TCP level health checks, the connection is
                // closed immediately by the latter.  Returning io.EOF here allows the
                // grpc server implementation to recognize this scenario and suppress
                // logging to reduce spam.
                if err == io.EOF </span><span class="cov0" title="0">{
                        return nil, io.EOF
                }</span>
                <span class="cov0" title="0">return nil, connectionErrorf(false, err, "transport: http2Server.HandleStreams failed to receive the preface from client: %v", err)</span>
        }
        <span class="cov8" title="1">if !bytes.Equal(preface, clientPreface) </span><span class="cov0" title="0">{
                return nil, connectionErrorf(false, nil, "transport: http2Server.HandleStreams received bogus greeting from client: %q", preface)
        }</span>

        <span class="cov8" title="1">frame, err := t.framer.fr.ReadFrame()
        if err == io.EOF || err == io.ErrUnexpectedEOF </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">if err != nil </span><span class="cov0" title="0">{
                return nil, connectionErrorf(false, err, "transport: http2Server.HandleStreams failed to read initial settings frame: %v", err)
        }</span>
        <span class="cov8" title="1">atomic.StoreInt64(&amp;t.lastRead, time.Now().UnixNano())
        sf, ok := frame.(*http2.SettingsFrame)
        if !ok </span><span class="cov0" title="0">{
                return nil, connectionErrorf(false, nil, "transport: http2Server.HandleStreams saw invalid preface type %T from client", frame)
        }</span>
        <span class="cov8" title="1">t.handleSettings(sf)

        go func() </span><span class="cov8" title="1">{
                t.loopy = newLoopyWriter(serverSide, t.framer, t.controlBuf, t.bdpEst)
                t.loopy.ssGoAwayHandler = t.outgoingGoAwayHandler
                if err := t.loopy.run(); err != nil </span><span class="cov8" title="1">{
                        if logger.V(logLevel) </span><span class="cov0" title="0">{
                                logger.Errorf("transport: loopyWriter.run returning. Err: %v", err)
                        }</span>
                }
                <span class="cov8" title="1">t.conn.Close()
                t.controlBuf.finish()
                close(t.writerDone)</span>
        }()
        <span class="cov8" title="1">go t.keepalive()
        return t, nil</span>
}

// operateHeader takes action on the decoded headers.
func (t *http2Server) operateHeaders(frame *http2.MetaHeadersFrame, handle func(*Stream), traceCtx func(context.Context, string) context.Context) (fatal bool) <span class="cov8" title="1">{
        // Acquire max stream ID lock for entire duration
        t.maxStreamMu.Lock()
        defer t.maxStreamMu.Unlock()

        streamID := frame.Header().StreamID

        // frame.Truncated is set to true when framer detects that the current header
        // list size hits MaxHeaderListSize limit.
        if frame.Truncated </span><span class="cov0" title="0">{
                t.controlBuf.put(&amp;cleanupStream{
                        streamID: streamID,
                        rst:      true,
                        rstCode:  http2.ErrCodeFrameSize,
                        onWrite:  func() </span>{<span class="cov0" title="0">}</span>,
                })
                <span class="cov0" title="0">return false</span>
        }

        <span class="cov8" title="1">if streamID%2 != 1 || streamID &lt;= t.maxStreamID </span><span class="cov0" title="0">{
                // illegal gRPC stream id.
                if logger.V(logLevel) </span><span class="cov0" title="0">{
                        logger.Errorf("transport: http2Server.HandleStreams received an illegal stream id: %v", streamID)
                }</span>
                <span class="cov0" title="0">return true</span>
        }
        <span class="cov8" title="1">t.maxStreamID = streamID

        buf := newRecvBuffer()
        s := &amp;Stream{
                id:  streamID,
                st:  t,
                buf: buf,
                fc:  &amp;inFlow{limit: uint32(t.initialWindowSize)},
        }
        var (
                // If a gRPC Response-Headers has already been received, then it means
                // that the peer is speaking gRPC and we are in gRPC mode.
                isGRPC     = false
                mdata      = make(map[string][]string)
                httpMethod string
                // headerError is set if an error is encountered while parsing the headers
                headerError bool

                timeoutSet bool
                timeout    time.Duration
        )

        for _, hf := range frame.Fields </span><span class="cov8" title="1">{
                switch hf.Name </span>{
                case "content-type":<span class="cov8" title="1">
                        contentSubtype, validContentType := grpcutil.ContentSubtype(hf.Value)
                        if !validContentType </span><span class="cov0" title="0">{
                                break</span>
                        }
                        <span class="cov8" title="1">mdata[hf.Name] = append(mdata[hf.Name], hf.Value)
                        s.contentSubtype = contentSubtype
                        isGRPC = true</span>
                case "grpc-encoding":<span class="cov0" title="0">
                        s.recvCompress = hf.Value</span>
                case ":method":<span class="cov8" title="1">
                        httpMethod = hf.Value</span>
                case ":path":<span class="cov8" title="1">
                        s.method = hf.Value</span>
                case "grpc-timeout":<span class="cov8" title="1">
                        timeoutSet = true
                        var err error
                        if timeout, err = decodeTimeout(hf.Value); err != nil </span><span class="cov0" title="0">{
                                headerError = true
                        }</span>
                // "Transports must consider requests containing the Connection header
                // as malformed." - A41
                case "connection":<span class="cov8" title="1">
                        if logger.V(logLevel) </span><span class="cov0" title="0">{
                                logger.Errorf("transport: http2Server.operateHeaders parsed a :connection header which makes a request malformed as per the HTTP/2 spec")
                        }</span>
                        <span class="cov8" title="1">headerError = true</span>
                default:<span class="cov8" title="1">
                        if isReservedHeader(hf.Name) &amp;&amp; !isWhitelistedHeader(hf.Name) </span><span class="cov8" title="1">{
                                break</span>
                        }
                        <span class="cov8" title="1">v, err := decodeMetadataHeader(hf.Name, hf.Value)
                        if err != nil </span><span class="cov0" title="0">{
                                headerError = true
                                logger.Warningf("Failed to decode metadata header (%q, %q): %v", hf.Name, hf.Value, err)
                                break</span>
                        }
                        <span class="cov8" title="1">mdata[hf.Name] = append(mdata[hf.Name], v)</span>
                }
        }

        // "If multiple Host headers or multiple :authority headers are present, the
        // request must be rejected with an HTTP status code 400 as required by Host
        // validation in RFC 7230 §5.4, gRPC status code INTERNAL, or RST_STREAM
        // with HTTP/2 error code PROTOCOL_ERROR." - A41. Since this is a HTTP/2
        // error, this takes precedence over a client not speaking gRPC.
        <span class="cov8" title="1">if len(mdata[":authority"]) &gt; 1 || len(mdata["host"]) &gt; 1 </span><span class="cov8" title="1">{
                errMsg := fmt.Sprintf("num values of :authority: %v, num values of host: %v, both must only have 1 value as per HTTP/2 spec", len(mdata[":authority"]), len(mdata["host"]))
                if logger.V(logLevel) </span><span class="cov0" title="0">{
                        logger.Errorf("transport: %v", errMsg)
                }</span>
                <span class="cov8" title="1">t.controlBuf.put(&amp;earlyAbortStream{
                        httpStatus:     400,
                        streamID:       streamID,
                        contentSubtype: s.contentSubtype,
                        status:         status.New(codes.Internal, errMsg),
                        rst:            !frame.StreamEnded(),
                })
                return false</span>
        }

        <span class="cov8" title="1">if !isGRPC || headerError </span><span class="cov8" title="1">{
                t.controlBuf.put(&amp;cleanupStream{
                        streamID: streamID,
                        rst:      true,
                        rstCode:  http2.ErrCodeProtocol,
                        onWrite:  func() </span>{<span class="cov8" title="1">}</span>,
                })
                <span class="cov8" title="1">return false</span>
        }

        // "If :authority is missing, Host must be renamed to :authority." - A41
        <span class="cov8" title="1">if len(mdata[":authority"]) == 0 </span><span class="cov0" title="0">{
                // No-op if host isn't present, no eventual :authority header is a valid
                // RPC.
                if host, ok := mdata["host"]; ok </span><span class="cov0" title="0">{
                        mdata[":authority"] = host
                        delete(mdata, "host")
                }</span>
        } else<span class="cov8" title="1"> {
                // "If :authority is present, Host must be discarded" - A41
                delete(mdata, "host")
        }</span>

        <span class="cov8" title="1">if frame.StreamEnded() </span><span class="cov0" title="0">{
                // s is just created by the caller. No lock needed.
                s.state = streamReadDone
        }</span>
        <span class="cov8" title="1">if timeoutSet </span><span class="cov8" title="1">{
                s.ctx, s.cancel = context.WithTimeout(t.ctx, timeout)
        }</span> else<span class="cov8" title="1"> {
                s.ctx, s.cancel = context.WithCancel(t.ctx)
        }</span>
        <span class="cov8" title="1">pr := &amp;peer.Peer{
                Addr: t.remoteAddr,
        }
        // Attach Auth info if there is any.
        if t.authInfo != nil </span><span class="cov0" title="0">{
                pr.AuthInfo = t.authInfo
        }</span>
        <span class="cov8" title="1">s.ctx = peer.NewContext(s.ctx, pr)
        // Attach the received metadata to the context.
        if len(mdata) &gt; 0 </span><span class="cov8" title="1">{
                s.ctx = metadata.NewIncomingContext(s.ctx, mdata)
                if statsTags := mdata["grpc-tags-bin"]; len(statsTags) &gt; 0 </span><span class="cov0" title="0">{
                        s.ctx = stats.SetIncomingTags(s.ctx, []byte(statsTags[len(statsTags)-1]))
                }</span>
                <span class="cov8" title="1">if statsTrace := mdata["grpc-trace-bin"]; len(statsTrace) &gt; 0 </span><span class="cov0" title="0">{
                        s.ctx = stats.SetIncomingTrace(s.ctx, []byte(statsTrace[len(statsTrace)-1]))
                }</span>
        }
        <span class="cov8" title="1">t.mu.Lock()
        if t.state != reachable </span><span class="cov0" title="0">{
                t.mu.Unlock()
                s.cancel()
                return false
        }</span>
        <span class="cov8" title="1">if uint32(len(t.activeStreams)) &gt;= t.maxStreams </span><span class="cov8" title="1">{
                t.mu.Unlock()
                t.controlBuf.put(&amp;cleanupStream{
                        streamID: streamID,
                        rst:      true,
                        rstCode:  http2.ErrCodeRefusedStream,
                        onWrite:  func() </span>{<span class="cov8" title="1">}</span>,
                })
                <span class="cov8" title="1">s.cancel()
                return false</span>
        }
        <span class="cov8" title="1">if httpMethod != http.MethodPost </span><span class="cov8" title="1">{
                t.mu.Unlock()
                errMsg := fmt.Sprintf("http2Server.operateHeaders parsed a :method field: %v which should be POST", httpMethod)
                if logger.V(logLevel) </span><span class="cov0" title="0">{
                        logger.Infof("transport: %v", errMsg)
                }</span>
                <span class="cov8" title="1">t.controlBuf.put(&amp;earlyAbortStream{
                        httpStatus:     405,
                        streamID:       streamID,
                        contentSubtype: s.contentSubtype,
                        status:         status.New(codes.Internal, errMsg),
                        rst:            !frame.StreamEnded(),
                })
                s.cancel()
                return false</span>
        }
        <span class="cov8" title="1">if t.inTapHandle != nil </span><span class="cov0" title="0">{
                var err error
                if s.ctx, err = t.inTapHandle(s.ctx, &amp;tap.Info{FullMethodName: s.method}); err != nil </span><span class="cov0" title="0">{
                        t.mu.Unlock()
                        if logger.V(logLevel) </span><span class="cov0" title="0">{
                                logger.Infof("transport: http2Server.operateHeaders got an error from InTapHandle: %v", err)
                        }</span>
                        <span class="cov0" title="0">stat, ok := status.FromError(err)
                        if !ok </span><span class="cov0" title="0">{
                                stat = status.New(codes.PermissionDenied, err.Error())
                        }</span>
                        <span class="cov0" title="0">t.controlBuf.put(&amp;earlyAbortStream{
                                httpStatus:     200,
                                streamID:       s.id,
                                contentSubtype: s.contentSubtype,
                                status:         stat,
                                rst:            !frame.StreamEnded(),
                        })
                        return false</span>
                }
        }
        <span class="cov8" title="1">t.activeStreams[streamID] = s
        if len(t.activeStreams) == 1 </span><span class="cov8" title="1">{
                t.idle = time.Time{}
        }</span>
        <span class="cov8" title="1">t.mu.Unlock()
        if channelz.IsOn() </span><span class="cov0" title="0">{
                atomic.AddInt64(&amp;t.czData.streamsStarted, 1)
                atomic.StoreInt64(&amp;t.czData.lastStreamCreatedTime, time.Now().UnixNano())
        }</span>
        <span class="cov8" title="1">s.requestRead = func(n int) </span><span class="cov8" title="1">{
                t.adjustWindow(s, uint32(n))
        }</span>
        <span class="cov8" title="1">s.ctx = traceCtx(s.ctx, s.method)
        for _, sh := range t.stats </span><span class="cov0" title="0">{
                s.ctx = sh.TagRPC(s.ctx, &amp;stats.RPCTagInfo{FullMethodName: s.method})
                inHeader := &amp;stats.InHeader{
                        FullMethod:  s.method,
                        RemoteAddr:  t.remoteAddr,
                        LocalAddr:   t.localAddr,
                        Compression: s.recvCompress,
                        WireLength:  int(frame.Header().Length),
                        Header:      metadata.MD(mdata).Copy(),
                }
                sh.HandleRPC(s.ctx, inHeader)
        }</span>
        <span class="cov8" title="1">s.ctxDone = s.ctx.Done()
        s.wq = newWriteQuota(defaultWriteQuota, s.ctxDone)
        s.trReader = &amp;transportReader{
                reader: &amp;recvBufferReader{
                        ctx:        s.ctx,
                        ctxDone:    s.ctxDone,
                        recv:       s.buf,
                        freeBuffer: t.bufferPool.put,
                },
                windowHandler: func(n int) </span><span class="cov8" title="1">{
                        t.updateWindow(s, uint32(n))
                }</span>,
        }
        // Register the stream with loopy.
        <span class="cov8" title="1">t.controlBuf.put(&amp;registerStream{
                streamID: s.id,
                wq:       s.wq,
        })
        handle(s)
        return false</span>
}

// HandleStreams receives incoming streams using the given handler. This is
// typically run in a separate goroutine.
// traceCtx attaches trace to ctx and returns the new context.
func (t *http2Server) HandleStreams(handle func(*Stream), traceCtx func(context.Context, string) context.Context) <span class="cov8" title="1">{
        defer close(t.readerDone)
        for </span><span class="cov8" title="1">{
                t.controlBuf.throttle()
                frame, err := t.framer.fr.ReadFrame()
                atomic.StoreInt64(&amp;t.lastRead, time.Now().UnixNano())
                if err != nil </span><span class="cov8" title="1">{
                        if se, ok := err.(http2.StreamError); ok </span><span class="cov8" title="1">{
                                if logger.V(logLevel) </span><span class="cov0" title="0">{
                                        logger.Warningf("transport: http2Server.HandleStreams encountered http2.StreamError: %v", se)
                                }</span>
                                <span class="cov8" title="1">t.mu.Lock()
                                s := t.activeStreams[se.StreamID]
                                t.mu.Unlock()
                                if s != nil </span><span class="cov0" title="0">{
                                        t.closeStream(s, true, se.Code, false)
                                }</span> else<span class="cov8" title="1"> {
                                        t.controlBuf.put(&amp;cleanupStream{
                                                streamID: se.StreamID,
                                                rst:      true,
                                                rstCode:  se.Code,
                                                onWrite:  func() </span>{<span class="cov8" title="1">}</span>,
                                        })
                                }
                                <span class="cov8" title="1">continue</span>
                        }
                        <span class="cov8" title="1">if err == io.EOF || err == io.ErrUnexpectedEOF </span><span class="cov8" title="1">{
                                t.Close()
                                return
                        }</span>
                        <span class="cov8" title="1">if logger.V(logLevel) </span><span class="cov0" title="0">{
                                logger.Warningf("transport: http2Server.HandleStreams failed to read frame: %v", err)
                        }</span>
                        <span class="cov8" title="1">t.Close()
                        return</span>
                }
                <span class="cov8" title="1">switch frame := frame.(type) </span>{
                case *http2.MetaHeadersFrame:<span class="cov8" title="1">
                        if t.operateHeaders(frame, handle, traceCtx) </span><span class="cov0" title="0">{
                                t.Close()
                                break</span>
                        }
                case *http2.DataFrame:<span class="cov8" title="1">
                        t.handleData(frame)</span>
                case *http2.RSTStreamFrame:<span class="cov8" title="1">
                        t.handleRSTStream(frame)</span>
                case *http2.SettingsFrame:<span class="cov8" title="1">
                        t.handleSettings(frame)</span>
                case *http2.PingFrame:<span class="cov8" title="1">
                        t.handlePing(frame)</span>
                case *http2.WindowUpdateFrame:<span class="cov8" title="1">
                        t.handleWindowUpdate(frame)</span>
                case *http2.GoAwayFrame:<span class="cov0" title="0"></span>
                        // TODO: Handle GoAway from the client appropriately.
                default:<span class="cov0" title="0">
                        if logger.V(logLevel) </span><span class="cov0" title="0">{
                                logger.Errorf("transport: http2Server.HandleStreams found unhandled frame type %v.", frame)
                        }</span>
                }
        }
}

func (t *http2Server) getStream(f http2.Frame) (*Stream, bool) <span class="cov8" title="1">{
        t.mu.Lock()
        defer t.mu.Unlock()
        if t.activeStreams == nil </span><span class="cov8" title="1">{
                // The transport is closing.
                return nil, false
        }</span>
        <span class="cov8" title="1">s, ok := t.activeStreams[f.Header().StreamID]
        if !ok </span><span class="cov8" title="1">{
                // The stream is already done.
                return nil, false
        }</span>
        <span class="cov8" title="1">return s, true</span>
}

// adjustWindow sends out extra window update over the initial window size
// of stream if the application is requesting data larger in size than
// the window.
func (t *http2Server) adjustWindow(s *Stream, n uint32) <span class="cov8" title="1">{
        if w := s.fc.maybeAdjust(n); w &gt; 0 </span><span class="cov8" title="1">{
                t.controlBuf.put(&amp;outgoingWindowUpdate{streamID: s.id, increment: w})
        }</span>

}

// updateWindow adjusts the inbound quota for the stream and the transport.
// Window updates will deliver to the controller for sending when
// the cumulative quota exceeds the corresponding threshold.
func (t *http2Server) updateWindow(s *Stream, n uint32) <span class="cov8" title="1">{
        if w := s.fc.onRead(n); w &gt; 0 </span><span class="cov8" title="1">{
                t.controlBuf.put(&amp;outgoingWindowUpdate{streamID: s.id,
                        increment: w,
                })
        }</span>
}

// updateFlowControl updates the incoming flow control windows
// for the transport and the stream based on the current bdp
// estimation.
func (t *http2Server) updateFlowControl(n uint32) <span class="cov8" title="1">{
        t.mu.Lock()
        for _, s := range t.activeStreams </span><span class="cov8" title="1">{
                s.fc.newLimit(n)
        }</span>
        <span class="cov8" title="1">t.initialWindowSize = int32(n)
        t.mu.Unlock()
        t.controlBuf.put(&amp;outgoingWindowUpdate{
                streamID:  0,
                increment: t.fc.newLimit(n),
        })
        t.controlBuf.put(&amp;outgoingSettings{
                ss: []http2.Setting{
                        {
                                ID:  http2.SettingInitialWindowSize,
                                Val: n,
                        },
                },
        })</span>

}

func (t *http2Server) handleData(f *http2.DataFrame) <span class="cov8" title="1">{
        size := f.Header().Length
        var sendBDPPing bool
        if t.bdpEst != nil </span><span class="cov8" title="1">{
                sendBDPPing = t.bdpEst.add(size)
        }</span>
        // Decouple connection's flow control from application's read.
        // An update on connection's flow control should not depend on
        // whether user application has read the data or not. Such a
        // restriction is already imposed on the stream's flow control,
        // and therefore the sender will be blocked anyways.
        // Decoupling the connection flow control will prevent other
        // active(fast) streams from starving in presence of slow or
        // inactive streams.
        <span class="cov8" title="1">if w := t.fc.onData(size); w &gt; 0 </span><span class="cov8" title="1">{
                t.controlBuf.put(&amp;outgoingWindowUpdate{
                        streamID:  0,
                        increment: w,
                })
        }</span>
        <span class="cov8" title="1">if sendBDPPing </span><span class="cov8" title="1">{
                // Avoid excessive ping detection (e.g. in an L7 proxy)
                // by sending a window update prior to the BDP ping.
                if w := t.fc.reset(); w &gt; 0 </span><span class="cov8" title="1">{
                        t.controlBuf.put(&amp;outgoingWindowUpdate{
                                streamID:  0,
                                increment: w,
                        })
                }</span>
                <span class="cov8" title="1">t.controlBuf.put(bdpPing)</span>
        }
        // Select the right stream to dispatch.
        <span class="cov8" title="1">s, ok := t.getStream(f)
        if !ok </span><span class="cov8" title="1">{
                return
        }</span>
        <span class="cov8" title="1">if s.getState() == streamReadDone </span><span class="cov0" title="0">{
                t.closeStream(s, true, http2.ErrCodeStreamClosed, false)
                return
        }</span>
        <span class="cov8" title="1">if size &gt; 0 </span><span class="cov8" title="1">{
                if err := s.fc.onData(size); err != nil </span><span class="cov8" title="1">{
                        t.closeStream(s, true, http2.ErrCodeFlowControl, false)
                        return
                }</span>
                <span class="cov8" title="1">if f.Header().Flags.Has(http2.FlagDataPadded) </span><span class="cov0" title="0">{
                        if w := s.fc.onRead(size - uint32(len(f.Data()))); w &gt; 0 </span><span class="cov0" title="0">{
                                t.controlBuf.put(&amp;outgoingWindowUpdate{s.id, w})
                        }</span>
                }
                // TODO(bradfitz, zhaoq): A copy is required here because there is no
                // guarantee f.Data() is consumed before the arrival of next frame.
                // Can this copy be eliminated?
                <span class="cov8" title="1">if len(f.Data()) &gt; 0 </span><span class="cov8" title="1">{
                        buffer := t.bufferPool.get()
                        buffer.Reset()
                        buffer.Write(f.Data())
                        s.write(recvMsg{buffer: buffer})
                }</span>
        }
        <span class="cov8" title="1">if f.StreamEnded() </span><span class="cov8" title="1">{
                // Received the end of stream from the client.
                s.compareAndSwapState(streamActive, streamReadDone)
                s.write(recvMsg{err: io.EOF})
        }</span>
}

func (t *http2Server) handleRSTStream(f *http2.RSTStreamFrame) <span class="cov8" title="1">{
        // If the stream is not deleted from the transport's active streams map, then do a regular close stream.
        if s, ok := t.getStream(f); ok </span><span class="cov8" title="1">{
                t.closeStream(s, false, 0, false)
                return
        }</span>
        // If the stream is already deleted from the active streams map, then put a cleanupStream item into controlbuf to delete the stream from loopy writer's established streams map.
        <span class="cov8" title="1">t.controlBuf.put(&amp;cleanupStream{
                streamID: f.Header().StreamID,
                rst:      false,
                rstCode:  0,
                onWrite:  func() </span>{<span class="cov0" title="0">}</span>,
        })
}

func (t *http2Server) handleSettings(f *http2.SettingsFrame) <span class="cov8" title="1">{
        if f.IsAck() </span><span class="cov8" title="1">{
                return
        }</span>
        <span class="cov8" title="1">var ss []http2.Setting
        var updateFuncs []func()
        f.ForeachSetting(func(s http2.Setting) error </span><span class="cov8" title="1">{
                switch s.ID </span>{
                case http2.SettingMaxHeaderListSize:<span class="cov0" title="0">
                        updateFuncs = append(updateFuncs, func() </span><span class="cov0" title="0">{
                                t.maxSendHeaderListSize = new(uint32)
                                *t.maxSendHeaderListSize = s.Val
                        }</span>)
                default:<span class="cov8" title="1">
                        ss = append(ss, s)</span>
                }
                <span class="cov8" title="1">return nil</span>
        })
        <span class="cov8" title="1">t.controlBuf.executeAndPut(func(interface{}) bool </span><span class="cov8" title="1">{
                for _, f := range updateFuncs </span><span class="cov0" title="0">{
                        f()
                }</span>
                <span class="cov8" title="1">return true</span>
        }, &amp;incomingSettings{
                ss: ss,
        })
}

const (
        maxPingStrikes     = 2
        defaultPingTimeout = 2 * time.Hour
)

func (t *http2Server) handlePing(f *http2.PingFrame) <span class="cov8" title="1">{
        if f.IsAck() </span><span class="cov8" title="1">{
                if f.Data == goAwayPing.data &amp;&amp; t.drainChan != nil </span><span class="cov8" title="1">{
                        close(t.drainChan)
                        return
                }</span>
                // Maybe it's a BDP ping.
                <span class="cov8" title="1">if t.bdpEst != nil </span><span class="cov8" title="1">{
                        t.bdpEst.calculate(f.Data)
                }</span>
                <span class="cov8" title="1">return</span>
        }
        <span class="cov8" title="1">pingAck := &amp;ping{ack: true}
        copy(pingAck.data[:], f.Data[:])
        t.controlBuf.put(pingAck)

        now := time.Now()
        defer func() </span><span class="cov8" title="1">{
                t.lastPingAt = now
        }</span>()
        // A reset ping strikes means that we don't need to check for policy
        // violation for this ping and the pingStrikes counter should be set
        // to 0.
        <span class="cov8" title="1">if atomic.CompareAndSwapUint32(&amp;t.resetPingStrikes, 1, 0) </span><span class="cov8" title="1">{
                t.pingStrikes = 0
                return
        }</span>
        <span class="cov8" title="1">t.mu.Lock()
        ns := len(t.activeStreams)
        t.mu.Unlock()
        if ns &lt; 1 &amp;&amp; !t.kep.PermitWithoutStream </span><span class="cov8" title="1">{
                // Keepalive shouldn't be active thus, this new ping should
                // have come after at least defaultPingTimeout.
                if t.lastPingAt.Add(defaultPingTimeout).After(now) </span><span class="cov8" title="1">{
                        t.pingStrikes++
                }</span>
        } else<span class="cov8" title="1"> {
                // Check if keepalive policy is respected.
                if t.lastPingAt.Add(t.kep.MinTime).After(now) </span><span class="cov8" title="1">{
                        t.pingStrikes++
                }</span>
        }

        <span class="cov8" title="1">if t.pingStrikes &gt; maxPingStrikes </span><span class="cov8" title="1">{
                // Send goaway and close the connection.
                if logger.V(logLevel) </span><span class="cov0" title="0">{
                        logger.Errorf("transport: Got too many pings from the client, closing the connection.")
                }</span>
                <span class="cov8" title="1">t.controlBuf.put(&amp;goAway{code: http2.ErrCodeEnhanceYourCalm, debugData: []byte("too_many_pings"), closeConn: true})</span>
        }
}

func (t *http2Server) handleWindowUpdate(f *http2.WindowUpdateFrame) <span class="cov8" title="1">{
        t.controlBuf.put(&amp;incomingWindowUpdate{
                streamID:  f.Header().StreamID,
                increment: f.Increment,
        })
}</span>

func appendHeaderFieldsFromMD(headerFields []hpack.HeaderField, md metadata.MD) []hpack.HeaderField <span class="cov8" title="1">{
        for k, vv := range md </span><span class="cov0" title="0">{
                if isReservedHeader(k) </span><span class="cov0" title="0">{
                        // Clients don't tolerate reading restricted headers after some non restricted ones were sent.
                        continue</span>
                }
                <span class="cov0" title="0">for _, v := range vv </span><span class="cov0" title="0">{
                        headerFields = append(headerFields, hpack.HeaderField{Name: k, Value: encodeMetadataHeader(k, v)})
                }</span>
        }
        <span class="cov8" title="1">return headerFields</span>
}

func (t *http2Server) checkForHeaderListSize(it interface{}) bool <span class="cov8" title="1">{
        if t.maxSendHeaderListSize == nil </span><span class="cov8" title="1">{
                return true
        }</span>
        <span class="cov0" title="0">hdrFrame := it.(*headerFrame)
        var sz int64
        for _, f := range hdrFrame.hf </span><span class="cov0" title="0">{
                if sz += int64(f.Size()); sz &gt; int64(*t.maxSendHeaderListSize) </span><span class="cov0" title="0">{
                        if logger.V(logLevel) </span><span class="cov0" title="0">{
                                logger.Errorf("header list size to send violates the maximum size (%d bytes) set by client", *t.maxSendHeaderListSize)
                        }</span>
                        <span class="cov0" title="0">return false</span>
                }
        }
        <span class="cov0" title="0">return true</span>
}

func (t *http2Server) streamContextErr(s *Stream) error <span class="cov0" title="0">{
        select </span>{
        case &lt;-t.done:<span class="cov0" title="0">
                return ErrConnClosing</span>
        default:<span class="cov0" title="0"></span>
        }
        <span class="cov0" title="0">return ContextErr(s.ctx.Err())</span>
}

// WriteHeader sends the header metadata md back to the client.
func (t *http2Server) WriteHeader(s *Stream, md metadata.MD) error <span class="cov8" title="1">{
        s.hdrMu.Lock()
        defer s.hdrMu.Unlock()
        if s.getState() == streamDone </span><span class="cov0" title="0">{
                return t.streamContextErr(s)
        }</span>

        <span class="cov8" title="1">if s.updateHeaderSent() </span><span class="cov0" title="0">{
                return ErrIllegalHeaderWrite
        }</span>

        <span class="cov8" title="1">if md.Len() &gt; 0 </span><span class="cov0" title="0">{
                if s.header.Len() &gt; 0 </span><span class="cov0" title="0">{
                        s.header = metadata.Join(s.header, md)
                }</span> else<span class="cov0" title="0"> {
                        s.header = md
                }</span>
        }
        <span class="cov8" title="1">if err := t.writeHeaderLocked(s); err != nil </span><span class="cov0" title="0">{
                return status.Convert(err).Err()
        }</span>
        <span class="cov8" title="1">return nil</span>
}

func (t *http2Server) setResetPingStrikes() <span class="cov8" title="1">{
        atomic.StoreUint32(&amp;t.resetPingStrikes, 1)
}</span>

func (t *http2Server) writeHeaderLocked(s *Stream) error <span class="cov8" title="1">{
        // TODO(mmukhi): Benchmark if the performance gets better if count the metadata and other header fields
        // first and create a slice of that exact size.
        headerFields := make([]hpack.HeaderField, 0, 2) // at least :status, content-type will be there if none else.
        headerFields = append(headerFields, hpack.HeaderField{Name: ":status", Value: "200"})
        headerFields = append(headerFields, hpack.HeaderField{Name: "content-type", Value: grpcutil.ContentType(s.contentSubtype)})
        if s.sendCompress != "" </span><span class="cov0" title="0">{
                headerFields = append(headerFields, hpack.HeaderField{Name: "grpc-encoding", Value: s.sendCompress})
        }</span>
        <span class="cov8" title="1">headerFields = appendHeaderFieldsFromMD(headerFields, s.header)
        success, err := t.controlBuf.executeAndPut(t.checkForHeaderListSize, &amp;headerFrame{
                streamID:  s.id,
                hf:        headerFields,
                endStream: false,
                onWrite:   t.setResetPingStrikes,
        })
        if !success </span><span class="cov0" title="0">{
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov0" title="0">t.closeStream(s, true, http2.ErrCodeInternal, false)
                return ErrHeaderListSizeLimitViolation</span>
        }
        <span class="cov8" title="1">for _, sh := range t.stats </span><span class="cov0" title="0">{
                // Note: Headers are compressed with hpack after this call returns.
                // No WireLength field is set here.
                outHeader := &amp;stats.OutHeader{
                        Header:      s.header.Copy(),
                        Compression: s.sendCompress,
                }
                sh.HandleRPC(s.Context(), outHeader)
        }</span>
        <span class="cov8" title="1">return nil</span>
}

// WriteStatus sends stream status to the client and terminates the stream.
// There is no further I/O operations being able to perform on this stream.
// TODO(zhaoq): Now it indicates the end of entire stream. Revisit if early
// OK is adopted.
func (t *http2Server) WriteStatus(s *Stream, st *status.Status) error <span class="cov8" title="1">{
        s.hdrMu.Lock()
        defer s.hdrMu.Unlock()

        if s.getState() == streamDone </span><span class="cov0" title="0">{
                return nil
        }</span>

        // TODO(mmukhi): Benchmark if the performance gets better if count the metadata and other header fields
        // first and create a slice of that exact size.
        <span class="cov8" title="1">headerFields := make([]hpack.HeaderField, 0, 2) // grpc-status and grpc-message will be there if none else.
        if !s.updateHeaderSent() </span><span class="cov8" title="1">{                      // No headers have been sent.
                if len(s.header) &gt; 0 </span><span class="cov0" title="0">{ // Send a separate header frame.
                        if err := t.writeHeaderLocked(s); err != nil </span><span class="cov0" title="0">{
                                return err
                        }</span>
                } else<span class="cov8" title="1"> { // Send a trailer only response.
                        headerFields = append(headerFields, hpack.HeaderField{Name: ":status", Value: "200"})
                        headerFields = append(headerFields, hpack.HeaderField{Name: "content-type", Value: grpcutil.ContentType(s.contentSubtype)})
                }</span>
        }
        <span class="cov8" title="1">headerFields = append(headerFields, hpack.HeaderField{Name: "grpc-status", Value: strconv.Itoa(int(st.Code()))})
        headerFields = append(headerFields, hpack.HeaderField{Name: "grpc-message", Value: encodeGrpcMessage(st.Message())})

        if p := st.Proto(); p != nil &amp;&amp; len(p.Details) &gt; 0 </span><span class="cov0" title="0">{
                stBytes, err := proto.Marshal(p)
                if err != nil </span><span class="cov0" title="0">{
                        // TODO: return error instead, when callers are able to handle it.
                        logger.Errorf("transport: failed to marshal rpc status: %v, error: %v", p, err)
                }</span> else<span class="cov0" title="0"> {
                        headerFields = append(headerFields, hpack.HeaderField{Name: "grpc-status-details-bin", Value: encodeBinHeader(stBytes)})
                }</span>
        }

        // Attach the trailer metadata.
        <span class="cov8" title="1">headerFields = appendHeaderFieldsFromMD(headerFields, s.trailer)
        trailingHeader := &amp;headerFrame{
                streamID:  s.id,
                hf:        headerFields,
                endStream: true,
                onWrite:   t.setResetPingStrikes,
        }

        success, err := t.controlBuf.execute(t.checkForHeaderListSize, trailingHeader)
        if !success </span><span class="cov0" title="0">{
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov0" title="0">t.closeStream(s, true, http2.ErrCodeInternal, false)
                return ErrHeaderListSizeLimitViolation</span>
        }
        // Send a RST_STREAM after the trailers if the client has not already half-closed.
        <span class="cov8" title="1">rst := s.getState() == streamActive
        t.finishStream(s, rst, http2.ErrCodeNo, trailingHeader, true)
        for _, sh := range t.stats </span><span class="cov0" title="0">{
                // Note: The trailer fields are compressed with hpack after this call returns.
                // No WireLength field is set here.
                sh.HandleRPC(s.Context(), &amp;stats.OutTrailer{
                        Trailer: s.trailer.Copy(),
                })
        }</span>
        <span class="cov8" title="1">return nil</span>
}

// Write converts the data into HTTP2 data frame and sends it out. Non-nil error
// is returns if it fails (e.g., framing error, transport error).
func (t *http2Server) Write(s *Stream, hdr []byte, data []byte, opts *Options) error <span class="cov8" title="1">{
        if !s.isHeaderSent() </span><span class="cov8" title="1">{ // Headers haven't been written yet.
                if err := t.WriteHeader(s, nil); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
        } else<span class="cov8" title="1"> {
                // Writing headers checks for this condition.
                if s.getState() == streamDone </span><span class="cov0" title="0">{
                        return t.streamContextErr(s)
                }</span>
        }
        <span class="cov8" title="1">df := &amp;dataFrame{
                streamID:    s.id,
                h:           hdr,
                d:           data,
                onEachWrite: t.setResetPingStrikes,
        }
        if err := s.wq.get(int32(len(hdr) + len(data))); err != nil </span><span class="cov0" title="0">{
                return t.streamContextErr(s)
        }</span>
        <span class="cov8" title="1">return t.controlBuf.put(df)</span>
}

// keepalive running in a separate goroutine does the following:
// 1. Gracefully closes an idle connection after a duration of keepalive.MaxConnectionIdle.
// 2. Gracefully closes any connection after a duration of keepalive.MaxConnectionAge.
// 3. Forcibly closes a connection after an additive period of keepalive.MaxConnectionAgeGrace over keepalive.MaxConnectionAge.
// 4. Makes sure a connection is alive by sending pings with a frequency of keepalive.Time and closes a non-responsive connection
// after an additional duration of keepalive.Timeout.
func (t *http2Server) keepalive() <span class="cov8" title="1">{
        p := &amp;ping{}
        // True iff a ping has been sent, and no data has been received since then.
        outstandingPing := false
        // Amount of time remaining before which we should receive an ACK for the
        // last sent ping.
        kpTimeoutLeft := time.Duration(0)
        // Records the last value of t.lastRead before we go block on the timer.
        // This is required to check for read activity since then.
        prevNano := time.Now().UnixNano()
        // Initialize the different timers to their default values.
        idleTimer := time.NewTimer(t.kp.MaxConnectionIdle)
        ageTimer := time.NewTimer(t.kp.MaxConnectionAge)
        kpTimer := time.NewTimer(t.kp.Time)
        defer func() </span><span class="cov8" title="1">{
                // We need to drain the underlying channel in these timers after a call
                // to Stop(), only if we are interested in resetting them. Clearly we
                // are not interested in resetting them here.
                idleTimer.Stop()
                ageTimer.Stop()
                kpTimer.Stop()
        }</span>()

        <span class="cov8" title="1">for </span><span class="cov8" title="1">{
                select </span>{
                case &lt;-idleTimer.C:<span class="cov8" title="1">
                        t.mu.Lock()
                        idle := t.idle
                        if idle.IsZero() </span><span class="cov8" title="1">{ // The connection is non-idle.
                                t.mu.Unlock()
                                idleTimer.Reset(t.kp.MaxConnectionIdle)
                                continue</span>
                        }
                        <span class="cov8" title="1">val := t.kp.MaxConnectionIdle - time.Since(idle)
                        t.mu.Unlock()
                        if val &lt;= 0 </span><span class="cov8" title="1">{
                                // The connection has been idle for a duration of keepalive.MaxConnectionIdle or more.
                                // Gracefully close the connection.
                                t.Drain()
                                return
                        }</span>
                        <span class="cov8" title="1">idleTimer.Reset(val)</span>
                case &lt;-ageTimer.C:<span class="cov8" title="1">
                        t.Drain()
                        ageTimer.Reset(t.kp.MaxConnectionAgeGrace)
                        select </span>{
                        case &lt;-ageTimer.C:<span class="cov8" title="1">
                                // Close the connection after grace period.
                                if logger.V(logLevel) </span><span class="cov0" title="0">{
                                        logger.Infof("transport: closing server transport due to maximum connection age.")
                                }</span>
                                <span class="cov8" title="1">t.Close()</span>
                        case &lt;-t.done:<span class="cov0" title="0"></span>
                        }
                        <span class="cov8" title="1">return</span>
                case &lt;-kpTimer.C:<span class="cov8" title="1">
                        lastRead := atomic.LoadInt64(&amp;t.lastRead)
                        if lastRead &gt; prevNano </span><span class="cov8" title="1">{
                                // There has been read activity since the last time we were
                                // here. Setup the timer to fire at kp.Time seconds from
                                // lastRead time and continue.
                                outstandingPing = false
                                kpTimer.Reset(time.Duration(lastRead) + t.kp.Time - time.Duration(time.Now().UnixNano()))
                                prevNano = lastRead
                                continue</span>
                        }
                        <span class="cov8" title="1">if outstandingPing &amp;&amp; kpTimeoutLeft &lt;= 0 </span><span class="cov8" title="1">{
                                if logger.V(logLevel) </span><span class="cov0" title="0">{
                                        logger.Infof("transport: closing server transport due to idleness.")
                                }</span>
                                <span class="cov8" title="1">t.Close()
                                return</span>
                        }
                        <span class="cov8" title="1">if !outstandingPing </span><span class="cov8" title="1">{
                                if channelz.IsOn() </span><span class="cov0" title="0">{
                                        atomic.AddInt64(&amp;t.czData.kpCount, 1)
                                }</span>
                                <span class="cov8" title="1">t.controlBuf.put(p)
                                kpTimeoutLeft = t.kp.Timeout
                                outstandingPing = true</span>
                        }
                        // The amount of time to sleep here is the minimum of kp.Time and
                        // timeoutLeft. This will ensure that we wait only for kp.Time
                        // before sending out the next ping (for cases where the ping is
                        // acked).
                        <span class="cov8" title="1">sleepDuration := minTime(t.kp.Time, kpTimeoutLeft)
                        kpTimeoutLeft -= sleepDuration
                        kpTimer.Reset(sleepDuration)</span>
                case &lt;-t.done:<span class="cov8" title="1">
                        return</span>
                }
        }
}

// Close starts shutting down the http2Server transport.
// TODO(zhaoq): Now the destruction is not blocked on any pending streams. This
// could cause some resource issue. Revisit this later.
func (t *http2Server) Close() <span class="cov8" title="1">{
        t.mu.Lock()
        if t.state == closing </span><span class="cov8" title="1">{
                t.mu.Unlock()
                return
        }</span>
        <span class="cov8" title="1">t.state = closing
        streams := t.activeStreams
        t.activeStreams = nil
        t.mu.Unlock()
        t.controlBuf.finish()
        close(t.done)
        if err := t.conn.Close(); err != nil &amp;&amp; logger.V(logLevel) </span><span class="cov0" title="0">{
                logger.Infof("transport: error closing conn during Close: %v", err)
        }</span>
        <span class="cov8" title="1">channelz.RemoveEntry(t.channelzID)
        // Cancel all active streams.
        for _, s := range streams </span><span class="cov8" title="1">{
                s.cancel()
        }</span>
        <span class="cov8" title="1">for _, sh := range t.stats </span><span class="cov0" title="0">{
                connEnd := &amp;stats.ConnEnd{}
                sh.HandleConn(t.ctx, connEnd)
        }</span>
}

// deleteStream deletes the stream s from transport's active streams.
func (t *http2Server) deleteStream(s *Stream, eosReceived bool) <span class="cov8" title="1">{

        t.mu.Lock()
        if _, ok := t.activeStreams[s.id]; ok </span><span class="cov8" title="1">{
                delete(t.activeStreams, s.id)
                if len(t.activeStreams) == 0 </span><span class="cov8" title="1">{
                        t.idle = time.Now()
                }</span>
        }
        <span class="cov8" title="1">t.mu.Unlock()

        if channelz.IsOn() </span><span class="cov0" title="0">{
                if eosReceived </span><span class="cov0" title="0">{
                        atomic.AddInt64(&amp;t.czData.streamsSucceeded, 1)
                }</span> else<span class="cov0" title="0"> {
                        atomic.AddInt64(&amp;t.czData.streamsFailed, 1)
                }</span>
        }
}

// finishStream closes the stream and puts the trailing headerFrame into controlbuf.
func (t *http2Server) finishStream(s *Stream, rst bool, rstCode http2.ErrCode, hdr *headerFrame, eosReceived bool) <span class="cov8" title="1">{
        // In case stream sending and receiving are invoked in separate
        // goroutines (e.g., bi-directional streaming), cancel needs to be
        // called to interrupt the potential blocking on other goroutines.
        s.cancel()

        oldState := s.swapState(streamDone)
        if oldState == streamDone </span><span class="cov0" title="0">{
                // If the stream was already done, return.
                return
        }</span>

        <span class="cov8" title="1">hdr.cleanup = &amp;cleanupStream{
                streamID: s.id,
                rst:      rst,
                rstCode:  rstCode,
                onWrite: func() </span><span class="cov8" title="1">{
                        t.deleteStream(s, eosReceived)
                }</span>,
        }
        <span class="cov8" title="1">t.controlBuf.put(hdr)</span>
}

// closeStream clears the footprint of a stream when the stream is not needed any more.
func (t *http2Server) closeStream(s *Stream, rst bool, rstCode http2.ErrCode, eosReceived bool) <span class="cov8" title="1">{
        // In case stream sending and receiving are invoked in separate
        // goroutines (e.g., bi-directional streaming), cancel needs to be
        // called to interrupt the potential blocking on other goroutines.
        s.cancel()

        s.swapState(streamDone)
        t.deleteStream(s, eosReceived)

        t.controlBuf.put(&amp;cleanupStream{
                streamID: s.id,
                rst:      rst,
                rstCode:  rstCode,
                onWrite:  func() </span>{<span class="cov8" title="1">}</span>,
        })
}

func (t *http2Server) RemoteAddr() net.Addr <span class="cov0" title="0">{
        return t.remoteAddr
}</span>

func (t *http2Server) Drain() <span class="cov8" title="1">{
        t.mu.Lock()
        defer t.mu.Unlock()
        if t.drainChan != nil </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov8" title="1">t.drainChan = make(chan struct{})
        t.controlBuf.put(&amp;goAway{code: http2.ErrCodeNo, debugData: []byte{}, headsUp: true})</span>
}

var goAwayPing = &amp;ping{data: [8]byte{1, 6, 1, 8, 0, 3, 3, 9}}

// Handles outgoing GoAway and returns true if loopy needs to put itself
// in draining mode.
func (t *http2Server) outgoingGoAwayHandler(g *goAway) (bool, error) <span class="cov8" title="1">{
        t.maxStreamMu.Lock()
        t.mu.Lock()
        if t.state == closing </span><span class="cov0" title="0">{ // TODO(mmukhi): This seems unnecessary.
                t.mu.Unlock()
                t.maxStreamMu.Unlock()
                // The transport is closing.
                return false, ErrConnClosing
        }</span>
        <span class="cov8" title="1">if !g.headsUp </span><span class="cov8" title="1">{
                // Stop accepting more streams now.
                t.state = draining
                sid := t.maxStreamID
                if len(t.activeStreams) == 0 </span><span class="cov8" title="1">{
                        g.closeConn = true
                }</span>
                <span class="cov8" title="1">t.mu.Unlock()
                t.maxStreamMu.Unlock()
                if err := t.framer.fr.WriteGoAway(sid, g.code, g.debugData); err != nil </span><span class="cov0" title="0">{
                        return false, err
                }</span>
                <span class="cov8" title="1">if g.closeConn </span><span class="cov8" title="1">{
                        // Abruptly close the connection following the GoAway (via
                        // loopywriter).  But flush out what's inside the buffer first.
                        t.framer.writer.Flush()
                        return false, fmt.Errorf("transport: Connection closing")
                }</span>
                <span class="cov8" title="1">return true, nil</span>
        }
        <span class="cov8" title="1">t.mu.Unlock()
        t.maxStreamMu.Unlock()
        // For a graceful close, send out a GoAway with stream ID of MaxUInt32,
        // Follow that with a ping and wait for the ack to come back or a timer
        // to expire. During this time accept new streams since they might have
        // originated before the GoAway reaches the client.
        // After getting the ack or timer expiration send out another GoAway this
        // time with an ID of the max stream server intends to process.
        if err := t.framer.fr.WriteGoAway(math.MaxUint32, http2.ErrCodeNo, []byte{}); err != nil </span><span class="cov0" title="0">{
                return false, err
        }</span>
        <span class="cov8" title="1">if err := t.framer.fr.WritePing(false, goAwayPing.data); err != nil </span><span class="cov0" title="0">{
                return false, err
        }</span>
        <span class="cov8" title="1">go func() </span><span class="cov8" title="1">{
                timer := time.NewTimer(time.Minute)
                defer timer.Stop()
                select </span>{
                case &lt;-t.drainChan:<span class="cov8" title="1"></span>
                case &lt;-timer.C:<span class="cov0" title="0"></span>
                case &lt;-t.done:<span class="cov8" title="1">
                        return</span>
                }
                <span class="cov8" title="1">t.controlBuf.put(&amp;goAway{code: g.code, debugData: g.debugData})</span>
        }()
        <span class="cov8" title="1">return false, nil</span>
}

func (t *http2Server) ChannelzMetric() *channelz.SocketInternalMetric <span class="cov0" title="0">{
        s := channelz.SocketInternalMetric{
                StreamsStarted:                   atomic.LoadInt64(&amp;t.czData.streamsStarted),
                StreamsSucceeded:                 atomic.LoadInt64(&amp;t.czData.streamsSucceeded),
                StreamsFailed:                    atomic.LoadInt64(&amp;t.czData.streamsFailed),
                MessagesSent:                     atomic.LoadInt64(&amp;t.czData.msgSent),
                MessagesReceived:                 atomic.LoadInt64(&amp;t.czData.msgRecv),
                KeepAlivesSent:                   atomic.LoadInt64(&amp;t.czData.kpCount),
                LastRemoteStreamCreatedTimestamp: time.Unix(0, atomic.LoadInt64(&amp;t.czData.lastStreamCreatedTime)),
                LastMessageSentTimestamp:         time.Unix(0, atomic.LoadInt64(&amp;t.czData.lastMsgSentTime)),
                LastMessageReceivedTimestamp:     time.Unix(0, atomic.LoadInt64(&amp;t.czData.lastMsgRecvTime)),
                LocalFlowControlWindow:           int64(t.fc.getSize()),
                SocketOptions:                    channelz.GetSocketOption(t.conn),
                LocalAddr:                        t.localAddr,
                RemoteAddr:                       t.remoteAddr,
                // RemoteName :
        }
        if au, ok := t.authInfo.(credentials.ChannelzSecurityInfo); ok </span><span class="cov0" title="0">{
                s.Security = au.GetSecurityValue()
        }</span>
        <span class="cov0" title="0">s.RemoteFlowControlWindow = t.getOutFlowWindow()
        return &amp;s</span>
}

func (t *http2Server) IncrMsgSent() <span class="cov0" title="0">{
        atomic.AddInt64(&amp;t.czData.msgSent, 1)
        atomic.StoreInt64(&amp;t.czData.lastMsgSentTime, time.Now().UnixNano())
}</span>

func (t *http2Server) IncrMsgRecv() <span class="cov0" title="0">{
        atomic.AddInt64(&amp;t.czData.msgRecv, 1)
        atomic.StoreInt64(&amp;t.czData.lastMsgRecvTime, time.Now().UnixNano())
}</span>

func (t *http2Server) getOutFlowWindow() int64 <span class="cov0" title="0">{
        resp := make(chan uint32, 1)
        timer := time.NewTimer(time.Second)
        defer timer.Stop()
        t.controlBuf.put(&amp;outFlowControlSizeRequest{resp})
        select </span>{
        case sz := &lt;-resp:<span class="cov0" title="0">
                return int64(sz)</span>
        case &lt;-t.done:<span class="cov0" title="0">
                return -1</span>
        case &lt;-timer.C:<span class="cov0" title="0">
                return -2</span>
        }
}

func getJitter(v time.Duration) time.Duration <span class="cov8" title="1">{
        if v == infinity </span><span class="cov8" title="1">{
                return 0
        }</span>
        // Generate a jitter between +/- 10% of the value.
        <span class="cov8" title="1">r := int64(v / 10)
        j := grpcrand.Int63n(2*r) - r
        return time.Duration(j)</span>
}

type connectionKey struct{}

// GetConnection gets the connection from the context.
func GetConnection(ctx context.Context) net.Conn <span class="cov0" title="0">{
        conn, _ := ctx.Value(connectionKey{}).(net.Conn)
        return conn
}</span>

// SetConnection adds the connection to the context to be able to get
// information about the destination ip and port for an incoming RPC. This also
// allows any unary or streaming interceptors to see the connection.
func setConnection(ctx context.Context, conn net.Conn) context.Context <span class="cov8" title="1">{
        return context.WithValue(ctx, connectionKey{}, conn)
}</span>
</pre>
		
		<pre class="file" id="file115" style="display: none">/*
 *
 * Copyright 2014 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package transport

import (
        "bufio"
        "bytes"
        "encoding/base64"
        "fmt"
        "io"
        "math"
        "net"
        "net/http"
        "net/url"
        "strconv"
        "strings"
        "time"
        "unicode/utf8"

        "github.com/golang/protobuf/proto"
        "golang.org/x/net/http2"
        "golang.org/x/net/http2/hpack"
        spb "google.golang.org/genproto/googleapis/rpc/status"
        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/grpclog"
        "google.golang.org/grpc/status"
)

const (
        // http2MaxFrameLen specifies the max length of a HTTP2 frame.
        http2MaxFrameLen = 16384 // 16KB frame
        // http://http2.github.io/http2-spec/#SettingValues
        http2InitHeaderTableSize = 4096
)

var (
        clientPreface   = []byte(http2.ClientPreface)
        http2ErrConvTab = map[http2.ErrCode]codes.Code{
                http2.ErrCodeNo:                 codes.Internal,
                http2.ErrCodeProtocol:           codes.Internal,
                http2.ErrCodeInternal:           codes.Internal,
                http2.ErrCodeFlowControl:        codes.ResourceExhausted,
                http2.ErrCodeSettingsTimeout:    codes.Internal,
                http2.ErrCodeStreamClosed:       codes.Internal,
                http2.ErrCodeFrameSize:          codes.Internal,
                http2.ErrCodeRefusedStream:      codes.Unavailable,
                http2.ErrCodeCancel:             codes.Canceled,
                http2.ErrCodeCompression:        codes.Internal,
                http2.ErrCodeConnect:            codes.Internal,
                http2.ErrCodeEnhanceYourCalm:    codes.ResourceExhausted,
                http2.ErrCodeInadequateSecurity: codes.PermissionDenied,
                http2.ErrCodeHTTP11Required:     codes.Internal,
        }
        // HTTPStatusConvTab is the HTTP status code to gRPC error code conversion table.
        HTTPStatusConvTab = map[int]codes.Code{
                // 400 Bad Request - INTERNAL.
                http.StatusBadRequest: codes.Internal,
                // 401 Unauthorized  - UNAUTHENTICATED.
                http.StatusUnauthorized: codes.Unauthenticated,
                // 403 Forbidden - PERMISSION_DENIED.
                http.StatusForbidden: codes.PermissionDenied,
                // 404 Not Found - UNIMPLEMENTED.
                http.StatusNotFound: codes.Unimplemented,
                // 429 Too Many Requests - UNAVAILABLE.
                http.StatusTooManyRequests: codes.Unavailable,
                // 502 Bad Gateway - UNAVAILABLE.
                http.StatusBadGateway: codes.Unavailable,
                // 503 Service Unavailable - UNAVAILABLE.
                http.StatusServiceUnavailable: codes.Unavailable,
                // 504 Gateway timeout - UNAVAILABLE.
                http.StatusGatewayTimeout: codes.Unavailable,
        }
        logger = grpclog.Component("transport")
)

// isReservedHeader checks whether hdr belongs to HTTP2 headers
// reserved by gRPC protocol. Any other headers are classified as the
// user-specified metadata.
func isReservedHeader(hdr string) bool <span class="cov8" title="1">{
        if hdr != "" &amp;&amp; hdr[0] == ':' </span><span class="cov8" title="1">{
                return true
        }</span>
        <span class="cov8" title="1">switch hdr </span>{
        case "content-type",
                "user-agent",
                "grpc-message-type",
                "grpc-encoding",
                "grpc-message",
                "grpc-status",
                "grpc-timeout",
                "grpc-status-details-bin",
                // Intentionally exclude grpc-previous-rpc-attempts and
                // grpc-retry-pushback-ms, which are "reserved", but their API
                // intentionally works via metadata.
                "te":<span class="cov8" title="1">
                return true</span>
        default:<span class="cov8" title="1">
                return false</span>
        }
}

// isWhitelistedHeader checks whether hdr should be propagated into metadata
// visible to users, even though it is classified as "reserved", above.
func isWhitelistedHeader(hdr string) bool <span class="cov8" title="1">{
        switch hdr </span>{
        case ":authority", "user-agent":<span class="cov8" title="1">
                return true</span>
        default:<span class="cov8" title="1">
                return false</span>
        }
}

const binHdrSuffix = "-bin"

func encodeBinHeader(v []byte) string <span class="cov8" title="1">{
        return base64.RawStdEncoding.EncodeToString(v)
}</span>

func decodeBinHeader(v string) ([]byte, error) <span class="cov8" title="1">{
        if len(v)%4 == 0 </span><span class="cov8" title="1">{
                // Input was padded, or padding was not necessary.
                return base64.StdEncoding.DecodeString(v)
        }</span>
        <span class="cov8" title="1">return base64.RawStdEncoding.DecodeString(v)</span>
}

func encodeMetadataHeader(k, v string) string <span class="cov8" title="1">{
        if strings.HasSuffix(k, binHdrSuffix) </span><span class="cov8" title="1">{
                return encodeBinHeader(([]byte)(v))
        }</span>
        <span class="cov8" title="1">return v</span>
}

func decodeMetadataHeader(k, v string) (string, error) <span class="cov8" title="1">{
        if strings.HasSuffix(k, binHdrSuffix) </span><span class="cov8" title="1">{
                b, err := decodeBinHeader(v)
                return string(b), err
        }</span>
        <span class="cov8" title="1">return v, nil</span>
}

func decodeGRPCStatusDetails(rawDetails string) (*status.Status, error) <span class="cov0" title="0">{
        v, err := decodeBinHeader(rawDetails)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">st := &amp;spb.Status{}
        if err = proto.Unmarshal(v, st); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">return status.FromProto(st), nil</span>
}

type timeoutUnit uint8

const (
        hour        timeoutUnit = 'H'
        minute      timeoutUnit = 'M'
        second      timeoutUnit = 'S'
        millisecond timeoutUnit = 'm'
        microsecond timeoutUnit = 'u'
        nanosecond  timeoutUnit = 'n'
)

func timeoutUnitToDuration(u timeoutUnit) (d time.Duration, ok bool) <span class="cov8" title="1">{
        switch u </span>{
        case hour:<span class="cov0" title="0">
                return time.Hour, true</span>
        case minute:<span class="cov0" title="0">
                return time.Minute, true</span>
        case second:<span class="cov8" title="1">
                return time.Second, true</span>
        case millisecond:<span class="cov8" title="1">
                return time.Millisecond, true</span>
        case microsecond:<span class="cov8" title="1">
                return time.Microsecond, true</span>
        case nanosecond:<span class="cov0" title="0">
                return time.Nanosecond, true</span>
        default:<span class="cov8" title="1"></span>
        }
        <span class="cov8" title="1">return</span>
}

func decodeTimeout(s string) (time.Duration, error) <span class="cov8" title="1">{
        size := len(s)
        if size &lt; 2 </span><span class="cov8" title="1">{
                return 0, fmt.Errorf("transport: timeout string is too short: %q", s)
        }</span>
        <span class="cov8" title="1">if size &gt; 9 </span><span class="cov0" title="0">{
                // Spec allows for 8 digits plus the unit.
                return 0, fmt.Errorf("transport: timeout string is too long: %q", s)
        }</span>
        <span class="cov8" title="1">unit := timeoutUnit(s[size-1])
        d, ok := timeoutUnitToDuration(unit)
        if !ok </span><span class="cov8" title="1">{
                return 0, fmt.Errorf("transport: timeout unit is not recognized: %q", s)
        }</span>
        <span class="cov8" title="1">t, err := strconv.ParseInt(s[:size-1], 10, 64)
        if err != nil </span><span class="cov0" title="0">{
                return 0, err
        }</span>
        <span class="cov8" title="1">const maxHours = math.MaxInt64 / int64(time.Hour)
        if d == time.Hour &amp;&amp; t &gt; maxHours </span><span class="cov0" title="0">{
                // This timeout would overflow math.MaxInt64; clamp it.
                return time.Duration(math.MaxInt64), nil
        }</span>
        <span class="cov8" title="1">return d * time.Duration(t), nil</span>
}

const (
        spaceByte   = ' '
        tildeByte   = '~'
        percentByte = '%'
)

// encodeGrpcMessage is used to encode status code in header field
// "grpc-message". It does percent encoding and also replaces invalid utf-8
// characters with Unicode replacement character.
//
// It checks to see if each individual byte in msg is an allowable byte, and
// then either percent encoding or passing it through. When percent encoding,
// the byte is converted into hexadecimal notation with a '%' prepended.
func encodeGrpcMessage(msg string) string <span class="cov8" title="1">{
        if msg == "" </span><span class="cov8" title="1">{
                return ""
        }</span>
        <span class="cov8" title="1">lenMsg := len(msg)
        for i := 0; i &lt; lenMsg; i++ </span><span class="cov8" title="1">{
                c := msg[i]
                if !(c &gt;= spaceByte &amp;&amp; c &lt;= tildeByte &amp;&amp; c != percentByte) </span><span class="cov8" title="1">{
                        return encodeGrpcMessageUnchecked(msg)
                }</span>
        }
        <span class="cov8" title="1">return msg</span>
}

func encodeGrpcMessageUnchecked(msg string) string <span class="cov8" title="1">{
        var buf bytes.Buffer
        for len(msg) &gt; 0 </span><span class="cov8" title="1">{
                r, size := utf8.DecodeRuneInString(msg)
                for _, b := range []byte(string(r)) </span><span class="cov8" title="1">{
                        if size &gt; 1 </span><span class="cov8" title="1">{
                                // If size &gt; 1, r is not ascii. Always do percent encoding.
                                buf.WriteString(fmt.Sprintf("%%%02X", b))
                                continue</span>
                        }

                        // The for loop is necessary even if size == 1. r could be
                        // utf8.RuneError.
                        //
                        // fmt.Sprintf("%%%02X", utf8.RuneError) gives "%FFFD".
                        <span class="cov8" title="1">if b &gt;= spaceByte &amp;&amp; b &lt;= tildeByte &amp;&amp; b != percentByte </span><span class="cov8" title="1">{
                                buf.WriteByte(b)
                        }</span> else<span class="cov8" title="1"> {
                                buf.WriteString(fmt.Sprintf("%%%02X", b))
                        }</span>
                }
                <span class="cov8" title="1">msg = msg[size:]</span>
        }
        <span class="cov8" title="1">return buf.String()</span>
}

// decodeGrpcMessage decodes the msg encoded by encodeGrpcMessage.
func decodeGrpcMessage(msg string) string <span class="cov8" title="1">{
        if msg == "" </span><span class="cov8" title="1">{
                return ""
        }</span>
        <span class="cov8" title="1">lenMsg := len(msg)
        for i := 0; i &lt; lenMsg; i++ </span><span class="cov8" title="1">{
                if msg[i] == percentByte &amp;&amp; i+2 &lt; lenMsg </span><span class="cov8" title="1">{
                        return decodeGrpcMessageUnchecked(msg)
                }</span>
        }
        <span class="cov8" title="1">return msg</span>
}

func decodeGrpcMessageUnchecked(msg string) string <span class="cov8" title="1">{
        var buf bytes.Buffer
        lenMsg := len(msg)
        for i := 0; i &lt; lenMsg; i++ </span><span class="cov8" title="1">{
                c := msg[i]
                if c == percentByte &amp;&amp; i+2 &lt; lenMsg </span><span class="cov8" title="1">{
                        parsed, err := strconv.ParseUint(msg[i+1:i+3], 16, 8)
                        if err != nil </span><span class="cov8" title="1">{
                                buf.WriteByte(c)
                        }</span> else<span class="cov8" title="1"> {
                                buf.WriteByte(byte(parsed))
                                i += 2
                        }</span>
                } else<span class="cov8" title="1"> {
                        buf.WriteByte(c)
                }</span>
        }
        <span class="cov8" title="1">return buf.String()</span>
}

type bufWriter struct {
        buf       []byte
        offset    int
        batchSize int
        conn      net.Conn
        err       error
}

func newBufWriter(conn net.Conn, batchSize int) *bufWriter <span class="cov8" title="1">{
        return &amp;bufWriter{
                buf:       make([]byte, batchSize*2),
                batchSize: batchSize,
                conn:      conn,
        }
}</span>

func (w *bufWriter) Write(b []byte) (n int, err error) <span class="cov8" title="1">{
        if w.err != nil </span><span class="cov0" title="0">{
                return 0, w.err
        }</span>
        <span class="cov8" title="1">if w.batchSize == 0 </span><span class="cov8" title="1">{ // Buffer has been disabled.
                return w.conn.Write(b)
        }</span>
        <span class="cov8" title="1">for len(b) &gt; 0 </span><span class="cov8" title="1">{
                nn := copy(w.buf[w.offset:], b)
                b = b[nn:]
                w.offset += nn
                n += nn
                if w.offset &gt;= w.batchSize </span><span class="cov0" title="0">{
                        err = w.Flush()
                }</span>
        }
        <span class="cov8" title="1">return n, err</span>
}

func (w *bufWriter) Flush() error <span class="cov8" title="1">{
        if w.err != nil </span><span class="cov0" title="0">{
                return w.err
        }</span>
        <span class="cov8" title="1">if w.offset == 0 </span><span class="cov8" title="1">{
                return nil
        }</span>
        <span class="cov8" title="1">_, w.err = w.conn.Write(w.buf[:w.offset])
        w.offset = 0
        return w.err</span>
}

type framer struct {
        writer *bufWriter
        fr     *http2.Framer
}

func newFramer(conn net.Conn, writeBufferSize, readBufferSize int, maxHeaderListSize uint32) *framer <span class="cov8" title="1">{
        if writeBufferSize &lt; 0 </span><span class="cov0" title="0">{
                writeBufferSize = 0
        }</span>
        <span class="cov8" title="1">var r io.Reader = conn
        if readBufferSize &gt; 0 </span><span class="cov8" title="1">{
                r = bufio.NewReaderSize(r, readBufferSize)
        }</span>
        <span class="cov8" title="1">w := newBufWriter(conn, writeBufferSize)
        f := &amp;framer{
                writer: w,
                fr:     http2.NewFramer(w, r),
        }
        f.fr.SetMaxReadFrameSize(http2MaxFrameLen)
        // Opt-in to Frame reuse API on framer to reduce garbage.
        // Frames aren't safe to read from after a subsequent call to ReadFrame.
        f.fr.SetReuseFrames()
        f.fr.MaxHeaderListSize = maxHeaderListSize
        f.fr.ReadMetaHeaders = hpack.NewDecoder(http2InitHeaderTableSize, nil)
        return f</span>
}

// parseDialTarget returns the network and address to pass to dialer.
func parseDialTarget(target string) (string, string) <span class="cov8" title="1">{
        net := "tcp"
        m1 := strings.Index(target, ":")
        m2 := strings.Index(target, ":/")
        // handle unix:addr which will fail with url.Parse
        if m1 &gt;= 0 &amp;&amp; m2 &lt; 0 </span><span class="cov8" title="1">{
                if n := target[0:m1]; n == "unix" </span><span class="cov8" title="1">{
                        return n, target[m1+1:]
                }</span>
        }
        <span class="cov8" title="1">if m2 &gt;= 0 </span><span class="cov8" title="1">{
                t, err := url.Parse(target)
                if err != nil </span><span class="cov0" title="0">{
                        return net, target
                }</span>
                <span class="cov8" title="1">scheme := t.Scheme
                addr := t.Path
                if scheme == "unix" </span><span class="cov8" title="1">{
                        if addr == "" </span><span class="cov8" title="1">{
                                addr = t.Host
                        }</span>
                        <span class="cov8" title="1">return scheme, addr</span>
                }
        }
        <span class="cov8" title="1">return net, target</span>
}
</pre>
		
		<pre class="file" id="file116" style="display: none">/*
 *
 * Copyright 2017 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package transport

import (
        "bufio"
        "context"
        "encoding/base64"
        "fmt"
        "io"
        "net"
        "net/http"
        "net/http/httputil"
        "net/url"
)

const proxyAuthHeaderKey = "Proxy-Authorization"

var (
        // The following variable will be overwritten in the tests.
        httpProxyFromEnvironment = http.ProxyFromEnvironment
)

func mapAddress(address string) (*url.URL, error) <span class="cov8" title="1">{
        req := &amp;http.Request{
                URL: &amp;url.URL{
                        Scheme: "https",
                        Host:   address,
                },
        }
        url, err := httpProxyFromEnvironment(req)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return url, nil</span>
}

// To read a response from a net.Conn, http.ReadResponse() takes a bufio.Reader.
// It's possible that this reader reads more than what's need for the response and stores
// those bytes in the buffer.
// bufConn wraps the original net.Conn and the bufio.Reader to make sure we don't lose the
// bytes in the buffer.
type bufConn struct {
        net.Conn
        r io.Reader
}

func (c *bufConn) Read(b []byte) (int, error) <span class="cov0" title="0">{
        return c.r.Read(b)
}</span>

func basicAuth(username, password string) string <span class="cov8" title="1">{
        auth := username + ":" + password
        return base64.StdEncoding.EncodeToString([]byte(auth))
}</span>

func doHTTPConnectHandshake(ctx context.Context, conn net.Conn, backendAddr string, proxyURL *url.URL, grpcUA string) (_ net.Conn, err error) <span class="cov8" title="1">{
        defer func() </span><span class="cov8" title="1">{
                if err != nil </span><span class="cov0" title="0">{
                        conn.Close()
                }</span>
        }()

        <span class="cov8" title="1">req := &amp;http.Request{
                Method: http.MethodConnect,
                URL:    &amp;url.URL{Host: backendAddr},
                Header: map[string][]string{"User-Agent": {grpcUA}},
        }
        if t := proxyURL.User; t != nil </span><span class="cov8" title="1">{
                u := t.Username()
                p, _ := t.Password()
                req.Header.Add(proxyAuthHeaderKey, "Basic "+basicAuth(u, p))
        }</span>

        <span class="cov8" title="1">if err := sendHTTPRequest(ctx, req, conn); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to write the HTTP request: %v", err)
        }</span>

        <span class="cov8" title="1">r := bufio.NewReader(conn)
        resp, err := http.ReadResponse(r, req)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("reading server HTTP response: %v", err)
        }</span>
        <span class="cov8" title="1">defer resp.Body.Close()
        if resp.StatusCode != http.StatusOK </span><span class="cov0" title="0">{
                dump, err := httputil.DumpResponse(resp, true)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to do connect handshake, status code: %s", resp.Status)
                }</span>
                <span class="cov0" title="0">return nil, fmt.Errorf("failed to do connect handshake, response: %q", dump)</span>
        }

        <span class="cov8" title="1">return &amp;bufConn{Conn: conn, r: r}, nil</span>
}

// proxyDial dials, connecting to a proxy first if necessary. Checks if a proxy
// is necessary, dials, does the HTTP CONNECT handshake, and returns the
// connection.
func proxyDial(ctx context.Context, addr string, grpcUA string) (conn net.Conn, err error) <span class="cov8" title="1">{
        newAddr := addr
        proxyURL, err := mapAddress(addr)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">if proxyURL != nil </span><span class="cov8" title="1">{
                newAddr = proxyURL.Host
        }</span>

        <span class="cov8" title="1">conn, err = (&amp;net.Dialer{}).DialContext(ctx, "tcp", newAddr)
        if err != nil </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov8" title="1">if proxyURL != nil </span><span class="cov8" title="1">{
                // proxy is disabled if proxyURL is nil.
                conn, err = doHTTPConnectHandshake(ctx, conn, addr, proxyURL, grpcUA)
        }</span>
        <span class="cov8" title="1">return</span>
}

func sendHTTPRequest(ctx context.Context, req *http.Request, conn net.Conn) error <span class="cov8" title="1">{
        req = req.WithContext(ctx)
        if err := req.Write(conn); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to write the HTTP request: %v", err)
        }</span>
        <span class="cov8" title="1">return nil</span>
}
</pre>
		
		<pre class="file" id="file117" style="display: none">/*
 *
 * Copyright 2014 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package transport defines and implements message oriented communication
// channel to complete various transactions (e.g., an RPC).  It is meant for
// grpc-internal usage and is not intended to be imported directly by users.
package transport

import (
        "bytes"
        "context"
        "errors"
        "fmt"
        "io"
        "net"
        "sync"
        "sync/atomic"
        "time"

        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/credentials"
        "google.golang.org/grpc/internal/channelz"
        "google.golang.org/grpc/keepalive"
        "google.golang.org/grpc/metadata"
        "google.golang.org/grpc/resolver"
        "google.golang.org/grpc/stats"
        "google.golang.org/grpc/status"
        "google.golang.org/grpc/tap"
)

const logLevel = 2

type bufferPool struct {
        pool sync.Pool
}

func newBufferPool() *bufferPool <span class="cov8" title="1">{
        return &amp;bufferPool{
                pool: sync.Pool{
                        New: func() interface{} </span><span class="cov8" title="1">{
                                return new(bytes.Buffer)
                        }</span>,
                },
        }
}

func (p *bufferPool) get() *bytes.Buffer <span class="cov8" title="1">{
        return p.pool.Get().(*bytes.Buffer)
}</span>

func (p *bufferPool) put(b *bytes.Buffer) <span class="cov8" title="1">{
        p.pool.Put(b)
}</span>

// recvMsg represents the received msg from the transport. All transport
// protocol specific info has been removed.
type recvMsg struct {
        buffer *bytes.Buffer
        // nil: received some data
        // io.EOF: stream is completed. data is nil.
        // other non-nil error: transport failure. data is nil.
        err error
}

// recvBuffer is an unbounded channel of recvMsg structs.
//
// Note: recvBuffer differs from buffer.Unbounded only in the fact that it
// holds a channel of recvMsg structs instead of objects implementing "item"
// interface. recvBuffer is written to much more often and using strict recvMsg
// structs helps avoid allocation in "recvBuffer.put"
type recvBuffer struct {
        c       chan recvMsg
        mu      sync.Mutex
        backlog []recvMsg
        err     error
}

func newRecvBuffer() *recvBuffer <span class="cov8" title="1">{
        b := &amp;recvBuffer{
                c: make(chan recvMsg, 1),
        }
        return b
}</span>

func (b *recvBuffer) put(r recvMsg) <span class="cov8" title="1">{
        b.mu.Lock()
        if b.err != nil </span><span class="cov8" title="1">{
                b.mu.Unlock()
                // An error had occurred earlier, don't accept more
                // data or errors.
                return
        }</span>
        <span class="cov8" title="1">b.err = r.err
        if len(b.backlog) == 0 </span><span class="cov8" title="1">{
                select </span>{
                case b.c &lt;- r:<span class="cov8" title="1">
                        b.mu.Unlock()
                        return</span>
                default:<span class="cov8" title="1"></span>
                }
        }
        <span class="cov8" title="1">b.backlog = append(b.backlog, r)
        b.mu.Unlock()</span>
}

func (b *recvBuffer) load() <span class="cov8" title="1">{
        b.mu.Lock()
        if len(b.backlog) &gt; 0 </span><span class="cov8" title="1">{
                select </span>{
                case b.c &lt;- b.backlog[0]:<span class="cov8" title="1">
                        b.backlog[0] = recvMsg{}
                        b.backlog = b.backlog[1:]</span>
                default:<span class="cov8" title="1"></span>
                }
        }
        <span class="cov8" title="1">b.mu.Unlock()</span>
}

// get returns the channel that receives a recvMsg in the buffer.
//
// Upon receipt of a recvMsg, the caller should call load to send another
// recvMsg onto the channel if there is any.
func (b *recvBuffer) get() &lt;-chan recvMsg <span class="cov8" title="1">{
        return b.c
}</span>

// recvBufferReader implements io.Reader interface to read the data from
// recvBuffer.
type recvBufferReader struct {
        closeStream func(error) // Closes the client transport stream with the given error and nil trailer metadata.
        ctx         context.Context
        ctxDone     &lt;-chan struct{} // cache of ctx.Done() (for performance).
        recv        *recvBuffer
        last        *bytes.Buffer // Stores the remaining data in the previous calls.
        err         error
        freeBuffer  func(*bytes.Buffer)
}

// Read reads the next len(p) bytes from last. If last is drained, it tries to
// read additional data from recv. It blocks if there no additional data available
// in recv. If Read returns any non-nil error, it will continue to return that error.
func (r *recvBufferReader) Read(p []byte) (n int, err error) <span class="cov8" title="1">{
        if r.err != nil </span><span class="cov0" title="0">{
                return 0, r.err
        }</span>
        <span class="cov8" title="1">if r.last != nil </span><span class="cov8" title="1">{
                // Read remaining data left in last call.
                copied, _ := r.last.Read(p)
                if r.last.Len() == 0 </span><span class="cov8" title="1">{
                        r.freeBuffer(r.last)
                        r.last = nil
                }</span>
                <span class="cov8" title="1">return copied, nil</span>
        }
        <span class="cov8" title="1">if r.closeStream != nil </span><span class="cov8" title="1">{
                n, r.err = r.readClient(p)
        }</span> else<span class="cov8" title="1"> {
                n, r.err = r.read(p)
        }</span>
        <span class="cov8" title="1">return n, r.err</span>
}

func (r *recvBufferReader) read(p []byte) (n int, err error) <span class="cov8" title="1">{
        select </span>{
        case &lt;-r.ctxDone:<span class="cov8" title="1">
                return 0, ContextErr(r.ctx.Err())</span>
        case m := &lt;-r.recv.get():<span class="cov8" title="1">
                return r.readAdditional(m, p)</span>
        }
}

func (r *recvBufferReader) readClient(p []byte) (n int, err error) <span class="cov8" title="1">{
        // If the context is canceled, then closes the stream with nil metadata.
        // closeStream writes its error parameter to r.recv as a recvMsg.
        // r.readAdditional acts on that message and returns the necessary error.
        select </span>{
        case &lt;-r.ctxDone:<span class="cov0" title="0">
                // Note that this adds the ctx error to the end of recv buffer, and
                // reads from the head. This will delay the error until recv buffer is
                // empty, thus will delay ctx cancellation in Recv().
                //
                // It's done this way to fix a race between ctx cancel and trailer. The
                // race was, stream.Recv() may return ctx error if ctxDone wins the
                // race, but stream.Trailer() may return a non-nil md because the stream
                // was not marked as done when trailer is received. This closeStream
                // call will mark stream as done, thus fix the race.
                //
                // TODO: delaying ctx error seems like a unnecessary side effect. What
                // we really want is to mark the stream as done, and return ctx error
                // faster.
                r.closeStream(ContextErr(r.ctx.Err()))
                m := &lt;-r.recv.get()
                return r.readAdditional(m, p)</span>
        case m := &lt;-r.recv.get():<span class="cov8" title="1">
                return r.readAdditional(m, p)</span>
        }
}

func (r *recvBufferReader) readAdditional(m recvMsg, p []byte) (n int, err error) <span class="cov8" title="1">{
        r.recv.load()
        if m.err != nil </span><span class="cov8" title="1">{
                return 0, m.err
        }</span>
        <span class="cov8" title="1">copied, _ := m.buffer.Read(p)
        if m.buffer.Len() == 0 </span><span class="cov8" title="1">{
                r.freeBuffer(m.buffer)
                r.last = nil
        }</span> else<span class="cov8" title="1"> {
                r.last = m.buffer
        }</span>
        <span class="cov8" title="1">return copied, nil</span>
}

type streamState uint32

const (
        streamActive    streamState = iota
        streamWriteDone             // EndStream sent
        streamReadDone              // EndStream received
        streamDone                  // the entire stream is finished.
)

// Stream represents an RPC in the transport layer.
type Stream struct {
        id           uint32
        st           ServerTransport    // nil for client side Stream
        ct           *http2Client       // nil for server side Stream
        ctx          context.Context    // the associated context of the stream
        cancel       context.CancelFunc // always nil for client side Stream
        done         chan struct{}      // closed at the end of stream to unblock writers. On the client side.
        doneFunc     func()             // invoked at the end of stream on client side.
        ctxDone      &lt;-chan struct{}    // same as done chan but for server side. Cache of ctx.Done() (for performance)
        method       string             // the associated RPC method of the stream
        recvCompress string
        sendCompress string
        buf          *recvBuffer
        trReader     io.Reader
        fc           *inFlow
        wq           *writeQuota

        // Callback to state application's intentions to read data. This
        // is used to adjust flow control, if needed.
        requestRead func(int)

        headerChan       chan struct{} // closed to indicate the end of header metadata.
        headerChanClosed uint32        // set when headerChan is closed. Used to avoid closing headerChan multiple times.
        // headerValid indicates whether a valid header was received.  Only
        // meaningful after headerChan is closed (always call waitOnHeader() before
        // reading its value).  Not valid on server side.
        headerValid bool

        // hdrMu protects header and trailer metadata on the server-side.
        hdrMu sync.Mutex
        // On client side, header keeps the received header metadata.
        //
        // On server side, header keeps the header set by SetHeader(). The complete
        // header will merged into this after t.WriteHeader() is called.
        header  metadata.MD
        trailer metadata.MD // the key-value map of trailer metadata.

        noHeaders bool // set if the client never received headers (set only after the stream is done).

        // On the server-side, headerSent is atomically set to 1 when the headers are sent out.
        headerSent uint32

        state streamState

        // On client-side it is the status error received from the server.
        // On server-side it is unused.
        status *status.Status

        bytesReceived uint32 // indicates whether any bytes have been received on this stream
        unprocessed   uint32 // set if the server sends a refused stream or GOAWAY including this stream

        // contentSubtype is the content-subtype for requests.
        // this must be lowercase or the behavior is undefined.
        contentSubtype string
}

// isHeaderSent is only valid on the server-side.
func (s *Stream) isHeaderSent() bool <span class="cov8" title="1">{
        return atomic.LoadUint32(&amp;s.headerSent) == 1
}</span>

// updateHeaderSent updates headerSent and returns true
// if it was alreay set. It is valid only on server-side.
func (s *Stream) updateHeaderSent() bool <span class="cov8" title="1">{
        return atomic.SwapUint32(&amp;s.headerSent, 1) == 1
}</span>

func (s *Stream) swapState(st streamState) streamState <span class="cov8" title="1">{
        return streamState(atomic.SwapUint32((*uint32)(&amp;s.state), uint32(st)))
}</span>

func (s *Stream) compareAndSwapState(oldState, newState streamState) bool <span class="cov8" title="1">{
        return atomic.CompareAndSwapUint32((*uint32)(&amp;s.state), uint32(oldState), uint32(newState))
}</span>

func (s *Stream) getState() streamState <span class="cov8" title="1">{
        return streamState(atomic.LoadUint32((*uint32)(&amp;s.state)))
}</span>

func (s *Stream) waitOnHeader() <span class="cov0" title="0">{
        if s.headerChan == nil </span><span class="cov0" title="0">{
                // On the server headerChan is always nil since a stream originates
                // only after having received headers.
                return
        }</span>
        <span class="cov0" title="0">select </span>{
        case &lt;-s.ctx.Done():<span class="cov0" title="0">
                // Close the stream to prevent headers/trailers from changing after
                // this function returns.
                s.ct.CloseStream(s, ContextErr(s.ctx.Err()))
                // headerChan could possibly not be closed yet if closeStream raced
                // with operateHeaders; wait until it is closed explicitly here.
                &lt;-s.headerChan</span>
        case &lt;-s.headerChan:<span class="cov0" title="0"></span>
        }
}

// RecvCompress returns the compression algorithm applied to the inbound
// message. It is empty string if there is no compression applied.
func (s *Stream) RecvCompress() string <span class="cov0" title="0">{
        s.waitOnHeader()
        return s.recvCompress
}</span>

// SetSendCompress sets the compression algorithm to the stream.
func (s *Stream) SetSendCompress(str string) <span class="cov0" title="0">{
        s.sendCompress = str
}</span>

// Done returns a channel which is closed when it receives the final status
// from the server.
func (s *Stream) Done() &lt;-chan struct{} <span class="cov8" title="1">{
        return s.done
}</span>

// Header returns the header metadata of the stream.
//
// On client side, it acquires the key-value pairs of header metadata once it is
// available. It blocks until i) the metadata is ready or ii) there is no header
// metadata or iii) the stream is canceled/expired.
//
// On server side, it returns the out header after t.WriteHeader is called.  It
// does not block and must not be called until after WriteHeader.
func (s *Stream) Header() (metadata.MD, error) <span class="cov0" title="0">{
        if s.headerChan == nil </span><span class="cov0" title="0">{
                // On server side, return the header in stream. It will be the out
                // header after t.WriteHeader is called.
                return s.header.Copy(), nil
        }</span>
        <span class="cov0" title="0">s.waitOnHeader()
        if !s.headerValid </span><span class="cov0" title="0">{
                return nil, s.status.Err()
        }</span>
        <span class="cov0" title="0">return s.header.Copy(), nil</span>
}

// TrailersOnly blocks until a header or trailers-only frame is received and
// then returns true if the stream was trailers-only.  If the stream ends
// before headers are received, returns true, nil.  Client-side only.
func (s *Stream) TrailersOnly() bool <span class="cov0" title="0">{
        s.waitOnHeader()
        return s.noHeaders
}</span>

// Trailer returns the cached trailer metedata. Note that if it is not called
// after the entire stream is done, it could return an empty MD. Client
// side only.
// It can be safely read only after stream has ended that is either read
// or write have returned io.EOF.
func (s *Stream) Trailer() metadata.MD <span class="cov8" title="1">{
        c := s.trailer.Copy()
        return c
}</span>

// ContentSubtype returns the content-subtype for a request. For example, a
// content-subtype of "proto" will result in a content-type of
// "application/grpc+proto". This will always be lowercase.  See
// https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md#requests for
// more details.
func (s *Stream) ContentSubtype() string <span class="cov0" title="0">{
        return s.contentSubtype
}</span>

// Context returns the context of the stream.
func (s *Stream) Context() context.Context <span class="cov8" title="1">{
        return s.ctx
}</span>

// Method returns the method for the stream.
func (s *Stream) Method() string <span class="cov8" title="1">{
        return s.method
}</span>

// Status returns the status received from the server.
// Status can be read safely only after the stream has ended,
// that is, after Done() is closed.
func (s *Stream) Status() *status.Status <span class="cov8" title="1">{
        return s.status
}</span>

// SetHeader sets the header metadata. This can be called multiple times.
// Server side only.
// This should not be called in parallel to other data writes.
func (s *Stream) SetHeader(md metadata.MD) error <span class="cov8" title="1">{
        if md.Len() == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">if s.isHeaderSent() || s.getState() == streamDone </span><span class="cov8" title="1">{
                return ErrIllegalHeaderWrite
        }</span>
        <span class="cov8" title="1">s.hdrMu.Lock()
        s.header = metadata.Join(s.header, md)
        s.hdrMu.Unlock()
        return nil</span>
}

// SendHeader sends the given header metadata. The given metadata is
// combined with any metadata set by previous calls to SetHeader and
// then written to the transport stream.
func (s *Stream) SendHeader(md metadata.MD) error <span class="cov8" title="1">{
        return s.st.WriteHeader(s, md)
}</span>

// SetTrailer sets the trailer metadata which will be sent with the RPC status
// by the server. This can be called multiple times. Server side only.
// This should not be called parallel to other data writes.
func (s *Stream) SetTrailer(md metadata.MD) error <span class="cov8" title="1">{
        if md.Len() == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">if s.getState() == streamDone </span><span class="cov0" title="0">{
                return ErrIllegalHeaderWrite
        }</span>
        <span class="cov8" title="1">s.hdrMu.Lock()
        s.trailer = metadata.Join(s.trailer, md)
        s.hdrMu.Unlock()
        return nil</span>
}

func (s *Stream) write(m recvMsg) <span class="cov8" title="1">{
        s.buf.put(m)
}</span>

// Read reads all p bytes from the wire for this stream.
func (s *Stream) Read(p []byte) (n int, err error) <span class="cov8" title="1">{
        // Don't request a read if there was an error earlier
        if er := s.trReader.(*transportReader).er; er != nil </span><span class="cov8" title="1">{
                return 0, er
        }</span>
        <span class="cov8" title="1">s.requestRead(len(p))
        return io.ReadFull(s.trReader, p)</span>
}

// tranportReader reads all the data available for this Stream from the transport and
// passes them into the decoder, which converts them into a gRPC message stream.
// The error is io.EOF when the stream is done or another non-nil error if
// the stream broke.
type transportReader struct {
        reader io.Reader
        // The handler to control the window update procedure for both this
        // particular stream and the associated transport.
        windowHandler func(int)
        er            error
}

func (t *transportReader) Read(p []byte) (n int, err error) <span class="cov8" title="1">{
        n, err = t.reader.Read(p)
        if err != nil </span><span class="cov8" title="1">{
                t.er = err
                return
        }</span>
        <span class="cov8" title="1">t.windowHandler(n)
        return</span>
}

// BytesReceived indicates whether any bytes have been received on this stream.
func (s *Stream) BytesReceived() bool <span class="cov0" title="0">{
        return atomic.LoadUint32(&amp;s.bytesReceived) == 1
}</span>

// Unprocessed indicates whether the server did not process this stream --
// i.e. it sent a refused stream or GOAWAY including this stream ID.
func (s *Stream) Unprocessed() bool <span class="cov0" title="0">{
        return atomic.LoadUint32(&amp;s.unprocessed) == 1
}</span>

// GoString is implemented by Stream so context.String() won't
// race when printing %#v.
func (s *Stream) GoString() string <span class="cov0" title="0">{
        return fmt.Sprintf("&lt;stream: %p, %v&gt;", s, s.method)
}</span>

// state of transport
type transportState int

const (
        reachable transportState = iota
        closing
        draining
)

// ServerConfig consists of all the configurations to establish a server transport.
type ServerConfig struct {
        MaxStreams            uint32
        ConnectionTimeout     time.Duration
        Credentials           credentials.TransportCredentials
        InTapHandle           tap.ServerInHandle
        StatsHandlers         []stats.Handler
        KeepaliveParams       keepalive.ServerParameters
        KeepalivePolicy       keepalive.EnforcementPolicy
        InitialWindowSize     int32
        InitialConnWindowSize int32
        WriteBufferSize       int
        ReadBufferSize        int
        ChannelzParentID      *channelz.Identifier
        MaxHeaderListSize     *uint32
        HeaderTableSize       *uint32
}

// ConnectOptions covers all relevant options for communicating with the server.
type ConnectOptions struct {
        // UserAgent is the application user agent.
        UserAgent string
        // Dialer specifies how to dial a network address.
        Dialer func(context.Context, string) (net.Conn, error)
        // FailOnNonTempDialError specifies if gRPC fails on non-temporary dial errors.
        FailOnNonTempDialError bool
        // PerRPCCredentials stores the PerRPCCredentials required to issue RPCs.
        PerRPCCredentials []credentials.PerRPCCredentials
        // TransportCredentials stores the Authenticator required to setup a client
        // connection. Only one of TransportCredentials and CredsBundle is non-nil.
        TransportCredentials credentials.TransportCredentials
        // CredsBundle is the credentials bundle to be used. Only one of
        // TransportCredentials and CredsBundle is non-nil.
        CredsBundle credentials.Bundle
        // KeepaliveParams stores the keepalive parameters.
        KeepaliveParams keepalive.ClientParameters
        // StatsHandlers stores the handler for stats.
        StatsHandlers []stats.Handler
        // InitialWindowSize sets the initial window size for a stream.
        InitialWindowSize int32
        // InitialConnWindowSize sets the initial window size for a connection.
        InitialConnWindowSize int32
        // WriteBufferSize sets the size of write buffer which in turn determines how much data can be batched before it's written on the wire.
        WriteBufferSize int
        // ReadBufferSize sets the size of read buffer, which in turn determines how much data can be read at most for one read syscall.
        ReadBufferSize int
        // ChannelzParentID sets the addrConn id which initiate the creation of this client transport.
        ChannelzParentID *channelz.Identifier
        // MaxHeaderListSize sets the max (uncompressed) size of header list that is prepared to be received.
        MaxHeaderListSize *uint32
        // UseProxy specifies if a proxy should be used.
        UseProxy bool
}

// NewClientTransport establishes the transport with the required ConnectOptions
// and returns it to the caller.
func NewClientTransport(connectCtx, ctx context.Context, addr resolver.Address, opts ConnectOptions, onPrefaceReceipt func(), onGoAway func(GoAwayReason), onClose func()) (ClientTransport, error) <span class="cov8" title="1">{
        return newHTTP2Client(connectCtx, ctx, addr, opts, onPrefaceReceipt, onGoAway, onClose)
}</span>

// Options provides additional hints and information for message
// transmission.
type Options struct {
        // Last indicates whether this write is the last piece for
        // this stream.
        Last bool
}

// CallHdr carries the information of a particular RPC.
type CallHdr struct {
        // Host specifies the peer's host.
        Host string

        // Method specifies the operation to perform.
        Method string

        // SendCompress specifies the compression algorithm applied on
        // outbound message.
        SendCompress string

        // Creds specifies credentials.PerRPCCredentials for a call.
        Creds credentials.PerRPCCredentials

        // ContentSubtype specifies the content-subtype for a request. For example, a
        // content-subtype of "proto" will result in a content-type of
        // "application/grpc+proto". The value of ContentSubtype must be all
        // lowercase, otherwise the behavior is undefined. See
        // https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md#requests
        // for more details.
        ContentSubtype string

        PreviousAttempts int // value of grpc-previous-rpc-attempts header to set

        DoneFunc func() // called when the stream is finished
}

// ClientTransport is the common interface for all gRPC client-side transport
// implementations.
type ClientTransport interface {
        // Close tears down this transport. Once it returns, the transport
        // should not be accessed any more. The caller must make sure this
        // is called only once.
        Close(err error)

        // GracefulClose starts to tear down the transport: the transport will stop
        // accepting new RPCs and NewStream will return error. Once all streams are
        // finished, the transport will close.
        //
        // It does not block.
        GracefulClose()

        // Write sends the data for the given stream. A nil stream indicates
        // the write is to be performed on the transport as a whole.
        Write(s *Stream, hdr []byte, data []byte, opts *Options) error

        // NewStream creates a Stream for an RPC.
        NewStream(ctx context.Context, callHdr *CallHdr) (*Stream, error)

        // CloseStream clears the footprint of a stream when the stream is
        // not needed any more. The err indicates the error incurred when
        // CloseStream is called. Must be called when a stream is finished
        // unless the associated transport is closing.
        CloseStream(stream *Stream, err error)

        // Error returns a channel that is closed when some I/O error
        // happens. Typically the caller should have a goroutine to monitor
        // this in order to take action (e.g., close the current transport
        // and create a new one) in error case. It should not return nil
        // once the transport is initiated.
        Error() &lt;-chan struct{}

        // GoAway returns a channel that is closed when ClientTransport
        // receives the draining signal from the server (e.g., GOAWAY frame in
        // HTTP/2).
        GoAway() &lt;-chan struct{}

        // GetGoAwayReason returns the reason why GoAway frame was received, along
        // with a human readable string with debug info.
        GetGoAwayReason() (GoAwayReason, string)

        // RemoteAddr returns the remote network address.
        RemoteAddr() net.Addr

        // IncrMsgSent increments the number of message sent through this transport.
        IncrMsgSent()

        // IncrMsgRecv increments the number of message received through this transport.
        IncrMsgRecv()
}

// ServerTransport is the common interface for all gRPC server-side transport
// implementations.
//
// Methods may be called concurrently from multiple goroutines, but
// Write methods for a given Stream will be called serially.
type ServerTransport interface {
        // HandleStreams receives incoming streams using the given handler.
        HandleStreams(func(*Stream), func(context.Context, string) context.Context)

        // WriteHeader sends the header metadata for the given stream.
        // WriteHeader may not be called on all streams.
        WriteHeader(s *Stream, md metadata.MD) error

        // Write sends the data for the given stream.
        // Write may not be called on all streams.
        Write(s *Stream, hdr []byte, data []byte, opts *Options) error

        // WriteStatus sends the status of a stream to the client.  WriteStatus is
        // the final call made on a stream and always occurs.
        WriteStatus(s *Stream, st *status.Status) error

        // Close tears down the transport. Once it is called, the transport
        // should not be accessed any more. All the pending streams and their
        // handlers will be terminated asynchronously.
        Close()

        // RemoteAddr returns the remote network address.
        RemoteAddr() net.Addr

        // Drain notifies the client this ServerTransport stops accepting new RPCs.
        Drain()

        // IncrMsgSent increments the number of message sent through this transport.
        IncrMsgSent()

        // IncrMsgRecv increments the number of message received through this transport.
        IncrMsgRecv()
}

// connectionErrorf creates an ConnectionError with the specified error description.
func connectionErrorf(temp bool, e error, format string, a ...interface{}) ConnectionError <span class="cov8" title="1">{
        return ConnectionError{
                Desc: fmt.Sprintf(format, a...),
                temp: temp,
                err:  e,
        }
}</span>

// ConnectionError is an error that results in the termination of the
// entire connection and the retry of all the active streams.
type ConnectionError struct {
        Desc string
        temp bool
        err  error
}

func (e ConnectionError) Error() string <span class="cov8" title="1">{
        return fmt.Sprintf("connection error: desc = %q", e.Desc)
}</span>

// Temporary indicates if this connection error is temporary or fatal.
func (e ConnectionError) Temporary() bool <span class="cov0" title="0">{
        return e.temp
}</span>

// Origin returns the original error of this connection error.
func (e ConnectionError) Origin() error <span class="cov0" title="0">{
        // Never return nil error here.
        // If the original error is nil, return itself.
        if e.err == nil </span><span class="cov0" title="0">{
                return e
        }</span>
        <span class="cov0" title="0">return e.err</span>
}

// Unwrap returns the original error of this connection error or nil when the
// origin is nil.
func (e ConnectionError) Unwrap() error <span class="cov8" title="1">{
        return e.err
}</span>

var (
        // ErrConnClosing indicates that the transport is closing.
        ErrConnClosing = connectionErrorf(true, nil, "transport is closing")
        // errStreamDrain indicates that the stream is rejected because the
        // connection is draining. This could be caused by goaway or balancer
        // removing the address.
        errStreamDrain = status.Error(codes.Unavailable, "the connection is draining")
        // errStreamDone is returned from write at the client side to indiacte application
        // layer of an error.
        errStreamDone = errors.New("the stream is done")
        // StatusGoAway indicates that the server sent a GOAWAY that included this
        // stream's ID in unprocessed RPCs.
        statusGoAway = status.New(codes.Unavailable, "the stream is rejected because server is draining the connection")
)

// GoAwayReason contains the reason for the GoAway frame received.
type GoAwayReason uint8

const (
        // GoAwayInvalid indicates that no GoAway frame is received.
        GoAwayInvalid GoAwayReason = 0
        // GoAwayNoReason is the default value when GoAway frame is received.
        GoAwayNoReason GoAwayReason = 1
        // GoAwayTooManyPings indicates that a GoAway frame with
        // ErrCodeEnhanceYourCalm was received and that the debug data said
        // "too_many_pings".
        GoAwayTooManyPings GoAwayReason = 2
)

// channelzData is used to store channelz related data for http2Client and http2Server.
// These fields cannot be embedded in the original structs (e.g. http2Client), since to do atomic
// operation on int64 variable on 32-bit machine, user is responsible to enforce memory alignment.
// Here, by grouping those int64 fields inside a struct, we are enforcing the alignment.
type channelzData struct {
        kpCount int64
        // The number of streams that have started, including already finished ones.
        streamsStarted int64
        // Client side: The number of streams that have ended successfully by receiving
        // EoS bit set frame from server.
        // Server side: The number of streams that have ended successfully by sending
        // frame with EoS bit set.
        streamsSucceeded int64
        streamsFailed    int64
        // lastStreamCreatedTime stores the timestamp that the last stream gets created. It is of int64 type
        // instead of time.Time since it's more costly to atomically update time.Time variable than int64
        // variable. The same goes for lastMsgSentTime and lastMsgRecvTime.
        lastStreamCreatedTime int64
        msgSent               int64
        msgRecv               int64
        lastMsgSentTime       int64
        lastMsgRecvTime       int64
}

// ContextErr converts the error from context package into a status error.
func ContextErr(err error) error <span class="cov8" title="1">{
        switch err </span>{
        case context.DeadlineExceeded:<span class="cov8" title="1">
                return status.Error(codes.DeadlineExceeded, err.Error())</span>
        case context.Canceled:<span class="cov8" title="1">
                return status.Error(codes.Canceled, err.Error())</span>
        }
        <span class="cov0" title="0">return status.Errorf(codes.Internal, "Unexpected error from context packet: %v", err)</span>
}
</pre>
		
		<pre class="file" id="file118" style="display: none">/*
 *
 * Copyright 2019 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package wrr

import (
        "container/heap"
        "sync"
)

// edfWrr is a struct for EDF weighted round robin implementation.
type edfWrr struct {
        lock               sync.Mutex
        items              edfPriorityQueue
        currentOrderOffset uint64
        currentTime        float64
}

// NewEDF creates Earliest Deadline First (EDF)
// (https://en.wikipedia.org/wiki/Earliest_deadline_first_scheduling) implementation for weighted round robin.
// Each pick from the schedule has the earliest deadline entry selected. Entries have deadlines set
// at current time + 1 / weight, providing weighted round robin behavior with O(log n) pick time.
func NewEDF() WRR <span class="cov8" title="1">{
        return &amp;edfWrr{}
}</span>

// edfEntry is an internal wrapper for item that also stores weight and relative position in the queue.
type edfEntry struct {
        deadline    float64
        weight      int64
        orderOffset uint64
        item        interface{}
}

// edfPriorityQueue is a heap.Interface implementation for edfEntry elements.
type edfPriorityQueue []*edfEntry

func (pq edfPriorityQueue) Len() int <span class="cov8" title="1">{ return len(pq) }</span>
func (pq edfPriorityQueue) Less(i, j int) bool <span class="cov8" title="1">{
        return pq[i].deadline &lt; pq[j].deadline || pq[i].deadline == pq[j].deadline &amp;&amp; pq[i].orderOffset &lt; pq[j].orderOffset
}</span>
func (pq edfPriorityQueue) Swap(i, j int) <span class="cov8" title="1">{ pq[i], pq[j] = pq[j], pq[i] }</span>

func (pq *edfPriorityQueue) Push(x interface{}) <span class="cov8" title="1">{
        *pq = append(*pq, x.(*edfEntry))
}</span>

func (pq *edfPriorityQueue) Pop() interface{} <span class="cov0" title="0">{
        old := *pq
        *pq = old[0 : len(old)-1]
        return old[len(old)-1]
}</span>

func (edf *edfWrr) Add(item interface{}, weight int64) <span class="cov8" title="1">{
        edf.lock.Lock()
        defer edf.lock.Unlock()
        entry := edfEntry{
                deadline:    edf.currentTime + 1.0/float64(weight),
                weight:      weight,
                item:        item,
                orderOffset: edf.currentOrderOffset,
        }
        edf.currentOrderOffset++
        heap.Push(&amp;edf.items, &amp;entry)
}</span>

func (edf *edfWrr) Next() interface{} <span class="cov8" title="1">{
        edf.lock.Lock()
        defer edf.lock.Unlock()
        if len(edf.items) == 0 </span><span class="cov8" title="1">{
                return nil
        }</span>
        <span class="cov8" title="1">item := edf.items[0]
        edf.currentTime = item.deadline
        item.deadline = edf.currentTime + 1.0/float64(item.weight)
        heap.Fix(&amp;edf.items, 0)
        return item.item</span>
}
</pre>
		
		<pre class="file" id="file119" style="display: none">/*
 *
 * Copyright 2019 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package wrr

import (
        "fmt"
        "sort"
        "sync"

        "google.golang.org/grpc/internal/grpcrand"
)

// weightedItem is a wrapped weighted item that is used to implement weighted random algorithm.
type weightedItem struct {
        item              interface{}
        weight            int64
        accumulatedWeight int64
}

func (w *weightedItem) String() string <span class="cov0" title="0">{
        return fmt.Sprint(*w)
}</span>

// randomWRR is a struct that contains weighted items implement weighted random algorithm.
type randomWRR struct {
        mu    sync.RWMutex
        items []*weightedItem
        // Are all item's weights equal
        equalWeights bool
}

// NewRandom creates a new WRR with random.
func NewRandom() WRR <span class="cov8" title="1">{
        return &amp;randomWRR{}
}</span>

var grpcrandInt63n = grpcrand.Int63n

func (rw *randomWRR) Next() (item interface{}) <span class="cov8" title="1">{
        rw.mu.RLock()
        defer rw.mu.RUnlock()
        if len(rw.items) == 0 </span><span class="cov8" title="1">{
                return nil
        }</span>
        <span class="cov8" title="1">if rw.equalWeights </span><span class="cov8" title="1">{
                return rw.items[grpcrandInt63n(int64(len(rw.items)))].item
        }</span>

        <span class="cov8" title="1">sumOfWeights := rw.items[len(rw.items)-1].accumulatedWeight
        // Random number in [0, sumOfWeights).
        randomWeight := grpcrandInt63n(sumOfWeights)
        // Item's accumulated weights are in ascending order, because item's weight &gt;= 0.
        // Binary search rw.items to find first item whose accumulatedWeight &gt; randomWeight
        // The return i is guaranteed to be in range [0, len(rw.items)) because randomWeight &lt; last item's accumulatedWeight
        i := sort.Search(len(rw.items), func(i int) bool </span><span class="cov8" title="1">{ return rw.items[i].accumulatedWeight &gt; randomWeight }</span>)
        <span class="cov8" title="1">return rw.items[i].item</span>
}

func (rw *randomWRR) Add(item interface{}, weight int64) <span class="cov8" title="1">{
        rw.mu.Lock()
        defer rw.mu.Unlock()
        accumulatedWeight := weight
        equalWeights := true
        if len(rw.items) &gt; 0 </span><span class="cov8" title="1">{
                lastItem := rw.items[len(rw.items)-1]
                accumulatedWeight = lastItem.accumulatedWeight + weight
                equalWeights = rw.equalWeights &amp;&amp; weight == lastItem.weight
        }</span>
        <span class="cov8" title="1">rw.equalWeights = equalWeights
        rItem := &amp;weightedItem{item: item, weight: weight, accumulatedWeight: accumulatedWeight}
        rw.items = append(rw.items, rItem)</span>
}

func (rw *randomWRR) String() string <span class="cov0" title="0">{
        return fmt.Sprint(rw.items)
}</span>
</pre>
		
		<pre class="file" id="file120" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package matcher

import (
        "fmt"
        "regexp"
        "strconv"
        "strings"

        "google.golang.org/grpc/internal/grpcutil"
        "google.golang.org/grpc/metadata"
)

// HeaderMatcher is an interface for header matchers. These are
// documented in (EnvoyProxy link here?). These matchers will match on different
// aspects of HTTP header name/value pairs.
type HeaderMatcher interface {
        Match(metadata.MD) bool
        String() string
}

// mdValuesFromOutgoingCtx retrieves metadata from context. If there are
// multiple values, the values are concatenated with "," (comma and no space).
//
// All header matchers only match against the comma-concatenated string.
func mdValuesFromOutgoingCtx(md metadata.MD, key string) (string, bool) <span class="cov8" title="1">{
        vs, ok := md[key]
        if !ok </span><span class="cov8" title="1">{
                return "", false
        }</span>
        <span class="cov8" title="1">return strings.Join(vs, ","), true</span>
}

// HeaderExactMatcher matches on an exact match of the value of the header.
type HeaderExactMatcher struct {
        key    string
        exact  string
        invert bool
}

// NewHeaderExactMatcher returns a new HeaderExactMatcher.
func NewHeaderExactMatcher(key, exact string, invert bool) *HeaderExactMatcher <span class="cov8" title="1">{
        return &amp;HeaderExactMatcher{key: key, exact: exact, invert: invert}
}</span>

// Match returns whether the passed in HTTP Headers match according to the
// HeaderExactMatcher.
func (hem *HeaderExactMatcher) Match(md metadata.MD) bool <span class="cov8" title="1">{
        v, ok := mdValuesFromOutgoingCtx(md, hem.key)
        if !ok </span><span class="cov8" title="1">{
                return false
        }</span>
        <span class="cov8" title="1">return (v == hem.exact) != hem.invert</span>
}

func (hem *HeaderExactMatcher) String() string <span class="cov0" title="0">{
        return fmt.Sprintf("headerExact:%v:%v", hem.key, hem.exact)
}</span>

// HeaderRegexMatcher matches on whether the entire request header value matches
// the regex.
type HeaderRegexMatcher struct {
        key    string
        re     *regexp.Regexp
        invert bool
}

// NewHeaderRegexMatcher returns a new HeaderRegexMatcher.
func NewHeaderRegexMatcher(key string, re *regexp.Regexp, invert bool) *HeaderRegexMatcher <span class="cov8" title="1">{
        return &amp;HeaderRegexMatcher{key: key, re: re, invert: invert}
}</span>

// Match returns whether the passed in HTTP Headers match according to the
// HeaderRegexMatcher.
func (hrm *HeaderRegexMatcher) Match(md metadata.MD) bool <span class="cov8" title="1">{
        v, ok := mdValuesFromOutgoingCtx(md, hrm.key)
        if !ok </span><span class="cov8" title="1">{
                return false
        }</span>
        <span class="cov8" title="1">return grpcutil.FullMatchWithRegex(hrm.re, v) != hrm.invert</span>
}

func (hrm *HeaderRegexMatcher) String() string <span class="cov0" title="0">{
        return fmt.Sprintf("headerRegex:%v:%v", hrm.key, hrm.re.String())
}</span>

// HeaderRangeMatcher matches on whether the request header value is within the
// range. The header value must be an integer in base 10 notation.
type HeaderRangeMatcher struct {
        key        string
        start, end int64 // represents [start, end).
        invert     bool
}

// NewHeaderRangeMatcher returns a new HeaderRangeMatcher.
func NewHeaderRangeMatcher(key string, start, end int64, invert bool) *HeaderRangeMatcher <span class="cov8" title="1">{
        return &amp;HeaderRangeMatcher{key: key, start: start, end: end, invert: invert}
}</span>

// Match returns whether the passed in HTTP Headers match according to the
// HeaderRangeMatcher.
func (hrm *HeaderRangeMatcher) Match(md metadata.MD) bool <span class="cov8" title="1">{
        v, ok := mdValuesFromOutgoingCtx(md, hrm.key)
        if !ok </span><span class="cov8" title="1">{
                return false
        }</span>
        <span class="cov8" title="1">if i, err := strconv.ParseInt(v, 10, 64); err == nil &amp;&amp; i &gt;= hrm.start &amp;&amp; i &lt; hrm.end </span><span class="cov8" title="1">{
                return !hrm.invert
        }</span>
        <span class="cov8" title="1">return hrm.invert</span>
}

func (hrm *HeaderRangeMatcher) String() string <span class="cov0" title="0">{
        return fmt.Sprintf("headerRange:%v:[%d,%d)", hrm.key, hrm.start, hrm.end)
}</span>

// HeaderPresentMatcher will match based on whether the header is present in the
// whole request.
type HeaderPresentMatcher struct {
        key     string
        present bool
}

// NewHeaderPresentMatcher returns a new HeaderPresentMatcher.
func NewHeaderPresentMatcher(key string, present bool, invert bool) *HeaderPresentMatcher <span class="cov8" title="1">{
        if invert </span><span class="cov8" title="1">{
                present = !present
        }</span>
        <span class="cov8" title="1">return &amp;HeaderPresentMatcher{key: key, present: present}</span>
}

// Match returns whether the passed in HTTP Headers match according to the
// HeaderPresentMatcher.
func (hpm *HeaderPresentMatcher) Match(md metadata.MD) bool <span class="cov8" title="1">{
        vs, ok := mdValuesFromOutgoingCtx(md, hpm.key)
        present := ok &amp;&amp; len(vs) &gt; 0 // TODO: Are we sure we need this len(vs) &gt; 0?
        return present == hpm.present
}</span>

func (hpm *HeaderPresentMatcher) String() string <span class="cov0" title="0">{
        return fmt.Sprintf("headerPresent:%v:%v", hpm.key, hpm.present)
}</span>

// HeaderPrefixMatcher matches on whether the prefix of the header value matches
// the prefix passed into this struct.
type HeaderPrefixMatcher struct {
        key    string
        prefix string
        invert bool
}

// NewHeaderPrefixMatcher returns a new HeaderPrefixMatcher.
func NewHeaderPrefixMatcher(key string, prefix string, invert bool) *HeaderPrefixMatcher <span class="cov8" title="1">{
        return &amp;HeaderPrefixMatcher{key: key, prefix: prefix, invert: invert}
}</span>

// Match returns whether the passed in HTTP Headers match according to the
// HeaderPrefixMatcher.
func (hpm *HeaderPrefixMatcher) Match(md metadata.MD) bool <span class="cov8" title="1">{
        v, ok := mdValuesFromOutgoingCtx(md, hpm.key)
        if !ok </span><span class="cov8" title="1">{
                return false
        }</span>
        <span class="cov8" title="1">return strings.HasPrefix(v, hpm.prefix) != hpm.invert</span>
}

func (hpm *HeaderPrefixMatcher) String() string <span class="cov0" title="0">{
        return fmt.Sprintf("headerPrefix:%v:%v", hpm.key, hpm.prefix)
}</span>

// HeaderSuffixMatcher matches on whether the suffix of the header value matches
// the suffix passed into this struct.
type HeaderSuffixMatcher struct {
        key    string
        suffix string
        invert bool
}

// NewHeaderSuffixMatcher returns a new HeaderSuffixMatcher.
func NewHeaderSuffixMatcher(key string, suffix string, invert bool) *HeaderSuffixMatcher <span class="cov8" title="1">{
        return &amp;HeaderSuffixMatcher{key: key, suffix: suffix, invert: invert}
}</span>

// Match returns whether the passed in HTTP Headers match according to the
// HeaderSuffixMatcher.
func (hsm *HeaderSuffixMatcher) Match(md metadata.MD) bool <span class="cov8" title="1">{
        v, ok := mdValuesFromOutgoingCtx(md, hsm.key)
        if !ok </span><span class="cov8" title="1">{
                return false
        }</span>
        <span class="cov8" title="1">return strings.HasSuffix(v, hsm.suffix) != hsm.invert</span>
}

func (hsm *HeaderSuffixMatcher) String() string <span class="cov0" title="0">{
        return fmt.Sprintf("headerSuffix:%v:%v", hsm.key, hsm.suffix)
}</span>

// HeaderContainsMatcher matches on whether the header value contains the
// value passed into this struct.
type HeaderContainsMatcher struct {
        key      string
        contains string
        invert   bool
}

// NewHeaderContainsMatcher returns a new HeaderContainsMatcher. key is the HTTP
// Header key to match on, and contains is the value that the header should
// should contain for a successful match. An empty contains string does not
// work, use HeaderPresentMatcher in that case.
func NewHeaderContainsMatcher(key string, contains string, invert bool) *HeaderContainsMatcher <span class="cov0" title="0">{
        return &amp;HeaderContainsMatcher{key: key, contains: contains, invert: invert}
}</span>

// Match returns whether the passed in HTTP Headers match according to the
// HeaderContainsMatcher.
func (hcm *HeaderContainsMatcher) Match(md metadata.MD) bool <span class="cov0" title="0">{
        v, ok := mdValuesFromOutgoingCtx(md, hcm.key)
        if !ok </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov0" title="0">return strings.Contains(v, hcm.contains) != hcm.invert</span>
}

func (hcm *HeaderContainsMatcher) String() string <span class="cov0" title="0">{
        return fmt.Sprintf("headerContains:%v%v", hcm.key, hcm.contains)
}</span>
</pre>
		
		<pre class="file" id="file121" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package matcher contains types that need to be shared between code under
// google.golang.org/grpc/xds/... and the rest of gRPC.
package matcher

import (
        "errors"
        "fmt"
        "regexp"
        "strings"

        v3matcherpb "github.com/envoyproxy/go-control-plane/envoy/type/matcher/v3"
        "google.golang.org/grpc/internal/grpcutil"
)

// StringMatcher contains match criteria for matching a string, and is an
// internal representation of the `StringMatcher` proto defined at
// https://github.com/envoyproxy/envoy/blob/main/api/envoy/type/matcher/v3/string.proto.
type StringMatcher struct {
        // Since these match fields are part of a `oneof` in the corresponding xDS
        // proto, only one of them is expected to be set.
        exactMatch    *string
        prefixMatch   *string
        suffixMatch   *string
        regexMatch    *regexp.Regexp
        containsMatch *string
        // If true, indicates the exact/prefix/suffix/contains matching should be
        // case insensitive. This has no effect on the regex match.
        ignoreCase bool
}

// Match returns true if input matches the criteria in the given StringMatcher.
func (sm StringMatcher) Match(input string) bool <span class="cov8" title="1">{
        if sm.ignoreCase </span><span class="cov8" title="1">{
                input = strings.ToLower(input)
        }</span>
        <span class="cov8" title="1">switch </span>{
        case sm.exactMatch != nil:<span class="cov8" title="1">
                return input == *sm.exactMatch</span>
        case sm.prefixMatch != nil:<span class="cov8" title="1">
                return strings.HasPrefix(input, *sm.prefixMatch)</span>
        case sm.suffixMatch != nil:<span class="cov8" title="1">
                return strings.HasSuffix(input, *sm.suffixMatch)</span>
        case sm.regexMatch != nil:<span class="cov8" title="1">
                return grpcutil.FullMatchWithRegex(sm.regexMatch, input)</span>
        case sm.containsMatch != nil:<span class="cov8" title="1">
                return strings.Contains(input, *sm.containsMatch)</span>
        }
        <span class="cov0" title="0">return false</span>
}

// StringMatcherFromProto is a helper function to create a StringMatcher from
// the corresponding StringMatcher proto.
//
// Returns a non-nil error if matcherProto is invalid.
func StringMatcherFromProto(matcherProto *v3matcherpb.StringMatcher) (StringMatcher, error) <span class="cov8" title="1">{
        if matcherProto == nil </span><span class="cov8" title="1">{
                return StringMatcher{}, errors.New("input StringMatcher proto is nil")
        }</span>

        <span class="cov8" title="1">matcher := StringMatcher{ignoreCase: matcherProto.GetIgnoreCase()}
        switch mt := matcherProto.GetMatchPattern().(type) </span>{
        case *v3matcherpb.StringMatcher_Exact:<span class="cov8" title="1">
                matcher.exactMatch = &amp;mt.Exact
                if matcher.ignoreCase </span><span class="cov8" title="1">{
                        *matcher.exactMatch = strings.ToLower(*matcher.exactMatch)
                }</span>
        case *v3matcherpb.StringMatcher_Prefix:<span class="cov8" title="1">
                if matcherProto.GetPrefix() == "" </span><span class="cov8" title="1">{
                        return StringMatcher{}, errors.New("empty prefix is not allowed in StringMatcher")
                }</span>
                <span class="cov8" title="1">matcher.prefixMatch = &amp;mt.Prefix
                if matcher.ignoreCase </span><span class="cov8" title="1">{
                        *matcher.prefixMatch = strings.ToLower(*matcher.prefixMatch)
                }</span>
        case *v3matcherpb.StringMatcher_Suffix:<span class="cov8" title="1">
                if matcherProto.GetSuffix() == "" </span><span class="cov8" title="1">{
                        return StringMatcher{}, errors.New("empty suffix is not allowed in StringMatcher")
                }</span>
                <span class="cov8" title="1">matcher.suffixMatch = &amp;mt.Suffix
                if matcher.ignoreCase </span><span class="cov8" title="1">{
                        *matcher.suffixMatch = strings.ToLower(*matcher.suffixMatch)
                }</span>
        case *v3matcherpb.StringMatcher_SafeRegex:<span class="cov8" title="1">
                regex := matcherProto.GetSafeRegex().GetRegex()
                re, err := regexp.Compile(regex)
                if err != nil </span><span class="cov8" title="1">{
                        return StringMatcher{}, fmt.Errorf("safe_regex matcher %q is invalid", regex)
                }</span>
                <span class="cov8" title="1">matcher.regexMatch = re</span>
        case *v3matcherpb.StringMatcher_Contains:<span class="cov8" title="1">
                if matcherProto.GetContains() == "" </span><span class="cov8" title="1">{
                        return StringMatcher{}, errors.New("empty contains is not allowed in StringMatcher")
                }</span>
                <span class="cov8" title="1">matcher.containsMatch = &amp;mt.Contains
                if matcher.ignoreCase </span><span class="cov8" title="1">{
                        *matcher.containsMatch = strings.ToLower(*matcher.containsMatch)
                }</span>
        default:<span class="cov0" title="0">
                return StringMatcher{}, fmt.Errorf("unrecognized string matcher: %+v", matcherProto)</span>
        }
        <span class="cov8" title="1">return matcher, nil</span>
}

// StringMatcherForTesting is a helper function to create a StringMatcher based
// on the given arguments. Intended only for testing purposes.
func StringMatcherForTesting(exact, prefix, suffix, contains *string, regex *regexp.Regexp, ignoreCase bool) StringMatcher <span class="cov0" title="0">{
        sm := StringMatcher{
                exactMatch:    exact,
                prefixMatch:   prefix,
                suffixMatch:   suffix,
                regexMatch:    regex,
                containsMatch: contains,
                ignoreCase:    ignoreCase,
        }
        if ignoreCase </span><span class="cov0" title="0">{
                switch </span>{
                case sm.exactMatch != nil:<span class="cov0" title="0">
                        *sm.exactMatch = strings.ToLower(*exact)</span>
                case sm.prefixMatch != nil:<span class="cov0" title="0">
                        *sm.prefixMatch = strings.ToLower(*prefix)</span>
                case sm.suffixMatch != nil:<span class="cov0" title="0">
                        *sm.suffixMatch = strings.ToLower(*suffix)</span>
                case sm.containsMatch != nil:<span class="cov0" title="0">
                        *sm.containsMatch = strings.ToLower(*contains)</span>
                }
        }
        <span class="cov0" title="0">return sm</span>
}

// ExactMatch returns the value of the configured exact match or an empty string
// if exact match criteria was not specified.
func (sm StringMatcher) ExactMatch() string <span class="cov0" title="0">{
        if sm.exactMatch != nil </span><span class="cov0" title="0">{
                return *sm.exactMatch
        }</span>
        <span class="cov0" title="0">return ""</span>
}

// Equal returns true if other and sm are equivalent to each other.
func (sm StringMatcher) Equal(other StringMatcher) bool <span class="cov8" title="1">{
        if sm.ignoreCase != other.ignoreCase </span><span class="cov0" title="0">{
                return false
        }</span>

        <span class="cov8" title="1">if (sm.exactMatch != nil) != (other.exactMatch != nil) ||
                (sm.prefixMatch != nil) != (other.prefixMatch != nil) ||
                (sm.suffixMatch != nil) != (other.suffixMatch != nil) ||
                (sm.regexMatch != nil) != (other.regexMatch != nil) ||
                (sm.containsMatch != nil) != (other.containsMatch != nil) </span><span class="cov0" title="0">{
                return false
        }</span>

        <span class="cov8" title="1">switch </span>{
        case sm.exactMatch != nil:<span class="cov8" title="1">
                return *sm.exactMatch == *other.exactMatch</span>
        case sm.prefixMatch != nil:<span class="cov8" title="1">
                return *sm.prefixMatch == *other.prefixMatch</span>
        case sm.suffixMatch != nil:<span class="cov8" title="1">
                return *sm.suffixMatch == *other.suffixMatch</span>
        case sm.regexMatch != nil:<span class="cov8" title="1">
                return sm.regexMatch.String() == other.regexMatch.String()</span>
        case sm.containsMatch != nil:<span class="cov8" title="1">
                return *sm.containsMatch == *other.containsMatch</span>
        }
        <span class="cov8" title="1">return true</span>
}
</pre>
		
		<pre class="file" id="file122" style="display: none">/*
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package rbac

import (
        "errors"
        "fmt"
        "net"
        "regexp"

        v3corepb "github.com/envoyproxy/go-control-plane/envoy/config/core/v3"
        v3rbacpb "github.com/envoyproxy/go-control-plane/envoy/config/rbac/v3"
        v3route_componentspb "github.com/envoyproxy/go-control-plane/envoy/config/route/v3"
        v3matcherpb "github.com/envoyproxy/go-control-plane/envoy/type/matcher/v3"
        internalmatcher "google.golang.org/grpc/internal/xds/matcher"
)

// matcher is an interface that takes data about incoming RPC's and returns
// whether it matches with whatever matcher implements this interface.
type matcher interface {
        match(data *rpcData) bool
}

// policyMatcher helps determine whether an incoming RPC call matches a policy.
// A policy is a logical role (e.g. Service Admin), which is comprised of
// permissions and principals. A principal is an identity (or identities) for a
// downstream subject which are assigned the policy (role), and a permission is
// an action(s) that a principal(s) can take. A policy matches if both a
// permission and a principal match, which will be determined by the child or
// permissions and principal matchers. policyMatcher implements the matcher
// interface.
type policyMatcher struct {
        permissions *orMatcher
        principals  *orMatcher
}

func newPolicyMatcher(policy *v3rbacpb.Policy) (*policyMatcher, error) <span class="cov8" title="1">{
        permissions, err := matchersFromPermissions(policy.Permissions)
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">principals, err := matchersFromPrincipals(policy.Principals)
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return &amp;policyMatcher{
                permissions: &amp;orMatcher{matchers: permissions},
                principals:  &amp;orMatcher{matchers: principals},
        }, nil</span>
}

func (pm *policyMatcher) match(data *rpcData) bool <span class="cov8" title="1">{
        // A policy matches if and only if at least one of its permissions match the
        // action taking place AND at least one if its principals match the
        // downstream peer.
        return pm.permissions.match(data) &amp;&amp; pm.principals.match(data)
}</span>

// matchersFromPermissions takes a list of permissions (can also be
// a single permission, e.g. from a not matcher which is logically !permission)
// and returns a list of matchers which correspond to that permission. This will
// be called in many instances throughout the initial construction of the RBAC
// engine from the AND and OR matchers and also from the NOT matcher.
func matchersFromPermissions(permissions []*v3rbacpb.Permission) ([]matcher, error) <span class="cov8" title="1">{
        var matchers []matcher
        for _, permission := range permissions </span><span class="cov8" title="1">{
                switch permission.GetRule().(type) </span>{
                case *v3rbacpb.Permission_AndRules:<span class="cov8" title="1">
                        mList, err := matchersFromPermissions(permission.GetAndRules().Rules)
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov8" title="1">matchers = append(matchers, &amp;andMatcher{matchers: mList})</span>
                case *v3rbacpb.Permission_OrRules:<span class="cov8" title="1">
                        mList, err := matchersFromPermissions(permission.GetOrRules().Rules)
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov8" title="1">matchers = append(matchers, &amp;orMatcher{matchers: mList})</span>
                case *v3rbacpb.Permission_Any:<span class="cov8" title="1">
                        matchers = append(matchers, &amp;alwaysMatcher{})</span>
                case *v3rbacpb.Permission_Header:<span class="cov8" title="1">
                        m, err := newHeaderMatcher(permission.GetHeader())
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov8" title="1">matchers = append(matchers, m)</span>
                case *v3rbacpb.Permission_UrlPath:<span class="cov8" title="1">
                        m, err := newURLPathMatcher(permission.GetUrlPath())
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov8" title="1">matchers = append(matchers, m)</span>
                case *v3rbacpb.Permission_DestinationIp:<span class="cov8" title="1">
                        // Due to this being on server side, the destination IP is the local
                        // IP.
                        m, err := newLocalIPMatcher(permission.GetDestinationIp())
                        if err != nil </span><span class="cov8" title="1">{
                                return nil, err
                        }</span>
                        <span class="cov8" title="1">matchers = append(matchers, m)</span>
                case *v3rbacpb.Permission_DestinationPort:<span class="cov8" title="1">
                        matchers = append(matchers, newPortMatcher(permission.GetDestinationPort()))</span>
                case *v3rbacpb.Permission_NotRule:<span class="cov8" title="1">
                        mList, err := matchersFromPermissions([]*v3rbacpb.Permission{{Rule: permission.GetNotRule().Rule}})
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov8" title="1">matchers = append(matchers, &amp;notMatcher{matcherToNot: mList[0]})</span>
                case *v3rbacpb.Permission_Metadata:<span class="cov8" title="1">
                        // Never matches - so no-op if not inverted, always match if
                        // inverted.
                        if permission.GetMetadata().GetInvert() </span><span class="cov8" title="1">{ // Test metadata being no-op and also metadata with invert always matching
                                matchers = append(matchers, &amp;alwaysMatcher{})
                        }</span>
                case *v3rbacpb.Permission_RequestedServerName:<span class="cov0" title="0"></span>
                        // Not supported in gRPC RBAC currently - a permission typed as
                        // requested server name in the initial config will be a no-op.
                }
        }
        <span class="cov8" title="1">return matchers, nil</span>
}

func matchersFromPrincipals(principals []*v3rbacpb.Principal) ([]matcher, error) <span class="cov8" title="1">{
        var matchers []matcher
        for _, principal := range principals </span><span class="cov8" title="1">{
                switch principal.GetIdentifier().(type) </span>{
                case *v3rbacpb.Principal_AndIds:<span class="cov8" title="1">
                        mList, err := matchersFromPrincipals(principal.GetAndIds().Ids)
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov8" title="1">matchers = append(matchers, &amp;andMatcher{matchers: mList})</span>
                case *v3rbacpb.Principal_OrIds:<span class="cov8" title="1">
                        mList, err := matchersFromPrincipals(principal.GetOrIds().Ids)
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov8" title="1">matchers = append(matchers, &amp;orMatcher{matchers: mList})</span>
                case *v3rbacpb.Principal_Any:<span class="cov8" title="1">
                        matchers = append(matchers, &amp;alwaysMatcher{})</span>
                case *v3rbacpb.Principal_Authenticated_:<span class="cov8" title="1">
                        authenticatedMatcher, err := newAuthenticatedMatcher(principal.GetAuthenticated())
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov8" title="1">matchers = append(matchers, authenticatedMatcher)</span>
                case *v3rbacpb.Principal_DirectRemoteIp:<span class="cov8" title="1">
                        m, err := newRemoteIPMatcher(principal.GetDirectRemoteIp())
                        if err != nil </span><span class="cov8" title="1">{
                                return nil, err
                        }</span>
                        <span class="cov8" title="1">matchers = append(matchers, m)</span>
                case *v3rbacpb.Principal_Header:<span class="cov8" title="1">
                        // Do we need an error here?
                        m, err := newHeaderMatcher(principal.GetHeader())
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov8" title="1">matchers = append(matchers, m)</span>
                case *v3rbacpb.Principal_UrlPath:<span class="cov8" title="1">
                        m, err := newURLPathMatcher(principal.GetUrlPath())
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov8" title="1">matchers = append(matchers, m)</span>
                case *v3rbacpb.Principal_NotId:<span class="cov8" title="1">
                        mList, err := matchersFromPrincipals([]*v3rbacpb.Principal{{Identifier: principal.GetNotId().Identifier}})
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov8" title="1">matchers = append(matchers, &amp;notMatcher{matcherToNot: mList[0]})</span>
                case *v3rbacpb.Principal_SourceIp:<span class="cov0" title="0"></span>
                        // The source ip principal identifier is deprecated. Thus, a
                        // principal typed as a source ip in the identifier will be a no-op.
                        // The config should use DirectRemoteIp instead.
                case *v3rbacpb.Principal_RemoteIp:<span class="cov8" title="1">
                        // RBAC in gRPC treats direct_remote_ip and remote_ip as logically
                        // equivalent, as per A41.
                        m, err := newRemoteIPMatcher(principal.GetRemoteIp())
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov8" title="1">matchers = append(matchers, m)</span>
                case *v3rbacpb.Principal_Metadata:<span class="cov0" title="0"></span>
                        // Not supported in gRPC RBAC currently - a principal typed as
                        // Metadata in the initial config will be a no-op.
                }
        }
        <span class="cov8" title="1">return matchers, nil</span>
}

// orMatcher is a matcher where it successfully matches if one of it's
// children successfully match. It also logically represents a principal or
// permission, but can also be it's own entity further down the tree of
// matchers. orMatcher implements the matcher interface.
type orMatcher struct {
        matchers []matcher
}

func (om *orMatcher) match(data *rpcData) bool <span class="cov8" title="1">{
        // Range through child matchers and pass in data about incoming RPC, and
        // only one child matcher has to match to be logically successful.
        for _, m := range om.matchers </span><span class="cov8" title="1">{
                if m.match(data) </span><span class="cov8" title="1">{
                        return true
                }</span>
        }
        <span class="cov8" title="1">return false</span>
}

// andMatcher is a matcher that is successful if every child matcher
// matches. andMatcher implements the matcher interface.
type andMatcher struct {
        matchers []matcher
}

func (am *andMatcher) match(data *rpcData) bool <span class="cov8" title="1">{
        for _, m := range am.matchers </span><span class="cov8" title="1">{
                if !m.match(data) </span><span class="cov8" title="1">{
                        return false
                }</span>
        }
        <span class="cov0" title="0">return true</span>
}

// alwaysMatcher is a matcher that will always match. This logically
// represents an any rule for a permission or a principal. alwaysMatcher
// implements the matcher interface.
type alwaysMatcher struct {
}

func (am *alwaysMatcher) match(data *rpcData) bool <span class="cov8" title="1">{
        return true
}</span>

// notMatcher is a matcher that nots an underlying matcher. notMatcher
// implements the matcher interface.
type notMatcher struct {
        matcherToNot matcher
}

func (nm *notMatcher) match(data *rpcData) bool <span class="cov8" title="1">{
        return !nm.matcherToNot.match(data)
}</span>

// headerMatcher is a matcher that matches on incoming HTTP Headers present
// in the incoming RPC. headerMatcher implements the matcher interface.
type headerMatcher struct {
        matcher internalmatcher.HeaderMatcher
}

func newHeaderMatcher(headerMatcherConfig *v3route_componentspb.HeaderMatcher) (*headerMatcher, error) <span class="cov8" title="1">{
        var m internalmatcher.HeaderMatcher
        switch headerMatcherConfig.HeaderMatchSpecifier.(type) </span>{
        case *v3route_componentspb.HeaderMatcher_ExactMatch:<span class="cov8" title="1">
                m = internalmatcher.NewHeaderExactMatcher(headerMatcherConfig.Name, headerMatcherConfig.GetExactMatch(), headerMatcherConfig.InvertMatch)</span>
        case *v3route_componentspb.HeaderMatcher_SafeRegexMatch:<span class="cov8" title="1">
                regex, err := regexp.Compile(headerMatcherConfig.GetSafeRegexMatch().Regex)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov8" title="1">m = internalmatcher.NewHeaderRegexMatcher(headerMatcherConfig.Name, regex, headerMatcherConfig.InvertMatch)</span>
        case *v3route_componentspb.HeaderMatcher_RangeMatch:<span class="cov8" title="1">
                m = internalmatcher.NewHeaderRangeMatcher(headerMatcherConfig.Name, headerMatcherConfig.GetRangeMatch().Start, headerMatcherConfig.GetRangeMatch().End, headerMatcherConfig.InvertMatch)</span>
        case *v3route_componentspb.HeaderMatcher_PresentMatch:<span class="cov8" title="1">
                m = internalmatcher.NewHeaderPresentMatcher(headerMatcherConfig.Name, headerMatcherConfig.GetPresentMatch(), headerMatcherConfig.InvertMatch)</span>
        case *v3route_componentspb.HeaderMatcher_PrefixMatch:<span class="cov8" title="1">
                m = internalmatcher.NewHeaderPrefixMatcher(headerMatcherConfig.Name, headerMatcherConfig.GetPrefixMatch(), headerMatcherConfig.InvertMatch)</span>
        case *v3route_componentspb.HeaderMatcher_SuffixMatch:<span class="cov8" title="1">
                m = internalmatcher.NewHeaderSuffixMatcher(headerMatcherConfig.Name, headerMatcherConfig.GetSuffixMatch(), headerMatcherConfig.InvertMatch)</span>
        case *v3route_componentspb.HeaderMatcher_ContainsMatch:<span class="cov8" title="1">
                m = internalmatcher.NewHeaderContainsMatcher(headerMatcherConfig.Name, headerMatcherConfig.GetContainsMatch(), headerMatcherConfig.InvertMatch)</span>
        default:<span class="cov0" title="0">
                return nil, errors.New("unknown header matcher type")</span>
        }
        <span class="cov8" title="1">return &amp;headerMatcher{matcher: m}, nil</span>
}

func (hm *headerMatcher) match(data *rpcData) bool <span class="cov8" title="1">{
        return hm.matcher.Match(data.md)
}</span>

// urlPathMatcher matches on the URL Path of the incoming RPC. In gRPC, this
// logically maps to the full method name the RPC is calling on the server side.
// urlPathMatcher implements the matcher interface.
type urlPathMatcher struct {
        stringMatcher internalmatcher.StringMatcher
}

func newURLPathMatcher(pathMatcher *v3matcherpb.PathMatcher) (*urlPathMatcher, error) <span class="cov8" title="1">{
        stringMatcher, err := internalmatcher.StringMatcherFromProto(pathMatcher.GetPath())
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return &amp;urlPathMatcher{stringMatcher: stringMatcher}, nil</span>
}

func (upm *urlPathMatcher) match(data *rpcData) bool <span class="cov8" title="1">{
        return upm.stringMatcher.Match(data.fullMethod)
}</span>

// remoteIPMatcher and localIPMatcher both are matchers that match against
// a CIDR Range. Two different matchers are needed as the remote and destination
// ip addresses come from different parts of the data about incoming RPC's
// passed in. Matching a CIDR Range means to determine whether the IP Address
// falls within the CIDR Range or not. They both implement the matcher
// interface.
type remoteIPMatcher struct {
        // ipNet represents the CidrRange that this matcher was configured with.
        // This is what will remote and destination IP's will be matched against.
        ipNet *net.IPNet
}

func newRemoteIPMatcher(cidrRange *v3corepb.CidrRange) (*remoteIPMatcher, error) <span class="cov8" title="1">{
        // Convert configuration to a cidrRangeString, as Go standard library has
        // methods that parse cidr string.
        cidrRangeString := fmt.Sprintf("%s/%d", cidrRange.AddressPrefix, cidrRange.PrefixLen.Value)
        _, ipNet, err := net.ParseCIDR(cidrRangeString)
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return &amp;remoteIPMatcher{ipNet: ipNet}, nil</span>
}

func (sim *remoteIPMatcher) match(data *rpcData) bool <span class="cov8" title="1">{
        return sim.ipNet.Contains(net.IP(net.ParseIP(data.peerInfo.Addr.String())))
}</span>

type localIPMatcher struct {
        ipNet *net.IPNet
}

func newLocalIPMatcher(cidrRange *v3corepb.CidrRange) (*localIPMatcher, error) <span class="cov8" title="1">{
        cidrRangeString := fmt.Sprintf("%s/%d", cidrRange.AddressPrefix, cidrRange.PrefixLen.Value)
        _, ipNet, err := net.ParseCIDR(cidrRangeString)
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return &amp;localIPMatcher{ipNet: ipNet}, nil</span>
}

func (dim *localIPMatcher) match(data *rpcData) bool <span class="cov8" title="1">{
        return dim.ipNet.Contains(net.IP(net.ParseIP(data.localAddr.String())))
}</span>

// portMatcher matches on whether the destination port of the RPC matches the
// destination port this matcher was instantiated with. portMatcher
// implements the matcher interface.
type portMatcher struct {
        destinationPort uint32
}

func newPortMatcher(destinationPort uint32) *portMatcher <span class="cov8" title="1">{
        return &amp;portMatcher{destinationPort: destinationPort}
}</span>

func (pm *portMatcher) match(data *rpcData) bool <span class="cov0" title="0">{
        return data.destinationPort == pm.destinationPort
}</span>

// authenticatedMatcher matches on the name of the Principal. If set, the URI
// SAN or DNS SAN in that order is used from the certificate, otherwise the
// subject field is used. If unset, it applies to any user that is
// authenticated. authenticatedMatcher implements the matcher interface.
type authenticatedMatcher struct {
        stringMatcher *internalmatcher.StringMatcher
}

func newAuthenticatedMatcher(authenticatedMatcherConfig *v3rbacpb.Principal_Authenticated) (*authenticatedMatcher, error) <span class="cov8" title="1">{
        // Represents this line in the RBAC documentation = "If unset, it applies to
        // any user that is authenticated" (see package-level comments).
        if authenticatedMatcherConfig.PrincipalName == nil </span><span class="cov0" title="0">{
                return &amp;authenticatedMatcher{}, nil
        }</span>
        <span class="cov8" title="1">stringMatcher, err := internalmatcher.StringMatcherFromProto(authenticatedMatcherConfig.PrincipalName)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return &amp;authenticatedMatcher{stringMatcher: &amp;stringMatcher}, nil</span>
}

func (am *authenticatedMatcher) match(data *rpcData) bool <span class="cov8" title="1">{
        if data.authType != "tls" </span><span class="cov8" title="1">{
                // Connection is not authenticated.
                return false
        }</span>
        <span class="cov8" title="1">if am.stringMatcher == nil </span><span class="cov0" title="0">{
                // Allows any authenticated user.
                return true
        }</span>
        // "If there is no client certificate (thus no SAN nor Subject), check if ""
        // (empty string) matches. If it matches, the principal_name is said to
        // match" - A41
        <span class="cov8" title="1">if len(data.certs) == 0 </span><span class="cov0" title="0">{
                return am.stringMatcher.Match("")
        }</span>
        <span class="cov8" title="1">cert := data.certs[0]
        // The order of matching as per the RBAC documentation (see package-level comments)
        // is as follows: URI SANs, DNS SANs, and then subject name.
        for _, uriSAN := range cert.URIs </span><span class="cov8" title="1">{
                if am.stringMatcher.Match(uriSAN.String()) </span><span class="cov8" title="1">{
                        return true
                }</span>
        }
        <span class="cov8" title="1">for _, dnsSAN := range cert.DNSNames </span><span class="cov0" title="0">{
                if am.stringMatcher.Match(dnsSAN) </span><span class="cov0" title="0">{
                        return true
                }</span>
        }
        <span class="cov8" title="1">return am.stringMatcher.Match(cert.Subject.String())</span>
}
</pre>
		
		<pre class="file" id="file123" style="display: none">/*
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// Package rbac provides service-level and method-level access control for a
// service. See
// https://www.envoyproxy.io/docs/envoy/latest/api-v3/config/rbac/v3/rbac.proto#role-based-access-control-rbac
// for documentation.
package rbac

import (
        "context"
        "crypto/x509"
        "errors"
        "fmt"
        "net"
        "strconv"

        v3rbacpb "github.com/envoyproxy/go-control-plane/envoy/config/rbac/v3"
        "google.golang.org/grpc"
        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/credentials"
        "google.golang.org/grpc/grpclog"
        "google.golang.org/grpc/internal/transport"
        "google.golang.org/grpc/metadata"
        "google.golang.org/grpc/peer"
        "google.golang.org/grpc/status"
)

var logger = grpclog.Component("rbac")

var getConnection = transport.GetConnection

// ChainEngine represents a chain of RBAC Engines, used to make authorization
// decisions on incoming RPCs.
type ChainEngine struct {
        chainedEngines []*engine
}

// NewChainEngine returns a chain of RBAC engines, used to make authorization
// decisions on incoming RPCs. Returns a non-nil error for invalid policies.
func NewChainEngine(policies []*v3rbacpb.RBAC) (*ChainEngine, error) <span class="cov8" title="1">{
        engines := make([]*engine, 0, len(policies))
        for _, policy := range policies </span><span class="cov8" title="1">{
                engine, err := newEngine(policy)
                if err != nil </span><span class="cov8" title="1">{
                        return nil, err
                }</span>
                <span class="cov8" title="1">engines = append(engines, engine)</span>
        }
        <span class="cov8" title="1">return &amp;ChainEngine{chainedEngines: engines}, nil</span>
}

func (cre *ChainEngine) logRequestDetails(rpcData *rpcData) <span class="cov8" title="1">{
        if logger.V(2) </span><span class="cov0" title="0">{
                logger.Infof("checking request: url path=%s", rpcData.fullMethod)
                if len(rpcData.certs) &gt; 0 </span><span class="cov0" title="0">{
                        cert := rpcData.certs[0]
                        logger.Infof("uri sans=%q, dns sans=%q, subject=%v", cert.URIs, cert.DNSNames, cert.Subject)
                }</span>
        }
}

// IsAuthorized determines if an incoming RPC is authorized based on the chain of RBAC
// engines and their associated actions.
//
// Errors returned by this function are compatible with the status package.
func (cre *ChainEngine) IsAuthorized(ctx context.Context) error <span class="cov8" title="1">{
        // This conversion step (i.e. pulling things out of ctx) can be done once,
        // and then be used for the whole chain of RBAC Engines.
        rpcData, err := newRPCData(ctx)
        if err != nil </span><span class="cov0" title="0">{
                logger.Errorf("newRPCData: %v", err)
                return status.Errorf(codes.Internal, "gRPC RBAC: %v", err)
        }</span>
        <span class="cov8" title="1">for _, engine := range cre.chainedEngines </span><span class="cov8" title="1">{
                matchingPolicyName, ok := engine.findMatchingPolicy(rpcData)
                if logger.V(2) &amp;&amp; ok </span><span class="cov0" title="0">{
                        logger.Infof("incoming RPC matched to policy %v in engine with action %v", matchingPolicyName, engine.action)
                }</span>

                <span class="cov8" title="1">switch </span>{
                case engine.action == v3rbacpb.RBAC_ALLOW &amp;&amp; !ok:<span class="cov8" title="1">
                        cre.logRequestDetails(rpcData)
                        return status.Errorf(codes.PermissionDenied, "incoming RPC did not match an allow policy")</span>
                case engine.action == v3rbacpb.RBAC_DENY &amp;&amp; ok:<span class="cov8" title="1">
                        cre.logRequestDetails(rpcData)
                        return status.Errorf(codes.PermissionDenied, "incoming RPC matched a deny policy %q", matchingPolicyName)</span>
                }
                // Every policy in the engine list must be queried. Thus, iterate to the
                // next policy.
        }
        // If the incoming RPC gets through all of the engines successfully (i.e.
        // doesn't not match an allow or match a deny engine), the RPC is authorized
        // to proceed.
        <span class="cov8" title="1">return nil</span>
}

// engine is used for matching incoming RPCs to policies.
type engine struct {
        policies map[string]*policyMatcher
        // action must be ALLOW or DENY.
        action v3rbacpb.RBAC_Action
}

// newEngine creates an RBAC Engine based on the contents of policy. Returns a
// non-nil error if the policy is invalid.
func newEngine(config *v3rbacpb.RBAC) (*engine, error) <span class="cov8" title="1">{
        a := config.GetAction()
        if a != v3rbacpb.RBAC_ALLOW &amp;&amp; a != v3rbacpb.RBAC_DENY </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("unsupported action %s", config.Action)
        }</span>

        <span class="cov8" title="1">policies := make(map[string]*policyMatcher, len(config.GetPolicies()))
        for name, policy := range config.GetPolicies() </span><span class="cov8" title="1">{
                matcher, err := newPolicyMatcher(policy)
                if err != nil </span><span class="cov8" title="1">{
                        return nil, err
                }</span>
                <span class="cov8" title="1">policies[name] = matcher</span>
        }
        <span class="cov8" title="1">return &amp;engine{
                policies: policies,
                action:   a,
        }, nil</span>
}

// findMatchingPolicy determines if an incoming RPC matches a policy. On a
// successful match, it returns the name of the matching policy and a true bool
// to specify that there was a matching policy found.  It returns false in
// the case of not finding a matching policy.
func (r *engine) findMatchingPolicy(rpcData *rpcData) (string, bool) <span class="cov8" title="1">{
        for policy, matcher := range r.policies </span><span class="cov8" title="1">{
                if matcher.match(rpcData) </span><span class="cov8" title="1">{
                        return policy, true
                }</span>
        }
        <span class="cov8" title="1">return "", false</span>
}

// newRPCData takes an incoming context (should be a context representing state
// needed for server RPC Call with metadata, peer info (used for source ip/port
// and TLS information) and connection (used for destination ip/port) piped into
// it) and the method name of the Service being called server side and populates
// an rpcData struct ready to be passed to the RBAC Engine to find a matching
// policy.
func newRPCData(ctx context.Context) (*rpcData, error) <span class="cov8" title="1">{
        // The caller should populate all of these fields (i.e. for empty headers,
        // pipe an empty md into context).
        md, ok := metadata.FromIncomingContext(ctx)
        if !ok </span><span class="cov0" title="0">{
                return nil, errors.New("missing metadata in incoming context")
        }</span>
        // ":method can be hard-coded to POST if unavailable" - A41
        <span class="cov8" title="1">md[":method"] = []string{"POST"}
        // "If the transport exposes TE in Metadata, then RBAC must special-case the
        // header to treat it as not present." - A41
        delete(md, "TE")

        pi, ok := peer.FromContext(ctx)
        if !ok </span><span class="cov0" title="0">{
                return nil, errors.New("missing peer info in incoming context")
        }</span>

        // The methodName will be available in the passed in ctx from a unary or streaming
        // interceptor, as grpc.Server pipes in a transport stream which contains the methodName
        // into contexts available in both unary or streaming interceptors.
        <span class="cov8" title="1">mn, ok := grpc.Method(ctx)
        if !ok </span><span class="cov0" title="0">{
                return nil, errors.New("missing method in incoming context")
        }</span>

        // The connection is needed in order to find the destination address and
        // port of the incoming RPC Call.
        <span class="cov8" title="1">conn := getConnection(ctx)
        if conn == nil </span><span class="cov0" title="0">{
                return nil, errors.New("missing connection in incoming context")
        }</span>
        <span class="cov8" title="1">_, dPort, err := net.SplitHostPort(conn.LocalAddr().String())
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("error parsing local address: %v", err)
        }</span>
        <span class="cov8" title="1">dp, err := strconv.ParseUint(dPort, 10, 32)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("error parsing local address: %v", err)
        }</span>

        <span class="cov8" title="1">var authType string
        var peerCertificates []*x509.Certificate
        if pi.AuthInfo != nil </span><span class="cov8" title="1">{
                tlsInfo, ok := pi.AuthInfo.(credentials.TLSInfo)
                if ok </span><span class="cov8" title="1">{
                        authType = pi.AuthInfo.AuthType()
                        peerCertificates = tlsInfo.State.PeerCertificates
                }</span>
        }

        <span class="cov8" title="1">return &amp;rpcData{
                md:              md,
                peerInfo:        pi,
                fullMethod:      mn,
                destinationPort: uint32(dp),
                localAddr:       conn.LocalAddr(),
                authType:        authType,
                certs:           peerCertificates,
        }, nil</span>
}

// rpcData wraps data pulled from an incoming RPC that the RBAC engine needs to
// find a matching policy.
type rpcData struct {
        // md is the HTTP Headers that are present in the incoming RPC.
        md metadata.MD
        // peerInfo is information about the downstream peer.
        peerInfo *peer.Peer
        // fullMethod is the method name being called on the upstream service.
        fullMethod string
        // destinationPort is the port that the RPC is being sent to on the
        // server.
        destinationPort uint32
        // localAddr is the address that the RPC is being sent to.
        localAddr net.Addr
        // authType is the type of authentication e.g. "tls".
        authType string
        // certs are the certificates presented by the peer during a TLS
        // handshake.
        certs []*x509.Certificate
}
</pre>
		
		<pre class="file" id="file124" style="display: none">/*
 *
 * Copyright 2014 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package metadata define the structure of the metadata supported by gRPC library.
// Please refer to https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md
// for more information about custom-metadata.
package metadata // import "google.golang.org/grpc/metadata"

import (
        "context"
        "fmt"
        "strings"
)

// DecodeKeyValue returns k, v, nil.
//
// Deprecated: use k and v directly instead.
func DecodeKeyValue(k, v string) (string, string, error) <span class="cov0" title="0">{
        return k, v, nil
}</span>

// MD is a mapping from metadata keys to values. Users should use the following
// two convenience functions New and Pairs to generate MD.
type MD map[string][]string

// New creates an MD from a given key-value map.
//
// Only the following ASCII characters are allowed in keys:
//  - digits: 0-9
//  - uppercase letters: A-Z (normalized to lower)
//  - lowercase letters: a-z
//  - special characters: -_.
// Uppercase letters are automatically converted to lowercase.
//
// Keys beginning with "grpc-" are reserved for grpc-internal use only and may
// result in errors if set in metadata.
func New(m map[string]string) MD <span class="cov0" title="0">{
        md := MD{}
        for k, val := range m </span><span class="cov0" title="0">{
                key := strings.ToLower(k)
                md[key] = append(md[key], val)
        }</span>
        <span class="cov0" title="0">return md</span>
}

// Pairs returns an MD formed by the mapping of key, value ...
// Pairs panics if len(kv) is odd.
//
// Only the following ASCII characters are allowed in keys:
//  - digits: 0-9
//  - uppercase letters: A-Z (normalized to lower)
//  - lowercase letters: a-z
//  - special characters: -_.
// Uppercase letters are automatically converted to lowercase.
//
// Keys beginning with "grpc-" are reserved for grpc-internal use only and may
// result in errors if set in metadata.
func Pairs(kv ...string) MD <span class="cov8" title="1">{
        if len(kv)%2 == 1 </span><span class="cov0" title="0">{
                panic(fmt.Sprintf("metadata: Pairs got the odd number of input pairs for metadata: %d", len(kv)))</span>
        }
        <span class="cov8" title="1">md := MD{}
        for i := 0; i &lt; len(kv); i += 2 </span><span class="cov8" title="1">{
                key := strings.ToLower(kv[i])
                md[key] = append(md[key], kv[i+1])
        }</span>
        <span class="cov8" title="1">return md</span>
}

// Len returns the number of items in md.
func (md MD) Len() int <span class="cov0" title="0">{
        return len(md)
}</span>

// Copy returns a copy of md.
func (md MD) Copy() MD <span class="cov8" title="1">{
        return Join(md)
}</span>

// Get obtains the values for a given key.
//
// k is converted to lowercase before searching in md.
func (md MD) Get(k string) []string <span class="cov8" title="1">{
        k = strings.ToLower(k)
        return md[k]
}</span>

// Set sets the value of a given key with a slice of values.
//
// k is converted to lowercase before storing in md.
func (md MD) Set(k string, vals ...string) <span class="cov8" title="1">{
        if len(vals) == 0 </span><span class="cov8" title="1">{
                return
        }</span>
        <span class="cov8" title="1">k = strings.ToLower(k)
        md[k] = vals</span>
}

// Append adds the values to key k, not overwriting what was already stored at
// that key.
//
// k is converted to lowercase before storing in md.
func (md MD) Append(k string, vals ...string) <span class="cov8" title="1">{
        if len(vals) == 0 </span><span class="cov8" title="1">{
                return
        }</span>
        <span class="cov8" title="1">k = strings.ToLower(k)
        md[k] = append(md[k], vals...)</span>
}

// Delete removes the values for a given key k which is converted to lowercase
// before removing it from md.
func (md MD) Delete(k string) <span class="cov8" title="1">{
        k = strings.ToLower(k)
        delete(md, k)
}</span>

// Join joins any number of mds into a single MD.
//
// The order of values for each key is determined by the order in which the mds
// containing those values are presented to Join.
func Join(mds ...MD) MD <span class="cov8" title="1">{
        out := MD{}
        for _, md := range mds </span><span class="cov8" title="1">{
                for k, v := range md </span><span class="cov8" title="1">{
                        out[k] = append(out[k], v...)
                }</span>
        }
        <span class="cov8" title="1">return out</span>
}

type mdIncomingKey struct{}
type mdOutgoingKey struct{}

// NewIncomingContext creates a new context with incoming md attached.
func NewIncomingContext(ctx context.Context, md MD) context.Context <span class="cov0" title="0">{
        return context.WithValue(ctx, mdIncomingKey{}, md)
}</span>

// NewOutgoingContext creates a new context with outgoing md attached. If used
// in conjunction with AppendToOutgoingContext, NewOutgoingContext will
// overwrite any previously-appended metadata.
func NewOutgoingContext(ctx context.Context, md MD) context.Context <span class="cov8" title="1">{
        return context.WithValue(ctx, mdOutgoingKey{}, rawMD{md: md})
}</span>

// AppendToOutgoingContext returns a new context with the provided kv merged
// with any existing metadata in the context. Please refer to the documentation
// of Pairs for a description of kv.
func AppendToOutgoingContext(ctx context.Context, kv ...string) context.Context <span class="cov8" title="1">{
        if len(kv)%2 == 1 </span><span class="cov0" title="0">{
                panic(fmt.Sprintf("metadata: AppendToOutgoingContext got an odd number of input pairs for metadata: %d", len(kv)))</span>
        }
        <span class="cov8" title="1">md, _ := ctx.Value(mdOutgoingKey{}).(rawMD)
        added := make([][]string, len(md.added)+1)
        copy(added, md.added)
        added[len(added)-1] = make([]string, len(kv))
        copy(added[len(added)-1], kv)
        return context.WithValue(ctx, mdOutgoingKey{}, rawMD{md: md.md, added: added})</span>
}

// FromIncomingContext returns the incoming metadata in ctx if it exists.
//
// All keys in the returned MD are lowercase.
func FromIncomingContext(ctx context.Context) (MD, bool) <span class="cov0" title="0">{
        md, ok := ctx.Value(mdIncomingKey{}).(MD)
        if !ok </span><span class="cov0" title="0">{
                return nil, false
        }</span>
        <span class="cov0" title="0">out := MD{}
        for k, v := range md </span><span class="cov0" title="0">{
                // We need to manually convert all keys to lower case, because MD is a
                // map, and there's no guarantee that the MD attached to the context is
                // created using our helper functions.
                key := strings.ToLower(k)
                s := make([]string, len(v))
                copy(s, v)
                out[key] = s
        }</span>
        <span class="cov0" title="0">return out, true</span>
}

// FromOutgoingContextRaw returns the un-merged, intermediary contents of rawMD.
//
// Remember to perform strings.ToLower on the keys, for both the returned MD (MD
// is a map, there's no guarantee it's created using our helper functions) and
// the extra kv pairs (AppendToOutgoingContext doesn't turn them into
// lowercase).
//
// This is intended for gRPC-internal use ONLY. Users should use
// FromOutgoingContext instead.
func FromOutgoingContextRaw(ctx context.Context) (MD, [][]string, bool) <span class="cov0" title="0">{
        raw, ok := ctx.Value(mdOutgoingKey{}).(rawMD)
        if !ok </span><span class="cov0" title="0">{
                return nil, nil, false
        }</span>

        <span class="cov0" title="0">return raw.md, raw.added, true</span>
}

// FromOutgoingContext returns the outgoing metadata in ctx if it exists.
//
// All keys in the returned MD are lowercase.
func FromOutgoingContext(ctx context.Context) (MD, bool) <span class="cov8" title="1">{
        raw, ok := ctx.Value(mdOutgoingKey{}).(rawMD)
        if !ok </span><span class="cov0" title="0">{
                return nil, false
        }</span>

        <span class="cov8" title="1">out := MD{}
        for k, v := range raw.md </span><span class="cov8" title="1">{
                // We need to manually convert all keys to lower case, because MD is a
                // map, and there's no guarantee that the MD attached to the context is
                // created using our helper functions.
                key := strings.ToLower(k)
                s := make([]string, len(v))
                copy(s, v)
                out[key] = s
        }</span>
        <span class="cov8" title="1">for _, added := range raw.added </span><span class="cov8" title="1">{
                if len(added)%2 == 1 </span><span class="cov0" title="0">{
                        panic(fmt.Sprintf("metadata: FromOutgoingContext got an odd number of input pairs for metadata: %d", len(added)))</span>
                }

                <span class="cov8" title="1">for i := 0; i &lt; len(added); i += 2 </span><span class="cov8" title="1">{
                        key := strings.ToLower(added[i])
                        out[key] = append(out[key], added[i+1])
                }</span>
        }
        <span class="cov8" title="1">return out, ok</span>
}

type rawMD struct {
        md    MD
        added [][]string
}
</pre>
		
		<pre class="file" id="file125" style="display: none">/*
 *
 * Copyright 2017 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package grpc

import (
        "context"
        "io"
        "sync"

        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/internal/channelz"
        "google.golang.org/grpc/internal/transport"
        "google.golang.org/grpc/status"
)

// pickerWrapper is a wrapper of balancer.Picker. It blocks on certain pick
// actions and unblock when there's a picker update.
type pickerWrapper struct {
        mu         sync.Mutex
        done       bool
        blockingCh chan struct{}
        picker     balancer.Picker
}

func newPickerWrapper() *pickerWrapper <span class="cov8" title="1">{
        return &amp;pickerWrapper{blockingCh: make(chan struct{})}
}</span>

// updatePicker is called by UpdateBalancerState. It unblocks all blocked pick.
func (pw *pickerWrapper) updatePicker(p balancer.Picker) <span class="cov8" title="1">{
        pw.mu.Lock()
        if pw.done </span><span class="cov0" title="0">{
                pw.mu.Unlock()
                return
        }</span>
        <span class="cov8" title="1">pw.picker = p
        // pw.blockingCh should never be nil.
        close(pw.blockingCh)
        pw.blockingCh = make(chan struct{})
        pw.mu.Unlock()</span>
}

func doneChannelzWrapper(acw *acBalancerWrapper, done func(balancer.DoneInfo)) func(balancer.DoneInfo) <span class="cov0" title="0">{
        acw.mu.Lock()
        ac := acw.ac
        acw.mu.Unlock()
        ac.incrCallsStarted()
        return func(b balancer.DoneInfo) </span><span class="cov0" title="0">{
                if b.Err != nil &amp;&amp; b.Err != io.EOF </span><span class="cov0" title="0">{
                        ac.incrCallsFailed()
                }</span> else<span class="cov0" title="0"> {
                        ac.incrCallsSucceeded()
                }</span>
                <span class="cov0" title="0">if done != nil </span><span class="cov0" title="0">{
                        done(b)
                }</span>
        }
}

// pick returns the transport that will be used for the RPC.
// It may block in the following cases:
// - there's no picker
// - the current picker returns ErrNoSubConnAvailable
// - the current picker returns other errors and failfast is false.
// - the subConn returned by the current picker is not READY
// When one of these situations happens, pick blocks until the picker gets updated.
func (pw *pickerWrapper) pick(ctx context.Context, failfast bool, info balancer.PickInfo) (transport.ClientTransport, func(balancer.DoneInfo), error) <span class="cov8" title="1">{
        var ch chan struct{}

        var lastPickErr error
        for </span><span class="cov8" title="1">{
                pw.mu.Lock()
                if pw.done </span><span class="cov0" title="0">{
                        pw.mu.Unlock()
                        return nil, nil, ErrClientConnClosing
                }</span>

                <span class="cov8" title="1">if pw.picker == nil </span><span class="cov8" title="1">{
                        ch = pw.blockingCh
                }</span>
                <span class="cov8" title="1">if ch == pw.blockingCh </span><span class="cov8" title="1">{
                        // This could happen when either:
                        // - pw.picker is nil (the previous if condition), or
                        // - has called pick on the current picker.
                        pw.mu.Unlock()
                        select </span>{
                        case &lt;-ctx.Done():<span class="cov8" title="1">
                                var errStr string
                                if lastPickErr != nil </span><span class="cov0" title="0">{
                                        errStr = "latest balancer error: " + lastPickErr.Error()
                                }</span> else<span class="cov8" title="1"> {
                                        errStr = ctx.Err().Error()
                                }</span>
                                <span class="cov8" title="1">switch ctx.Err() </span>{
                                case context.DeadlineExceeded:<span class="cov8" title="1">
                                        return nil, nil, status.Error(codes.DeadlineExceeded, errStr)</span>
                                case context.Canceled:<span class="cov0" title="0">
                                        return nil, nil, status.Error(codes.Canceled, errStr)</span>
                                }
                        case &lt;-ch:<span class="cov8" title="1"></span>
                        }
                        <span class="cov8" title="1">continue</span>
                }

                <span class="cov8" title="1">ch = pw.blockingCh
                p := pw.picker
                pw.mu.Unlock()

                pickResult, err := p.Pick(info)

                if err != nil </span><span class="cov8" title="1">{
                        if err == balancer.ErrNoSubConnAvailable </span><span class="cov8" title="1">{
                                continue</span>
                        }
                        <span class="cov8" title="1">if _, ok := status.FromError(err); ok </span><span class="cov0" title="0">{
                                // Status error: end the RPC unconditionally with this status.
                                return nil, nil, dropError{error: err}
                        }</span>
                        // For all other errors, wait for ready RPCs should block and other
                        // RPCs should fail with unavailable.
                        <span class="cov8" title="1">if !failfast </span><span class="cov8" title="1">{
                                lastPickErr = err
                                continue</span>
                        }
                        <span class="cov0" title="0">return nil, nil, status.Error(codes.Unavailable, err.Error())</span>
                }

                <span class="cov8" title="1">acw, ok := pickResult.SubConn.(*acBalancerWrapper)
                if !ok </span><span class="cov0" title="0">{
                        logger.Errorf("subconn returned from pick is type %T, not *acBalancerWrapper", pickResult.SubConn)
                        continue</span>
                }
                <span class="cov8" title="1">if t := acw.getAddrConn().getReadyTransport(); t != nil </span><span class="cov8" title="1">{
                        if channelz.IsOn() </span><span class="cov0" title="0">{
                                return t, doneChannelzWrapper(acw, pickResult.Done), nil
                        }</span>
                        <span class="cov8" title="1">return t, pickResult.Done, nil</span>
                }
                <span class="cov8" title="1">if pickResult.Done != nil </span><span class="cov0" title="0">{
                        // Calling done with nil error, no bytes sent and no bytes received.
                        // DoneInfo with default value works.
                        pickResult.Done(balancer.DoneInfo{})
                }</span>
                <span class="cov8" title="1">logger.Infof("blockingPicker: the picked transport is not ready, loop back to repick")</span>
                // If ok == false, ac.state is not READY.
                // A valid picker always returns READY subConn. This means the state of ac
                // just changed, and picker will be updated shortly.
                // continue back to the beginning of the for loop to repick.
        }
}

func (pw *pickerWrapper) close() <span class="cov8" title="1">{
        pw.mu.Lock()
        defer pw.mu.Unlock()
        if pw.done </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov8" title="1">pw.done = true
        close(pw.blockingCh)</span>
}

// dropError is a wrapper error that indicates the LB policy wishes to drop the
// RPC and not retry it.
type dropError struct {
        error
}
</pre>
		
		<pre class="file" id="file126" style="display: none">/*
 *
 * Copyright 2017 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package grpc

import (
        "errors"
        "fmt"

        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/connectivity"
)

// PickFirstBalancerName is the name of the pick_first balancer.
const PickFirstBalancerName = "pick_first"

func newPickfirstBuilder() balancer.Builder <span class="cov8" title="1">{
        return &amp;pickfirstBuilder{}
}</span>

type pickfirstBuilder struct{}

func (*pickfirstBuilder) Build(cc balancer.ClientConn, opt balancer.BuildOptions) balancer.Balancer <span class="cov8" title="1">{
        return &amp;pickfirstBalancer{cc: cc}
}</span>

func (*pickfirstBuilder) Name() string <span class="cov8" title="1">{
        return PickFirstBalancerName
}</span>

type pickfirstBalancer struct {
        state   connectivity.State
        cc      balancer.ClientConn
        subConn balancer.SubConn
}

func (b *pickfirstBalancer) ResolverError(err error) <span class="cov8" title="1">{
        if logger.V(2) </span><span class="cov0" title="0">{
                logger.Infof("pickfirstBalancer: ResolverError called with error %v", err)
        }</span>
        <span class="cov8" title="1">if b.subConn == nil </span><span class="cov8" title="1">{
                b.state = connectivity.TransientFailure
        }</span>

        <span class="cov8" title="1">if b.state != connectivity.TransientFailure </span><span class="cov0" title="0">{
                // The picker will not change since the balancer does not currently
                // report an error.
                return
        }</span>
        <span class="cov8" title="1">b.cc.UpdateState(balancer.State{
                ConnectivityState: connectivity.TransientFailure,
                Picker:            &amp;picker{err: fmt.Errorf("name resolver error: %v", err)},
        })</span>
}

func (b *pickfirstBalancer) UpdateClientConnState(state balancer.ClientConnState) error <span class="cov8" title="1">{
        if len(state.ResolverState.Addresses) == 0 </span><span class="cov8" title="1">{
                // The resolver reported an empty address list. Treat it like an error by
                // calling b.ResolverError.
                if b.subConn != nil </span><span class="cov0" title="0">{
                        // Remove the old subConn. All addresses were removed, so it is no longer
                        // valid.
                        b.cc.RemoveSubConn(b.subConn)
                        b.subConn = nil
                }</span>
                <span class="cov8" title="1">b.ResolverError(errors.New("produced zero addresses"))
                return balancer.ErrBadResolverState</span>
        }

        <span class="cov8" title="1">if b.subConn != nil </span><span class="cov0" title="0">{
                b.cc.UpdateAddresses(b.subConn, state.ResolverState.Addresses)
                return nil
        }</span>

        <span class="cov8" title="1">subConn, err := b.cc.NewSubConn(state.ResolverState.Addresses, balancer.NewSubConnOptions{})
        if err != nil </span><span class="cov0" title="0">{
                if logger.V(2) </span><span class="cov0" title="0">{
                        logger.Errorf("pickfirstBalancer: failed to NewSubConn: %v", err)
                }</span>
                <span class="cov0" title="0">b.state = connectivity.TransientFailure
                b.cc.UpdateState(balancer.State{
                        ConnectivityState: connectivity.TransientFailure,
                        Picker:            &amp;picker{err: fmt.Errorf("error creating connection: %v", err)},
                })
                return balancer.ErrBadResolverState</span>
        }
        <span class="cov8" title="1">b.subConn = subConn
        b.state = connectivity.Idle
        b.cc.UpdateState(balancer.State{
                ConnectivityState: connectivity.Idle,
                Picker:            &amp;picker{result: balancer.PickResult{SubConn: b.subConn}},
        })
        b.subConn.Connect()
        return nil</span>
}

func (b *pickfirstBalancer) UpdateSubConnState(subConn balancer.SubConn, state balancer.SubConnState) <span class="cov8" title="1">{
        if logger.V(2) </span><span class="cov0" title="0">{
                logger.Infof("pickfirstBalancer: UpdateSubConnState: %p, %v", subConn, state)
        }</span>
        <span class="cov8" title="1">if b.subConn != subConn </span><span class="cov0" title="0">{
                if logger.V(2) </span><span class="cov0" title="0">{
                        logger.Infof("pickfirstBalancer: ignored state change because subConn is not recognized")
                }</span>
                <span class="cov0" title="0">return</span>
        }
        <span class="cov8" title="1">b.state = state.ConnectivityState
        if state.ConnectivityState == connectivity.Shutdown </span><span class="cov0" title="0">{
                b.subConn = nil
                return
        }</span>

        <span class="cov8" title="1">switch state.ConnectivityState </span>{
        case connectivity.Ready:<span class="cov8" title="1">
                b.cc.UpdateState(balancer.State{
                        ConnectivityState: state.ConnectivityState,
                        Picker:            &amp;picker{result: balancer.PickResult{SubConn: subConn}},
                })</span>
        case connectivity.Connecting:<span class="cov8" title="1">
                b.cc.UpdateState(balancer.State{
                        ConnectivityState: state.ConnectivityState,
                        Picker:            &amp;picker{err: balancer.ErrNoSubConnAvailable},
                })</span>
        case connectivity.Idle:<span class="cov8" title="1">
                b.cc.UpdateState(balancer.State{
                        ConnectivityState: state.ConnectivityState,
                        Picker:            &amp;idlePicker{subConn: subConn},
                })</span>
        case connectivity.TransientFailure:<span class="cov8" title="1">
                b.cc.UpdateState(balancer.State{
                        ConnectivityState: state.ConnectivityState,
                        Picker:            &amp;picker{err: state.ConnectionError},
                })</span>
        }
}

func (b *pickfirstBalancer) Close() {<span class="cov8" title="1">
}</span>

func (b *pickfirstBalancer) ExitIdle() <span class="cov8" title="1">{
        if b.subConn != nil &amp;&amp; b.state == connectivity.Idle </span><span class="cov8" title="1">{
                b.subConn.Connect()
        }</span>
}

type picker struct {
        result balancer.PickResult
        err    error
}

func (p *picker) Pick(balancer.PickInfo) (balancer.PickResult, error) <span class="cov0" title="0">{
        return p.result, p.err
}</span>

// idlePicker is used when the SubConn is IDLE and kicks the SubConn into
// CONNECTING when Pick is called.
type idlePicker struct {
        subConn balancer.SubConn
}

func (i *idlePicker) Pick(balancer.PickInfo) (balancer.PickResult, error) <span class="cov0" title="0">{
        i.subConn.Connect()
        return balancer.PickResult{}, balancer.ErrNoSubConnAvailable
}</span>

func init() <span class="cov8" title="1">{
        balancer.Register(newPickfirstBuilder())
}</span>
</pre>
		
		<pre class="file" id="file127" style="display: none">/*
 *
 * Copyright 2019 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package grpc

import (
        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/status"
)

// PreparedMsg is responsible for creating a Marshalled and Compressed object.
//
// Experimental
//
// Notice: This type is EXPERIMENTAL and may be changed or removed in a
// later release.
type PreparedMsg struct {
        // Struct for preparing msg before sending them
        encodedData []byte
        hdr         []byte
        payload     []byte
}

// Encode marshalls and compresses the message using the codec and compressor for the stream.
func (p *PreparedMsg) Encode(s Stream, msg interface{}) error <span class="cov0" title="0">{
        ctx := s.Context()
        rpcInfo, ok := rpcInfoFromContext(ctx)
        if !ok </span><span class="cov0" title="0">{
                return status.Errorf(codes.Internal, "grpc: unable to get rpcInfo")
        }</span>

        // check if the context has the relevant information to prepareMsg
        <span class="cov0" title="0">if rpcInfo.preloaderInfo == nil </span><span class="cov0" title="0">{
                return status.Errorf(codes.Internal, "grpc: rpcInfo.preloaderInfo is nil")
        }</span>
        <span class="cov0" title="0">if rpcInfo.preloaderInfo.codec == nil </span><span class="cov0" title="0">{
                return status.Errorf(codes.Internal, "grpc: rpcInfo.preloaderInfo.codec is nil")
        }</span>

        // prepare the msg
        <span class="cov0" title="0">data, err := encode(rpcInfo.preloaderInfo.codec, msg)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov0" title="0">p.encodedData = data
        compData, err := compress(data, rpcInfo.preloaderInfo.cp, rpcInfo.preloaderInfo.comp)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov0" title="0">p.hdr, p.payload = msgHeader(data, compData)
        return nil</span>
}
</pre>
		
		<pre class="file" id="file128" style="display: none">/*
 *
 * Copyright 2016 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

/*
Package reflection implements server reflection service.

The service implemented is defined in:
https://github.com/grpc/grpc/blob/master/src/proto/grpc/reflection/v1alpha/reflection.proto.

To register server reflection on a gRPC server:
        import "google.golang.org/grpc/reflection"

        s := grpc.NewServer()
        pb.RegisterYourOwnServer(s, &amp;server{})

        // Register reflection service on gRPC server.
        reflection.Register(s)

        s.Serve(lis)

*/
package reflection // import "google.golang.org/grpc/reflection"

import (
        "io"
        "sort"

        "google.golang.org/grpc"
        "google.golang.org/grpc/codes"
        rpb "google.golang.org/grpc/reflection/grpc_reflection_v1alpha"
        "google.golang.org/grpc/status"
        "google.golang.org/protobuf/proto"
        "google.golang.org/protobuf/reflect/protodesc"
        "google.golang.org/protobuf/reflect/protoreflect"
        "google.golang.org/protobuf/reflect/protoregistry"
)

// GRPCServer is the interface provided by a gRPC server. It is implemented by
// *grpc.Server, but could also be implemented by other concrete types. It acts
// as a registry, for accumulating the services exposed by the server.
type GRPCServer interface {
        grpc.ServiceRegistrar
        ServiceInfoProvider
}

var _ GRPCServer = (*grpc.Server)(nil)

// Register registers the server reflection service on the given gRPC server.
func Register(s GRPCServer) <span class="cov8" title="1">{
        svr := NewServer(ServerOptions{Services: s})
        rpb.RegisterServerReflectionServer(s, svr)
}</span>

// ServiceInfoProvider is an interface used to retrieve metadata about the
// services to expose.
//
// The reflection service is only interested in the service names, but the
// signature is this way so that *grpc.Server implements it. So it is okay
// for a custom implementation to return zero values for the
// grpc.ServiceInfo values in the map.
//
// Experimental
//
// Notice: This type is EXPERIMENTAL and may be changed or removed in a
// later release.
type ServiceInfoProvider interface {
        GetServiceInfo() map[string]grpc.ServiceInfo
}

// ExtensionResolver is the interface used to query details about extensions.
// This interface is satisfied by protoregistry.GlobalTypes.
//
// Experimental
//
// Notice: This type is EXPERIMENTAL and may be changed or removed in a
// later release.
type ExtensionResolver interface {
        protoregistry.ExtensionTypeResolver
        RangeExtensionsByMessage(message protoreflect.FullName, f func(protoreflect.ExtensionType) bool)
}

// ServerOptions represents the options used to construct a reflection server.
//
// Experimental
//
// Notice: This type is EXPERIMENTAL and may be changed or removed in a
// later release.
type ServerOptions struct {
        // The source of advertised RPC services. If not specified, the reflection
        // server will report an empty list when asked to list services.
        //
        // This value will typically be a *grpc.Server. But the set of advertised
        // services can be customized by wrapping a *grpc.Server or using an
        // alternate implementation that returns a custom set of service names.
        Services ServiceInfoProvider
        // Optional resolver used to load descriptors. If not specified,
        // protoregistry.GlobalFiles will be used.
        DescriptorResolver protodesc.Resolver
        // Optional resolver used to query for known extensions. If not specified,
        // protoregistry.GlobalTypes will be used.
        ExtensionResolver ExtensionResolver
}

// NewServer returns a reflection server implementation using the given options.
// This can be used to customize behavior of the reflection service. Most usages
// should prefer to use Register instead.
//
// Experimental
//
// Notice: This function is EXPERIMENTAL and may be changed or removed in a
// later release.
func NewServer(opts ServerOptions) rpb.ServerReflectionServer <span class="cov8" title="1">{
        if opts.DescriptorResolver == nil </span><span class="cov8" title="1">{
                opts.DescriptorResolver = protoregistry.GlobalFiles
        }</span>
        <span class="cov8" title="1">if opts.ExtensionResolver == nil </span><span class="cov8" title="1">{
                opts.ExtensionResolver = protoregistry.GlobalTypes
        }</span>
        <span class="cov8" title="1">return &amp;serverReflectionServer{
                s:            opts.Services,
                descResolver: opts.DescriptorResolver,
                extResolver:  opts.ExtensionResolver,
        }</span>
}

type serverReflectionServer struct {
        rpb.UnimplementedServerReflectionServer
        s            ServiceInfoProvider
        descResolver protodesc.Resolver
        extResolver  ExtensionResolver
}

// fileDescWithDependencies returns a slice of serialized fileDescriptors in
// wire format ([]byte). The fileDescriptors will include fd and all the
// transitive dependencies of fd with names not in sentFileDescriptors.
func (s *serverReflectionServer) fileDescWithDependencies(fd protoreflect.FileDescriptor, sentFileDescriptors map[string]bool) ([][]byte, error) <span class="cov8" title="1">{
        var r [][]byte
        queue := []protoreflect.FileDescriptor{fd}
        for len(queue) &gt; 0 </span><span class="cov8" title="1">{
                currentfd := queue[0]
                queue = queue[1:]
                if sent := sentFileDescriptors[currentfd.Path()]; len(r) == 0 || !sent </span><span class="cov8" title="1">{
                        sentFileDescriptors[currentfd.Path()] = true
                        fdProto := protodesc.ToFileDescriptorProto(currentfd)
                        currentfdEncoded, err := proto.Marshal(fdProto)
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov8" title="1">r = append(r, currentfdEncoded)</span>
                }
                <span class="cov8" title="1">for i := 0; i &lt; currentfd.Imports().Len(); i++ </span><span class="cov8" title="1">{
                        queue = append(queue, currentfd.Imports().Get(i))
                }</span>
        }
        <span class="cov8" title="1">return r, nil</span>
}

// fileDescEncodingContainingSymbol finds the file descriptor containing the
// given symbol, finds all of its previously unsent transitive dependencies,
// does marshalling on them, and returns the marshalled result. The given symbol
// can be a type, a service or a method.
func (s *serverReflectionServer) fileDescEncodingContainingSymbol(name string, sentFileDescriptors map[string]bool) ([][]byte, error) <span class="cov8" title="1">{
        d, err := s.descResolver.FindDescriptorByName(protoreflect.FullName(name))
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return s.fileDescWithDependencies(d.ParentFile(), sentFileDescriptors)</span>
}

// fileDescEncodingContainingExtension finds the file descriptor containing
// given extension, finds all of its previously unsent transitive dependencies,
// does marshalling on them, and returns the marshalled result.
func (s *serverReflectionServer) fileDescEncodingContainingExtension(typeName string, extNum int32, sentFileDescriptors map[string]bool) ([][]byte, error) <span class="cov8" title="1">{
        xt, err := s.extResolver.FindExtensionByNumber(protoreflect.FullName(typeName), protoreflect.FieldNumber(extNum))
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return s.fileDescWithDependencies(xt.TypeDescriptor().ParentFile(), sentFileDescriptors)</span>
}

// allExtensionNumbersForTypeName returns all extension numbers for the given type.
func (s *serverReflectionServer) allExtensionNumbersForTypeName(name string) ([]int32, error) <span class="cov8" title="1">{
        var numbers []int32
        s.extResolver.RangeExtensionsByMessage(protoreflect.FullName(name), func(xt protoreflect.ExtensionType) bool </span><span class="cov8" title="1">{
                numbers = append(numbers, int32(xt.TypeDescriptor().Number()))
                return true
        }</span>)
        <span class="cov8" title="1">sort.Slice(numbers, func(i, j int) bool </span><span class="cov8" title="1">{
                return numbers[i] &lt; numbers[j]
        }</span>)
        <span class="cov8" title="1">if len(numbers) == 0 </span><span class="cov8" title="1">{
                // maybe return an error if given type name is not known
                if _, err := s.descResolver.FindDescriptorByName(protoreflect.FullName(name)); err != nil </span><span class="cov8" title="1">{
                        return nil, err
                }</span>
        }
        <span class="cov8" title="1">return numbers, nil</span>
}

// listServices returns the names of services this server exposes.
func (s *serverReflectionServer) listServices() []*rpb.ServiceResponse <span class="cov8" title="1">{
        serviceInfo := s.s.GetServiceInfo()
        resp := make([]*rpb.ServiceResponse, 0, len(serviceInfo))
        for svc := range serviceInfo </span><span class="cov8" title="1">{
                resp = append(resp, &amp;rpb.ServiceResponse{Name: svc})
        }</span>
        <span class="cov8" title="1">sort.Slice(resp, func(i, j int) bool </span><span class="cov8" title="1">{
                return resp[i].Name &lt; resp[j].Name
        }</span>)
        <span class="cov8" title="1">return resp</span>
}

// ServerReflectionInfo is the reflection service handler.
func (s *serverReflectionServer) ServerReflectionInfo(stream rpb.ServerReflection_ServerReflectionInfoServer) error <span class="cov8" title="1">{
        sentFileDescriptors := make(map[string]bool)
        for </span><span class="cov8" title="1">{
                in, err := stream.Recv()
                if err == io.EOF </span><span class="cov0" title="0">{
                        return nil
                }</span>
                <span class="cov8" title="1">if err != nil </span><span class="cov8" title="1">{
                        return err
                }</span>

                <span class="cov8" title="1">out := &amp;rpb.ServerReflectionResponse{
                        ValidHost:       in.Host,
                        OriginalRequest: in,
                }
                switch req := in.MessageRequest.(type) </span>{
                case *rpb.ServerReflectionRequest_FileByFilename:<span class="cov8" title="1">
                        var b [][]byte
                        fd, err := s.descResolver.FindFileByPath(req.FileByFilename)
                        if err == nil </span><span class="cov8" title="1">{
                                b, err = s.fileDescWithDependencies(fd, sentFileDescriptors)
                        }</span>
                        <span class="cov8" title="1">if err != nil </span><span class="cov8" title="1">{
                                out.MessageResponse = &amp;rpb.ServerReflectionResponse_ErrorResponse{
                                        ErrorResponse: &amp;rpb.ErrorResponse{
                                                ErrorCode:    int32(codes.NotFound),
                                                ErrorMessage: err.Error(),
                                        },
                                }
                        }</span> else<span class="cov8" title="1"> {
                                out.MessageResponse = &amp;rpb.ServerReflectionResponse_FileDescriptorResponse{
                                        FileDescriptorResponse: &amp;rpb.FileDescriptorResponse{FileDescriptorProto: b},
                                }
                        }</span>
                case *rpb.ServerReflectionRequest_FileContainingSymbol:<span class="cov8" title="1">
                        b, err := s.fileDescEncodingContainingSymbol(req.FileContainingSymbol, sentFileDescriptors)
                        if err != nil </span><span class="cov8" title="1">{
                                out.MessageResponse = &amp;rpb.ServerReflectionResponse_ErrorResponse{
                                        ErrorResponse: &amp;rpb.ErrorResponse{
                                                ErrorCode:    int32(codes.NotFound),
                                                ErrorMessage: err.Error(),
                                        },
                                }
                        }</span> else<span class="cov8" title="1"> {
                                out.MessageResponse = &amp;rpb.ServerReflectionResponse_FileDescriptorResponse{
                                        FileDescriptorResponse: &amp;rpb.FileDescriptorResponse{FileDescriptorProto: b},
                                }
                        }</span>
                case *rpb.ServerReflectionRequest_FileContainingExtension:<span class="cov8" title="1">
                        typeName := req.FileContainingExtension.ContainingType
                        extNum := req.FileContainingExtension.ExtensionNumber
                        b, err := s.fileDescEncodingContainingExtension(typeName, extNum, sentFileDescriptors)
                        if err != nil </span><span class="cov8" title="1">{
                                out.MessageResponse = &amp;rpb.ServerReflectionResponse_ErrorResponse{
                                        ErrorResponse: &amp;rpb.ErrorResponse{
                                                ErrorCode:    int32(codes.NotFound),
                                                ErrorMessage: err.Error(),
                                        },
                                }
                        }</span> else<span class="cov8" title="1"> {
                                out.MessageResponse = &amp;rpb.ServerReflectionResponse_FileDescriptorResponse{
                                        FileDescriptorResponse: &amp;rpb.FileDescriptorResponse{FileDescriptorProto: b},
                                }
                        }</span>
                case *rpb.ServerReflectionRequest_AllExtensionNumbersOfType:<span class="cov8" title="1">
                        extNums, err := s.allExtensionNumbersForTypeName(req.AllExtensionNumbersOfType)
                        if err != nil </span><span class="cov8" title="1">{
                                out.MessageResponse = &amp;rpb.ServerReflectionResponse_ErrorResponse{
                                        ErrorResponse: &amp;rpb.ErrorResponse{
                                                ErrorCode:    int32(codes.NotFound),
                                                ErrorMessage: err.Error(),
                                        },
                                }
                        }</span> else<span class="cov8" title="1"> {
                                out.MessageResponse = &amp;rpb.ServerReflectionResponse_AllExtensionNumbersResponse{
                                        AllExtensionNumbersResponse: &amp;rpb.ExtensionNumberResponse{
                                                BaseTypeName:    req.AllExtensionNumbersOfType,
                                                ExtensionNumber: extNums,
                                        },
                                }
                        }</span>
                case *rpb.ServerReflectionRequest_ListServices:<span class="cov8" title="1">
                        out.MessageResponse = &amp;rpb.ServerReflectionResponse_ListServicesResponse{
                                ListServicesResponse: &amp;rpb.ListServiceResponse{
                                        Service: s.listServices(),
                                },
                        }</span>
                default:<span class="cov0" title="0">
                        return status.Errorf(codes.InvalidArgument, "invalid MessageRequest: %v", in.MessageRequest)</span>
                }

                <span class="cov8" title="1">if err := stream.Send(out); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
        }
}
</pre>
		
		<pre class="file" id="file129" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package resolver

type addressMapEntry struct {
        addr  Address
        value interface{}
}

// AddressMap is a map of addresses to arbitrary values taking into account
// Attributes.  BalancerAttributes are ignored, as are Metadata and Type.
// Multiple accesses may not be performed concurrently.  Must be created via
// NewAddressMap; do not construct directly.
type AddressMap struct {
        // The underlying map is keyed by an Address with fields that we don't care
        // about being set to their zero values. The only fields that we care about
        // are `Addr`, `ServerName` and `Attributes`. Since we need to be able to
        // distinguish between addresses with same `Addr` and `ServerName`, but
        // different `Attributes`, we cannot store the `Attributes` in the map key.
        //
        // The comparison operation for structs work as follows:
        //  Struct values are comparable if all their fields are comparable. Two
        //  struct values are equal if their corresponding non-blank fields are equal.
        //
        // The value type of the map contains a slice of addresses which match the key
        // in their `Addr` and `ServerName` fields and contain the corresponding value
        // associated with them.
        m map[Address]addressMapEntryList
}

func toMapKey(addr *Address) Address <span class="cov8" title="1">{
        return Address{Addr: addr.Addr, ServerName: addr.ServerName}
}</span>

type addressMapEntryList []*addressMapEntry

// NewAddressMap creates a new AddressMap.
func NewAddressMap() *AddressMap <span class="cov8" title="1">{
        return &amp;AddressMap{m: make(map[Address]addressMapEntryList)}
}</span>

// find returns the index of addr in the addressMapEntry slice, or -1 if not
// present.
func (l addressMapEntryList) find(addr Address) int <span class="cov8" title="1">{
        for i, entry := range l </span><span class="cov8" title="1">{
                // Attributes are the only thing to match on here, since `Addr` and
                // `ServerName` are already equal.
                if entry.addr.Attributes.Equal(addr.Attributes) </span><span class="cov8" title="1">{
                        return i
                }</span>
        }
        <span class="cov8" title="1">return -1</span>
}

// Get returns the value for the address in the map, if present.
func (a *AddressMap) Get(addr Address) (value interface{}, ok bool) <span class="cov8" title="1">{
        addrKey := toMapKey(&amp;addr)
        entryList := a.m[addrKey]
        if entry := entryList.find(addr); entry != -1 </span><span class="cov8" title="1">{
                return entryList[entry].value, true
        }</span>
        <span class="cov8" title="1">return nil, false</span>
}

// Set updates or adds the value to the address in the map.
func (a *AddressMap) Set(addr Address, value interface{}) <span class="cov8" title="1">{
        addrKey := toMapKey(&amp;addr)
        entryList := a.m[addrKey]
        if entry := entryList.find(addr); entry != -1 </span><span class="cov8" title="1">{
                entryList[entry].value = value
                return
        }</span>
        <span class="cov8" title="1">a.m[addrKey] = append(entryList, &amp;addressMapEntry{addr: addr, value: value})</span>
}

// Delete removes addr from the map.
func (a *AddressMap) Delete(addr Address) <span class="cov8" title="1">{
        addrKey := toMapKey(&amp;addr)
        entryList := a.m[addrKey]
        entry := entryList.find(addr)
        if entry == -1 </span><span class="cov8" title="1">{
                return
        }</span>
        <span class="cov8" title="1">if len(entryList) == 1 </span><span class="cov8" title="1">{
                entryList = nil
        }</span> else<span class="cov0" title="0"> {
                copy(entryList[entry:], entryList[entry+1:])
                entryList = entryList[:len(entryList)-1]
        }</span>
        <span class="cov8" title="1">a.m[addrKey] = entryList</span>
}

// Len returns the number of entries in the map.
func (a *AddressMap) Len() int <span class="cov8" title="1">{
        ret := 0
        for _, entryList := range a.m </span><span class="cov8" title="1">{
                ret += len(entryList)
        }</span>
        <span class="cov8" title="1">return ret</span>
}

// Keys returns a slice of all current map keys.
func (a *AddressMap) Keys() []Address <span class="cov8" title="1">{
        ret := make([]Address, 0, a.Len())
        for _, entryList := range a.m </span><span class="cov8" title="1">{
                for _, entry := range entryList </span><span class="cov8" title="1">{
                        ret = append(ret, entry.addr)
                }</span>
        }
        <span class="cov8" title="1">return ret</span>
}

// Values returns a slice of all current map values.
func (a *AddressMap) Values() []interface{} <span class="cov8" title="1">{
        ret := make([]interface{}, 0, a.Len())
        for _, entryList := range a.m </span><span class="cov8" title="1">{
                for _, entry := range entryList </span><span class="cov8" title="1">{
                        ret = append(ret, entry.value)
                }</span>
        }
        <span class="cov8" title="1">return ret</span>
}
</pre>
		
		<pre class="file" id="file130" style="display: none">/*
 *
 * Copyright 2017 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package resolver defines APIs for name resolution in gRPC.
// All APIs in this package are experimental.
package resolver

import (
        "context"
        "net"
        "net/url"

        "google.golang.org/grpc/attributes"
        "google.golang.org/grpc/credentials"
        "google.golang.org/grpc/internal/pretty"
        "google.golang.org/grpc/serviceconfig"
)

var (
        // m is a map from scheme to resolver builder.
        m = make(map[string]Builder)
        // defaultScheme is the default scheme to use.
        defaultScheme = "passthrough"
)

// TODO(bar) install dns resolver in init(){}.

// Register registers the resolver builder to the resolver map. b.Scheme will be
// used as the scheme registered with this builder.
//
// NOTE: this function must only be called during initialization time (i.e. in
// an init() function), and is not thread-safe. If multiple Resolvers are
// registered with the same name, the one registered last will take effect.
func Register(b Builder) <span class="cov0" title="0">{
        m[b.Scheme()] = b
}</span>

// Get returns the resolver builder registered with the given scheme.
//
// If no builder is register with the scheme, nil will be returned.
func Get(scheme string) Builder <span class="cov0" title="0">{
        if b, ok := m[scheme]; ok </span><span class="cov0" title="0">{
                return b
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// SetDefaultScheme sets the default scheme that will be used. The default
// default scheme is "passthrough".
//
// NOTE: this function must only be called during initialization time (i.e. in
// an init() function), and is not thread-safe. The scheme set last overrides
// previously set values.
func SetDefaultScheme(scheme string) <span class="cov0" title="0">{
        defaultScheme = scheme
}</span>

// GetDefaultScheme gets the default scheme that will be used.
func GetDefaultScheme() string <span class="cov0" title="0">{
        return defaultScheme
}</span>

// AddressType indicates the address type returned by name resolution.
//
// Deprecated: use Attributes in Address instead.
type AddressType uint8

const (
        // Backend indicates the address is for a backend server.
        //
        // Deprecated: use Attributes in Address instead.
        Backend AddressType = iota
        // GRPCLB indicates the address is for a grpclb load balancer.
        //
        // Deprecated: to select the GRPCLB load balancing policy, use a service
        // config with a corresponding loadBalancingConfig.  To supply balancer
        // addresses to the GRPCLB load balancing policy, set State.Attributes
        // using balancer/grpclb/state.Set.
        GRPCLB
)

// Address represents a server the client connects to.
//
// Experimental
//
// Notice: This type is EXPERIMENTAL and may be changed or removed in a
// later release.
type Address struct {
        // Addr is the server address on which a connection will be established.
        Addr string

        // ServerName is the name of this address.
        // If non-empty, the ServerName is used as the transport certification authority for
        // the address, instead of the hostname from the Dial target string. In most cases,
        // this should not be set.
        //
        // If Type is GRPCLB, ServerName should be the name of the remote load
        // balancer, not the name of the backend.
        //
        // WARNING: ServerName must only be populated with trusted values. It
        // is insecure to populate it with data from untrusted inputs since untrusted
        // values could be used to bypass the authority checks performed by TLS.
        ServerName string

        // Attributes contains arbitrary data about this address intended for
        // consumption by the SubConn.
        Attributes *attributes.Attributes

        // BalancerAttributes contains arbitrary data about this address intended
        // for consumption by the LB policy.  These attribes do not affect SubConn
        // creation, connection establishment, handshaking, etc.
        BalancerAttributes *attributes.Attributes

        // Type is the type of this address.
        //
        // Deprecated: use Attributes instead.
        Type AddressType

        // Metadata is the information associated with Addr, which may be used
        // to make load balancing decision.
        //
        // Deprecated: use Attributes instead.
        Metadata interface{}
}

// Equal returns whether a and o are identical.  Metadata is compared directly,
// not with any recursive introspection.
func (a Address) Equal(o Address) bool <span class="cov8" title="1">{
        return a.Addr == o.Addr &amp;&amp; a.ServerName == o.ServerName &amp;&amp;
                a.Attributes.Equal(o.Attributes) &amp;&amp;
                a.BalancerAttributes.Equal(o.BalancerAttributes) &amp;&amp;
                a.Type == o.Type &amp;&amp; a.Metadata == o.Metadata
}</span>

// String returns JSON formatted string representation of the address.
func (a Address) String() string <span class="cov8" title="1">{
        return pretty.ToJSON(a)
}</span>

// BuildOptions includes additional information for the builder to create
// the resolver.
type BuildOptions struct {
        // DisableServiceConfig indicates whether a resolver implementation should
        // fetch service config data.
        DisableServiceConfig bool
        // DialCreds is the transport credentials used by the ClientConn for
        // communicating with the target gRPC service (set via
        // WithTransportCredentials). In cases where a name resolution service
        // requires the same credentials, the resolver may use this field. In most
        // cases though, it is not appropriate, and this field may be ignored.
        DialCreds credentials.TransportCredentials
        // CredsBundle is the credentials bundle used by the ClientConn for
        // communicating with the target gRPC service (set via
        // WithCredentialsBundle). In cases where a name resolution service
        // requires the same credentials, the resolver may use this field. In most
        // cases though, it is not appropriate, and this field may be ignored.
        CredsBundle credentials.Bundle
        // Dialer is the custom dialer used by the ClientConn for dialling the
        // target gRPC service (set via WithDialer). In cases where a name
        // resolution service requires the same dialer, the resolver may use this
        // field. In most cases though, it is not appropriate, and this field may
        // be ignored.
        Dialer func(context.Context, string) (net.Conn, error)
}

// State contains the current Resolver state relevant to the ClientConn.
type State struct {
        // Addresses is the latest set of resolved addresses for the target.
        Addresses []Address

        // ServiceConfig contains the result from parsing the latest service
        // config.  If it is nil, it indicates no service config is present or the
        // resolver does not provide service configs.
        ServiceConfig *serviceconfig.ParseResult

        // Attributes contains arbitrary data about the resolver intended for
        // consumption by the load balancing policy.
        Attributes *attributes.Attributes
}

// ClientConn contains the callbacks for resolver to notify any updates
// to the gRPC ClientConn.
//
// This interface is to be implemented by gRPC. Users should not need a
// brand new implementation of this interface. For the situations like
// testing, the new implementation should embed this interface. This allows
// gRPC to add new methods to this interface.
type ClientConn interface {
        // UpdateState updates the state of the ClientConn appropriately.
        UpdateState(State) error
        // ReportError notifies the ClientConn that the Resolver encountered an
        // error.  The ClientConn will notify the load balancer and begin calling
        // ResolveNow on the Resolver with exponential backoff.
        ReportError(error)
        // NewAddress is called by resolver to notify ClientConn a new list
        // of resolved addresses.
        // The address list should be the complete list of resolved addresses.
        //
        // Deprecated: Use UpdateState instead.
        NewAddress(addresses []Address)
        // NewServiceConfig is called by resolver to notify ClientConn a new
        // service config. The service config should be provided as a json string.
        //
        // Deprecated: Use UpdateState instead.
        NewServiceConfig(serviceConfig string)
        // ParseServiceConfig parses the provided service config and returns an
        // object that provides the parsed config.
        ParseServiceConfig(serviceConfigJSON string) *serviceconfig.ParseResult
}

// Target represents a target for gRPC, as specified in:
// https://github.com/grpc/grpc/blob/master/doc/naming.md.
// It is parsed from the target string that gets passed into Dial or DialContext
// by the user. And gRPC passes it to the resolver and the balancer.
//
// If the target follows the naming spec, and the parsed scheme is registered
// with gRPC, we will parse the target string according to the spec. If the
// target does not contain a scheme or if the parsed scheme is not registered
// (i.e. no corresponding resolver available to resolve the endpoint), we will
// apply the default scheme, and will attempt to reparse it.
//
// Examples:
//
// - "dns://some_authority/foo.bar"
//   Target{Scheme: "dns", Authority: "some_authority", Endpoint: "foo.bar"}
// - "foo.bar"
//   Target{Scheme: resolver.GetDefaultScheme(), Endpoint: "foo.bar"}
// - "unknown_scheme://authority/endpoint"
//   Target{Scheme: resolver.GetDefaultScheme(), Endpoint: "unknown_scheme://authority/endpoint"}
type Target struct {
        // Deprecated: use URL.Scheme instead.
        Scheme string
        // Deprecated: use URL.Host instead.
        Authority string
        // Deprecated: use URL.Path or URL.Opaque instead. The latter is set when
        // the former is empty.
        Endpoint string
        // URL contains the parsed dial target with an optional default scheme added
        // to it if the original dial target contained no scheme or contained an
        // unregistered scheme. Any query params specified in the original dial
        // target can be accessed from here.
        URL url.URL
}

// Builder creates a resolver that will be used to watch name resolution updates.
type Builder interface {
        // Build creates a new resolver for the given target.
        //
        // gRPC dial calls Build synchronously, and fails if the returned error is
        // not nil.
        Build(target Target, cc ClientConn, opts BuildOptions) (Resolver, error)
        // Scheme returns the scheme supported by this resolver.
        // Scheme is defined at https://github.com/grpc/grpc/blob/master/doc/naming.md.
        Scheme() string
}

// ResolveNowOptions includes additional information for ResolveNow.
type ResolveNowOptions struct{}

// Resolver watches for the updates on the specified target.
// Updates include address updates and service config updates.
type Resolver interface {
        // ResolveNow will be called by gRPC to try to resolve the target name
        // again. It's just a hint, resolver can ignore this if it's not necessary.
        //
        // It could be called multiple times concurrently.
        ResolveNow(ResolveNowOptions)
        // Close closes the resolver.
        Close()
}

// UnregisterForTesting removes the resolver builder with the given scheme from the
// resolver map.
// This function is for testing only.
func UnregisterForTesting(scheme string) <span class="cov0" title="0">{
        delete(m, scheme)
}</span>
</pre>
		
		<pre class="file" id="file131" style="display: none">/*
 *
 * Copyright 2017 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package grpc

import (
        "strings"
        "sync"

        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/credentials"
        "google.golang.org/grpc/internal/channelz"
        "google.golang.org/grpc/internal/grpcsync"
        "google.golang.org/grpc/internal/pretty"
        "google.golang.org/grpc/resolver"
        "google.golang.org/grpc/serviceconfig"
)

// ccResolverWrapper is a wrapper on top of cc for resolvers.
// It implements resolver.ClientConn interface.
type ccResolverWrapper struct {
        cc         *ClientConn
        resolverMu sync.Mutex
        resolver   resolver.Resolver
        done       *grpcsync.Event
        curState   resolver.State

        incomingMu sync.Mutex // Synchronizes all the incoming calls.
}

// newCCResolverWrapper uses the resolver.Builder to build a Resolver and
// returns a ccResolverWrapper object which wraps the newly built resolver.
func newCCResolverWrapper(cc *ClientConn, rb resolver.Builder) (*ccResolverWrapper, error) <span class="cov8" title="1">{
        ccr := &amp;ccResolverWrapper{
                cc:   cc,
                done: grpcsync.NewEvent(),
        }

        var credsClone credentials.TransportCredentials
        if creds := cc.dopts.copts.TransportCredentials; creds != nil </span><span class="cov8" title="1">{
                credsClone = creds.Clone()
        }</span>
        <span class="cov8" title="1">rbo := resolver.BuildOptions{
                DisableServiceConfig: cc.dopts.disableServiceConfig,
                DialCreds:            credsClone,
                CredsBundle:          cc.dopts.copts.CredsBundle,
                Dialer:               cc.dopts.copts.Dialer,
        }

        var err error
        // We need to hold the lock here while we assign to the ccr.resolver field
        // to guard against a data race caused by the following code path,
        // rb.Build--&gt;ccr.ReportError--&gt;ccr.poll--&gt;ccr.resolveNow, would end up
        // accessing ccr.resolver which is being assigned here.
        ccr.resolverMu.Lock()
        defer ccr.resolverMu.Unlock()
        ccr.resolver, err = rb.Build(cc.parsedTarget, ccr, rbo)
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return ccr, nil</span>
}

func (ccr *ccResolverWrapper) resolveNow(o resolver.ResolveNowOptions) <span class="cov8" title="1">{
        ccr.resolverMu.Lock()
        if !ccr.done.HasFired() </span><span class="cov8" title="1">{
                ccr.resolver.ResolveNow(o)
        }</span>
        <span class="cov8" title="1">ccr.resolverMu.Unlock()</span>
}

func (ccr *ccResolverWrapper) close() <span class="cov8" title="1">{
        ccr.resolverMu.Lock()
        ccr.resolver.Close()
        ccr.done.Fire()
        ccr.resolverMu.Unlock()
}</span>

func (ccr *ccResolverWrapper) UpdateState(s resolver.State) error <span class="cov8" title="1">{
        ccr.incomingMu.Lock()
        defer ccr.incomingMu.Unlock()
        if ccr.done.HasFired() </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">ccr.addChannelzTraceEvent(s)
        ccr.curState = s
        if err := ccr.cc.updateResolverState(ccr.curState, nil); err == balancer.ErrBadResolverState </span><span class="cov8" title="1">{
                return balancer.ErrBadResolverState
        }</span>
        <span class="cov8" title="1">return nil</span>
}

func (ccr *ccResolverWrapper) ReportError(err error) <span class="cov8" title="1">{
        ccr.incomingMu.Lock()
        defer ccr.incomingMu.Unlock()
        if ccr.done.HasFired() </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov8" title="1">channelz.Warningf(logger, ccr.cc.channelzID, "ccResolverWrapper: reporting error to cc: %v", err)
        ccr.cc.updateResolverState(resolver.State{}, err)</span>
}

// NewAddress is called by the resolver implementation to send addresses to gRPC.
func (ccr *ccResolverWrapper) NewAddress(addrs []resolver.Address) <span class="cov0" title="0">{
        ccr.incomingMu.Lock()
        defer ccr.incomingMu.Unlock()
        if ccr.done.HasFired() </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov0" title="0">ccr.addChannelzTraceEvent(resolver.State{Addresses: addrs, ServiceConfig: ccr.curState.ServiceConfig})
        ccr.curState.Addresses = addrs
        ccr.cc.updateResolverState(ccr.curState, nil)</span>
}

// NewServiceConfig is called by the resolver implementation to send service
// configs to gRPC.
func (ccr *ccResolverWrapper) NewServiceConfig(sc string) <span class="cov0" title="0">{
        ccr.incomingMu.Lock()
        defer ccr.incomingMu.Unlock()
        if ccr.done.HasFired() </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov0" title="0">channelz.Infof(logger, ccr.cc.channelzID, "ccResolverWrapper: got new service config: %s", sc)
        if ccr.cc.dopts.disableServiceConfig </span><span class="cov0" title="0">{
                channelz.Info(logger, ccr.cc.channelzID, "Service config lookups disabled; ignoring config")
                return
        }</span>
        <span class="cov0" title="0">scpr := parseServiceConfig(sc)
        if scpr.Err != nil </span><span class="cov0" title="0">{
                channelz.Warningf(logger, ccr.cc.channelzID, "ccResolverWrapper: error parsing service config: %v", scpr.Err)
                return
        }</span>
        <span class="cov0" title="0">ccr.addChannelzTraceEvent(resolver.State{Addresses: ccr.curState.Addresses, ServiceConfig: scpr})
        ccr.curState.ServiceConfig = scpr
        ccr.cc.updateResolverState(ccr.curState, nil)</span>
}

func (ccr *ccResolverWrapper) ParseServiceConfig(scJSON string) *serviceconfig.ParseResult <span class="cov8" title="1">{
        return parseServiceConfig(scJSON)
}</span>

func (ccr *ccResolverWrapper) addChannelzTraceEvent(s resolver.State) <span class="cov8" title="1">{
        var updates []string
        var oldSC, newSC *ServiceConfig
        var oldOK, newOK bool
        if ccr.curState.ServiceConfig != nil </span><span class="cov0" title="0">{
                oldSC, oldOK = ccr.curState.ServiceConfig.Config.(*ServiceConfig)
        }</span>
        <span class="cov8" title="1">if s.ServiceConfig != nil </span><span class="cov8" title="1">{
                newSC, newOK = s.ServiceConfig.Config.(*ServiceConfig)
        }</span>
        <span class="cov8" title="1">if oldOK != newOK || (oldOK &amp;&amp; newOK &amp;&amp; oldSC.rawJSONString != newSC.rawJSONString) </span><span class="cov8" title="1">{
                updates = append(updates, "service config updated")
        }</span>
        <span class="cov8" title="1">if len(ccr.curState.Addresses) &gt; 0 &amp;&amp; len(s.Addresses) == 0 </span><span class="cov0" title="0">{
                updates = append(updates, "resolver returned an empty address list")
        }</span> else<span class="cov8" title="1"> if len(ccr.curState.Addresses) == 0 &amp;&amp; len(s.Addresses) &gt; 0 </span><span class="cov8" title="1">{
                updates = append(updates, "resolver returned new addresses")
        }</span>
        <span class="cov8" title="1">channelz.Infof(logger, ccr.cc.channelzID, "Resolver state updated: %s (%v)", pretty.ToJSON(s), strings.Join(updates, "; "))</span>
}
</pre>
		
		<pre class="file" id="file132" style="display: none">/*
 *
 * Copyright 2014 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package grpc

import (
        "bytes"
        "compress/gzip"
        "context"
        "encoding/binary"
        "fmt"
        "io"
        "io/ioutil"
        "math"
        "strings"
        "sync"
        "time"

        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/credentials"
        "google.golang.org/grpc/encoding"
        "google.golang.org/grpc/encoding/proto"
        "google.golang.org/grpc/internal/transport"
        "google.golang.org/grpc/metadata"
        "google.golang.org/grpc/peer"
        "google.golang.org/grpc/stats"
        "google.golang.org/grpc/status"
)

// Compressor defines the interface gRPC uses to compress a message.
//
// Deprecated: use package encoding.
type Compressor interface {
        // Do compresses p into w.
        Do(w io.Writer, p []byte) error
        // Type returns the compression algorithm the Compressor uses.
        Type() string
}

type gzipCompressor struct {
        pool sync.Pool
}

// NewGZIPCompressor creates a Compressor based on GZIP.
//
// Deprecated: use package encoding/gzip.
func NewGZIPCompressor() Compressor <span class="cov8" title="1">{
        c, _ := NewGZIPCompressorWithLevel(gzip.DefaultCompression)
        return c
}</span>

// NewGZIPCompressorWithLevel is like NewGZIPCompressor but specifies the gzip compression level instead
// of assuming DefaultCompression.
//
// The error returned will be nil if the level is valid.
//
// Deprecated: use package encoding/gzip.
func NewGZIPCompressorWithLevel(level int) (Compressor, error) <span class="cov8" title="1">{
        if level &lt; gzip.DefaultCompression || level &gt; gzip.BestCompression </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("grpc: invalid compression level: %d", level)
        }</span>
        <span class="cov8" title="1">return &amp;gzipCompressor{
                pool: sync.Pool{
                        New: func() interface{} </span><span class="cov8" title="1">{
                                w, err := gzip.NewWriterLevel(ioutil.Discard, level)
                                if err != nil </span><span class="cov0" title="0">{
                                        panic(err)</span>
                                }
                                <span class="cov8" title="1">return w</span>
                        },
                },
        }, nil
}

func (c *gzipCompressor) Do(w io.Writer, p []byte) error <span class="cov8" title="1">{
        z := c.pool.Get().(*gzip.Writer)
        defer c.pool.Put(z)
        z.Reset(w)
        if _, err := z.Write(p); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov8" title="1">return z.Close()</span>
}

func (c *gzipCompressor) Type() string <span class="cov0" title="0">{
        return "gzip"
}</span>

// Decompressor defines the interface gRPC uses to decompress a message.
//
// Deprecated: use package encoding.
type Decompressor interface {
        // Do reads the data from r and uncompress them.
        Do(r io.Reader) ([]byte, error)
        // Type returns the compression algorithm the Decompressor uses.
        Type() string
}

type gzipDecompressor struct {
        pool sync.Pool
}

// NewGZIPDecompressor creates a Decompressor based on GZIP.
//
// Deprecated: use package encoding/gzip.
func NewGZIPDecompressor() Decompressor <span class="cov8" title="1">{
        return &amp;gzipDecompressor{}
}</span>

func (d *gzipDecompressor) Do(r io.Reader) ([]byte, error) <span class="cov8" title="1">{
        var z *gzip.Reader
        switch maybeZ := d.pool.Get().(type) </span>{
        case nil:<span class="cov8" title="1">
                newZ, err := gzip.NewReader(r)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov8" title="1">z = newZ</span>
        case *gzip.Reader:<span class="cov0" title="0">
                z = maybeZ
                if err := z.Reset(r); err != nil </span><span class="cov0" title="0">{
                        d.pool.Put(z)
                        return nil, err
                }</span>
        }

        <span class="cov8" title="1">defer func() </span><span class="cov8" title="1">{
                z.Close()
                d.pool.Put(z)
        }</span>()
        <span class="cov8" title="1">return ioutil.ReadAll(z)</span>
}

func (d *gzipDecompressor) Type() string <span class="cov0" title="0">{
        return "gzip"
}</span>

// callInfo contains all related configuration and information about an RPC.
type callInfo struct {
        compressorType        string
        failFast              bool
        maxReceiveMessageSize *int
        maxSendMessageSize    *int
        creds                 credentials.PerRPCCredentials
        contentSubtype        string
        codec                 baseCodec
        maxRetryRPCBufferSize int
}

func defaultCallInfo() *callInfo <span class="cov0" title="0">{
        return &amp;callInfo{
                failFast:              true,
                maxRetryRPCBufferSize: 256 * 1024, // 256KB
        }
}</span>

// CallOption configures a Call before it starts or extracts information from
// a Call after it completes.
type CallOption interface {
        // before is called before the call is sent to any server.  If before
        // returns a non-nil error, the RPC fails with that error.
        before(*callInfo) error

        // after is called after the call has completed.  after cannot return an
        // error, so any failures should be reported via output parameters.
        after(*callInfo, *csAttempt)
}

// EmptyCallOption does not alter the Call configuration.
// It can be embedded in another structure to carry satellite data for use
// by interceptors.
type EmptyCallOption struct{}

func (EmptyCallOption) before(*callInfo) error      <span class="cov0" title="0">{ return nil }</span>
func (EmptyCallOption) after(*callInfo, *csAttempt) {<span class="cov0" title="0">}</span>

// Header returns a CallOptions that retrieves the header metadata
// for a unary RPC.
func Header(md *metadata.MD) CallOption <span class="cov0" title="0">{
        return HeaderCallOption{HeaderAddr: md}
}</span>

// HeaderCallOption is a CallOption for collecting response header metadata.
// The metadata field will be populated *after* the RPC completes.
//
// Experimental
//
// Notice: This type is EXPERIMENTAL and may be changed or removed in a
// later release.
type HeaderCallOption struct {
        HeaderAddr *metadata.MD
}

func (o HeaderCallOption) before(c *callInfo) error <span class="cov0" title="0">{ return nil }</span>
func (o HeaderCallOption) after(c *callInfo, attempt *csAttempt) <span class="cov0" title="0">{
        *o.HeaderAddr, _ = attempt.s.Header()
}</span>

// Trailer returns a CallOptions that retrieves the trailer metadata
// for a unary RPC.
func Trailer(md *metadata.MD) CallOption <span class="cov0" title="0">{
        return TrailerCallOption{TrailerAddr: md}
}</span>

// TrailerCallOption is a CallOption for collecting response trailer metadata.
// The metadata field will be populated *after* the RPC completes.
//
// Experimental
//
// Notice: This type is EXPERIMENTAL and may be changed or removed in a
// later release.
type TrailerCallOption struct {
        TrailerAddr *metadata.MD
}

func (o TrailerCallOption) before(c *callInfo) error <span class="cov0" title="0">{ return nil }</span>
func (o TrailerCallOption) after(c *callInfo, attempt *csAttempt) <span class="cov0" title="0">{
        *o.TrailerAddr = attempt.s.Trailer()
}</span>

// Peer returns a CallOption that retrieves peer information for a unary RPC.
// The peer field will be populated *after* the RPC completes.
func Peer(p *peer.Peer) CallOption <span class="cov0" title="0">{
        return PeerCallOption{PeerAddr: p}
}</span>

// PeerCallOption is a CallOption for collecting the identity of the remote
// peer. The peer field will be populated *after* the RPC completes.
//
// Experimental
//
// Notice: This type is EXPERIMENTAL and may be changed or removed in a
// later release.
type PeerCallOption struct {
        PeerAddr *peer.Peer
}

func (o PeerCallOption) before(c *callInfo) error <span class="cov0" title="0">{ return nil }</span>
func (o PeerCallOption) after(c *callInfo, attempt *csAttempt) <span class="cov0" title="0">{
        if x, ok := peer.FromContext(attempt.s.Context()); ok </span><span class="cov0" title="0">{
                *o.PeerAddr = *x
        }</span>
}

// WaitForReady configures the action to take when an RPC is attempted on broken
// connections or unreachable servers. If waitForReady is false and the
// connection is in the TRANSIENT_FAILURE state, the RPC will fail
// immediately. Otherwise, the RPC client will block the call until a
// connection is available (or the call is canceled or times out) and will
// retry the call if it fails due to a transient error.  gRPC will not retry if
// data was written to the wire unless the server indicates it did not process
// the data.  Please refer to
// https://github.com/grpc/grpc/blob/master/doc/wait-for-ready.md.
//
// By default, RPCs don't "wait for ready".
func WaitForReady(waitForReady bool) CallOption <span class="cov0" title="0">{
        return FailFastCallOption{FailFast: !waitForReady}
}</span>

// FailFast is the opposite of WaitForReady.
//
// Deprecated: use WaitForReady.
func FailFast(failFast bool) CallOption <span class="cov0" title="0">{
        return FailFastCallOption{FailFast: failFast}
}</span>

// FailFastCallOption is a CallOption for indicating whether an RPC should fail
// fast or not.
//
// Experimental
//
// Notice: This type is EXPERIMENTAL and may be changed or removed in a
// later release.
type FailFastCallOption struct {
        FailFast bool
}

func (o FailFastCallOption) before(c *callInfo) error <span class="cov0" title="0">{
        c.failFast = o.FailFast
        return nil
}</span>
func (o FailFastCallOption) after(c *callInfo, attempt *csAttempt) {<span class="cov0" title="0">}</span>

// MaxCallRecvMsgSize returns a CallOption which sets the maximum message size
// in bytes the client can receive.
func MaxCallRecvMsgSize(bytes int) CallOption <span class="cov0" title="0">{
        return MaxRecvMsgSizeCallOption{MaxRecvMsgSize: bytes}
}</span>

// MaxRecvMsgSizeCallOption is a CallOption that indicates the maximum message
// size in bytes the client can receive.
//
// Experimental
//
// Notice: This type is EXPERIMENTAL and may be changed or removed in a
// later release.
type MaxRecvMsgSizeCallOption struct {
        MaxRecvMsgSize int
}

func (o MaxRecvMsgSizeCallOption) before(c *callInfo) error <span class="cov0" title="0">{
        c.maxReceiveMessageSize = &amp;o.MaxRecvMsgSize
        return nil
}</span>
func (o MaxRecvMsgSizeCallOption) after(c *callInfo, attempt *csAttempt) {<span class="cov0" title="0">}</span>

// MaxCallSendMsgSize returns a CallOption which sets the maximum message size
// in bytes the client can send.
func MaxCallSendMsgSize(bytes int) CallOption <span class="cov0" title="0">{
        return MaxSendMsgSizeCallOption{MaxSendMsgSize: bytes}
}</span>

// MaxSendMsgSizeCallOption is a CallOption that indicates the maximum message
// size in bytes the client can send.
//
// Experimental
//
// Notice: This type is EXPERIMENTAL and may be changed or removed in a
// later release.
type MaxSendMsgSizeCallOption struct {
        MaxSendMsgSize int
}

func (o MaxSendMsgSizeCallOption) before(c *callInfo) error <span class="cov0" title="0">{
        c.maxSendMessageSize = &amp;o.MaxSendMsgSize
        return nil
}</span>
func (o MaxSendMsgSizeCallOption) after(c *callInfo, attempt *csAttempt) {<span class="cov0" title="0">}</span>

// PerRPCCredentials returns a CallOption that sets credentials.PerRPCCredentials
// for a call.
func PerRPCCredentials(creds credentials.PerRPCCredentials) CallOption <span class="cov0" title="0">{
        return PerRPCCredsCallOption{Creds: creds}
}</span>

// PerRPCCredsCallOption is a CallOption that indicates the per-RPC
// credentials to use for the call.
//
// Experimental
//
// Notice: This type is EXPERIMENTAL and may be changed or removed in a
// later release.
type PerRPCCredsCallOption struct {
        Creds credentials.PerRPCCredentials
}

func (o PerRPCCredsCallOption) before(c *callInfo) error <span class="cov0" title="0">{
        c.creds = o.Creds
        return nil
}</span>
func (o PerRPCCredsCallOption) after(c *callInfo, attempt *csAttempt) {<span class="cov0" title="0">}</span>

// UseCompressor returns a CallOption which sets the compressor used when
// sending the request.  If WithCompressor is also set, UseCompressor has
// higher priority.
//
// Experimental
//
// Notice: This API is EXPERIMENTAL and may be changed or removed in a
// later release.
func UseCompressor(name string) CallOption <span class="cov0" title="0">{
        return CompressorCallOption{CompressorType: name}
}</span>

// CompressorCallOption is a CallOption that indicates the compressor to use.
//
// Experimental
//
// Notice: This type is EXPERIMENTAL and may be changed or removed in a
// later release.
type CompressorCallOption struct {
        CompressorType string
}

func (o CompressorCallOption) before(c *callInfo) error <span class="cov0" title="0">{
        c.compressorType = o.CompressorType
        return nil
}</span>
func (o CompressorCallOption) after(c *callInfo, attempt *csAttempt) {<span class="cov0" title="0">}</span>

// CallContentSubtype returns a CallOption that will set the content-subtype
// for a call. For example, if content-subtype is "json", the Content-Type over
// the wire will be "application/grpc+json". The content-subtype is converted
// to lowercase before being included in Content-Type. See Content-Type on
// https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md#requests for
// more details.
//
// If ForceCodec is not also used, the content-subtype will be used to look up
// the Codec to use in the registry controlled by RegisterCodec. See the
// documentation on RegisterCodec for details on registration. The lookup of
// content-subtype is case-insensitive. If no such Codec is found, the call
// will result in an error with code codes.Internal.
//
// If ForceCodec is also used, that Codec will be used for all request and
// response messages, with the content-subtype set to the given contentSubtype
// here for requests.
func CallContentSubtype(contentSubtype string) CallOption <span class="cov0" title="0">{
        return ContentSubtypeCallOption{ContentSubtype: strings.ToLower(contentSubtype)}
}</span>

// ContentSubtypeCallOption is a CallOption that indicates the content-subtype
// used for marshaling messages.
//
// Experimental
//
// Notice: This type is EXPERIMENTAL and may be changed or removed in a
// later release.
type ContentSubtypeCallOption struct {
        ContentSubtype string
}

func (o ContentSubtypeCallOption) before(c *callInfo) error <span class="cov0" title="0">{
        c.contentSubtype = o.ContentSubtype
        return nil
}</span>
func (o ContentSubtypeCallOption) after(c *callInfo, attempt *csAttempt) {<span class="cov0" title="0">}</span>

// ForceCodec returns a CallOption that will set codec to be used for all
// request and response messages for a call. The result of calling Name() will
// be used as the content-subtype after converting to lowercase, unless
// CallContentSubtype is also used.
//
// See Content-Type on
// https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md#requests for
// more details. Also see the documentation on RegisterCodec and
// CallContentSubtype for more details on the interaction between Codec and
// content-subtype.
//
// This function is provided for advanced users; prefer to use only
// CallContentSubtype to select a registered codec instead.
//
// Experimental
//
// Notice: This API is EXPERIMENTAL and may be changed or removed in a
// later release.
func ForceCodec(codec encoding.Codec) CallOption <span class="cov0" title="0">{
        return ForceCodecCallOption{Codec: codec}
}</span>

// ForceCodecCallOption is a CallOption that indicates the codec used for
// marshaling messages.
//
// Experimental
//
// Notice: This type is EXPERIMENTAL and may be changed or removed in a
// later release.
type ForceCodecCallOption struct {
        Codec encoding.Codec
}

func (o ForceCodecCallOption) before(c *callInfo) error <span class="cov0" title="0">{
        c.codec = o.Codec
        return nil
}</span>
func (o ForceCodecCallOption) after(c *callInfo, attempt *csAttempt) {<span class="cov0" title="0">}</span>

// CallCustomCodec behaves like ForceCodec, but accepts a grpc.Codec instead of
// an encoding.Codec.
//
// Deprecated: use ForceCodec instead.
func CallCustomCodec(codec Codec) CallOption <span class="cov0" title="0">{
        return CustomCodecCallOption{Codec: codec}
}</span>

// CustomCodecCallOption is a CallOption that indicates the codec used for
// marshaling messages.
//
// Experimental
//
// Notice: This type is EXPERIMENTAL and may be changed or removed in a
// later release.
type CustomCodecCallOption struct {
        Codec Codec
}

func (o CustomCodecCallOption) before(c *callInfo) error <span class="cov0" title="0">{
        c.codec = o.Codec
        return nil
}</span>
func (o CustomCodecCallOption) after(c *callInfo, attempt *csAttempt) {<span class="cov0" title="0">}</span>

// MaxRetryRPCBufferSize returns a CallOption that limits the amount of memory
// used for buffering this RPC's requests for retry purposes.
//
// Experimental
//
// Notice: This API is EXPERIMENTAL and may be changed or removed in a
// later release.
func MaxRetryRPCBufferSize(bytes int) CallOption <span class="cov0" title="0">{
        return MaxRetryRPCBufferSizeCallOption{bytes}
}</span>

// MaxRetryRPCBufferSizeCallOption is a CallOption indicating the amount of
// memory to be used for caching this RPC for retry purposes.
//
// Experimental
//
// Notice: This type is EXPERIMENTAL and may be changed or removed in a
// later release.
type MaxRetryRPCBufferSizeCallOption struct {
        MaxRetryRPCBufferSize int
}

func (o MaxRetryRPCBufferSizeCallOption) before(c *callInfo) error <span class="cov0" title="0">{
        c.maxRetryRPCBufferSize = o.MaxRetryRPCBufferSize
        return nil
}</span>
func (o MaxRetryRPCBufferSizeCallOption) after(c *callInfo, attempt *csAttempt) {<span class="cov0" title="0">}</span>

// The format of the payload: compressed or not?
type payloadFormat uint8

const (
        compressionNone payloadFormat = 0 // no compression
        compressionMade payloadFormat = 1 // compressed
)

// parser reads complete gRPC messages from the underlying reader.
type parser struct {
        // r is the underlying reader.
        // See the comment on recvMsg for the permissible
        // error types.
        r io.Reader

        // The header of a gRPC message. Find more detail at
        // https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md
        header [5]byte
}

// recvMsg reads a complete gRPC message from the stream.
//
// It returns the message and its payload (compression/encoding)
// format. The caller owns the returned msg memory.
//
// If there is an error, possible values are:
//   * io.EOF, when no messages remain
//   * io.ErrUnexpectedEOF
//   * of type transport.ConnectionError
//   * an error from the status package
// No other error values or types must be returned, which also means
// that the underlying io.Reader must not return an incompatible
// error.
func (p *parser) recvMsg(maxReceiveMessageSize int) (pf payloadFormat, msg []byte, err error) <span class="cov8" title="1">{
        if _, err := p.r.Read(p.header[:]); err != nil </span><span class="cov8" title="1">{
                return 0, nil, err
        }</span>

        <span class="cov8" title="1">pf = payloadFormat(p.header[0])
        length := binary.BigEndian.Uint32(p.header[1:])

        if length == 0 </span><span class="cov8" title="1">{
                return pf, nil, nil
        }</span>
        <span class="cov8" title="1">if int64(length) &gt; int64(maxInt) </span><span class="cov0" title="0">{
                return 0, nil, status.Errorf(codes.ResourceExhausted, "grpc: received message larger than max length allowed on current machine (%d vs. %d)", length, maxInt)
        }</span>
        <span class="cov8" title="1">if int(length) &gt; maxReceiveMessageSize </span><span class="cov0" title="0">{
                return 0, nil, status.Errorf(codes.ResourceExhausted, "grpc: received message larger than max (%d vs. %d)", length, maxReceiveMessageSize)
        }</span>
        // TODO(bradfitz,zhaoq): garbage. reuse buffer after proto decoding instead
        // of making it for each message:
        <span class="cov8" title="1">msg = make([]byte, int(length))
        if _, err := p.r.Read(msg); err != nil </span><span class="cov8" title="1">{
                if err == io.EOF </span><span class="cov0" title="0">{
                        err = io.ErrUnexpectedEOF
                }</span>
                <span class="cov8" title="1">return 0, nil, err</span>
        }
        <span class="cov8" title="1">return pf, msg, nil</span>
}

// encode serializes msg and returns a buffer containing the message, or an
// error if it is too large to be transmitted by grpc.  If msg is nil, it
// generates an empty message.
func encode(c baseCodec, msg interface{}) ([]byte, error) <span class="cov8" title="1">{
        if msg == nil </span><span class="cov8" title="1">{ // NOTE: typed nils will not be caught by this check
                return nil, nil
        }</span>
        <span class="cov0" title="0">b, err := c.Marshal(msg)
        if err != nil </span><span class="cov0" title="0">{
                return nil, status.Errorf(codes.Internal, "grpc: error while marshaling: %v", err.Error())
        }</span>
        <span class="cov0" title="0">if uint(len(b)) &gt; math.MaxUint32 </span><span class="cov0" title="0">{
                return nil, status.Errorf(codes.ResourceExhausted, "grpc: message too large (%d bytes)", len(b))
        }</span>
        <span class="cov0" title="0">return b, nil</span>
}

// compress returns the input bytes compressed by compressor or cp.  If both
// compressors are nil, returns nil.
//
// TODO(dfawley): eliminate cp parameter by wrapping Compressor in an encoding.Compressor.
func compress(in []byte, cp Compressor, compressor encoding.Compressor) ([]byte, error) <span class="cov0" title="0">{
        if compressor == nil &amp;&amp; cp == nil </span><span class="cov0" title="0">{
                return nil, nil
        }</span>
        <span class="cov0" title="0">wrapErr := func(err error) error </span><span class="cov0" title="0">{
                return status.Errorf(codes.Internal, "grpc: error while compressing: %v", err.Error())
        }</span>
        <span class="cov0" title="0">cbuf := &amp;bytes.Buffer{}
        if compressor != nil </span><span class="cov0" title="0">{
                z, err := compressor.Compress(cbuf)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, wrapErr(err)
                }</span>
                <span class="cov0" title="0">if _, err := z.Write(in); err != nil </span><span class="cov0" title="0">{
                        return nil, wrapErr(err)
                }</span>
                <span class="cov0" title="0">if err := z.Close(); err != nil </span><span class="cov0" title="0">{
                        return nil, wrapErr(err)
                }</span>
        } else<span class="cov0" title="0"> {
                if err := cp.Do(cbuf, in); err != nil </span><span class="cov0" title="0">{
                        return nil, wrapErr(err)
                }</span>
        }
        <span class="cov0" title="0">return cbuf.Bytes(), nil</span>
}

const (
        payloadLen = 1
        sizeLen    = 4
        headerLen  = payloadLen + sizeLen
)

// msgHeader returns a 5-byte header for the message being transmitted and the
// payload, which is compData if non-nil or data otherwise.
func msgHeader(data, compData []byte) (hdr []byte, payload []byte) <span class="cov8" title="1">{
        hdr = make([]byte, headerLen)
        if compData != nil </span><span class="cov0" title="0">{
                hdr[0] = byte(compressionMade)
                data = compData
        }</span> else<span class="cov8" title="1"> {
                hdr[0] = byte(compressionNone)
        }</span>

        // Write length of payload into buf
        <span class="cov8" title="1">binary.BigEndian.PutUint32(hdr[payloadLen:], uint32(len(data)))
        return hdr, data</span>
}

func outPayload(client bool, msg interface{}, data, payload []byte, t time.Time) *stats.OutPayload <span class="cov0" title="0">{
        return &amp;stats.OutPayload{
                Client:     client,
                Payload:    msg,
                Data:       data,
                Length:     len(data),
                WireLength: len(payload) + headerLen,
                SentTime:   t,
        }
}</span>

func checkRecvPayload(pf payloadFormat, recvCompress string, haveCompressor bool) *status.Status <span class="cov0" title="0">{
        switch pf </span>{
        case compressionNone:<span class="cov0" title="0"></span>
        case compressionMade:<span class="cov0" title="0">
                if recvCompress == "" || recvCompress == encoding.Identity </span><span class="cov0" title="0">{
                        return status.New(codes.Internal, "grpc: compressed flag set with identity or empty encoding")
                }</span>
                <span class="cov0" title="0">if !haveCompressor </span><span class="cov0" title="0">{
                        return status.Newf(codes.Unimplemented, "grpc: Decompressor is not installed for grpc-encoding %q", recvCompress)
                }</span>
        default:<span class="cov0" title="0">
                return status.Newf(codes.Internal, "grpc: received unexpected payload format %d", pf)</span>
        }
        <span class="cov0" title="0">return nil</span>
}

type payloadInfo struct {
        wireLength        int // The compressed length got from wire.
        uncompressedBytes []byte
}

func recvAndDecompress(p *parser, s *transport.Stream, dc Decompressor, maxReceiveMessageSize int, payInfo *payloadInfo, compressor encoding.Compressor) ([]byte, error) <span class="cov0" title="0">{
        pf, d, err := p.recvMsg(maxReceiveMessageSize)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">if payInfo != nil </span><span class="cov0" title="0">{
                payInfo.wireLength = len(d)
        }</span>

        <span class="cov0" title="0">if st := checkRecvPayload(pf, s.RecvCompress(), compressor != nil || dc != nil); st != nil </span><span class="cov0" title="0">{
                return nil, st.Err()
        }</span>

        <span class="cov0" title="0">var size int
        if pf == compressionMade </span><span class="cov0" title="0">{
                // To match legacy behavior, if the decompressor is set by WithDecompressor or RPCDecompressor,
                // use this decompressor as the default.
                if dc != nil </span><span class="cov0" title="0">{
                        d, err = dc.Do(bytes.NewReader(d))
                        size = len(d)
                }</span> else<span class="cov0" title="0"> {
                        d, size, err = decompress(compressor, d, maxReceiveMessageSize)
                }</span>
                <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                        return nil, status.Errorf(codes.Internal, "grpc: failed to decompress the received message %v", err)
                }</span>
                <span class="cov0" title="0">if size &gt; maxReceiveMessageSize </span><span class="cov0" title="0">{
                        // TODO: Revisit the error code. Currently keep it consistent with java
                        // implementation.
                        return nil, status.Errorf(codes.ResourceExhausted, "grpc: received message after decompression larger than max (%d vs. %d)", size, maxReceiveMessageSize)
                }</span>
        }
        <span class="cov0" title="0">return d, nil</span>
}

// Using compressor, decompress d, returning data and size.
// Optionally, if data will be over maxReceiveMessageSize, just return the size.
func decompress(compressor encoding.Compressor, d []byte, maxReceiveMessageSize int) ([]byte, int, error) <span class="cov0" title="0">{
        dcReader, err := compressor.Decompress(bytes.NewReader(d))
        if err != nil </span><span class="cov0" title="0">{
                return nil, 0, err
        }</span>
        <span class="cov0" title="0">if sizer, ok := compressor.(interface {
                DecompressedSize(compressedBytes []byte) int
        }); ok </span><span class="cov0" title="0">{
                if size := sizer.DecompressedSize(d); size &gt;= 0 </span><span class="cov0" title="0">{
                        if size &gt; maxReceiveMessageSize </span><span class="cov0" title="0">{
                                return nil, size, nil
                        }</span>
                        // size is used as an estimate to size the buffer, but we
                        // will read more data if available.
                        // +MinRead so ReadFrom will not reallocate if size is correct.
                        <span class="cov0" title="0">buf := bytes.NewBuffer(make([]byte, 0, size+bytes.MinRead))
                        bytesRead, err := buf.ReadFrom(io.LimitReader(dcReader, int64(maxReceiveMessageSize)+1))
                        return buf.Bytes(), int(bytesRead), err</span>
                }
        }
        // Read from LimitReader with limit max+1. So if the underlying
        // reader is over limit, the result will be bigger than max.
        <span class="cov0" title="0">d, err = ioutil.ReadAll(io.LimitReader(dcReader, int64(maxReceiveMessageSize)+1))
        return d, len(d), err</span>
}

// For the two compressor parameters, both should not be set, but if they are,
// dc takes precedence over compressor.
// TODO(dfawley): wrap the old compressor/decompressor using the new API?
func recv(p *parser, c baseCodec, s *transport.Stream, dc Decompressor, m interface{}, maxReceiveMessageSize int, payInfo *payloadInfo, compressor encoding.Compressor) error <span class="cov0" title="0">{
        d, err := recvAndDecompress(p, s, dc, maxReceiveMessageSize, payInfo, compressor)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov0" title="0">if err := c.Unmarshal(d, m); err != nil </span><span class="cov0" title="0">{
                return status.Errorf(codes.Internal, "grpc: failed to unmarshal the received message %v", err)
        }</span>
        <span class="cov0" title="0">if payInfo != nil </span><span class="cov0" title="0">{
                payInfo.uncompressedBytes = d
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// Information about RPC
type rpcInfo struct {
        failfast      bool
        preloaderInfo *compressorInfo
}

// Information about Preloader
// Responsible for storing codec, and compressors
// If stream (s) has  context s.Context which stores rpcInfo that has non nil
// pointers to codec, and compressors, then we can use preparedMsg for Async message prep
// and reuse marshalled bytes
type compressorInfo struct {
        codec baseCodec
        cp    Compressor
        comp  encoding.Compressor
}

type rpcInfoContextKey struct{}

func newContextWithRPCInfo(ctx context.Context, failfast bool, codec baseCodec, cp Compressor, comp encoding.Compressor) context.Context <span class="cov0" title="0">{
        return context.WithValue(ctx, rpcInfoContextKey{}, &amp;rpcInfo{
                failfast: failfast,
                preloaderInfo: &amp;compressorInfo{
                        codec: codec,
                        cp:    cp,
                        comp:  comp,
                },
        })
}</span>

func rpcInfoFromContext(ctx context.Context) (s *rpcInfo, ok bool) <span class="cov0" title="0">{
        s, ok = ctx.Value(rpcInfoContextKey{}).(*rpcInfo)
        return
}</span>

// Code returns the error code for err if it was produced by the rpc system.
// Otherwise, it returns codes.Unknown.
//
// Deprecated: use status.Code instead.
func Code(err error) codes.Code <span class="cov0" title="0">{
        return status.Code(err)
}</span>

// ErrorDesc returns the error description of err if it was produced by the rpc system.
// Otherwise, it returns err.Error() or empty string when err is nil.
//
// Deprecated: use status.Convert and Message method instead.
func ErrorDesc(err error) string <span class="cov0" title="0">{
        return status.Convert(err).Message()
}</span>

// Errorf returns an error containing an error code and a description;
// Errorf returns nil if c is OK.
//
// Deprecated: use status.Errorf instead.
func Errorf(c codes.Code, format string, a ...interface{}) error <span class="cov0" title="0">{
        return status.Errorf(c, format, a...)
}</span>

// toRPCErr converts an error into an error from the status package.
func toRPCErr(err error) error <span class="cov8" title="1">{
        switch err </span>{
        case nil, io.EOF:<span class="cov0" title="0">
                return err</span>
        case context.DeadlineExceeded:<span class="cov0" title="0">
                return status.Error(codes.DeadlineExceeded, err.Error())</span>
        case context.Canceled:<span class="cov0" title="0">
                return status.Error(codes.Canceled, err.Error())</span>
        case io.ErrUnexpectedEOF:<span class="cov8" title="1">
                return status.Error(codes.Internal, err.Error())</span>
        }

        <span class="cov8" title="1">switch e := err.(type) </span>{
        case transport.ConnectionError:<span class="cov8" title="1">
                return status.Error(codes.Unavailable, e.Desc)</span>
        case *transport.NewStreamError:<span class="cov0" title="0">
                return toRPCErr(e.Err)</span>
        }

        <span class="cov0" title="0">if _, ok := status.FromError(err); ok </span><span class="cov0" title="0">{
                return err
        }</span>

        <span class="cov0" title="0">return status.Error(codes.Unknown, err.Error())</span>
}

// setCallInfoCodec should only be called after CallOptions have been applied.
func setCallInfoCodec(c *callInfo) error <span class="cov0" title="0">{
        if c.codec != nil </span><span class="cov0" title="0">{
                // codec was already set by a CallOption; use it, but set the content
                // subtype if it is not set.
                if c.contentSubtype == "" </span><span class="cov0" title="0">{
                        // c.codec is a baseCodec to hide the difference between grpc.Codec and
                        // encoding.Codec (Name vs. String method name).  We only support
                        // setting content subtype from encoding.Codec to avoid a behavior
                        // change with the deprecated version.
                        if ec, ok := c.codec.(encoding.Codec); ok </span><span class="cov0" title="0">{
                                c.contentSubtype = strings.ToLower(ec.Name())
                        }</span>
                }
                <span class="cov0" title="0">return nil</span>
        }

        <span class="cov0" title="0">if c.contentSubtype == "" </span><span class="cov0" title="0">{
                // No codec specified in CallOptions; use proto by default.
                c.codec = encoding.GetCodec(proto.Name)
                return nil
        }</span>

        // c.contentSubtype is already lowercased in CallContentSubtype
        <span class="cov0" title="0">c.codec = encoding.GetCodec(c.contentSubtype)
        if c.codec == nil </span><span class="cov0" title="0">{
                return status.Errorf(codes.Internal, "no codec registered for content-subtype %s", c.contentSubtype)
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// channelzData is used to store channelz related data for ClientConn, addrConn and Server.
// These fields cannot be embedded in the original structs (e.g. ClientConn), since to do atomic
// operation on int64 variable on 32-bit machine, user is responsible to enforce memory alignment.
// Here, by grouping those int64 fields inside a struct, we are enforcing the alignment.
type channelzData struct {
        callsStarted   int64
        callsFailed    int64
        callsSucceeded int64
        // lastCallStartedTime stores the timestamp that last call starts. It is of int64 type instead of
        // time.Time since it's more costly to atomically update time.Time variable than int64 variable.
        lastCallStartedTime int64
}

// The SupportPackageIsVersion variables are referenced from generated protocol
// buffer files to ensure compatibility with the gRPC version used.  The latest
// support package version is 7.
//
// Older versions are kept for compatibility.
//
// These constants should not be referenced from any other code.
const (
        SupportPackageIsVersion3 = true
        SupportPackageIsVersion4 = true
        SupportPackageIsVersion5 = true
        SupportPackageIsVersion6 = true
        SupportPackageIsVersion7 = true
)

const grpcUA = "grpc-go/" + Version
</pre>
		
		<pre class="file" id="file133" style="display: none">/*
 *
 * Copyright 2014 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package grpc

import (
        "context"
        "errors"
        "fmt"
        "io"
        "math"
        "net"
        "net/http"
        "reflect"
        "runtime"
        "strings"
        "sync"
        "sync/atomic"
        "time"

        "golang.org/x/net/trace"

        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/credentials"
        "google.golang.org/grpc/encoding"
        "google.golang.org/grpc/encoding/proto"
        "google.golang.org/grpc/grpclog"
        "google.golang.org/grpc/internal"
        "google.golang.org/grpc/internal/binarylog"
        "google.golang.org/grpc/internal/channelz"
        "google.golang.org/grpc/internal/grpcrand"
        "google.golang.org/grpc/internal/grpcsync"
        "google.golang.org/grpc/internal/transport"
        "google.golang.org/grpc/keepalive"
        "google.golang.org/grpc/metadata"
        "google.golang.org/grpc/peer"
        "google.golang.org/grpc/stats"
        "google.golang.org/grpc/status"
        "google.golang.org/grpc/tap"
)

const (
        defaultServerMaxReceiveMessageSize = 1024 * 1024 * 4
        defaultServerMaxSendMessageSize    = math.MaxInt32

        // Server transports are tracked in a map which is keyed on listener
        // address. For regular gRPC traffic, connections are accepted in Serve()
        // through a call to Accept(), and we use the actual listener address as key
        // when we add it to the map. But for connections received through
        // ServeHTTP(), we do not have a listener and hence use this dummy value.
        listenerAddressForServeHTTP = "listenerAddressForServeHTTP"
)

func init() <span class="cov8" title="1">{
        internal.GetServerCredentials = func(srv *Server) credentials.TransportCredentials </span><span class="cov0" title="0">{
                return srv.opts.creds
        }</span>
        <span class="cov8" title="1">internal.DrainServerTransports = func(srv *Server, addr string) </span><span class="cov0" title="0">{
                srv.drainServerTransports(addr)
        }</span>
        <span class="cov8" title="1">internal.AddExtraServerOptions = func(opt ...ServerOption) </span><span class="cov8" title="1">{
                extraServerOptions = opt
        }</span>
        <span class="cov8" title="1">internal.ClearExtraServerOptions = func() </span><span class="cov8" title="1">{
                extraServerOptions = nil
        }</span>
}

var statusOK = status.New(codes.OK, "")
var logger = grpclog.Component("core")

type methodHandler func(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor UnaryServerInterceptor) (interface{}, error)

// MethodDesc represents an RPC service's method specification.
type MethodDesc struct {
        MethodName string
        Handler    methodHandler
}

// ServiceDesc represents an RPC service's specification.
type ServiceDesc struct {
        ServiceName string
        // The pointer to the service interface. Used to check whether the user
        // provided implementation satisfies the interface requirements.
        HandlerType interface{}
        Methods     []MethodDesc
        Streams     []StreamDesc
        Metadata    interface{}
}

// serviceInfo wraps information about a service. It is very similar to
// ServiceDesc and is constructed from it for internal purposes.
type serviceInfo struct {
        // Contains the implementation for the methods in this service.
        serviceImpl interface{}
        methods     map[string]*MethodDesc
        streams     map[string]*StreamDesc
        mdata       interface{}
}

type serverWorkerData struct {
        st     transport.ServerTransport
        wg     *sync.WaitGroup
        stream *transport.Stream
}

// Server is a gRPC server to serve RPC requests.
type Server struct {
        opts serverOptions

        mu  sync.Mutex // guards following
        lis map[net.Listener]bool
        // conns contains all active server transports. It is a map keyed on a
        // listener address with the value being the set of active transports
        // belonging to that listener.
        conns    map[string]map[transport.ServerTransport]bool
        serve    bool
        drain    bool
        cv       *sync.Cond              // signaled when connections close for GracefulStop
        services map[string]*serviceInfo // service name -&gt; service info
        events   trace.EventLog

        quit               *grpcsync.Event
        done               *grpcsync.Event
        channelzRemoveOnce sync.Once
        serveWG            sync.WaitGroup // counts active Serve goroutines for GracefulStop

        channelzID *channelz.Identifier
        czData     *channelzData

        serverWorkerChannels []chan *serverWorkerData
}

type serverOptions struct {
        creds                 credentials.TransportCredentials
        codec                 baseCodec
        cp                    Compressor
        dc                    Decompressor
        unaryInt              UnaryServerInterceptor
        streamInt             StreamServerInterceptor
        chainUnaryInts        []UnaryServerInterceptor
        chainStreamInts       []StreamServerInterceptor
        inTapHandle           tap.ServerInHandle
        statsHandlers         []stats.Handler
        maxConcurrentStreams  uint32
        maxReceiveMessageSize int
        maxSendMessageSize    int
        unknownStreamDesc     *StreamDesc
        keepaliveParams       keepalive.ServerParameters
        keepalivePolicy       keepalive.EnforcementPolicy
        initialWindowSize     int32
        initialConnWindowSize int32
        writeBufferSize       int
        readBufferSize        int
        connectionTimeout     time.Duration
        maxHeaderListSize     *uint32
        headerTableSize       *uint32
        numServerWorkers      uint32
}

var defaultServerOptions = serverOptions{
        maxReceiveMessageSize: defaultServerMaxReceiveMessageSize,
        maxSendMessageSize:    defaultServerMaxSendMessageSize,
        connectionTimeout:     120 * time.Second,
        writeBufferSize:       defaultWriteBufSize,
        readBufferSize:        defaultReadBufSize,
}
var extraServerOptions []ServerOption

// A ServerOption sets options such as credentials, codec and keepalive parameters, etc.
type ServerOption interface {
        apply(*serverOptions)
}

// EmptyServerOption does not alter the server configuration. It can be embedded
// in another structure to build custom server options.
//
// # Experimental
//
// Notice: This type is EXPERIMENTAL and may be changed or removed in a
// later release.
type EmptyServerOption struct{}

func (EmptyServerOption) apply(*serverOptions) {<span class="cov0" title="0">}</span>

// funcServerOption wraps a function that modifies serverOptions into an
// implementation of the ServerOption interface.
type funcServerOption struct {
        f func(*serverOptions)
}

func (fdo *funcServerOption) apply(do *serverOptions) <span class="cov8" title="1">{
        fdo.f(do)
}</span>

func newFuncServerOption(f func(*serverOptions)) *funcServerOption <span class="cov8" title="1">{
        return &amp;funcServerOption{
                f: f,
        }
}</span>

// WriteBufferSize determines how much data can be batched before doing a write on the wire.
// The corresponding memory allocation for this buffer will be twice the size to keep syscalls low.
// The default value for this buffer is 32KB.
// Zero will disable the write buffer such that each write will be on underlying connection.
// Note: A Send call may not directly translate to a write.
func WriteBufferSize(s int) ServerOption <span class="cov0" title="0">{
        return newFuncServerOption(func(o *serverOptions) </span><span class="cov0" title="0">{
                o.writeBufferSize = s
        }</span>)
}

// ReadBufferSize lets you set the size of read buffer, this determines how much data can be read at most
// for one read syscall.
// The default value for this buffer is 32KB.
// Zero will disable read buffer for a connection so data framer can access the underlying
// conn directly.
func ReadBufferSize(s int) ServerOption <span class="cov0" title="0">{
        return newFuncServerOption(func(o *serverOptions) </span><span class="cov0" title="0">{
                o.readBufferSize = s
        }</span>)
}

// InitialWindowSize returns a ServerOption that sets window size for stream.
// The lower bound for window size is 64K and any value smaller than that will be ignored.
func InitialWindowSize(s int32) ServerOption <span class="cov0" title="0">{
        return newFuncServerOption(func(o *serverOptions) </span><span class="cov0" title="0">{
                o.initialWindowSize = s
        }</span>)
}

// InitialConnWindowSize returns a ServerOption that sets window size for a connection.
// The lower bound for window size is 64K and any value smaller than that will be ignored.
func InitialConnWindowSize(s int32) ServerOption <span class="cov0" title="0">{
        return newFuncServerOption(func(o *serverOptions) </span><span class="cov0" title="0">{
                o.initialConnWindowSize = s
        }</span>)
}

// KeepaliveParams returns a ServerOption that sets keepalive and max-age parameters for the server.
func KeepaliveParams(kp keepalive.ServerParameters) ServerOption <span class="cov0" title="0">{
        if kp.Time &gt; 0 &amp;&amp; kp.Time &lt; time.Second </span><span class="cov0" title="0">{
                logger.Warning("Adjusting keepalive ping interval to minimum period of 1s")
                kp.Time = time.Second
        }</span>

        <span class="cov0" title="0">return newFuncServerOption(func(o *serverOptions) </span><span class="cov0" title="0">{
                o.keepaliveParams = kp
        }</span>)
}

// KeepaliveEnforcementPolicy returns a ServerOption that sets keepalive enforcement policy for the server.
func KeepaliveEnforcementPolicy(kep keepalive.EnforcementPolicy) ServerOption <span class="cov0" title="0">{
        return newFuncServerOption(func(o *serverOptions) </span><span class="cov0" title="0">{
                o.keepalivePolicy = kep
        }</span>)
}

// CustomCodec returns a ServerOption that sets a codec for message marshaling and unmarshaling.
//
// This will override any lookups by content-subtype for Codecs registered with RegisterCodec.
//
// Deprecated: register codecs using encoding.RegisterCodec. The server will
// automatically use registered codecs based on the incoming requests' headers.
// See also
// https://github.com/grpc/grpc-go/blob/master/Documentation/encoding.md#using-a-codec.
// Will be supported throughout 1.x.
func CustomCodec(codec Codec) ServerOption <span class="cov0" title="0">{
        return newFuncServerOption(func(o *serverOptions) </span><span class="cov0" title="0">{
                o.codec = codec
        }</span>)
}

// ForceServerCodec returns a ServerOption that sets a codec for message
// marshaling and unmarshaling.
//
// This will override any lookups by content-subtype for Codecs registered
// with RegisterCodec.
//
// See Content-Type on
// https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md#requests for
// more details. Also see the documentation on RegisterCodec and
// CallContentSubtype for more details on the interaction between encoding.Codec
// and content-subtype.
//
// This function is provided for advanced users; prefer to register codecs
// using encoding.RegisterCodec.
// The server will automatically use registered codecs based on the incoming
// requests' headers. See also
// https://github.com/grpc/grpc-go/blob/master/Documentation/encoding.md#using-a-codec.
// Will be supported throughout 1.x.
//
// # Experimental
//
// Notice: This API is EXPERIMENTAL and may be changed or removed in a
// later release.
func ForceServerCodec(codec encoding.Codec) ServerOption <span class="cov0" title="0">{
        return newFuncServerOption(func(o *serverOptions) </span><span class="cov0" title="0">{
                o.codec = codec
        }</span>)
}

// RPCCompressor returns a ServerOption that sets a compressor for outbound
// messages.  For backward compatibility, all outbound messages will be sent
// using this compressor, regardless of incoming message compression.  By
// default, server messages will be sent using the same compressor with which
// request messages were sent.
//
// Deprecated: use encoding.RegisterCompressor instead. Will be supported
// throughout 1.x.
func RPCCompressor(cp Compressor) ServerOption <span class="cov0" title="0">{
        return newFuncServerOption(func(o *serverOptions) </span><span class="cov0" title="0">{
                o.cp = cp
        }</span>)
}

// RPCDecompressor returns a ServerOption that sets a decompressor for inbound
// messages.  It has higher priority than decompressors registered via
// encoding.RegisterCompressor.
//
// Deprecated: use encoding.RegisterCompressor instead. Will be supported
// throughout 1.x.
func RPCDecompressor(dc Decompressor) ServerOption <span class="cov0" title="0">{
        return newFuncServerOption(func(o *serverOptions) </span><span class="cov0" title="0">{
                o.dc = dc
        }</span>)
}

// MaxMsgSize returns a ServerOption to set the max message size in bytes the server can receive.
// If this is not set, gRPC uses the default limit.
//
// Deprecated: use MaxRecvMsgSize instead. Will be supported throughout 1.x.
func MaxMsgSize(m int) ServerOption <span class="cov0" title="0">{
        return MaxRecvMsgSize(m)
}</span>

// MaxRecvMsgSize returns a ServerOption to set the max message size in bytes the server can receive.
// If this is not set, gRPC uses the default 4MB.
func MaxRecvMsgSize(m int) ServerOption <span class="cov8" title="1">{
        return newFuncServerOption(func(o *serverOptions) </span><span class="cov8" title="1">{
                o.maxReceiveMessageSize = m
        }</span>)
}

// MaxSendMsgSize returns a ServerOption to set the max message size in bytes the server can send.
// If this is not set, gRPC uses the default `math.MaxInt32`.
func MaxSendMsgSize(m int) ServerOption <span class="cov0" title="0">{
        return newFuncServerOption(func(o *serverOptions) </span><span class="cov0" title="0">{
                o.maxSendMessageSize = m
        }</span>)
}

// MaxConcurrentStreams returns a ServerOption that will apply a limit on the number
// of concurrent streams to each ServerTransport.
func MaxConcurrentStreams(n uint32) ServerOption <span class="cov0" title="0">{
        return newFuncServerOption(func(o *serverOptions) </span><span class="cov0" title="0">{
                o.maxConcurrentStreams = n
        }</span>)
}

// Creds returns a ServerOption that sets credentials for server connections.
func Creds(c credentials.TransportCredentials) ServerOption <span class="cov8" title="1">{
        return newFuncServerOption(func(o *serverOptions) </span><span class="cov8" title="1">{
                o.creds = c
        }</span>)
}

// UnaryInterceptor returns a ServerOption that sets the UnaryServerInterceptor for the
// server. Only one unary interceptor can be installed. The construction of multiple
// interceptors (e.g., chaining) can be implemented at the caller.
func UnaryInterceptor(i UnaryServerInterceptor) ServerOption <span class="cov0" title="0">{
        return newFuncServerOption(func(o *serverOptions) </span><span class="cov0" title="0">{
                if o.unaryInt != nil </span><span class="cov0" title="0">{
                        panic("The unary server interceptor was already set and may not be reset.")</span>
                }
                <span class="cov0" title="0">o.unaryInt = i</span>
        })
}

// ChainUnaryInterceptor returns a ServerOption that specifies the chained interceptor
// for unary RPCs. The first interceptor will be the outer most,
// while the last interceptor will be the inner most wrapper around the real call.
// All unary interceptors added by this method will be chained.
func ChainUnaryInterceptor(interceptors ...UnaryServerInterceptor) ServerOption <span class="cov0" title="0">{
        return newFuncServerOption(func(o *serverOptions) </span><span class="cov0" title="0">{
                o.chainUnaryInts = append(o.chainUnaryInts, interceptors...)
        }</span>)
}

// StreamInterceptor returns a ServerOption that sets the StreamServerInterceptor for the
// server. Only one stream interceptor can be installed.
func StreamInterceptor(i StreamServerInterceptor) ServerOption <span class="cov0" title="0">{
        return newFuncServerOption(func(o *serverOptions) </span><span class="cov0" title="0">{
                if o.streamInt != nil </span><span class="cov0" title="0">{
                        panic("The stream server interceptor was already set and may not be reset.")</span>
                }
                <span class="cov0" title="0">o.streamInt = i</span>
        })
}

// ChainStreamInterceptor returns a ServerOption that specifies the chained interceptor
// for streaming RPCs. The first interceptor will be the outer most,
// while the last interceptor will be the inner most wrapper around the real call.
// All stream interceptors added by this method will be chained.
func ChainStreamInterceptor(interceptors ...StreamServerInterceptor) ServerOption <span class="cov0" title="0">{
        return newFuncServerOption(func(o *serverOptions) </span><span class="cov0" title="0">{
                o.chainStreamInts = append(o.chainStreamInts, interceptors...)
        }</span>)
}

// InTapHandle returns a ServerOption that sets the tap handle for all the server
// transport to be created. Only one can be installed.
//
// # Experimental
//
// Notice: This API is EXPERIMENTAL and may be changed or removed in a
// later release.
func InTapHandle(h tap.ServerInHandle) ServerOption <span class="cov0" title="0">{
        return newFuncServerOption(func(o *serverOptions) </span><span class="cov0" title="0">{
                if o.inTapHandle != nil </span><span class="cov0" title="0">{
                        panic("The tap handle was already set and may not be reset.")</span>
                }
                <span class="cov0" title="0">o.inTapHandle = h</span>
        })
}

// StatsHandler returns a ServerOption that sets the stats handler for the server.
func StatsHandler(h stats.Handler) ServerOption <span class="cov0" title="0">{
        return newFuncServerOption(func(o *serverOptions) </span><span class="cov0" title="0">{
                if h == nil </span><span class="cov0" title="0">{
                        logger.Error("ignoring nil parameter in grpc.StatsHandler ServerOption")
                        // Do not allow a nil stats handler, which would otherwise cause
                        // panics.
                        return
                }</span>
                <span class="cov0" title="0">o.statsHandlers = append(o.statsHandlers, h)</span>
        })
}

// UnknownServiceHandler returns a ServerOption that allows for adding a custom
// unknown service handler. The provided method is a bidi-streaming RPC service
// handler that will be invoked instead of returning the "unimplemented" gRPC
// error whenever a request is received for an unregistered service or method.
// The handling function and stream interceptor (if set) have full access to
// the ServerStream, including its Context.
func UnknownServiceHandler(streamHandler StreamHandler) ServerOption <span class="cov0" title="0">{
        return newFuncServerOption(func(o *serverOptions) </span><span class="cov0" title="0">{
                o.unknownStreamDesc = &amp;StreamDesc{
                        StreamName: "unknown_service_handler",
                        Handler:    streamHandler,
                        // We need to assume that the users of the streamHandler will want to use both.
                        ClientStreams: true,
                        ServerStreams: true,
                }
        }</span>)
}

// ConnectionTimeout returns a ServerOption that sets the timeout for
// connection establishment (up to and including HTTP/2 handshaking) for all
// new connections.  If this is not set, the default is 120 seconds.  A zero or
// negative value will result in an immediate timeout.
//
// # Experimental
//
// Notice: This API is EXPERIMENTAL and may be changed or removed in a
// later release.
func ConnectionTimeout(d time.Duration) ServerOption <span class="cov0" title="0">{
        return newFuncServerOption(func(o *serverOptions) </span><span class="cov0" title="0">{
                o.connectionTimeout = d
        }</span>)
}

// MaxHeaderListSize returns a ServerOption that sets the max (uncompressed) size
// of header list that the server is prepared to accept.
func MaxHeaderListSize(s uint32) ServerOption <span class="cov0" title="0">{
        return newFuncServerOption(func(o *serverOptions) </span><span class="cov0" title="0">{
                o.maxHeaderListSize = &amp;s
        }</span>)
}

// HeaderTableSize returns a ServerOption that sets the size of dynamic
// header table for stream.
//
// # Experimental
//
// Notice: This API is EXPERIMENTAL and may be changed or removed in a
// later release.
func HeaderTableSize(s uint32) ServerOption <span class="cov0" title="0">{
        return newFuncServerOption(func(o *serverOptions) </span><span class="cov0" title="0">{
                o.headerTableSize = &amp;s
        }</span>)
}

// NumStreamWorkers returns a ServerOption that sets the number of worker
// goroutines that should be used to process incoming streams. Setting this to
// zero (default) will disable workers and spawn a new goroutine for each
// stream.
//
// # Experimental
//
// Notice: This API is EXPERIMENTAL and may be changed or removed in a
// later release.
func NumStreamWorkers(numServerWorkers uint32) ServerOption <span class="cov0" title="0">{
        // TODO: If/when this API gets stabilized (i.e. stream workers become the
        // only way streams are processed), change the behavior of the zero value to
        // a sane default. Preliminary experiments suggest that a value equal to the
        // number of CPUs available is most performant; requires thorough testing.
        return newFuncServerOption(func(o *serverOptions) </span><span class="cov0" title="0">{
                o.numServerWorkers = numServerWorkers
        }</span>)
}

// serverWorkerResetThreshold defines how often the stack must be reset. Every
// N requests, by spawning a new goroutine in its place, a worker can reset its
// stack so that large stacks don't live in memory forever. 2^16 should allow
// each goroutine stack to live for at least a few seconds in a typical
// workload (assuming a QPS of a few thousand requests/sec).
const serverWorkerResetThreshold = 1 &lt;&lt; 16

// serverWorkers blocks on a *transport.Stream channel forever and waits for
// data to be fed by serveStreams. This allows different requests to be
// processed by the same goroutine, removing the need for expensive stack
// re-allocations (see the runtime.morestack problem [1]).
//
// [1] https://github.com/golang/go/issues/18138
func (s *Server) serverWorker(ch chan *serverWorkerData) <span class="cov0" title="0">{
        // To make sure all server workers don't reset at the same time, choose a
        // random number of iterations before resetting.
        threshold := serverWorkerResetThreshold + grpcrand.Intn(serverWorkerResetThreshold)
        for completed := 0; completed &lt; threshold; completed++ </span><span class="cov0" title="0">{
                data, ok := &lt;-ch
                if !ok </span><span class="cov0" title="0">{
                        return
                }</span>
                <span class="cov0" title="0">s.handleStream(data.st, data.stream, s.traceInfo(data.st, data.stream))
                data.wg.Done()</span>
        }
        <span class="cov0" title="0">go s.serverWorker(ch)</span>
}

// initServerWorkers creates worker goroutines and channels to process incoming
// connections to reduce the time spent overall on runtime.morestack.
func (s *Server) initServerWorkers() <span class="cov0" title="0">{
        s.serverWorkerChannels = make([]chan *serverWorkerData, s.opts.numServerWorkers)
        for i := uint32(0); i &lt; s.opts.numServerWorkers; i++ </span><span class="cov0" title="0">{
                s.serverWorkerChannels[i] = make(chan *serverWorkerData)
                go s.serverWorker(s.serverWorkerChannels[i])
        }</span>
}

func (s *Server) stopServerWorkers() <span class="cov0" title="0">{
        for i := uint32(0); i &lt; s.opts.numServerWorkers; i++ </span><span class="cov0" title="0">{
                close(s.serverWorkerChannels[i])
        }</span>
}

// NewServer creates a gRPC server which has no service registered and has not
// started to accept requests yet.
func NewServer(opt ...ServerOption) *Server <span class="cov8" title="1">{
        opts := defaultServerOptions
        for _, o := range extraServerOptions </span><span class="cov8" title="1">{
                o.apply(&amp;opts)
        }</span>
        <span class="cov8" title="1">for _, o := range opt </span><span class="cov0" title="0">{
                o.apply(&amp;opts)
        }</span>
        <span class="cov8" title="1">s := &amp;Server{
                lis:      make(map[net.Listener]bool),
                opts:     opts,
                conns:    make(map[string]map[transport.ServerTransport]bool),
                services: make(map[string]*serviceInfo),
                quit:     grpcsync.NewEvent(),
                done:     grpcsync.NewEvent(),
                czData:   new(channelzData),
        }
        chainUnaryServerInterceptors(s)
        chainStreamServerInterceptors(s)
        s.cv = sync.NewCond(&amp;s.mu)
        if EnableTracing </span><span class="cov0" title="0">{
                _, file, line, _ := runtime.Caller(1)
                s.events = trace.NewEventLog("grpc.Server", fmt.Sprintf("%s:%d", file, line))
        }</span>

        <span class="cov8" title="1">if s.opts.numServerWorkers &gt; 0 </span><span class="cov0" title="0">{
                s.initServerWorkers()
        }</span>

        <span class="cov8" title="1">s.channelzID = channelz.RegisterServer(&amp;channelzServer{s}, "")
        channelz.Info(logger, s.channelzID, "Server created")
        return s</span>
}

// printf records an event in s's event log, unless s has been stopped.
// REQUIRES s.mu is held.
func (s *Server) printf(format string, a ...interface{}) <span class="cov8" title="1">{
        if s.events != nil </span><span class="cov0" title="0">{
                s.events.Printf(format, a...)
        }</span>
}

// errorf records an error in s's event log, unless s has been stopped.
// REQUIRES s.mu is held.
func (s *Server) errorf(format string, a ...interface{}) <span class="cov0" title="0">{
        if s.events != nil </span><span class="cov0" title="0">{
                s.events.Errorf(format, a...)
        }</span>
}

// ServiceRegistrar wraps a single method that supports service registration. It
// enables users to pass concrete types other than grpc.Server to the service
// registration methods exported by the IDL generated code.
type ServiceRegistrar interface {
        // RegisterService registers a service and its implementation to the
        // concrete type implementing this interface.  It may not be called
        // once the server has started serving.
        // desc describes the service and its methods and handlers. impl is the
        // service implementation which is passed to the method handlers.
        RegisterService(desc *ServiceDesc, impl interface{})
}

// RegisterService registers a service and its implementation to the gRPC
// server. It is called from the IDL generated code. This must be called before
// invoking Serve. If ss is non-nil (for legacy code), its type is checked to
// ensure it implements sd.HandlerType.
func (s *Server) RegisterService(sd *ServiceDesc, ss interface{}) <span class="cov8" title="1">{
        if ss != nil </span><span class="cov8" title="1">{
                ht := reflect.TypeOf(sd.HandlerType).Elem()
                st := reflect.TypeOf(ss)
                if !st.Implements(ht) </span><span class="cov0" title="0">{
                        logger.Fatalf("grpc: Server.RegisterService found the handler of type %v that does not satisfy %v", st, ht)
                }</span>
        }
        <span class="cov8" title="1">s.register(sd, ss)</span>
}

func (s *Server) register(sd *ServiceDesc, ss interface{}) <span class="cov8" title="1">{
        s.mu.Lock()
        defer s.mu.Unlock()
        s.printf("RegisterService(%q)", sd.ServiceName)
        if s.serve </span><span class="cov0" title="0">{
                logger.Fatalf("grpc: Server.RegisterService after Server.Serve for %q", sd.ServiceName)
        }</span>
        <span class="cov8" title="1">if _, ok := s.services[sd.ServiceName]; ok </span><span class="cov0" title="0">{
                logger.Fatalf("grpc: Server.RegisterService found duplicate service registration for %q", sd.ServiceName)
        }</span>
        <span class="cov8" title="1">info := &amp;serviceInfo{
                serviceImpl: ss,
                methods:     make(map[string]*MethodDesc),
                streams:     make(map[string]*StreamDesc),
                mdata:       sd.Metadata,
        }
        for i := range sd.Methods </span><span class="cov8" title="1">{
                d := &amp;sd.Methods[i]
                info.methods[d.MethodName] = d
        }</span>
        <span class="cov8" title="1">for i := range sd.Streams </span><span class="cov8" title="1">{
                d := &amp;sd.Streams[i]
                info.streams[d.StreamName] = d
        }</span>
        <span class="cov8" title="1">s.services[sd.ServiceName] = info</span>
}

// MethodInfo contains the information of an RPC including its method name and type.
type MethodInfo struct {
        // Name is the method name only, without the service name or package name.
        Name string
        // IsClientStream indicates whether the RPC is a client streaming RPC.
        IsClientStream bool
        // IsServerStream indicates whether the RPC is a server streaming RPC.
        IsServerStream bool
}

// ServiceInfo contains unary RPC method info, streaming RPC method info and metadata for a service.
type ServiceInfo struct {
        Methods []MethodInfo
        // Metadata is the metadata specified in ServiceDesc when registering service.
        Metadata interface{}
}

// GetServiceInfo returns a map from service names to ServiceInfo.
// Service names include the package names, in the form of &lt;package&gt;.&lt;service&gt;.
func (s *Server) GetServiceInfo() map[string]ServiceInfo <span class="cov8" title="1">{
        ret := make(map[string]ServiceInfo)
        for n, srv := range s.services </span><span class="cov8" title="1">{
                methods := make([]MethodInfo, 0, len(srv.methods)+len(srv.streams))
                for m := range srv.methods </span><span class="cov8" title="1">{
                        methods = append(methods, MethodInfo{
                                Name:           m,
                                IsClientStream: false,
                                IsServerStream: false,
                        })
                }</span>
                <span class="cov8" title="1">for m, d := range srv.streams </span><span class="cov8" title="1">{
                        methods = append(methods, MethodInfo{
                                Name:           m,
                                IsClientStream: d.ClientStreams,
                                IsServerStream: d.ServerStreams,
                        })
                }</span>

                <span class="cov8" title="1">ret[n] = ServiceInfo{
                        Methods:  methods,
                        Metadata: srv.mdata,
                }</span>
        }
        <span class="cov8" title="1">return ret</span>
}

// ErrServerStopped indicates that the operation is now illegal because of
// the server being stopped.
var ErrServerStopped = errors.New("grpc: the server has been stopped")

type listenSocket struct {
        net.Listener
        channelzID *channelz.Identifier
}

func (l *listenSocket) ChannelzMetric() *channelz.SocketInternalMetric <span class="cov0" title="0">{
        return &amp;channelz.SocketInternalMetric{
                SocketOptions: channelz.GetSocketOption(l.Listener),
                LocalAddr:     l.Listener.Addr(),
        }
}</span>

func (l *listenSocket) Close() error <span class="cov8" title="1">{
        err := l.Listener.Close()
        channelz.RemoveEntry(l.channelzID)
        channelz.Info(logger, l.channelzID, "ListenSocket deleted")
        return err
}</span>

// Serve accepts incoming connections on the listener lis, creating a new
// ServerTransport and service goroutine for each. The service goroutines
// read gRPC requests and then call the registered handlers to reply to them.
// Serve returns when lis.Accept fails with fatal errors.  lis will be closed when
// this method returns.
// Serve will return a non-nil error unless Stop or GracefulStop is called.
func (s *Server) Serve(lis net.Listener) error <span class="cov8" title="1">{
        s.mu.Lock()
        s.printf("serving")
        s.serve = true
        if s.lis == nil </span><span class="cov8" title="1">{
                // Serve called after Stop or GracefulStop.
                s.mu.Unlock()
                lis.Close()
                return ErrServerStopped
        }</span>

        <span class="cov8" title="1">s.serveWG.Add(1)
        defer func() </span><span class="cov8" title="1">{
                s.serveWG.Done()
                if s.quit.HasFired() </span><span class="cov8" title="1">{
                        // Stop or GracefulStop called; block until done and return nil.
                        &lt;-s.done.Done()
                }</span>
        }()

        <span class="cov8" title="1">ls := &amp;listenSocket{Listener: lis}
        s.lis[ls] = true

        defer func() </span><span class="cov8" title="1">{
                s.mu.Lock()
                if s.lis != nil &amp;&amp; s.lis[ls] </span><span class="cov0" title="0">{
                        ls.Close()
                        delete(s.lis, ls)
                }</span>
                <span class="cov8" title="1">s.mu.Unlock()</span>
        }()

        <span class="cov8" title="1">var err error
        ls.channelzID, err = channelz.RegisterListenSocket(ls, s.channelzID, lis.Addr().String())
        if err != nil </span><span class="cov0" title="0">{
                s.mu.Unlock()
                return err
        }</span>
        <span class="cov8" title="1">s.mu.Unlock()
        channelz.Info(logger, ls.channelzID, "ListenSocket created")

        var tempDelay time.Duration // how long to sleep on accept failure
        for </span><span class="cov8" title="1">{
                rawConn, err := lis.Accept()
                if err != nil </span><span class="cov8" title="1">{
                        if ne, ok := err.(interface {
                                Temporary() bool
                        }); ok &amp;&amp; ne.Temporary() </span><span class="cov0" title="0">{
                                if tempDelay == 0 </span><span class="cov0" title="0">{
                                        tempDelay = 5 * time.Millisecond
                                }</span> else<span class="cov0" title="0"> {
                                        tempDelay *= 2
                                }</span>
                                <span class="cov0" title="0">if max := 1 * time.Second; tempDelay &gt; max </span><span class="cov0" title="0">{
                                        tempDelay = max
                                }</span>
                                <span class="cov0" title="0">s.mu.Lock()
                                s.printf("Accept error: %v; retrying in %v", err, tempDelay)
                                s.mu.Unlock()
                                timer := time.NewTimer(tempDelay)
                                select </span>{
                                case &lt;-timer.C:<span class="cov0" title="0"></span>
                                case &lt;-s.quit.Done():<span class="cov0" title="0">
                                        timer.Stop()
                                        return nil</span>
                                }
                                <span class="cov0" title="0">continue</span>
                        }
                        <span class="cov8" title="1">s.mu.Lock()
                        s.printf("done serving; Accept = %v", err)
                        s.mu.Unlock()

                        if s.quit.HasFired() </span><span class="cov8" title="1">{
                                return nil
                        }</span>
                        <span class="cov0" title="0">return err</span>
                }
                <span class="cov0" title="0">tempDelay = 0
                // Start a new goroutine to deal with rawConn so we don't stall this Accept
                // loop goroutine.
                //
                // Make sure we account for the goroutine so GracefulStop doesn't nil out
                // s.conns before this conn can be added.
                s.serveWG.Add(1)
                go func() </span><span class="cov0" title="0">{
                        s.handleRawConn(lis.Addr().String(), rawConn)
                        s.serveWG.Done()
                }</span>()
        }
}

// handleRawConn forks a goroutine to handle a just-accepted connection that
// has not had any I/O performed on it yet.
func (s *Server) handleRawConn(lisAddr string, rawConn net.Conn) <span class="cov0" title="0">{
        if s.quit.HasFired() </span><span class="cov0" title="0">{
                rawConn.Close()
                return
        }</span>
        <span class="cov0" title="0">rawConn.SetDeadline(time.Now().Add(s.opts.connectionTimeout))

        // Finish handshaking (HTTP2)
        st := s.newHTTP2Transport(rawConn)
        rawConn.SetDeadline(time.Time{})
        if st == nil </span><span class="cov0" title="0">{
                return
        }</span>

        <span class="cov0" title="0">if !s.addConn(lisAddr, st) </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov0" title="0">go func() </span><span class="cov0" title="0">{
                s.serveStreams(st)
                s.removeConn(lisAddr, st)
        }</span>()
}

func (s *Server) drainServerTransports(addr string) <span class="cov0" title="0">{
        s.mu.Lock()
        conns := s.conns[addr]
        for st := range conns </span><span class="cov0" title="0">{
                st.Drain()
        }</span>
        <span class="cov0" title="0">s.mu.Unlock()</span>
}

// newHTTP2Transport sets up a http/2 transport (using the
// gRPC http2 server transport in transport/http2_server.go).
func (s *Server) newHTTP2Transport(c net.Conn) transport.ServerTransport <span class="cov0" title="0">{
        config := &amp;transport.ServerConfig{
                MaxStreams:            s.opts.maxConcurrentStreams,
                ConnectionTimeout:     s.opts.connectionTimeout,
                Credentials:           s.opts.creds,
                InTapHandle:           s.opts.inTapHandle,
                StatsHandlers:         s.opts.statsHandlers,
                KeepaliveParams:       s.opts.keepaliveParams,
                KeepalivePolicy:       s.opts.keepalivePolicy,
                InitialWindowSize:     s.opts.initialWindowSize,
                InitialConnWindowSize: s.opts.initialConnWindowSize,
                WriteBufferSize:       s.opts.writeBufferSize,
                ReadBufferSize:        s.opts.readBufferSize,
                ChannelzParentID:      s.channelzID,
                MaxHeaderListSize:     s.opts.maxHeaderListSize,
                HeaderTableSize:       s.opts.headerTableSize,
        }
        st, err := transport.NewServerTransport(c, config)
        if err != nil </span><span class="cov0" title="0">{
                s.mu.Lock()
                s.errorf("NewServerTransport(%q) failed: %v", c.RemoteAddr(), err)
                s.mu.Unlock()
                // ErrConnDispatched means that the connection was dispatched away from
                // gRPC; those connections should be left open.
                if err != credentials.ErrConnDispatched </span><span class="cov0" title="0">{
                        // Don't log on ErrConnDispatched and io.EOF to prevent log spam.
                        if err != io.EOF </span><span class="cov0" title="0">{
                                channelz.Info(logger, s.channelzID, "grpc: Server.Serve failed to create ServerTransport: ", err)
                        }</span>
                        <span class="cov0" title="0">c.Close()</span>
                }
                <span class="cov0" title="0">return nil</span>
        }

        <span class="cov0" title="0">return st</span>
}

func (s *Server) serveStreams(st transport.ServerTransport) <span class="cov0" title="0">{
        defer st.Close()
        var wg sync.WaitGroup

        var roundRobinCounter uint32
        st.HandleStreams(func(stream *transport.Stream) </span><span class="cov0" title="0">{
                wg.Add(1)
                if s.opts.numServerWorkers &gt; 0 </span><span class="cov0" title="0">{
                        data := &amp;serverWorkerData{st: st, wg: &amp;wg, stream: stream}
                        select </span>{
                        case s.serverWorkerChannels[atomic.AddUint32(&amp;roundRobinCounter, 1)%s.opts.numServerWorkers] &lt;- data:<span class="cov0" title="0"></span>
                        default:<span class="cov0" title="0">
                                // If all stream workers are busy, fallback to the default code path.
                                go func() </span><span class="cov0" title="0">{
                                        s.handleStream(st, stream, s.traceInfo(st, stream))
                                        wg.Done()
                                }</span>()
                        }
                } else<span class="cov0" title="0"> {
                        go func() </span><span class="cov0" title="0">{
                                defer wg.Done()
                                s.handleStream(st, stream, s.traceInfo(st, stream))
                        }</span>()
                }
        }, func(ctx context.Context, method string) context.Context <span class="cov0" title="0">{
                if !EnableTracing </span><span class="cov0" title="0">{
                        return ctx
                }</span>
                <span class="cov0" title="0">tr := trace.New("grpc.Recv."+methodFamily(method), method)
                return trace.NewContext(ctx, tr)</span>
        })
        <span class="cov0" title="0">wg.Wait()</span>
}

var _ http.Handler = (*Server)(nil)

// ServeHTTP implements the Go standard library's http.Handler
// interface by responding to the gRPC request r, by looking up
// the requested gRPC method in the gRPC server s.
//
// The provided HTTP request must have arrived on an HTTP/2
// connection. When using the Go standard library's server,
// practically this means that the Request must also have arrived
// over TLS.
//
// To share one port (such as 443 for https) between gRPC and an
// existing http.Handler, use a root http.Handler such as:
//
//        if r.ProtoMajor == 2 &amp;&amp; strings.HasPrefix(
//                r.Header.Get("Content-Type"), "application/grpc") {
//                grpcServer.ServeHTTP(w, r)
//        } else {
//                yourMux.ServeHTTP(w, r)
//        }
//
// Note that ServeHTTP uses Go's HTTP/2 server implementation which is totally
// separate from grpc-go's HTTP/2 server. Performance and features may vary
// between the two paths. ServeHTTP does not support some gRPC features
// available through grpc-go's HTTP/2 server.
//
// # Experimental
//
// Notice: This API is EXPERIMENTAL and may be changed or removed in a
// later release.
func (s *Server) ServeHTTP(w http.ResponseWriter, r *http.Request) <span class="cov0" title="0">{
        st, err := transport.NewServerHandlerTransport(w, r, s.opts.statsHandlers)
        if err != nil </span><span class="cov0" title="0">{
                http.Error(w, err.Error(), http.StatusInternalServerError)
                return
        }</span>
        <span class="cov0" title="0">if !s.addConn(listenerAddressForServeHTTP, st) </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov0" title="0">defer s.removeConn(listenerAddressForServeHTTP, st)
        s.serveStreams(st)</span>
}

// traceInfo returns a traceInfo and associates it with stream, if tracing is enabled.
// If tracing is not enabled, it returns nil.
func (s *Server) traceInfo(st transport.ServerTransport, stream *transport.Stream) (trInfo *traceInfo) <span class="cov0" title="0">{
        if !EnableTracing </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">tr, ok := trace.FromContext(stream.Context())
        if !ok </span><span class="cov0" title="0">{
                return nil
        }</span>

        <span class="cov0" title="0">trInfo = &amp;traceInfo{
                tr: tr,
                firstLine: firstLine{
                        client:     false,
                        remoteAddr: st.RemoteAddr(),
                },
        }
        if dl, ok := stream.Context().Deadline(); ok </span><span class="cov0" title="0">{
                trInfo.firstLine.deadline = time.Until(dl)
        }</span>
        <span class="cov0" title="0">return trInfo</span>
}

func (s *Server) addConn(addr string, st transport.ServerTransport) bool <span class="cov0" title="0">{
        s.mu.Lock()
        defer s.mu.Unlock()
        if s.conns == nil </span><span class="cov0" title="0">{
                st.Close()
                return false
        }</span>
        <span class="cov0" title="0">if s.drain </span><span class="cov0" title="0">{
                // Transport added after we drained our existing conns: drain it
                // immediately.
                st.Drain()
        }</span>

        <span class="cov0" title="0">if s.conns[addr] == nil </span><span class="cov0" title="0">{
                // Create a map entry if this is the first connection on this listener.
                s.conns[addr] = make(map[transport.ServerTransport]bool)
        }</span>
        <span class="cov0" title="0">s.conns[addr][st] = true
        return true</span>
}

func (s *Server) removeConn(addr string, st transport.ServerTransport) <span class="cov0" title="0">{
        s.mu.Lock()
        defer s.mu.Unlock()

        conns := s.conns[addr]
        if conns != nil </span><span class="cov0" title="0">{
                delete(conns, st)
                if len(conns) == 0 </span><span class="cov0" title="0">{
                        // If the last connection for this address is being removed, also
                        // remove the map entry corresponding to the address. This is used
                        // in GracefulStop() when waiting for all connections to be closed.
                        delete(s.conns, addr)
                }</span>
                <span class="cov0" title="0">s.cv.Broadcast()</span>
        }
}

func (s *Server) channelzMetric() *channelz.ServerInternalMetric <span class="cov0" title="0">{
        return &amp;channelz.ServerInternalMetric{
                CallsStarted:             atomic.LoadInt64(&amp;s.czData.callsStarted),
                CallsSucceeded:           atomic.LoadInt64(&amp;s.czData.callsSucceeded),
                CallsFailed:              atomic.LoadInt64(&amp;s.czData.callsFailed),
                LastCallStartedTimestamp: time.Unix(0, atomic.LoadInt64(&amp;s.czData.lastCallStartedTime)),
        }
}</span>

func (s *Server) incrCallsStarted() <span class="cov0" title="0">{
        atomic.AddInt64(&amp;s.czData.callsStarted, 1)
        atomic.StoreInt64(&amp;s.czData.lastCallStartedTime, time.Now().UnixNano())
}</span>

func (s *Server) incrCallsSucceeded() <span class="cov0" title="0">{
        atomic.AddInt64(&amp;s.czData.callsSucceeded, 1)
}</span>

func (s *Server) incrCallsFailed() <span class="cov0" title="0">{
        atomic.AddInt64(&amp;s.czData.callsFailed, 1)
}</span>

func (s *Server) sendResponse(t transport.ServerTransport, stream *transport.Stream, msg interface{}, cp Compressor, opts *transport.Options, comp encoding.Compressor) error <span class="cov0" title="0">{
        data, err := encode(s.getCodec(stream.ContentSubtype()), msg)
        if err != nil </span><span class="cov0" title="0">{
                channelz.Error(logger, s.channelzID, "grpc: server failed to encode response: ", err)
                return err
        }</span>
        <span class="cov0" title="0">compData, err := compress(data, cp, comp)
        if err != nil </span><span class="cov0" title="0">{
                channelz.Error(logger, s.channelzID, "grpc: server failed to compress response: ", err)
                return err
        }</span>
        <span class="cov0" title="0">hdr, payload := msgHeader(data, compData)
        // TODO(dfawley): should we be checking len(data) instead?
        if len(payload) &gt; s.opts.maxSendMessageSize </span><span class="cov0" title="0">{
                return status.Errorf(codes.ResourceExhausted, "grpc: trying to send message larger than max (%d vs. %d)", len(payload), s.opts.maxSendMessageSize)
        }</span>
        <span class="cov0" title="0">err = t.Write(stream, hdr, payload, opts)
        if err == nil </span><span class="cov0" title="0">{
                for _, sh := range s.opts.statsHandlers </span><span class="cov0" title="0">{
                        sh.HandleRPC(stream.Context(), outPayload(false, msg, data, payload, time.Now()))
                }</span>
        }
        <span class="cov0" title="0">return err</span>
}

// chainUnaryServerInterceptors chains all unary server interceptors into one.
func chainUnaryServerInterceptors(s *Server) <span class="cov8" title="1">{
        // Prepend opts.unaryInt to the chaining interceptors if it exists, since unaryInt will
        // be executed before any other chained interceptors.
        interceptors := s.opts.chainUnaryInts
        if s.opts.unaryInt != nil </span><span class="cov0" title="0">{
                interceptors = append([]UnaryServerInterceptor{s.opts.unaryInt}, s.opts.chainUnaryInts...)
        }</span>

        <span class="cov8" title="1">var chainedInt UnaryServerInterceptor
        if len(interceptors) == 0 </span><span class="cov8" title="1">{
                chainedInt = nil
        }</span> else<span class="cov0" title="0"> if len(interceptors) == 1 </span><span class="cov0" title="0">{
                chainedInt = interceptors[0]
        }</span> else<span class="cov0" title="0"> {
                chainedInt = chainUnaryInterceptors(interceptors)
        }</span>

        <span class="cov8" title="1">s.opts.unaryInt = chainedInt</span>
}

func chainUnaryInterceptors(interceptors []UnaryServerInterceptor) UnaryServerInterceptor <span class="cov0" title="0">{
        return func(ctx context.Context, req interface{}, info *UnaryServerInfo, handler UnaryHandler) (interface{}, error) </span><span class="cov0" title="0">{
                // the struct ensures the variables are allocated together, rather than separately, since we
                // know they should be garbage collected together. This saves 1 allocation and decreases
                // time/call by about 10% on the microbenchmark.
                var state struct {
                        i    int
                        next UnaryHandler
                }
                state.next = func(ctx context.Context, req interface{}) (interface{}, error) </span><span class="cov0" title="0">{
                        if state.i == len(interceptors)-1 </span><span class="cov0" title="0">{
                                return interceptors[state.i](ctx, req, info, handler)
                        }</span>
                        <span class="cov0" title="0">state.i++
                        return interceptors[state.i-1](ctx, req, info, state.next)</span>
                }
                <span class="cov0" title="0">return state.next(ctx, req)</span>
        }
}

func (s *Server) processUnaryRPC(t transport.ServerTransport, stream *transport.Stream, info *serviceInfo, md *MethodDesc, trInfo *traceInfo) (err error) <span class="cov0" title="0">{
        shs := s.opts.statsHandlers
        if len(shs) != 0 || trInfo != nil || channelz.IsOn() </span><span class="cov0" title="0">{
                if channelz.IsOn() </span><span class="cov0" title="0">{
                        s.incrCallsStarted()
                }</span>
                <span class="cov0" title="0">var statsBegin *stats.Begin
                for _, sh := range shs </span><span class="cov0" title="0">{
                        beginTime := time.Now()
                        statsBegin = &amp;stats.Begin{
                                BeginTime:      beginTime,
                                IsClientStream: false,
                                IsServerStream: false,
                        }
                        sh.HandleRPC(stream.Context(), statsBegin)
                }</span>
                <span class="cov0" title="0">if trInfo != nil </span><span class="cov0" title="0">{
                        trInfo.tr.LazyLog(&amp;trInfo.firstLine, false)
                }</span>
                // The deferred error handling for tracing, stats handler and channelz are
                // combined into one function to reduce stack usage -- a defer takes ~56-64
                // bytes on the stack, so overflowing the stack will require a stack
                // re-allocation, which is expensive.
                //
                // To maintain behavior similar to separate deferred statements, statements
                // should be executed in the reverse order. That is, tracing first, stats
                // handler second, and channelz last. Note that panics *within* defers will
                // lead to different behavior, but that's an acceptable compromise; that
                // would be undefined behavior territory anyway.
                <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                        if trInfo != nil </span><span class="cov0" title="0">{
                                if err != nil &amp;&amp; err != io.EOF </span><span class="cov0" title="0">{
                                        trInfo.tr.LazyLog(&amp;fmtStringer{"%v", []interface{}{err}}, true)
                                        trInfo.tr.SetError()
                                }</span>
                                <span class="cov0" title="0">trInfo.tr.Finish()</span>
                        }

                        <span class="cov0" title="0">for _, sh := range shs </span><span class="cov0" title="0">{
                                end := &amp;stats.End{
                                        BeginTime: statsBegin.BeginTime,
                                        EndTime:   time.Now(),
                                }
                                if err != nil &amp;&amp; err != io.EOF </span><span class="cov0" title="0">{
                                        end.Error = toRPCErr(err)
                                }</span>
                                <span class="cov0" title="0">sh.HandleRPC(stream.Context(), end)</span>
                        }

                        <span class="cov0" title="0">if channelz.IsOn() </span><span class="cov0" title="0">{
                                if err != nil &amp;&amp; err != io.EOF </span><span class="cov0" title="0">{
                                        s.incrCallsFailed()
                                }</span> else<span class="cov0" title="0"> {
                                        s.incrCallsSucceeded()
                                }</span>
                        }
                }()
        }

        <span class="cov0" title="0">binlog := binarylog.GetMethodLogger(stream.Method())
        if binlog != nil </span><span class="cov0" title="0">{
                ctx := stream.Context()
                md, _ := metadata.FromIncomingContext(ctx)
                logEntry := &amp;binarylog.ClientHeader{
                        Header:     md,
                        MethodName: stream.Method(),
                        PeerAddr:   nil,
                }
                if deadline, ok := ctx.Deadline(); ok </span><span class="cov0" title="0">{
                        logEntry.Timeout = time.Until(deadline)
                        if logEntry.Timeout &lt; 0 </span><span class="cov0" title="0">{
                                logEntry.Timeout = 0
                        }</span>
                }
                <span class="cov0" title="0">if a := md[":authority"]; len(a) &gt; 0 </span><span class="cov0" title="0">{
                        logEntry.Authority = a[0]
                }</span>
                <span class="cov0" title="0">if peer, ok := peer.FromContext(ctx); ok </span><span class="cov0" title="0">{
                        logEntry.PeerAddr = peer.Addr
                }</span>
                <span class="cov0" title="0">binlog.Log(logEntry)</span>
        }

        // comp and cp are used for compression.  decomp and dc are used for
        // decompression.  If comp and decomp are both set, they are the same;
        // however they are kept separate to ensure that at most one of the
        // compressor/decompressor variable pairs are set for use later.
        <span class="cov0" title="0">var comp, decomp encoding.Compressor
        var cp Compressor
        var dc Decompressor

        // If dc is set and matches the stream's compression, use it.  Otherwise, try
        // to find a matching registered compressor for decomp.
        if rc := stream.RecvCompress(); s.opts.dc != nil &amp;&amp; s.opts.dc.Type() == rc </span><span class="cov0" title="0">{
                dc = s.opts.dc
        }</span> else<span class="cov0" title="0"> if rc != "" &amp;&amp; rc != encoding.Identity </span><span class="cov0" title="0">{
                decomp = encoding.GetCompressor(rc)
                if decomp == nil </span><span class="cov0" title="0">{
                        st := status.Newf(codes.Unimplemented, "grpc: Decompressor is not installed for grpc-encoding %q", rc)
                        t.WriteStatus(stream, st)
                        return st.Err()
                }</span>
        }

        // If cp is set, use it.  Otherwise, attempt to compress the response using
        // the incoming message compression method.
        //
        // NOTE: this needs to be ahead of all handling, https://github.com/grpc/grpc-go/issues/686.
        <span class="cov0" title="0">if s.opts.cp != nil </span><span class="cov0" title="0">{
                cp = s.opts.cp
                stream.SetSendCompress(cp.Type())
        }</span> else<span class="cov0" title="0"> if rc := stream.RecvCompress(); rc != "" &amp;&amp; rc != encoding.Identity </span><span class="cov0" title="0">{
                // Legacy compressor not specified; attempt to respond with same encoding.
                comp = encoding.GetCompressor(rc)
                if comp != nil </span><span class="cov0" title="0">{
                        stream.SetSendCompress(rc)
                }</span>
        }

        <span class="cov0" title="0">var payInfo *payloadInfo
        if len(shs) != 0 || binlog != nil </span><span class="cov0" title="0">{
                payInfo = &amp;payloadInfo{}
        }</span>
        <span class="cov0" title="0">d, err := recvAndDecompress(&amp;parser{r: stream}, stream, dc, s.opts.maxReceiveMessageSize, payInfo, decomp)
        if err != nil </span><span class="cov0" title="0">{
                if e := t.WriteStatus(stream, status.Convert(err)); e != nil </span><span class="cov0" title="0">{
                        channelz.Warningf(logger, s.channelzID, "grpc: Server.processUnaryRPC failed to write status %v", e)
                }</span>
                <span class="cov0" title="0">return err</span>
        }
        <span class="cov0" title="0">if channelz.IsOn() </span><span class="cov0" title="0">{
                t.IncrMsgRecv()
        }</span>
        <span class="cov0" title="0">df := func(v interface{}) error </span><span class="cov0" title="0">{
                if err := s.getCodec(stream.ContentSubtype()).Unmarshal(d, v); err != nil </span><span class="cov0" title="0">{
                        return status.Errorf(codes.Internal, "grpc: error unmarshalling request: %v", err)
                }</span>
                <span class="cov0" title="0">for _, sh := range shs </span><span class="cov0" title="0">{
                        sh.HandleRPC(stream.Context(), &amp;stats.InPayload{
                                RecvTime:   time.Now(),
                                Payload:    v,
                                WireLength: payInfo.wireLength + headerLen,
                                Data:       d,
                                Length:     len(d),
                        })
                }</span>
                <span class="cov0" title="0">if binlog != nil </span><span class="cov0" title="0">{
                        binlog.Log(&amp;binarylog.ClientMessage{
                                Message: d,
                        })
                }</span>
                <span class="cov0" title="0">if trInfo != nil </span><span class="cov0" title="0">{
                        trInfo.tr.LazyLog(&amp;payload{sent: false, msg: v}, true)
                }</span>
                <span class="cov0" title="0">return nil</span>
        }
        <span class="cov0" title="0">ctx := NewContextWithServerTransportStream(stream.Context(), stream)
        reply, appErr := md.Handler(info.serviceImpl, ctx, df, s.opts.unaryInt)
        if appErr != nil </span><span class="cov0" title="0">{
                appStatus, ok := status.FromError(appErr)
                if !ok </span><span class="cov0" title="0">{
                        // Convert non-status application error to a status error with code
                        // Unknown, but handle context errors specifically.
                        appStatus = status.FromContextError(appErr)
                        appErr = appStatus.Err()
                }</span>
                <span class="cov0" title="0">if trInfo != nil </span><span class="cov0" title="0">{
                        trInfo.tr.LazyLog(stringer(appStatus.Message()), true)
                        trInfo.tr.SetError()
                }</span>
                <span class="cov0" title="0">if e := t.WriteStatus(stream, appStatus); e != nil </span><span class="cov0" title="0">{
                        channelz.Warningf(logger, s.channelzID, "grpc: Server.processUnaryRPC failed to write status: %v", e)
                }</span>
                <span class="cov0" title="0">if binlog != nil </span><span class="cov0" title="0">{
                        if h, _ := stream.Header(); h.Len() &gt; 0 </span><span class="cov0" title="0">{
                                // Only log serverHeader if there was header. Otherwise it can
                                // be trailer only.
                                binlog.Log(&amp;binarylog.ServerHeader{
                                        Header: h,
                                })
                        }</span>
                        <span class="cov0" title="0">binlog.Log(&amp;binarylog.ServerTrailer{
                                Trailer: stream.Trailer(),
                                Err:     appErr,
                        })</span>
                }
                <span class="cov0" title="0">return appErr</span>
        }
        <span class="cov0" title="0">if trInfo != nil </span><span class="cov0" title="0">{
                trInfo.tr.LazyLog(stringer("OK"), false)
        }</span>
        <span class="cov0" title="0">opts := &amp;transport.Options{Last: true}

        if err := s.sendResponse(t, stream, reply, cp, opts, comp); err != nil </span><span class="cov0" title="0">{
                if err == io.EOF </span><span class="cov0" title="0">{
                        // The entire stream is done (for unary RPC only).
                        return err
                }</span>
                <span class="cov0" title="0">if sts, ok := status.FromError(err); ok </span><span class="cov0" title="0">{
                        if e := t.WriteStatus(stream, sts); e != nil </span><span class="cov0" title="0">{
                                channelz.Warningf(logger, s.channelzID, "grpc: Server.processUnaryRPC failed to write status: %v", e)
                        }</span>
                } else<span class="cov0" title="0"> {
                        switch st := err.(type) </span>{
                        case transport.ConnectionError:<span class="cov0" title="0"></span>
                                // Nothing to do here.
                        default:<span class="cov0" title="0">
                                panic(fmt.Sprintf("grpc: Unexpected error (%T) from sendResponse: %v", st, st))</span>
                        }
                }
                <span class="cov0" title="0">if binlog != nil </span><span class="cov0" title="0">{
                        h, _ := stream.Header()
                        binlog.Log(&amp;binarylog.ServerHeader{
                                Header: h,
                        })
                        binlog.Log(&amp;binarylog.ServerTrailer{
                                Trailer: stream.Trailer(),
                                Err:     appErr,
                        })
                }</span>
                <span class="cov0" title="0">return err</span>
        }
        <span class="cov0" title="0">if binlog != nil </span><span class="cov0" title="0">{
                h, _ := stream.Header()
                binlog.Log(&amp;binarylog.ServerHeader{
                        Header: h,
                })
                binlog.Log(&amp;binarylog.ServerMessage{
                        Message: reply,
                })
        }</span>
        <span class="cov0" title="0">if channelz.IsOn() </span><span class="cov0" title="0">{
                t.IncrMsgSent()
        }</span>
        <span class="cov0" title="0">if trInfo != nil </span><span class="cov0" title="0">{
                trInfo.tr.LazyLog(&amp;payload{sent: true, msg: reply}, true)
        }</span>
        // TODO: Should we be logging if writing status failed here, like above?
        // Should the logging be in WriteStatus?  Should we ignore the WriteStatus
        // error or allow the stats handler to see it?
        <span class="cov0" title="0">err = t.WriteStatus(stream, statusOK)
        if binlog != nil </span><span class="cov0" title="0">{
                binlog.Log(&amp;binarylog.ServerTrailer{
                        Trailer: stream.Trailer(),
                        Err:     appErr,
                })
        }</span>
        <span class="cov0" title="0">return err</span>
}

// chainStreamServerInterceptors chains all stream server interceptors into one.
func chainStreamServerInterceptors(s *Server) <span class="cov8" title="1">{
        // Prepend opts.streamInt to the chaining interceptors if it exists, since streamInt will
        // be executed before any other chained interceptors.
        interceptors := s.opts.chainStreamInts
        if s.opts.streamInt != nil </span><span class="cov0" title="0">{
                interceptors = append([]StreamServerInterceptor{s.opts.streamInt}, s.opts.chainStreamInts...)
        }</span>

        <span class="cov8" title="1">var chainedInt StreamServerInterceptor
        if len(interceptors) == 0 </span><span class="cov8" title="1">{
                chainedInt = nil
        }</span> else<span class="cov0" title="0"> if len(interceptors) == 1 </span><span class="cov0" title="0">{
                chainedInt = interceptors[0]
        }</span> else<span class="cov0" title="0"> {
                chainedInt = chainStreamInterceptors(interceptors)
        }</span>

        <span class="cov8" title="1">s.opts.streamInt = chainedInt</span>
}

func chainStreamInterceptors(interceptors []StreamServerInterceptor) StreamServerInterceptor <span class="cov0" title="0">{
        return func(srv interface{}, ss ServerStream, info *StreamServerInfo, handler StreamHandler) error </span><span class="cov0" title="0">{
                // the struct ensures the variables are allocated together, rather than separately, since we
                // know they should be garbage collected together. This saves 1 allocation and decreases
                // time/call by about 10% on the microbenchmark.
                var state struct {
                        i    int
                        next StreamHandler
                }
                state.next = func(srv interface{}, ss ServerStream) error </span><span class="cov0" title="0">{
                        if state.i == len(interceptors)-1 </span><span class="cov0" title="0">{
                                return interceptors[state.i](srv, ss, info, handler)
                        }</span>
                        <span class="cov0" title="0">state.i++
                        return interceptors[state.i-1](srv, ss, info, state.next)</span>
                }
                <span class="cov0" title="0">return state.next(srv, ss)</span>
        }
}

func (s *Server) processStreamingRPC(t transport.ServerTransport, stream *transport.Stream, info *serviceInfo, sd *StreamDesc, trInfo *traceInfo) (err error) <span class="cov0" title="0">{
        if channelz.IsOn() </span><span class="cov0" title="0">{
                s.incrCallsStarted()
        }</span>
        <span class="cov0" title="0">shs := s.opts.statsHandlers
        var statsBegin *stats.Begin
        if len(shs) != 0 </span><span class="cov0" title="0">{
                beginTime := time.Now()
                statsBegin = &amp;stats.Begin{
                        BeginTime:      beginTime,
                        IsClientStream: sd.ClientStreams,
                        IsServerStream: sd.ServerStreams,
                }
                for _, sh := range shs </span><span class="cov0" title="0">{
                        sh.HandleRPC(stream.Context(), statsBegin)
                }</span>
        }
        <span class="cov0" title="0">ctx := NewContextWithServerTransportStream(stream.Context(), stream)
        ss := &amp;serverStream{
                ctx:                   ctx,
                t:                     t,
                s:                     stream,
                p:                     &amp;parser{r: stream},
                codec:                 s.getCodec(stream.ContentSubtype()),
                maxReceiveMessageSize: s.opts.maxReceiveMessageSize,
                maxSendMessageSize:    s.opts.maxSendMessageSize,
                trInfo:                trInfo,
                statsHandler:          shs,
        }

        if len(shs) != 0 || trInfo != nil || channelz.IsOn() </span><span class="cov0" title="0">{
                // See comment in processUnaryRPC on defers.
                defer func() </span><span class="cov0" title="0">{
                        if trInfo != nil </span><span class="cov0" title="0">{
                                ss.mu.Lock()
                                if err != nil &amp;&amp; err != io.EOF </span><span class="cov0" title="0">{
                                        ss.trInfo.tr.LazyLog(&amp;fmtStringer{"%v", []interface{}{err}}, true)
                                        ss.trInfo.tr.SetError()
                                }</span>
                                <span class="cov0" title="0">ss.trInfo.tr.Finish()
                                ss.trInfo.tr = nil
                                ss.mu.Unlock()</span>
                        }

                        <span class="cov0" title="0">if len(shs) != 0 </span><span class="cov0" title="0">{
                                end := &amp;stats.End{
                                        BeginTime: statsBegin.BeginTime,
                                        EndTime:   time.Now(),
                                }
                                if err != nil &amp;&amp; err != io.EOF </span><span class="cov0" title="0">{
                                        end.Error = toRPCErr(err)
                                }</span>
                                <span class="cov0" title="0">for _, sh := range shs </span><span class="cov0" title="0">{
                                        sh.HandleRPC(stream.Context(), end)
                                }</span>
                        }

                        <span class="cov0" title="0">if channelz.IsOn() </span><span class="cov0" title="0">{
                                if err != nil &amp;&amp; err != io.EOF </span><span class="cov0" title="0">{
                                        s.incrCallsFailed()
                                }</span> else<span class="cov0" title="0"> {
                                        s.incrCallsSucceeded()
                                }</span>
                        }
                }()
        }

        <span class="cov0" title="0">ss.binlog = binarylog.GetMethodLogger(stream.Method())
        if ss.binlog != nil </span><span class="cov0" title="0">{
                md, _ := metadata.FromIncomingContext(ctx)
                logEntry := &amp;binarylog.ClientHeader{
                        Header:     md,
                        MethodName: stream.Method(),
                        PeerAddr:   nil,
                }
                if deadline, ok := ctx.Deadline(); ok </span><span class="cov0" title="0">{
                        logEntry.Timeout = time.Until(deadline)
                        if logEntry.Timeout &lt; 0 </span><span class="cov0" title="0">{
                                logEntry.Timeout = 0
                        }</span>
                }
                <span class="cov0" title="0">if a := md[":authority"]; len(a) &gt; 0 </span><span class="cov0" title="0">{
                        logEntry.Authority = a[0]
                }</span>
                <span class="cov0" title="0">if peer, ok := peer.FromContext(ss.Context()); ok </span><span class="cov0" title="0">{
                        logEntry.PeerAddr = peer.Addr
                }</span>
                <span class="cov0" title="0">ss.binlog.Log(logEntry)</span>
        }

        // If dc is set and matches the stream's compression, use it.  Otherwise, try
        // to find a matching registered compressor for decomp.
        <span class="cov0" title="0">if rc := stream.RecvCompress(); s.opts.dc != nil &amp;&amp; s.opts.dc.Type() == rc </span><span class="cov0" title="0">{
                ss.dc = s.opts.dc
        }</span> else<span class="cov0" title="0"> if rc != "" &amp;&amp; rc != encoding.Identity </span><span class="cov0" title="0">{
                ss.decomp = encoding.GetCompressor(rc)
                if ss.decomp == nil </span><span class="cov0" title="0">{
                        st := status.Newf(codes.Unimplemented, "grpc: Decompressor is not installed for grpc-encoding %q", rc)
                        t.WriteStatus(ss.s, st)
                        return st.Err()
                }</span>
        }

        // If cp is set, use it.  Otherwise, attempt to compress the response using
        // the incoming message compression method.
        //
        // NOTE: this needs to be ahead of all handling, https://github.com/grpc/grpc-go/issues/686.
        <span class="cov0" title="0">if s.opts.cp != nil </span><span class="cov0" title="0">{
                ss.cp = s.opts.cp
                stream.SetSendCompress(s.opts.cp.Type())
        }</span> else<span class="cov0" title="0"> if rc := stream.RecvCompress(); rc != "" &amp;&amp; rc != encoding.Identity </span><span class="cov0" title="0">{
                // Legacy compressor not specified; attempt to respond with same encoding.
                ss.comp = encoding.GetCompressor(rc)
                if ss.comp != nil </span><span class="cov0" title="0">{
                        stream.SetSendCompress(rc)
                }</span>
        }

        <span class="cov0" title="0">ss.ctx = newContextWithRPCInfo(ss.ctx, false, ss.codec, ss.cp, ss.comp)

        if trInfo != nil </span><span class="cov0" title="0">{
                trInfo.tr.LazyLog(&amp;trInfo.firstLine, false)
        }</span>
        <span class="cov0" title="0">var appErr error
        var server interface{}
        if info != nil </span><span class="cov0" title="0">{
                server = info.serviceImpl
        }</span>
        <span class="cov0" title="0">if s.opts.streamInt == nil </span><span class="cov0" title="0">{
                appErr = sd.Handler(server, ss)
        }</span> else<span class="cov0" title="0"> {
                info := &amp;StreamServerInfo{
                        FullMethod:     stream.Method(),
                        IsClientStream: sd.ClientStreams,
                        IsServerStream: sd.ServerStreams,
                }
                appErr = s.opts.streamInt(server, ss, info, sd.Handler)
        }</span>
        <span class="cov0" title="0">if appErr != nil </span><span class="cov0" title="0">{
                appStatus, ok := status.FromError(appErr)
                if !ok </span><span class="cov0" title="0">{
                        // Convert non-status application error to a status error with code
                        // Unknown, but handle context errors specifically.
                        appStatus = status.FromContextError(appErr)
                        appErr = appStatus.Err()
                }</span>
                <span class="cov0" title="0">if trInfo != nil </span><span class="cov0" title="0">{
                        ss.mu.Lock()
                        ss.trInfo.tr.LazyLog(stringer(appStatus.Message()), true)
                        ss.trInfo.tr.SetError()
                        ss.mu.Unlock()
                }</span>
                <span class="cov0" title="0">t.WriteStatus(ss.s, appStatus)
                if ss.binlog != nil </span><span class="cov0" title="0">{
                        ss.binlog.Log(&amp;binarylog.ServerTrailer{
                                Trailer: ss.s.Trailer(),
                                Err:     appErr,
                        })
                }</span>
                // TODO: Should we log an error from WriteStatus here and below?
                <span class="cov0" title="0">return appErr</span>
        }
        <span class="cov0" title="0">if trInfo != nil </span><span class="cov0" title="0">{
                ss.mu.Lock()
                ss.trInfo.tr.LazyLog(stringer("OK"), false)
                ss.mu.Unlock()
        }</span>
        <span class="cov0" title="0">err = t.WriteStatus(ss.s, statusOK)
        if ss.binlog != nil </span><span class="cov0" title="0">{
                ss.binlog.Log(&amp;binarylog.ServerTrailer{
                        Trailer: ss.s.Trailer(),
                        Err:     appErr,
                })
        }</span>
        <span class="cov0" title="0">return err</span>
}

func (s *Server) handleStream(t transport.ServerTransport, stream *transport.Stream, trInfo *traceInfo) <span class="cov0" title="0">{
        sm := stream.Method()
        if sm != "" &amp;&amp; sm[0] == '/' </span><span class="cov0" title="0">{
                sm = sm[1:]
        }</span>
        <span class="cov0" title="0">pos := strings.LastIndex(sm, "/")
        if pos == -1 </span><span class="cov0" title="0">{
                if trInfo != nil </span><span class="cov0" title="0">{
                        trInfo.tr.LazyLog(&amp;fmtStringer{"Malformed method name %q", []interface{}{sm}}, true)
                        trInfo.tr.SetError()
                }</span>
                <span class="cov0" title="0">errDesc := fmt.Sprintf("malformed method name: %q", stream.Method())
                if err := t.WriteStatus(stream, status.New(codes.Unimplemented, errDesc)); err != nil </span><span class="cov0" title="0">{
                        if trInfo != nil </span><span class="cov0" title="0">{
                                trInfo.tr.LazyLog(&amp;fmtStringer{"%v", []interface{}{err}}, true)
                                trInfo.tr.SetError()
                        }</span>
                        <span class="cov0" title="0">channelz.Warningf(logger, s.channelzID, "grpc: Server.handleStream failed to write status: %v", err)</span>
                }
                <span class="cov0" title="0">if trInfo != nil </span><span class="cov0" title="0">{
                        trInfo.tr.Finish()
                }</span>
                <span class="cov0" title="0">return</span>
        }
        <span class="cov0" title="0">service := sm[:pos]
        method := sm[pos+1:]

        srv, knownService := s.services[service]
        if knownService </span><span class="cov0" title="0">{
                if md, ok := srv.methods[method]; ok </span><span class="cov0" title="0">{
                        s.processUnaryRPC(t, stream, srv, md, trInfo)
                        return
                }</span>
                <span class="cov0" title="0">if sd, ok := srv.streams[method]; ok </span><span class="cov0" title="0">{
                        s.processStreamingRPC(t, stream, srv, sd, trInfo)
                        return
                }</span>
        }
        // Unknown service, or known server unknown method.
        <span class="cov0" title="0">if unknownDesc := s.opts.unknownStreamDesc; unknownDesc != nil </span><span class="cov0" title="0">{
                s.processStreamingRPC(t, stream, nil, unknownDesc, trInfo)
                return
        }</span>
        <span class="cov0" title="0">var errDesc string
        if !knownService </span><span class="cov0" title="0">{
                errDesc = fmt.Sprintf("unknown service %v", service)
        }</span> else<span class="cov0" title="0"> {
                errDesc = fmt.Sprintf("unknown method %v for service %v", method, service)
        }</span>
        <span class="cov0" title="0">if trInfo != nil </span><span class="cov0" title="0">{
                trInfo.tr.LazyPrintf("%s", errDesc)
                trInfo.tr.SetError()
        }</span>
        <span class="cov0" title="0">if err := t.WriteStatus(stream, status.New(codes.Unimplemented, errDesc)); err != nil </span><span class="cov0" title="0">{
                if trInfo != nil </span><span class="cov0" title="0">{
                        trInfo.tr.LazyLog(&amp;fmtStringer{"%v", []interface{}{err}}, true)
                        trInfo.tr.SetError()
                }</span>
                <span class="cov0" title="0">channelz.Warningf(logger, s.channelzID, "grpc: Server.handleStream failed to write status: %v", err)</span>
        }
        <span class="cov0" title="0">if trInfo != nil </span><span class="cov0" title="0">{
                trInfo.tr.Finish()
        }</span>
}

// The key to save ServerTransportStream in the context.
type streamKey struct{}

// NewContextWithServerTransportStream creates a new context from ctx and
// attaches stream to it.
//
// # Experimental
//
// Notice: This API is EXPERIMENTAL and may be changed or removed in a
// later release.
func NewContextWithServerTransportStream(ctx context.Context, stream ServerTransportStream) context.Context <span class="cov8" title="1">{
        return context.WithValue(ctx, streamKey{}, stream)
}</span>

// ServerTransportStream is a minimal interface that a transport stream must
// implement. This can be used to mock an actual transport stream for tests of
// handler code that use, for example, grpc.SetHeader (which requires some
// stream to be in context).
//
// See also NewContextWithServerTransportStream.
//
// # Experimental
//
// Notice: This type is EXPERIMENTAL and may be changed or removed in a
// later release.
type ServerTransportStream interface {
        Method() string
        SetHeader(md metadata.MD) error
        SendHeader(md metadata.MD) error
        SetTrailer(md metadata.MD) error
}

// ServerTransportStreamFromContext returns the ServerTransportStream saved in
// ctx. Returns nil if the given context has no stream associated with it
// (which implies it is not an RPC invocation context).
//
// # Experimental
//
// Notice: This API is EXPERIMENTAL and may be changed or removed in a
// later release.
func ServerTransportStreamFromContext(ctx context.Context) ServerTransportStream <span class="cov8" title="1">{
        s, _ := ctx.Value(streamKey{}).(ServerTransportStream)
        return s
}</span>

// Stop stops the gRPC server. It immediately closes all open
// connections and listeners.
// It cancels all active RPCs on the server side and the corresponding
// pending RPCs on the client side will get notified by connection
// errors.
func (s *Server) Stop() <span class="cov8" title="1">{
        s.quit.Fire()

        defer func() </span><span class="cov8" title="1">{
                s.serveWG.Wait()
                s.done.Fire()
        }</span>()

        <span class="cov8" title="1">s.channelzRemoveOnce.Do(func() </span><span class="cov8" title="1">{ channelz.RemoveEntry(s.channelzID) }</span>)

        <span class="cov8" title="1">s.mu.Lock()
        listeners := s.lis
        s.lis = nil
        conns := s.conns
        s.conns = nil
        // interrupt GracefulStop if Stop and GracefulStop are called concurrently.
        s.cv.Broadcast()
        s.mu.Unlock()

        for lis := range listeners </span><span class="cov0" title="0">{
                lis.Close()
        }</span>
        <span class="cov8" title="1">for _, cs := range conns </span><span class="cov0" title="0">{
                for st := range cs </span><span class="cov0" title="0">{
                        st.Close()
                }</span>
        }
        <span class="cov8" title="1">if s.opts.numServerWorkers &gt; 0 </span><span class="cov0" title="0">{
                s.stopServerWorkers()
        }</span>

        <span class="cov8" title="1">s.mu.Lock()
        if s.events != nil </span><span class="cov0" title="0">{
                s.events.Finish()
                s.events = nil
        }</span>
        <span class="cov8" title="1">s.mu.Unlock()</span>
}

// GracefulStop stops the gRPC server gracefully. It stops the server from
// accepting new connections and RPCs and blocks until all the pending RPCs are
// finished.
func (s *Server) GracefulStop() <span class="cov8" title="1">{
        s.quit.Fire()
        defer s.done.Fire()

        s.channelzRemoveOnce.Do(func() </span><span class="cov8" title="1">{ channelz.RemoveEntry(s.channelzID) }</span>)
        <span class="cov8" title="1">s.mu.Lock()
        if s.conns == nil </span><span class="cov0" title="0">{
                s.mu.Unlock()
                return
        }</span>

        <span class="cov8" title="1">for lis := range s.lis </span><span class="cov8" title="1">{
                lis.Close()
        }</span>
        <span class="cov8" title="1">s.lis = nil
        if !s.drain </span><span class="cov8" title="1">{
                for _, conns := range s.conns </span><span class="cov0" title="0">{
                        for st := range conns </span><span class="cov0" title="0">{
                                st.Drain()
                        }</span>
                }
                <span class="cov8" title="1">s.drain = true</span>
        }

        // Wait for serving threads to be ready to exit.  Only then can we be sure no
        // new conns will be created.
        <span class="cov8" title="1">s.mu.Unlock()
        s.serveWG.Wait()
        s.mu.Lock()

        for len(s.conns) != 0 </span><span class="cov0" title="0">{
                s.cv.Wait()
        }</span>
        <span class="cov8" title="1">s.conns = nil
        if s.events != nil </span><span class="cov0" title="0">{
                s.events.Finish()
                s.events = nil
        }</span>
        <span class="cov8" title="1">s.mu.Unlock()</span>
}

// contentSubtype must be lowercase
// cannot return nil
func (s *Server) getCodec(contentSubtype string) baseCodec <span class="cov0" title="0">{
        if s.opts.codec != nil </span><span class="cov0" title="0">{
                return s.opts.codec
        }</span>
        <span class="cov0" title="0">if contentSubtype == "" </span><span class="cov0" title="0">{
                return encoding.GetCodec(proto.Name)
        }</span>
        <span class="cov0" title="0">codec := encoding.GetCodec(contentSubtype)
        if codec == nil </span><span class="cov0" title="0">{
                return encoding.GetCodec(proto.Name)
        }</span>
        <span class="cov0" title="0">return codec</span>
}

// SetHeader sets the header metadata to be sent from the server to the client.
// The context provided must be the context passed to the server's handler.
//
// Streaming RPCs should prefer the SetHeader method of the ServerStream.
//
// When called multiple times, all the provided metadata will be merged.  All
// the metadata will be sent out when one of the following happens:
//
//   - grpc.SendHeader is called, or for streaming handlers, stream.SendHeader.
//   - The first response message is sent.  For unary handlers, this occurs when
//     the handler returns; for streaming handlers, this can happen when stream's
//     SendMsg method is called.
//   - An RPC status is sent out (error or success).  This occurs when the handler
//     returns.
//
// SetHeader will fail if called after any of the events above.
//
// The error returned is compatible with the status package.  However, the
// status code will often not match the RPC status as seen by the client
// application, and therefore, should not be relied upon for this purpose.
func SetHeader(ctx context.Context, md metadata.MD) error <span class="cov0" title="0">{
        if md.Len() == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">stream := ServerTransportStreamFromContext(ctx)
        if stream == nil </span><span class="cov0" title="0">{
                return status.Errorf(codes.Internal, "grpc: failed to fetch the stream from the context %v", ctx)
        }</span>
        <span class="cov0" title="0">return stream.SetHeader(md)</span>
}

// SendHeader sends header metadata. It may be called at most once, and may not
// be called after any event that causes headers to be sent (see SetHeader for
// a complete list).  The provided md and headers set by SetHeader() will be
// sent.
//
// The error returned is compatible with the status package.  However, the
// status code will often not match the RPC status as seen by the client
// application, and therefore, should not be relied upon for this purpose.
func SendHeader(ctx context.Context, md metadata.MD) error <span class="cov0" title="0">{
        stream := ServerTransportStreamFromContext(ctx)
        if stream == nil </span><span class="cov0" title="0">{
                return status.Errorf(codes.Internal, "grpc: failed to fetch the stream from the context %v", ctx)
        }</span>
        <span class="cov0" title="0">if err := stream.SendHeader(md); err != nil </span><span class="cov0" title="0">{
                return toRPCErr(err)
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// SetTrailer sets the trailer metadata that will be sent when an RPC returns.
// When called more than once, all the provided metadata will be merged.
//
// The error returned is compatible with the status package.  However, the
// status code will often not match the RPC status as seen by the client
// application, and therefore, should not be relied upon for this purpose.
func SetTrailer(ctx context.Context, md metadata.MD) error <span class="cov0" title="0">{
        if md.Len() == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">stream := ServerTransportStreamFromContext(ctx)
        if stream == nil </span><span class="cov0" title="0">{
                return status.Errorf(codes.Internal, "grpc: failed to fetch the stream from the context %v", ctx)
        }</span>
        <span class="cov0" title="0">return stream.SetTrailer(md)</span>
}

// Method returns the method string for the server context.  The returned
// string is in the format of "/service/method".
func Method(ctx context.Context) (string, bool) <span class="cov0" title="0">{
        s := ServerTransportStreamFromContext(ctx)
        if s == nil </span><span class="cov0" title="0">{
                return "", false
        }</span>
        <span class="cov0" title="0">return s.Method(), true</span>
}

type channelzServer struct {
        s *Server
}

func (c *channelzServer) ChannelzMetric() *channelz.ServerInternalMetric <span class="cov0" title="0">{
        return c.s.channelzMetric()
}</span>
</pre>
		
		<pre class="file" id="file134" style="display: none">/*
 *
 * Copyright 2017 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package grpc

import (
        "encoding/json"
        "errors"
        "fmt"
        "reflect"
        "strconv"
        "strings"
        "time"

        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/internal"
        internalserviceconfig "google.golang.org/grpc/internal/serviceconfig"
        "google.golang.org/grpc/serviceconfig"
)

const maxInt = int(^uint(0) &gt;&gt; 1)

// MethodConfig defines the configuration recommended by the service providers for a
// particular method.
//
// Deprecated: Users should not use this struct. Service config should be received
// through name resolver, as specified here
// https://github.com/grpc/grpc/blob/master/doc/service_config.md
type MethodConfig = internalserviceconfig.MethodConfig

type lbConfig struct {
        name string
        cfg  serviceconfig.LoadBalancingConfig
}

// ServiceConfig is provided by the service provider and contains parameters for how
// clients that connect to the service should behave.
//
// Deprecated: Users should not use this struct. Service config should be received
// through name resolver, as specified here
// https://github.com/grpc/grpc/blob/master/doc/service_config.md
type ServiceConfig struct {
        serviceconfig.Config

        // LB is the load balancer the service providers recommends.  This is
        // deprecated; lbConfigs is preferred.  If lbConfig and LB are both present,
        // lbConfig will be used.
        LB *string

        // lbConfig is the service config's load balancing configuration.  If
        // lbConfig and LB are both present, lbConfig will be used.
        lbConfig *lbConfig

        // Methods contains a map for the methods in this service.  If there is an
        // exact match for a method (i.e. /service/method) in the map, use the
        // corresponding MethodConfig.  If there's no exact match, look for the
        // default config for the service (/service/) and use the corresponding
        // MethodConfig if it exists.  Otherwise, the method has no MethodConfig to
        // use.
        Methods map[string]MethodConfig

        // If a retryThrottlingPolicy is provided, gRPC will automatically throttle
        // retry attempts and hedged RPCs when the client’s ratio of failures to
        // successes exceeds a threshold.
        //
        // For each server name, the gRPC client will maintain a token_count which is
        // initially set to maxTokens, and can take values between 0 and maxTokens.
        //
        // Every outgoing RPC (regardless of service or method invoked) will change
        // token_count as follows:
        //
        //   - Every failed RPC will decrement the token_count by 1.
        //   - Every successful RPC will increment the token_count by tokenRatio.
        //
        // If token_count is less than or equal to maxTokens / 2, then RPCs will not
        // be retried and hedged RPCs will not be sent.
        retryThrottling *retryThrottlingPolicy
        // healthCheckConfig must be set as one of the requirement to enable LB channel
        // health check.
        healthCheckConfig *healthCheckConfig
        // rawJSONString stores service config json string that get parsed into
        // this service config struct.
        rawJSONString string
}

// healthCheckConfig defines the go-native version of the LB channel health check config.
type healthCheckConfig struct {
        // serviceName is the service name to use in the health-checking request.
        ServiceName string
}

type jsonRetryPolicy struct {
        MaxAttempts          int
        InitialBackoff       string
        MaxBackoff           string
        BackoffMultiplier    float64
        RetryableStatusCodes []codes.Code
}

// retryThrottlingPolicy defines the go-native version of the retry throttling
// policy defined by the service config here:
// https://github.com/grpc/proposal/blob/master/A6-client-retries.md#integration-with-service-config
type retryThrottlingPolicy struct {
        // The number of tokens starts at maxTokens. The token_count will always be
        // between 0 and maxTokens.
        //
        // This field is required and must be greater than zero.
        MaxTokens float64
        // The amount of tokens to add on each successful RPC. Typically this will
        // be some number between 0 and 1, e.g., 0.1.
        //
        // This field is required and must be greater than zero. Up to 3 decimal
        // places are supported.
        TokenRatio float64
}

func parseDuration(s *string) (*time.Duration, error) <span class="cov8" title="1">{
        if s == nil </span><span class="cov8" title="1">{
                return nil, nil
        }</span>
        <span class="cov8" title="1">if !strings.HasSuffix(*s, "s") </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("malformed duration %q", *s)
        }</span>
        <span class="cov8" title="1">ss := strings.SplitN((*s)[:len(*s)-1], ".", 3)
        if len(ss) &gt; 2 </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("malformed duration %q", *s)
        }</span>
        // hasDigits is set if either the whole or fractional part of the number is
        // present, since both are optional but one is required.
        <span class="cov8" title="1">hasDigits := false
        var d time.Duration
        if len(ss[0]) &gt; 0 </span><span class="cov8" title="1">{
                i, err := strconv.ParseInt(ss[0], 10, 32)
                if err != nil </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("malformed duration %q: %v", *s, err)
                }</span>
                <span class="cov8" title="1">d = time.Duration(i) * time.Second
                hasDigits = true</span>
        }
        <span class="cov8" title="1">if len(ss) == 2 &amp;&amp; len(ss[1]) &gt; 0 </span><span class="cov8" title="1">{
                if len(ss[1]) &gt; 9 </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("malformed duration %q", *s)
                }</span>
                <span class="cov8" title="1">f, err := strconv.ParseInt(ss[1], 10, 64)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("malformed duration %q: %v", *s, err)
                }</span>
                <span class="cov8" title="1">for i := 9; i &gt; len(ss[1]); i-- </span><span class="cov8" title="1">{
                        f *= 10
                }</span>
                <span class="cov8" title="1">d += time.Duration(f)
                hasDigits = true</span>
        }
        <span class="cov8" title="1">if !hasDigits </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("malformed duration %q", *s)
        }</span>

        <span class="cov8" title="1">return &amp;d, nil</span>
}

type jsonName struct {
        Service string
        Method  string
}

var (
        errDuplicatedName             = errors.New("duplicated name")
        errEmptyServiceNonEmptyMethod = errors.New("cannot combine empty 'service' and non-empty 'method'")
)

func (j jsonName) generatePath() (string, error) <span class="cov8" title="1">{
        if j.Service == "" </span><span class="cov8" title="1">{
                if j.Method != "" </span><span class="cov8" title="1">{
                        return "", errEmptyServiceNonEmptyMethod
                }</span>
                <span class="cov8" title="1">return "", nil</span>
        }
        <span class="cov8" title="1">res := "/" + j.Service + "/"
        if j.Method != "" </span><span class="cov8" title="1">{
                res += j.Method
        }</span>
        <span class="cov8" title="1">return res, nil</span>
}

// TODO(lyuxuan): delete this struct after cleaning up old service config implementation.
type jsonMC struct {
        Name                    *[]jsonName
        WaitForReady            *bool
        Timeout                 *string
        MaxRequestMessageBytes  *int64
        MaxResponseMessageBytes *int64
        RetryPolicy             *jsonRetryPolicy
}

// TODO(lyuxuan): delete this struct after cleaning up old service config implementation.
type jsonSC struct {
        LoadBalancingPolicy *string
        LoadBalancingConfig *internalserviceconfig.BalancerConfig
        MethodConfig        *[]jsonMC
        RetryThrottling     *retryThrottlingPolicy
        HealthCheckConfig   *healthCheckConfig
}

func init() <span class="cov8" title="1">{
        internal.ParseServiceConfig = parseServiceConfig
}</span>
func parseServiceConfig(js string) *serviceconfig.ParseResult <span class="cov8" title="1">{
        if len(js) == 0 </span><span class="cov8" title="1">{
                return &amp;serviceconfig.ParseResult{Err: fmt.Errorf("no JSON service config provided")}
        }</span>
        <span class="cov8" title="1">var rsc jsonSC
        err := json.Unmarshal([]byte(js), &amp;rsc)
        if err != nil </span><span class="cov8" title="1">{
                logger.Warningf("grpc: parseServiceConfig error unmarshaling %s due to %v", js, err)
                return &amp;serviceconfig.ParseResult{Err: err}
        }</span>
        <span class="cov8" title="1">sc := ServiceConfig{
                LB:                rsc.LoadBalancingPolicy,
                Methods:           make(map[string]MethodConfig),
                retryThrottling:   rsc.RetryThrottling,
                healthCheckConfig: rsc.HealthCheckConfig,
                rawJSONString:     js,
        }
        if c := rsc.LoadBalancingConfig; c != nil </span><span class="cov8" title="1">{
                sc.lbConfig = &amp;lbConfig{
                        name: c.Name,
                        cfg:  c.Config,
                }
        }</span>

        <span class="cov8" title="1">if rsc.MethodConfig == nil </span><span class="cov8" title="1">{
                return &amp;serviceconfig.ParseResult{Config: &amp;sc}
        }</span>

        <span class="cov8" title="1">paths := map[string]struct{}{}
        for _, m := range *rsc.MethodConfig </span><span class="cov8" title="1">{
                if m.Name == nil </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov8" title="1">d, err := parseDuration(m.Timeout)
                if err != nil </span><span class="cov8" title="1">{
                        logger.Warningf("grpc: parseServiceConfig error unmarshaling %s due to %v", js, err)
                        return &amp;serviceconfig.ParseResult{Err: err}
                }</span>

                <span class="cov8" title="1">mc := MethodConfig{
                        WaitForReady: m.WaitForReady,
                        Timeout:      d,
                }
                if mc.RetryPolicy, err = convertRetryPolicy(m.RetryPolicy); err != nil </span><span class="cov0" title="0">{
                        logger.Warningf("grpc: parseServiceConfig error unmarshaling %s due to %v", js, err)
                        return &amp;serviceconfig.ParseResult{Err: err}
                }</span>
                <span class="cov8" title="1">if m.MaxRequestMessageBytes != nil </span><span class="cov8" title="1">{
                        if *m.MaxRequestMessageBytes &gt; int64(maxInt) </span><span class="cov0" title="0">{
                                mc.MaxReqSize = newInt(maxInt)
                        }</span> else<span class="cov8" title="1"> {
                                mc.MaxReqSize = newInt(int(*m.MaxRequestMessageBytes))
                        }</span>
                }
                <span class="cov8" title="1">if m.MaxResponseMessageBytes != nil </span><span class="cov8" title="1">{
                        if *m.MaxResponseMessageBytes &gt; int64(maxInt) </span><span class="cov0" title="0">{
                                mc.MaxRespSize = newInt(maxInt)
                        }</span> else<span class="cov8" title="1"> {
                                mc.MaxRespSize = newInt(int(*m.MaxResponseMessageBytes))
                        }</span>
                }
                <span class="cov8" title="1">for i, n := range *m.Name </span><span class="cov8" title="1">{
                        path, err := n.generatePath()
                        if err != nil </span><span class="cov8" title="1">{
                                logger.Warningf("grpc: parseServiceConfig error unmarshaling %s due to methodConfig[%d]: %v", js, i, err)
                                return &amp;serviceconfig.ParseResult{Err: err}
                        }</span>

                        <span class="cov8" title="1">if _, ok := paths[path]; ok </span><span class="cov8" title="1">{
                                err = errDuplicatedName
                                logger.Warningf("grpc: parseServiceConfig error unmarshaling %s due to methodConfig[%d]: %v", js, i, err)
                                return &amp;serviceconfig.ParseResult{Err: err}
                        }</span>
                        <span class="cov8" title="1">paths[path] = struct{}{}
                        sc.Methods[path] = mc</span>
                }
        }

        <span class="cov8" title="1">if sc.retryThrottling != nil </span><span class="cov0" title="0">{
                if mt := sc.retryThrottling.MaxTokens; mt &lt;= 0 || mt &gt; 1000 </span><span class="cov0" title="0">{
                        return &amp;serviceconfig.ParseResult{Err: fmt.Errorf("invalid retry throttling config: maxTokens (%v) out of range (0, 1000]", mt)}
                }</span>
                <span class="cov0" title="0">if tr := sc.retryThrottling.TokenRatio; tr &lt;= 0 </span><span class="cov0" title="0">{
                        return &amp;serviceconfig.ParseResult{Err: fmt.Errorf("invalid retry throttling config: tokenRatio (%v) may not be negative", tr)}
                }</span>
        }
        <span class="cov8" title="1">return &amp;serviceconfig.ParseResult{Config: &amp;sc}</span>
}

func convertRetryPolicy(jrp *jsonRetryPolicy) (p *internalserviceconfig.RetryPolicy, err error) <span class="cov8" title="1">{
        if jrp == nil </span><span class="cov8" title="1">{
                return nil, nil
        }</span>
        <span class="cov0" title="0">ib, err := parseDuration(&amp;jrp.InitialBackoff)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">mb, err := parseDuration(&amp;jrp.MaxBackoff)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov0" title="0">if jrp.MaxAttempts &lt;= 1 ||
                *ib &lt;= 0 ||
                *mb &lt;= 0 ||
                jrp.BackoffMultiplier &lt;= 0 ||
                len(jrp.RetryableStatusCodes) == 0 </span><span class="cov0" title="0">{
                logger.Warningf("grpc: ignoring retry policy %v due to illegal configuration", jrp)
                return nil, nil
        }</span>

        <span class="cov0" title="0">rp := &amp;internalserviceconfig.RetryPolicy{
                MaxAttempts:          jrp.MaxAttempts,
                InitialBackoff:       *ib,
                MaxBackoff:           *mb,
                BackoffMultiplier:    jrp.BackoffMultiplier,
                RetryableStatusCodes: make(map[codes.Code]bool),
        }
        if rp.MaxAttempts &gt; 5 </span><span class="cov0" title="0">{
                // TODO(retry): Make the max maxAttempts configurable.
                rp.MaxAttempts = 5
        }</span>
        <span class="cov0" title="0">for _, code := range jrp.RetryableStatusCodes </span><span class="cov0" title="0">{
                rp.RetryableStatusCodes[code] = true
        }</span>
        <span class="cov0" title="0">return rp, nil</span>
}

func min(a, b *int) *int <span class="cov0" title="0">{
        if *a &lt; *b </span><span class="cov0" title="0">{
                return a
        }</span>
        <span class="cov0" title="0">return b</span>
}

func getMaxSize(mcMax, doptMax *int, defaultVal int) *int <span class="cov0" title="0">{
        if mcMax == nil &amp;&amp; doptMax == nil </span><span class="cov0" title="0">{
                return &amp;defaultVal
        }</span>
        <span class="cov0" title="0">if mcMax != nil &amp;&amp; doptMax != nil </span><span class="cov0" title="0">{
                return min(mcMax, doptMax)
        }</span>
        <span class="cov0" title="0">if mcMax != nil </span><span class="cov0" title="0">{
                return mcMax
        }</span>
        <span class="cov0" title="0">return doptMax</span>
}

func newInt(b int) *int <span class="cov8" title="1">{
        return &amp;b
}</span>

func init() <span class="cov8" title="1">{
        internal.EqualServiceConfigForTesting = equalServiceConfig
}</span>

// equalServiceConfig compares two configs. The rawJSONString field is ignored,
// because they may diff in white spaces.
//
// If any of them is NOT *ServiceConfig, return false.
func equalServiceConfig(a, b serviceconfig.Config) bool <span class="cov0" title="0">{
        if a == nil &amp;&amp; b == nil </span><span class="cov0" title="0">{
                return true
        }</span>
        <span class="cov0" title="0">aa, ok := a.(*ServiceConfig)
        if !ok </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov0" title="0">bb, ok := b.(*ServiceConfig)
        if !ok </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov0" title="0">aaRaw := aa.rawJSONString
        aa.rawJSONString = ""
        bbRaw := bb.rawJSONString
        bb.rawJSONString = ""
        defer func() </span><span class="cov0" title="0">{
                aa.rawJSONString = aaRaw
                bb.rawJSONString = bbRaw
        }</span>()
        // Using reflect.DeepEqual instead of cmp.Equal because many balancer
        // configs are unexported, and cmp.Equal cannot compare unexported fields
        // from unexported structs.
        <span class="cov0" title="0">return reflect.DeepEqual(aa, bb)</span>
}
</pre>
		
		<pre class="file" id="file135" style="display: none">/*
 *
 * Copyright 2016 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package stats is for collecting and reporting various network and RPC stats.
// This package is for monitoring purpose only. All fields are read-only.
// All APIs are experimental.
package stats // import "google.golang.org/grpc/stats"

import (
        "context"
        "net"
        "time"

        "google.golang.org/grpc/metadata"
)

// RPCStats contains stats information about RPCs.
type RPCStats interface {
        isRPCStats()
        // IsClient returns true if this RPCStats is from client side.
        IsClient() bool
}

// Begin contains stats when an RPC attempt begins.
// FailFast is only valid if this Begin is from client side.
type Begin struct {
        // Client is true if this Begin is from client side.
        Client bool
        // BeginTime is the time when the RPC attempt begins.
        BeginTime time.Time
        // FailFast indicates if this RPC is failfast.
        FailFast bool
        // IsClientStream indicates whether the RPC is a client streaming RPC.
        IsClientStream bool
        // IsServerStream indicates whether the RPC is a server streaming RPC.
        IsServerStream bool
        // IsTransparentRetryAttempt indicates whether this attempt was initiated
        // due to transparently retrying a previous attempt.
        IsTransparentRetryAttempt bool
}

// IsClient indicates if the stats information is from client side.
func (s *Begin) IsClient() bool <span class="cov8" title="1">{ return s.Client }</span>

func (s *Begin) isRPCStats() {<span class="cov0" title="0">}</span>

// InPayload contains the information for an incoming payload.
type InPayload struct {
        // Client is true if this InPayload is from client side.
        Client bool
        // Payload is the payload with original type.
        Payload interface{}
        // Data is the serialized message payload.
        Data []byte
        // Length is the length of uncompressed data.
        Length int
        // WireLength is the length of data on wire (compressed, signed, encrypted).
        WireLength int
        // RecvTime is the time when the payload is received.
        RecvTime time.Time
}

// IsClient indicates if the stats information is from client side.
func (s *InPayload) IsClient() bool <span class="cov8" title="1">{ return s.Client }</span>

func (s *InPayload) isRPCStats() {<span class="cov0" title="0">}</span>

// InHeader contains stats when a header is received.
type InHeader struct {
        // Client is true if this InHeader is from client side.
        Client bool
        // WireLength is the wire length of header.
        WireLength int
        // Compression is the compression algorithm used for the RPC.
        Compression string
        // Header contains the header metadata received.
        Header metadata.MD

        // The following fields are valid only if Client is false.
        // FullMethod is the full RPC method string, i.e., /package.service/method.
        FullMethod string
        // RemoteAddr is the remote address of the corresponding connection.
        RemoteAddr net.Addr
        // LocalAddr is the local address of the corresponding connection.
        LocalAddr net.Addr
}

// IsClient indicates if the stats information is from client side.
func (s *InHeader) IsClient() bool <span class="cov8" title="1">{ return s.Client }</span>

func (s *InHeader) isRPCStats() {<span class="cov0" title="0">}</span>

// InTrailer contains stats when a trailer is received.
type InTrailer struct {
        // Client is true if this InTrailer is from client side.
        Client bool
        // WireLength is the wire length of trailer.
        WireLength int
        // Trailer contains the trailer metadata received from the server. This
        // field is only valid if this InTrailer is from the client side.
        Trailer metadata.MD
}

// IsClient indicates if the stats information is from client side.
func (s *InTrailer) IsClient() bool <span class="cov8" title="1">{ return s.Client }</span>

func (s *InTrailer) isRPCStats() {<span class="cov0" title="0">}</span>

// OutPayload contains the information for an outgoing payload.
type OutPayload struct {
        // Client is true if this OutPayload is from client side.
        Client bool
        // Payload is the payload with original type.
        Payload interface{}
        // Data is the serialized message payload.
        Data []byte
        // Length is the length of uncompressed data.
        Length int
        // WireLength is the length of data on wire (compressed, signed, encrypted).
        WireLength int
        // SentTime is the time when the payload is sent.
        SentTime time.Time
}

// IsClient indicates if this stats information is from client side.
func (s *OutPayload) IsClient() bool <span class="cov8" title="1">{ return s.Client }</span>

func (s *OutPayload) isRPCStats() {<span class="cov0" title="0">}</span>

// OutHeader contains stats when a header is sent.
type OutHeader struct {
        // Client is true if this OutHeader is from client side.
        Client bool
        // Compression is the compression algorithm used for the RPC.
        Compression string
        // Header contains the header metadata sent.
        Header metadata.MD

        // The following fields are valid only if Client is true.
        // FullMethod is the full RPC method string, i.e., /package.service/method.
        FullMethod string
        // RemoteAddr is the remote address of the corresponding connection.
        RemoteAddr net.Addr
        // LocalAddr is the local address of the corresponding connection.
        LocalAddr net.Addr
}

// IsClient indicates if this stats information is from client side.
func (s *OutHeader) IsClient() bool <span class="cov8" title="1">{ return s.Client }</span>

func (s *OutHeader) isRPCStats() {<span class="cov0" title="0">}</span>

// OutTrailer contains stats when a trailer is sent.
type OutTrailer struct {
        // Client is true if this OutTrailer is from client side.
        Client bool
        // WireLength is the wire length of trailer.
        //
        // Deprecated: This field is never set. The length is not known when this message is
        // emitted because the trailer fields are compressed with hpack after that.
        WireLength int
        // Trailer contains the trailer metadata sent to the client. This
        // field is only valid if this OutTrailer is from the server side.
        Trailer metadata.MD
}

// IsClient indicates if this stats information is from client side.
func (s *OutTrailer) IsClient() bool <span class="cov8" title="1">{ return s.Client }</span>

func (s *OutTrailer) isRPCStats() {<span class="cov0" title="0">}</span>

// End contains stats when an RPC ends.
type End struct {
        // Client is true if this End is from client side.
        Client bool
        // BeginTime is the time when the RPC began.
        BeginTime time.Time
        // EndTime is the time when the RPC ends.
        EndTime time.Time
        // Trailer contains the trailer metadata received from the server. This
        // field is only valid if this End is from the client side.
        // Deprecated: use Trailer in InTrailer instead.
        Trailer metadata.MD
        // Error is the error the RPC ended with. It is an error generated from
        // status.Status and can be converted back to status.Status using
        // status.FromError if non-nil.
        Error error
}

// IsClient indicates if this is from client side.
func (s *End) IsClient() bool <span class="cov8" title="1">{ return s.Client }</span>

func (s *End) isRPCStats() {<span class="cov0" title="0">}</span>

// ConnStats contains stats information about connections.
type ConnStats interface {
        isConnStats()
        // IsClient returns true if this ConnStats is from client side.
        IsClient() bool
}

// ConnBegin contains the stats of a connection when it is established.
type ConnBegin struct {
        // Client is true if this ConnBegin is from client side.
        Client bool
}

// IsClient indicates if this is from client side.
func (s *ConnBegin) IsClient() bool <span class="cov8" title="1">{ return s.Client }</span>

func (s *ConnBegin) isConnStats() {<span class="cov0" title="0">}</span>

// ConnEnd contains the stats of a connection when it ends.
type ConnEnd struct {
        // Client is true if this ConnEnd is from client side.
        Client bool
}

// IsClient indicates if this is from client side.
func (s *ConnEnd) IsClient() bool <span class="cov8" title="1">{ return s.Client }</span>

func (s *ConnEnd) isConnStats() {<span class="cov0" title="0">}</span>

type incomingTagsKey struct{}
type outgoingTagsKey struct{}

// SetTags attaches stats tagging data to the context, which will be sent in
// the outgoing RPC with the header grpc-tags-bin.  Subsequent calls to
// SetTags will overwrite the values from earlier calls.
//
// NOTE: this is provided only for backward compatibility with existing clients
// and will likely be removed in an upcoming release.  New uses should transmit
// this type of data using metadata with a different, non-reserved (i.e. does
// not begin with "grpc-") header name.
func SetTags(ctx context.Context, b []byte) context.Context <span class="cov8" title="1">{
        return context.WithValue(ctx, outgoingTagsKey{}, b)
}</span>

// Tags returns the tags from the context for the inbound RPC.
//
// NOTE: this is provided only for backward compatibility with existing clients
// and will likely be removed in an upcoming release.  New uses should transmit
// this type of data using metadata with a different, non-reserved (i.e. does
// not begin with "grpc-") header name.
func Tags(ctx context.Context) []byte <span class="cov8" title="1">{
        b, _ := ctx.Value(incomingTagsKey{}).([]byte)
        return b
}</span>

// SetIncomingTags attaches stats tagging data to the context, to be read by
// the application (not sent in outgoing RPCs).
//
// This is intended for gRPC-internal use ONLY.
func SetIncomingTags(ctx context.Context, b []byte) context.Context <span class="cov8" title="1">{
        return context.WithValue(ctx, incomingTagsKey{}, b)
}</span>

// OutgoingTags returns the tags from the context for the outbound RPC.
//
// This is intended for gRPC-internal use ONLY.
func OutgoingTags(ctx context.Context) []byte <span class="cov8" title="1">{
        b, _ := ctx.Value(outgoingTagsKey{}).([]byte)
        return b
}</span>

type incomingTraceKey struct{}
type outgoingTraceKey struct{}

// SetTrace attaches stats tagging data to the context, which will be sent in
// the outgoing RPC with the header grpc-trace-bin.  Subsequent calls to
// SetTrace will overwrite the values from earlier calls.
//
// NOTE: this is provided only for backward compatibility with existing clients
// and will likely be removed in an upcoming release.  New uses should transmit
// this type of data using metadata with a different, non-reserved (i.e. does
// not begin with "grpc-") header name.
func SetTrace(ctx context.Context, b []byte) context.Context <span class="cov8" title="1">{
        return context.WithValue(ctx, outgoingTraceKey{}, b)
}</span>

// Trace returns the trace from the context for the inbound RPC.
//
// NOTE: this is provided only for backward compatibility with existing clients
// and will likely be removed in an upcoming release.  New uses should transmit
// this type of data using metadata with a different, non-reserved (i.e. does
// not begin with "grpc-") header name.
func Trace(ctx context.Context) []byte <span class="cov8" title="1">{
        b, _ := ctx.Value(incomingTraceKey{}).([]byte)
        return b
}</span>

// SetIncomingTrace attaches stats tagging data to the context, to be read by
// the application (not sent in outgoing RPCs).  It is intended for
// gRPC-internal use.
func SetIncomingTrace(ctx context.Context, b []byte) context.Context <span class="cov8" title="1">{
        return context.WithValue(ctx, incomingTraceKey{}, b)
}</span>

// OutgoingTrace returns the trace from the context for the outbound RPC.  It is
// intended for gRPC-internal use.
func OutgoingTrace(ctx context.Context) []byte <span class="cov8" title="1">{
        b, _ := ctx.Value(outgoingTraceKey{}).([]byte)
        return b
}</span>
</pre>
		
		<pre class="file" id="file136" style="display: none">/*
 *
 * Copyright 2017 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package status implements errors returned by gRPC.  These errors are
// serialized and transmitted on the wire between server and client, and allow
// for additional data to be transmitted via the Details field in the status
// proto.  gRPC service handlers should return an error created by this
// package, and gRPC clients should expect a corresponding error to be
// returned from the RPC call.
//
// This package upholds the invariants that a non-nil error may not
// contain an OK code, and an OK code must result in a nil error.
package status

import (
        "context"
        "errors"
        "fmt"

        spb "google.golang.org/genproto/googleapis/rpc/status"

        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/internal/status"
)

// Status references google.golang.org/grpc/internal/status. It represents an
// RPC status code, message, and details.  It is immutable and should be
// created with New, Newf, or FromProto.
// https://godoc.org/google.golang.org/grpc/internal/status
type Status = status.Status

// New returns a Status representing c and msg.
func New(c codes.Code, msg string) *Status <span class="cov8" title="1">{
        return status.New(c, msg)
}</span>

// Newf returns New(c, fmt.Sprintf(format, a...)).
func Newf(c codes.Code, format string, a ...interface{}) *Status <span class="cov0" title="0">{
        return New(c, fmt.Sprintf(format, a...))
}</span>

// Error returns an error representing c and msg.  If c is OK, returns nil.
func Error(c codes.Code, msg string) error <span class="cov8" title="1">{
        return New(c, msg).Err()
}</span>

// Errorf returns Error(c, fmt.Sprintf(format, a...)).
func Errorf(c codes.Code, format string, a ...interface{}) error <span class="cov8" title="1">{
        return Error(c, fmt.Sprintf(format, a...))
}</span>

// ErrorProto returns an error representing s.  If s.Code is OK, returns nil.
func ErrorProto(s *spb.Status) error <span class="cov8" title="1">{
        return FromProto(s).Err()
}</span>

// FromProto returns a Status representing s.
func FromProto(s *spb.Status) *Status <span class="cov8" title="1">{
        return status.FromProto(s)
}</span>

// FromError returns a Status representation of err.
//
// - If err was produced by this package or implements the method `GRPCStatus()
//   *Status`, the appropriate Status is returned.
//
// - If err is nil, a Status is returned with codes.OK and no message.
//
// - Otherwise, err is an error not compatible with this package.  In this
//   case, a Status is returned with codes.Unknown and err's Error() message,
//   and ok is false.
func FromError(err error) (s *Status, ok bool) <span class="cov8" title="1">{
        if err == nil </span><span class="cov8" title="1">{
                return nil, true
        }</span>
        <span class="cov8" title="1">if se, ok := err.(interface {
                GRPCStatus() *Status
        }); ok </span><span class="cov8" title="1">{
                return se.GRPCStatus(), true
        }</span>
        <span class="cov8" title="1">return New(codes.Unknown, err.Error()), false</span>
}

// Convert is a convenience function which removes the need to handle the
// boolean return value from FromError.
func Convert(err error) *Status <span class="cov8" title="1">{
        s, _ := FromError(err)
        return s
}</span>

// Code returns the Code of the error if it is a Status error, codes.OK if err
// is nil, or codes.Unknown otherwise.
func Code(err error) codes.Code <span class="cov0" title="0">{
        // Don't use FromError to avoid allocation of OK status.
        if err == nil </span><span class="cov0" title="0">{
                return codes.OK
        }</span>
        <span class="cov0" title="0">if se, ok := err.(interface {
                GRPCStatus() *Status
        }); ok </span><span class="cov0" title="0">{
                return se.GRPCStatus().Code()
        }</span>
        <span class="cov0" title="0">return codes.Unknown</span>
}

// FromContextError converts a context error or wrapped context error into a
// Status.  It returns a Status with codes.OK if err is nil, or a Status with
// codes.Unknown if err is non-nil and not a context error.
func FromContextError(err error) *Status <span class="cov8" title="1">{
        if err == nil </span><span class="cov8" title="1">{
                return nil
        }</span>
        <span class="cov8" title="1">if errors.Is(err, context.DeadlineExceeded) </span><span class="cov8" title="1">{
                return New(codes.DeadlineExceeded, err.Error())
        }</span>
        <span class="cov8" title="1">if errors.Is(err, context.Canceled) </span><span class="cov8" title="1">{
                return New(codes.Canceled, err.Error())
        }</span>
        <span class="cov8" title="1">return New(codes.Unknown, err.Error())</span>
}
</pre>
		
		<pre class="file" id="file137" style="display: none">/*
 *
 * Copyright 2014 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package grpc

import (
        "context"
        "errors"
        "io"
        "math"
        "strconv"
        "sync"
        "time"

        "golang.org/x/net/trace"
        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/encoding"
        "google.golang.org/grpc/internal/balancerload"
        "google.golang.org/grpc/internal/binarylog"
        "google.golang.org/grpc/internal/channelz"
        "google.golang.org/grpc/internal/grpcrand"
        "google.golang.org/grpc/internal/grpcutil"
        imetadata "google.golang.org/grpc/internal/metadata"
        iresolver "google.golang.org/grpc/internal/resolver"
        "google.golang.org/grpc/internal/serviceconfig"
        "google.golang.org/grpc/internal/transport"
        "google.golang.org/grpc/metadata"
        "google.golang.org/grpc/peer"
        "google.golang.org/grpc/stats"
        "google.golang.org/grpc/status"
)

// StreamHandler defines the handler called by gRPC server to complete the
// execution of a streaming RPC.
//
// If a StreamHandler returns an error, it should either be produced by the
// status package, or be one of the context errors. Otherwise, gRPC will use
// codes.Unknown as the status code and err.Error() as the status message of the
// RPC.
type StreamHandler func(srv interface{}, stream ServerStream) error

// StreamDesc represents a streaming RPC service's method specification.  Used
// on the server when registering services and on the client when initiating
// new streams.
type StreamDesc struct {
        // StreamName and Handler are only used when registering handlers on a
        // server.
        StreamName string        // the name of the method excluding the service
        Handler    StreamHandler // the handler called for the method

        // ServerStreams and ClientStreams are used for registering handlers on a
        // server as well as defining RPC behavior when passed to NewClientStream
        // and ClientConn.NewStream.  At least one must be true.
        ServerStreams bool // indicates the server can perform streaming sends
        ClientStreams bool // indicates the client can perform streaming sends
}

// Stream defines the common interface a client or server stream has to satisfy.
//
// Deprecated: See ClientStream and ServerStream documentation instead.
type Stream interface {
        // Deprecated: See ClientStream and ServerStream documentation instead.
        Context() context.Context
        // Deprecated: See ClientStream and ServerStream documentation instead.
        SendMsg(m interface{}) error
        // Deprecated: See ClientStream and ServerStream documentation instead.
        RecvMsg(m interface{}) error
}

// ClientStream defines the client-side behavior of a streaming RPC.
//
// All errors returned from ClientStream methods are compatible with the
// status package.
type ClientStream interface {
        // Header returns the header metadata received from the server if there
        // is any. It blocks if the metadata is not ready to read.
        Header() (metadata.MD, error)
        // Trailer returns the trailer metadata from the server, if there is any.
        // It must only be called after stream.CloseAndRecv has returned, or
        // stream.Recv has returned a non-nil error (including io.EOF).
        Trailer() metadata.MD
        // CloseSend closes the send direction of the stream. It closes the stream
        // when non-nil error is met. It is also not safe to call CloseSend
        // concurrently with SendMsg.
        CloseSend() error
        // Context returns the context for this stream.
        //
        // It should not be called until after Header or RecvMsg has returned. Once
        // called, subsequent client-side retries are disabled.
        Context() context.Context
        // SendMsg is generally called by generated code. On error, SendMsg aborts
        // the stream. If the error was generated by the client, the status is
        // returned directly; otherwise, io.EOF is returned and the status of
        // the stream may be discovered using RecvMsg.
        //
        // SendMsg blocks until:
        //   - There is sufficient flow control to schedule m with the transport, or
        //   - The stream is done, or
        //   - The stream breaks.
        //
        // SendMsg does not wait until the message is received by the server. An
        // untimely stream closure may result in lost messages. To ensure delivery,
        // users should ensure the RPC completed successfully using RecvMsg.
        //
        // It is safe to have a goroutine calling SendMsg and another goroutine
        // calling RecvMsg on the same stream at the same time, but it is not safe
        // to call SendMsg on the same stream in different goroutines. It is also
        // not safe to call CloseSend concurrently with SendMsg.
        SendMsg(m interface{}) error
        // RecvMsg blocks until it receives a message into m or the stream is
        // done. It returns io.EOF when the stream completes successfully. On
        // any other error, the stream is aborted and the error contains the RPC
        // status.
        //
        // It is safe to have a goroutine calling SendMsg and another goroutine
        // calling RecvMsg on the same stream at the same time, but it is not
        // safe to call RecvMsg on the same stream in different goroutines.
        RecvMsg(m interface{}) error
}

// NewStream creates a new Stream for the client side. This is typically
// called by generated code. ctx is used for the lifetime of the stream.
//
// To ensure resources are not leaked due to the stream returned, one of the following
// actions must be performed:
//
//  1. Call Close on the ClientConn.
//  2. Cancel the context provided.
//  3. Call RecvMsg until a non-nil error is returned. A protobuf-generated
//     client-streaming RPC, for instance, might use the helper function
//     CloseAndRecv (note that CloseSend does not Recv, therefore is not
//     guaranteed to release all resources).
//  4. Receive a non-nil, non-io.EOF error from Header or SendMsg.
//
// If none of the above happen, a goroutine and a context will be leaked, and grpc
// will not call the optionally-configured stats handler with a stats.End message.
func (cc *ClientConn) NewStream(ctx context.Context, desc *StreamDesc, method string, opts ...CallOption) (ClientStream, error) <span class="cov0" title="0">{
        // allow interceptor to see all applicable call options, which means those
        // configured as defaults from dial option as well as per-call options
        opts = combine(cc.dopts.callOptions, opts)

        if cc.dopts.streamInt != nil </span><span class="cov0" title="0">{
                return cc.dopts.streamInt(ctx, desc, cc, method, newClientStream, opts...)
        }</span>
        <span class="cov0" title="0">return newClientStream(ctx, desc, cc, method, opts...)</span>
}

// NewClientStream is a wrapper for ClientConn.NewStream.
func NewClientStream(ctx context.Context, desc *StreamDesc, cc *ClientConn, method string, opts ...CallOption) (ClientStream, error) <span class="cov0" title="0">{
        return cc.NewStream(ctx, desc, method, opts...)
}</span>

func newClientStream(ctx context.Context, desc *StreamDesc, cc *ClientConn, method string, opts ...CallOption) (_ ClientStream, err error) <span class="cov0" title="0">{
        if md, _, ok := metadata.FromOutgoingContextRaw(ctx); ok </span><span class="cov0" title="0">{
                if err := imetadata.Validate(md); err != nil </span><span class="cov0" title="0">{
                        return nil, status.Error(codes.Internal, err.Error())
                }</span>
        }
        <span class="cov0" title="0">if channelz.IsOn() </span><span class="cov0" title="0">{
                cc.incrCallsStarted()
                defer func() </span><span class="cov0" title="0">{
                        if err != nil </span><span class="cov0" title="0">{
                                cc.incrCallsFailed()
                        }</span>
                }()
        }
        // Provide an opportunity for the first RPC to see the first service config
        // provided by the resolver.
        <span class="cov0" title="0">if err := cc.waitForResolvedAddrs(ctx); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov0" title="0">var mc serviceconfig.MethodConfig
        var onCommit func()
        var newStream = func(ctx context.Context, done func()) (iresolver.ClientStream, error) </span><span class="cov0" title="0">{
                return newClientStreamWithParams(ctx, desc, cc, method, mc, onCommit, done, opts...)
        }</span>

        <span class="cov0" title="0">rpcInfo := iresolver.RPCInfo{Context: ctx, Method: method}
        rpcConfig, err := cc.safeConfigSelector.SelectConfig(rpcInfo)
        if err != nil </span><span class="cov0" title="0">{
                return nil, toRPCErr(err)
        }</span>

        <span class="cov0" title="0">if rpcConfig != nil </span><span class="cov0" title="0">{
                if rpcConfig.Context != nil </span><span class="cov0" title="0">{
                        ctx = rpcConfig.Context
                }</span>
                <span class="cov0" title="0">mc = rpcConfig.MethodConfig
                onCommit = rpcConfig.OnCommitted
                if rpcConfig.Interceptor != nil </span><span class="cov0" title="0">{
                        rpcInfo.Context = nil
                        ns := newStream
                        newStream = func(ctx context.Context, done func()) (iresolver.ClientStream, error) </span><span class="cov0" title="0">{
                                cs, err := rpcConfig.Interceptor.NewStream(ctx, rpcInfo, done, ns)
                                if err != nil </span><span class="cov0" title="0">{
                                        return nil, toRPCErr(err)
                                }</span>
                                <span class="cov0" title="0">return cs, nil</span>
                        }
                }
        }

        <span class="cov0" title="0">return newStream(ctx, func() </span>{<span class="cov0" title="0">}</span>)
}

func newClientStreamWithParams(ctx context.Context, desc *StreamDesc, cc *ClientConn, method string, mc serviceconfig.MethodConfig, onCommit, doneFunc func(), opts ...CallOption) (_ iresolver.ClientStream, err error) <span class="cov0" title="0">{
        c := defaultCallInfo()
        if mc.WaitForReady != nil </span><span class="cov0" title="0">{
                c.failFast = !*mc.WaitForReady
        }</span>

        // Possible context leak:
        // The cancel function for the child context we create will only be called
        // when RecvMsg returns a non-nil error, if the ClientConn is closed, or if
        // an error is generated by SendMsg.
        // https://github.com/grpc/grpc-go/issues/1818.
        <span class="cov0" title="0">var cancel context.CancelFunc
        if mc.Timeout != nil &amp;&amp; *mc.Timeout &gt;= 0 </span><span class="cov0" title="0">{
                ctx, cancel = context.WithTimeout(ctx, *mc.Timeout)
        }</span> else<span class="cov0" title="0"> {
                ctx, cancel = context.WithCancel(ctx)
        }</span>
        <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                if err != nil </span><span class="cov0" title="0">{
                        cancel()
                }</span>
        }()

        <span class="cov0" title="0">for _, o := range opts </span><span class="cov0" title="0">{
                if err := o.before(c); err != nil </span><span class="cov0" title="0">{
                        return nil, toRPCErr(err)
                }</span>
        }
        <span class="cov0" title="0">c.maxSendMessageSize = getMaxSize(mc.MaxReqSize, c.maxSendMessageSize, defaultClientMaxSendMessageSize)
        c.maxReceiveMessageSize = getMaxSize(mc.MaxRespSize, c.maxReceiveMessageSize, defaultClientMaxReceiveMessageSize)
        if err := setCallInfoCodec(c); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov0" title="0">callHdr := &amp;transport.CallHdr{
                Host:           cc.authority,
                Method:         method,
                ContentSubtype: c.contentSubtype,
                DoneFunc:       doneFunc,
        }

        // Set our outgoing compression according to the UseCompressor CallOption, if
        // set.  In that case, also find the compressor from the encoding package.
        // Otherwise, use the compressor configured by the WithCompressor DialOption,
        // if set.
        var cp Compressor
        var comp encoding.Compressor
        if ct := c.compressorType; ct != "" </span><span class="cov0" title="0">{
                callHdr.SendCompress = ct
                if ct != encoding.Identity </span><span class="cov0" title="0">{
                        comp = encoding.GetCompressor(ct)
                        if comp == nil </span><span class="cov0" title="0">{
                                return nil, status.Errorf(codes.Internal, "grpc: Compressor is not installed for requested grpc-encoding %q", ct)
                        }</span>
                }
        } else<span class="cov0" title="0"> if cc.dopts.cp != nil </span><span class="cov0" title="0">{
                callHdr.SendCompress = cc.dopts.cp.Type()
                cp = cc.dopts.cp
        }</span>
        <span class="cov0" title="0">if c.creds != nil </span><span class="cov0" title="0">{
                callHdr.Creds = c.creds
        }</span>

        <span class="cov0" title="0">cs := &amp;clientStream{
                callHdr:      callHdr,
                ctx:          ctx,
                methodConfig: &amp;mc,
                opts:         opts,
                callInfo:     c,
                cc:           cc,
                desc:         desc,
                codec:        c.codec,
                cp:           cp,
                comp:         comp,
                cancel:       cancel,
                firstAttempt: true,
                onCommit:     onCommit,
        }
        if !cc.dopts.disableRetry </span><span class="cov0" title="0">{
                cs.retryThrottler = cc.retryThrottler.Load().(*retryThrottler)
        }</span>
        <span class="cov0" title="0">cs.binlog = binarylog.GetMethodLogger(method)

        // Pick the transport to use and create a new stream on the transport.
        // Assign cs.attempt upon success.
        op := func(a *csAttempt) error </span><span class="cov0" title="0">{
                if err := a.getTransport(); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov0" title="0">if err := a.newStream(); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                // Because this operation is always called either here (while creating
                // the clientStream) or by the retry code while locked when replaying
                // the operation, it is safe to access cs.attempt directly.
                <span class="cov0" title="0">cs.attempt = a
                return nil</span>
        }
        <span class="cov0" title="0">if err := cs.withRetry(op, func() </span><span class="cov0" title="0">{ cs.bufferForRetryLocked(0, op) }</span>); err != nil <span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov0" title="0">if cs.binlog != nil </span><span class="cov0" title="0">{
                md, _ := metadata.FromOutgoingContext(ctx)
                logEntry := &amp;binarylog.ClientHeader{
                        OnClientSide: true,
                        Header:       md,
                        MethodName:   method,
                        Authority:    cs.cc.authority,
                }
                if deadline, ok := ctx.Deadline(); ok </span><span class="cov0" title="0">{
                        logEntry.Timeout = time.Until(deadline)
                        if logEntry.Timeout &lt; 0 </span><span class="cov0" title="0">{
                                logEntry.Timeout = 0
                        }</span>
                }
                <span class="cov0" title="0">cs.binlog.Log(logEntry)</span>
        }

        <span class="cov0" title="0">if desc != unaryStreamDesc </span><span class="cov0" title="0">{
                // Listen on cc and stream contexts to cleanup when the user closes the
                // ClientConn or cancels the stream context.  In all other cases, an error
                // should already be injected into the recv buffer by the transport, which
                // the client will eventually receive, and then we will cancel the stream's
                // context in clientStream.finish.
                go func() </span><span class="cov0" title="0">{
                        select </span>{
                        case &lt;-cc.ctx.Done():<span class="cov0" title="0">
                                cs.finish(ErrClientConnClosing)</span>
                        case &lt;-ctx.Done():<span class="cov0" title="0">
                                cs.finish(toRPCErr(ctx.Err()))</span>
                        }
                }()
        }
        <span class="cov0" title="0">return cs, nil</span>
}

// newAttemptLocked creates a new csAttempt without a transport or stream.
func (cs *clientStream) newAttemptLocked(isTransparent bool) (*csAttempt, error) <span class="cov0" title="0">{
        if err := cs.ctx.Err(); err != nil </span><span class="cov0" title="0">{
                return nil, toRPCErr(err)
        }</span>
        <span class="cov0" title="0">if err := cs.cc.ctx.Err(); err != nil </span><span class="cov0" title="0">{
                return nil, ErrClientConnClosing
        }</span>

        <span class="cov0" title="0">ctx := newContextWithRPCInfo(cs.ctx, cs.callInfo.failFast, cs.callInfo.codec, cs.cp, cs.comp)
        method := cs.callHdr.Method
        var beginTime time.Time
        shs := cs.cc.dopts.copts.StatsHandlers
        for _, sh := range shs </span><span class="cov0" title="0">{
                ctx = sh.TagRPC(ctx, &amp;stats.RPCTagInfo{FullMethodName: method, FailFast: cs.callInfo.failFast})
                beginTime = time.Now()
                begin := &amp;stats.Begin{
                        Client:                    true,
                        BeginTime:                 beginTime,
                        FailFast:                  cs.callInfo.failFast,
                        IsClientStream:            cs.desc.ClientStreams,
                        IsServerStream:            cs.desc.ServerStreams,
                        IsTransparentRetryAttempt: isTransparent,
                }
                sh.HandleRPC(ctx, begin)
        }</span>

        <span class="cov0" title="0">var trInfo *traceInfo
        if EnableTracing </span><span class="cov0" title="0">{
                trInfo = &amp;traceInfo{
                        tr: trace.New("grpc.Sent."+methodFamily(method), method),
                        firstLine: firstLine{
                                client: true,
                        },
                }
                if deadline, ok := ctx.Deadline(); ok </span><span class="cov0" title="0">{
                        trInfo.firstLine.deadline = time.Until(deadline)
                }</span>
                <span class="cov0" title="0">trInfo.tr.LazyLog(&amp;trInfo.firstLine, false)
                ctx = trace.NewContext(ctx, trInfo.tr)</span>
        }

        <span class="cov0" title="0">if cs.cc.parsedTarget.Scheme == "xds" </span><span class="cov0" title="0">{
                // Add extra metadata (metadata that will be added by transport) to context
                // so the balancer can see them.
                ctx = grpcutil.WithExtraMetadata(ctx, metadata.Pairs(
                        "content-type", grpcutil.ContentType(cs.callHdr.ContentSubtype),
                ))
        }</span>

        <span class="cov0" title="0">return &amp;csAttempt{
                ctx:           ctx,
                beginTime:     beginTime,
                cs:            cs,
                dc:            cs.cc.dopts.dc,
                statsHandlers: shs,
                trInfo:        trInfo,
        }, nil</span>
}

func (a *csAttempt) getTransport() error <span class="cov0" title="0">{
        cs := a.cs

        var err error
        a.t, a.done, err = cs.cc.getTransport(a.ctx, cs.callInfo.failFast, cs.callHdr.Method)
        if err != nil </span><span class="cov0" title="0">{
                if de, ok := err.(dropError); ok </span><span class="cov0" title="0">{
                        err = de.error
                        a.drop = true
                }</span>
                <span class="cov0" title="0">return err</span>
        }
        <span class="cov0" title="0">if a.trInfo != nil </span><span class="cov0" title="0">{
                a.trInfo.firstLine.SetRemoteAddr(a.t.RemoteAddr())
        }</span>
        <span class="cov0" title="0">return nil</span>
}

func (a *csAttempt) newStream() error <span class="cov0" title="0">{
        cs := a.cs
        cs.callHdr.PreviousAttempts = cs.numRetries
        s, err := a.t.NewStream(a.ctx, cs.callHdr)
        if err != nil </span><span class="cov0" title="0">{
                nse, ok := err.(*transport.NewStreamError)
                if !ok </span><span class="cov0" title="0">{
                        // Unexpected.
                        return err
                }</span>

                <span class="cov0" title="0">if nse.AllowTransparentRetry </span><span class="cov0" title="0">{
                        a.allowTransparentRetry = true
                }</span>

                // Unwrap and convert error.
                <span class="cov0" title="0">return toRPCErr(nse.Err)</span>
        }
        <span class="cov0" title="0">a.s = s
        a.p = &amp;parser{r: s}
        return nil</span>
}

// clientStream implements a client side Stream.
type clientStream struct {
        callHdr  *transport.CallHdr
        opts     []CallOption
        callInfo *callInfo
        cc       *ClientConn
        desc     *StreamDesc

        codec baseCodec
        cp    Compressor
        comp  encoding.Compressor

        cancel context.CancelFunc // cancels all attempts

        sentLast bool // sent an end stream

        methodConfig *MethodConfig

        ctx context.Context // the application's context, wrapped by stats/tracing

        retryThrottler *retryThrottler // The throttler active when the RPC began.

        binlog binarylog.MethodLogger // Binary logger, can be nil.
        // serverHeaderBinlogged is a boolean for whether server header has been
        // logged. Server header will be logged when the first time one of those
        // happens: stream.Header(), stream.Recv().
        //
        // It's only read and used by Recv() and Header(), so it doesn't need to be
        // synchronized.
        serverHeaderBinlogged bool

        mu                      sync.Mutex
        firstAttempt            bool // if true, transparent retry is valid
        numRetries              int  // exclusive of transparent retry attempt(s)
        numRetriesSincePushback int  // retries since pushback; to reset backoff
        finished                bool // TODO: replace with atomic cmpxchg or sync.Once?
        // attempt is the active client stream attempt.
        // The only place where it is written is the newAttemptLocked method and this method never writes nil.
        // So, attempt can be nil only inside newClientStream function when clientStream is first created.
        // One of the first things done after clientStream's creation, is to call newAttemptLocked which either
        // assigns a non nil value to the attempt or returns an error. If an error is returned from newAttemptLocked,
        // then newClientStream calls finish on the clientStream and returns. So, finish method is the only
        // place where we need to check if the attempt is nil.
        attempt *csAttempt
        // TODO(hedging): hedging will have multiple attempts simultaneously.
        committed  bool // active attempt committed for retry?
        onCommit   func()
        buffer     []func(a *csAttempt) error // operations to replay on retry
        bufferSize int                        // current size of buffer
}

// csAttempt implements a single transport stream attempt within a
// clientStream.
type csAttempt struct {
        ctx  context.Context
        cs   *clientStream
        t    transport.ClientTransport
        s    *transport.Stream
        p    *parser
        done func(balancer.DoneInfo)

        finished  bool
        dc        Decompressor
        decomp    encoding.Compressor
        decompSet bool

        mu sync.Mutex // guards trInfo.tr
        // trInfo may be nil (if EnableTracing is false).
        // trInfo.tr is set when created (if EnableTracing is true),
        // and cleared when the finish method is called.
        trInfo *traceInfo

        statsHandlers []stats.Handler
        beginTime     time.Time

        // set for newStream errors that may be transparently retried
        allowTransparentRetry bool
        // set for pick errors that are returned as a status
        drop bool
}

func (cs *clientStream) commitAttemptLocked() <span class="cov0" title="0">{
        if !cs.committed &amp;&amp; cs.onCommit != nil </span><span class="cov0" title="0">{
                cs.onCommit()
        }</span>
        <span class="cov0" title="0">cs.committed = true
        cs.buffer = nil</span>
}

func (cs *clientStream) commitAttempt() <span class="cov0" title="0">{
        cs.mu.Lock()
        cs.commitAttemptLocked()
        cs.mu.Unlock()
}</span>

// shouldRetry returns nil if the RPC should be retried; otherwise it returns
// the error that should be returned by the operation.  If the RPC should be
// retried, the bool indicates whether it is being retried transparently.
func (a *csAttempt) shouldRetry(err error) (bool, error) <span class="cov0" title="0">{
        cs := a.cs

        if cs.finished || cs.committed || a.drop </span><span class="cov0" title="0">{
                // RPC is finished or committed or was dropped by the picker; cannot retry.
                return false, err
        }</span>
        <span class="cov0" title="0">if a.s == nil &amp;&amp; a.allowTransparentRetry </span><span class="cov0" title="0">{
                return true, nil
        }</span>
        // Wait for the trailers.
        <span class="cov0" title="0">unprocessed := false
        if a.s != nil </span><span class="cov0" title="0">{
                &lt;-a.s.Done()
                unprocessed = a.s.Unprocessed()
        }</span>
        <span class="cov0" title="0">if cs.firstAttempt &amp;&amp; unprocessed </span><span class="cov0" title="0">{
                // First attempt, stream unprocessed: transparently retry.
                return true, nil
        }</span>
        <span class="cov0" title="0">if cs.cc.dopts.disableRetry </span><span class="cov0" title="0">{
                return false, err
        }</span>

        <span class="cov0" title="0">pushback := 0
        hasPushback := false
        if a.s != nil </span><span class="cov0" title="0">{
                if !a.s.TrailersOnly() </span><span class="cov0" title="0">{
                        return false, err
                }</span>

                // TODO(retry): Move down if the spec changes to not check server pushback
                // before considering this a failure for throttling.
                <span class="cov0" title="0">sps := a.s.Trailer()["grpc-retry-pushback-ms"]
                if len(sps) == 1 </span><span class="cov0" title="0">{
                        var e error
                        if pushback, e = strconv.Atoi(sps[0]); e != nil || pushback &lt; 0 </span><span class="cov0" title="0">{
                                channelz.Infof(logger, cs.cc.channelzID, "Server retry pushback specified to abort (%q).", sps[0])
                                cs.retryThrottler.throttle() // This counts as a failure for throttling.
                                return false, err
                        }</span>
                        <span class="cov0" title="0">hasPushback = true</span>
                } else<span class="cov0" title="0"> if len(sps) &gt; 1 </span><span class="cov0" title="0">{
                        channelz.Warningf(logger, cs.cc.channelzID, "Server retry pushback specified multiple values (%q); not retrying.", sps)
                        cs.retryThrottler.throttle() // This counts as a failure for throttling.
                        return false, err
                }</span>
        }

        <span class="cov0" title="0">var code codes.Code
        if a.s != nil </span><span class="cov0" title="0">{
                code = a.s.Status().Code()
        }</span> else<span class="cov0" title="0"> {
                code = status.Code(err)
        }</span>

        <span class="cov0" title="0">rp := cs.methodConfig.RetryPolicy
        if rp == nil || !rp.RetryableStatusCodes[code] </span><span class="cov0" title="0">{
                return false, err
        }</span>

        // Note: the ordering here is important; we count this as a failure
        // only if the code matched a retryable code.
        <span class="cov0" title="0">if cs.retryThrottler.throttle() </span><span class="cov0" title="0">{
                return false, err
        }</span>
        <span class="cov0" title="0">if cs.numRetries+1 &gt;= rp.MaxAttempts </span><span class="cov0" title="0">{
                return false, err
        }</span>

        <span class="cov0" title="0">var dur time.Duration
        if hasPushback </span><span class="cov0" title="0">{
                dur = time.Millisecond * time.Duration(pushback)
                cs.numRetriesSincePushback = 0
        }</span> else<span class="cov0" title="0"> {
                fact := math.Pow(rp.BackoffMultiplier, float64(cs.numRetriesSincePushback))
                cur := float64(rp.InitialBackoff) * fact
                if max := float64(rp.MaxBackoff); cur &gt; max </span><span class="cov0" title="0">{
                        cur = max
                }</span>
                <span class="cov0" title="0">dur = time.Duration(grpcrand.Int63n(int64(cur)))
                cs.numRetriesSincePushback++</span>
        }

        // TODO(dfawley): we could eagerly fail here if dur puts us past the
        // deadline, but unsure if it is worth doing.
        <span class="cov0" title="0">t := time.NewTimer(dur)
        select </span>{
        case &lt;-t.C:<span class="cov0" title="0">
                cs.numRetries++
                return false, nil</span>
        case &lt;-cs.ctx.Done():<span class="cov0" title="0">
                t.Stop()
                return false, status.FromContextError(cs.ctx.Err()).Err()</span>
        }
}

// Returns nil if a retry was performed and succeeded; error otherwise.
func (cs *clientStream) retryLocked(attempt *csAttempt, lastErr error) error <span class="cov0" title="0">{
        for </span><span class="cov0" title="0">{
                attempt.finish(toRPCErr(lastErr))
                isTransparent, err := attempt.shouldRetry(lastErr)
                if err != nil </span><span class="cov0" title="0">{
                        cs.commitAttemptLocked()
                        return err
                }</span>
                <span class="cov0" title="0">cs.firstAttempt = false
                attempt, err = cs.newAttemptLocked(isTransparent)
                if err != nil </span><span class="cov0" title="0">{
                        // Only returns error if the clientconn is closed or the context of
                        // the stream is canceled.
                        return err
                }</span>
                // Note that the first op in the replay buffer always sets cs.attempt
                // if it is able to pick a transport and create a stream.
                <span class="cov0" title="0">if lastErr = cs.replayBufferLocked(attempt); lastErr == nil </span><span class="cov0" title="0">{
                        return nil
                }</span>
        }
}

func (cs *clientStream) Context() context.Context <span class="cov0" title="0">{
        cs.commitAttempt()
        // No need to lock before using attempt, since we know it is committed and
        // cannot change.
        if cs.attempt.s != nil </span><span class="cov0" title="0">{
                return cs.attempt.s.Context()
        }</span>
        <span class="cov0" title="0">return cs.ctx</span>
}

func (cs *clientStream) withRetry(op func(a *csAttempt) error, onSuccess func()) error <span class="cov0" title="0">{
        cs.mu.Lock()
        for </span><span class="cov0" title="0">{
                if cs.committed </span><span class="cov0" title="0">{
                        cs.mu.Unlock()
                        // toRPCErr is used in case the error from the attempt comes from
                        // NewClientStream, which intentionally doesn't return a status
                        // error to allow for further inspection; all other errors should
                        // already be status errors.
                        return toRPCErr(op(cs.attempt))
                }</span>
                <span class="cov0" title="0">if len(cs.buffer) == 0 </span><span class="cov0" title="0">{
                        // For the first op, which controls creation of the stream and
                        // assigns cs.attempt, we need to create a new attempt inline
                        // before executing the first op.  On subsequent ops, the attempt
                        // is created immediately before replaying the ops.
                        var err error
                        if cs.attempt, err = cs.newAttemptLocked(false /* isTransparent */); err != nil </span><span class="cov0" title="0">{
                                cs.mu.Unlock()
                                cs.finish(err)
                                return err
                        }</span>
                }
                <span class="cov0" title="0">a := cs.attempt
                cs.mu.Unlock()
                err := op(a)
                cs.mu.Lock()
                if a != cs.attempt </span><span class="cov0" title="0">{
                        // We started another attempt already.
                        continue</span>
                }
                <span class="cov0" title="0">if err == io.EOF </span><span class="cov0" title="0">{
                        &lt;-a.s.Done()
                }</span>
                <span class="cov0" title="0">if err == nil || (err == io.EOF &amp;&amp; a.s.Status().Code() == codes.OK) </span><span class="cov0" title="0">{
                        onSuccess()
                        cs.mu.Unlock()
                        return err
                }</span>
                <span class="cov0" title="0">if err := cs.retryLocked(a, err); err != nil </span><span class="cov0" title="0">{
                        cs.mu.Unlock()
                        return err
                }</span>
        }
}

func (cs *clientStream) Header() (metadata.MD, error) <span class="cov0" title="0">{
        var m metadata.MD
        err := cs.withRetry(func(a *csAttempt) error </span><span class="cov0" title="0">{
                var err error
                m, err = a.s.Header()
                return toRPCErr(err)
        }</span>, cs.commitAttemptLocked)
        <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                cs.finish(err)
                return nil, err
        }</span>
        <span class="cov0" title="0">if cs.binlog != nil &amp;&amp; !cs.serverHeaderBinlogged </span><span class="cov0" title="0">{
                // Only log if binary log is on and header has not been logged.
                logEntry := &amp;binarylog.ServerHeader{
                        OnClientSide: true,
                        Header:       m,
                        PeerAddr:     nil,
                }
                if peer, ok := peer.FromContext(cs.Context()); ok </span><span class="cov0" title="0">{
                        logEntry.PeerAddr = peer.Addr
                }</span>
                <span class="cov0" title="0">cs.binlog.Log(logEntry)
                cs.serverHeaderBinlogged = true</span>
        }
        <span class="cov0" title="0">return m, nil</span>
}

func (cs *clientStream) Trailer() metadata.MD <span class="cov0" title="0">{
        // On RPC failure, we never need to retry, because usage requires that
        // RecvMsg() returned a non-nil error before calling this function is valid.
        // We would have retried earlier if necessary.
        //
        // Commit the attempt anyway, just in case users are not following those
        // directions -- it will prevent races and should not meaningfully impact
        // performance.
        cs.commitAttempt()
        if cs.attempt.s == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">return cs.attempt.s.Trailer()</span>
}

func (cs *clientStream) replayBufferLocked(attempt *csAttempt) error <span class="cov0" title="0">{
        for _, f := range cs.buffer </span><span class="cov0" title="0">{
                if err := f(attempt); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
        }
        <span class="cov0" title="0">return nil</span>
}

func (cs *clientStream) bufferForRetryLocked(sz int, op func(a *csAttempt) error) <span class="cov0" title="0">{
        // Note: we still will buffer if retry is disabled (for transparent retries).
        if cs.committed </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov0" title="0">cs.bufferSize += sz
        if cs.bufferSize &gt; cs.callInfo.maxRetryRPCBufferSize </span><span class="cov0" title="0">{
                cs.commitAttemptLocked()
                return
        }</span>
        <span class="cov0" title="0">cs.buffer = append(cs.buffer, op)</span>
}

func (cs *clientStream) SendMsg(m interface{}) (err error) <span class="cov0" title="0">{
        defer func() </span><span class="cov0" title="0">{
                if err != nil &amp;&amp; err != io.EOF </span><span class="cov0" title="0">{
                        // Call finish on the client stream for errors generated by this SendMsg
                        // call, as these indicate problems created by this client.  (Transport
                        // errors are converted to an io.EOF error in csAttempt.sendMsg; the real
                        // error will be returned from RecvMsg eventually in that case, or be
                        // retried.)
                        cs.finish(err)
                }</span>
        }()
        <span class="cov0" title="0">if cs.sentLast </span><span class="cov0" title="0">{
                return status.Errorf(codes.Internal, "SendMsg called after CloseSend")
        }</span>
        <span class="cov0" title="0">if !cs.desc.ClientStreams </span><span class="cov0" title="0">{
                cs.sentLast = true
        }</span>

        // load hdr, payload, data
        <span class="cov0" title="0">hdr, payload, data, err := prepareMsg(m, cs.codec, cs.cp, cs.comp)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        // TODO(dfawley): should we be checking len(data) instead?
        <span class="cov0" title="0">if len(payload) &gt; *cs.callInfo.maxSendMessageSize </span><span class="cov0" title="0">{
                return status.Errorf(codes.ResourceExhausted, "trying to send message larger than max (%d vs. %d)", len(payload), *cs.callInfo.maxSendMessageSize)
        }</span>
        <span class="cov0" title="0">op := func(a *csAttempt) error </span><span class="cov0" title="0">{
                return a.sendMsg(m, hdr, payload, data)
        }</span>
        <span class="cov0" title="0">err = cs.withRetry(op, func() </span><span class="cov0" title="0">{ cs.bufferForRetryLocked(len(hdr)+len(payload), op) }</span>)
        <span class="cov0" title="0">if cs.binlog != nil &amp;&amp; err == nil </span><span class="cov0" title="0">{
                cs.binlog.Log(&amp;binarylog.ClientMessage{
                        OnClientSide: true,
                        Message:      data,
                })
        }</span>
        <span class="cov0" title="0">return err</span>
}

func (cs *clientStream) RecvMsg(m interface{}) error <span class="cov0" title="0">{
        if cs.binlog != nil &amp;&amp; !cs.serverHeaderBinlogged </span><span class="cov0" title="0">{
                // Call Header() to binary log header if it's not already logged.
                cs.Header()
        }</span>
        <span class="cov0" title="0">var recvInfo *payloadInfo
        if cs.binlog != nil </span><span class="cov0" title="0">{
                recvInfo = &amp;payloadInfo{}
        }</span>
        <span class="cov0" title="0">err := cs.withRetry(func(a *csAttempt) error </span><span class="cov0" title="0">{
                return a.recvMsg(m, recvInfo)
        }</span>, cs.commitAttemptLocked)
        <span class="cov0" title="0">if cs.binlog != nil &amp;&amp; err == nil </span><span class="cov0" title="0">{
                cs.binlog.Log(&amp;binarylog.ServerMessage{
                        OnClientSide: true,
                        Message:      recvInfo.uncompressedBytes,
                })
        }</span>
        <span class="cov0" title="0">if err != nil || !cs.desc.ServerStreams </span><span class="cov0" title="0">{
                // err != nil or non-server-streaming indicates end of stream.
                cs.finish(err)

                if cs.binlog != nil </span><span class="cov0" title="0">{
                        // finish will not log Trailer. Log Trailer here.
                        logEntry := &amp;binarylog.ServerTrailer{
                                OnClientSide: true,
                                Trailer:      cs.Trailer(),
                                Err:          err,
                        }
                        if logEntry.Err == io.EOF </span><span class="cov0" title="0">{
                                logEntry.Err = nil
                        }</span>
                        <span class="cov0" title="0">if peer, ok := peer.FromContext(cs.Context()); ok </span><span class="cov0" title="0">{
                                logEntry.PeerAddr = peer.Addr
                        }</span>
                        <span class="cov0" title="0">cs.binlog.Log(logEntry)</span>
                }
        }
        <span class="cov0" title="0">return err</span>
}

func (cs *clientStream) CloseSend() error <span class="cov0" title="0">{
        if cs.sentLast </span><span class="cov0" title="0">{
                // TODO: return an error and finish the stream instead, due to API misuse?
                return nil
        }</span>
        <span class="cov0" title="0">cs.sentLast = true
        op := func(a *csAttempt) error </span><span class="cov0" title="0">{
                a.t.Write(a.s, nil, nil, &amp;transport.Options{Last: true})
                // Always return nil; io.EOF is the only error that might make sense
                // instead, but there is no need to signal the client to call RecvMsg
                // as the only use left for the stream after CloseSend is to call
                // RecvMsg.  This also matches historical behavior.
                return nil
        }</span>
        <span class="cov0" title="0">cs.withRetry(op, func() </span><span class="cov0" title="0">{ cs.bufferForRetryLocked(0, op) }</span>)
        <span class="cov0" title="0">if cs.binlog != nil </span><span class="cov0" title="0">{
                cs.binlog.Log(&amp;binarylog.ClientHalfClose{
                        OnClientSide: true,
                })
        }</span>
        // We never returned an error here for reasons.
        <span class="cov0" title="0">return nil</span>
}

func (cs *clientStream) finish(err error) <span class="cov0" title="0">{
        if err == io.EOF </span><span class="cov0" title="0">{
                // Ending a stream with EOF indicates a success.
                err = nil
        }</span>
        <span class="cov0" title="0">cs.mu.Lock()
        if cs.finished </span><span class="cov0" title="0">{
                cs.mu.Unlock()
                return
        }</span>
        <span class="cov0" title="0">cs.finished = true
        cs.commitAttemptLocked()
        if cs.attempt != nil </span><span class="cov0" title="0">{
                cs.attempt.finish(err)
                // after functions all rely upon having a stream.
                if cs.attempt.s != nil </span><span class="cov0" title="0">{
                        for _, o := range cs.opts </span><span class="cov0" title="0">{
                                o.after(cs.callInfo, cs.attempt)
                        }</span>
                }
        }
        <span class="cov0" title="0">cs.mu.Unlock()
        // For binary logging. only log cancel in finish (could be caused by RPC ctx
        // canceled or ClientConn closed). Trailer will be logged in RecvMsg.
        //
        // Only one of cancel or trailer needs to be logged. In the cases where
        // users don't call RecvMsg, users must have already canceled the RPC.
        if cs.binlog != nil &amp;&amp; status.Code(err) == codes.Canceled </span><span class="cov0" title="0">{
                cs.binlog.Log(&amp;binarylog.Cancel{
                        OnClientSide: true,
                })
        }</span>
        <span class="cov0" title="0">if err == nil </span><span class="cov0" title="0">{
                cs.retryThrottler.successfulRPC()
        }</span>
        <span class="cov0" title="0">if channelz.IsOn() </span><span class="cov0" title="0">{
                if err != nil </span><span class="cov0" title="0">{
                        cs.cc.incrCallsFailed()
                }</span> else<span class="cov0" title="0"> {
                        cs.cc.incrCallsSucceeded()
                }</span>
        }
        <span class="cov0" title="0">cs.cancel()</span>
}

func (a *csAttempt) sendMsg(m interface{}, hdr, payld, data []byte) error <span class="cov0" title="0">{
        cs := a.cs
        if a.trInfo != nil </span><span class="cov0" title="0">{
                a.mu.Lock()
                if a.trInfo.tr != nil </span><span class="cov0" title="0">{
                        a.trInfo.tr.LazyLog(&amp;payload{sent: true, msg: m}, true)
                }</span>
                <span class="cov0" title="0">a.mu.Unlock()</span>
        }
        <span class="cov0" title="0">if err := a.t.Write(a.s, hdr, payld, &amp;transport.Options{Last: !cs.desc.ClientStreams}); err != nil </span><span class="cov0" title="0">{
                if !cs.desc.ClientStreams </span><span class="cov0" title="0">{
                        // For non-client-streaming RPCs, we return nil instead of EOF on error
                        // because the generated code requires it.  finish is not called; RecvMsg()
                        // will call it with the stream's status independently.
                        return nil
                }</span>
                <span class="cov0" title="0">return io.EOF</span>
        }
        <span class="cov0" title="0">for _, sh := range a.statsHandlers </span><span class="cov0" title="0">{
                sh.HandleRPC(a.ctx, outPayload(true, m, data, payld, time.Now()))
        }</span>
        <span class="cov0" title="0">if channelz.IsOn() </span><span class="cov0" title="0">{
                a.t.IncrMsgSent()
        }</span>
        <span class="cov0" title="0">return nil</span>
}

func (a *csAttempt) recvMsg(m interface{}, payInfo *payloadInfo) (err error) <span class="cov0" title="0">{
        cs := a.cs
        if len(a.statsHandlers) != 0 &amp;&amp; payInfo == nil </span><span class="cov0" title="0">{
                payInfo = &amp;payloadInfo{}
        }</span>

        <span class="cov0" title="0">if !a.decompSet </span><span class="cov0" title="0">{
                // Block until we receive headers containing received message encoding.
                if ct := a.s.RecvCompress(); ct != "" &amp;&amp; ct != encoding.Identity </span><span class="cov0" title="0">{
                        if a.dc == nil || a.dc.Type() != ct </span><span class="cov0" title="0">{
                                // No configured decompressor, or it does not match the incoming
                                // message encoding; attempt to find a registered compressor that does.
                                a.dc = nil
                                a.decomp = encoding.GetCompressor(ct)
                        }</span>
                } else<span class="cov0" title="0"> {
                        // No compression is used; disable our decompressor.
                        a.dc = nil
                }</span>
                // Only initialize this state once per stream.
                <span class="cov0" title="0">a.decompSet = true</span>
        }
        <span class="cov0" title="0">err = recv(a.p, cs.codec, a.s, a.dc, m, *cs.callInfo.maxReceiveMessageSize, payInfo, a.decomp)
        if err != nil </span><span class="cov0" title="0">{
                if err == io.EOF </span><span class="cov0" title="0">{
                        if statusErr := a.s.Status().Err(); statusErr != nil </span><span class="cov0" title="0">{
                                return statusErr
                        }</span>
                        <span class="cov0" title="0">return io.EOF</span> // indicates successful end of stream.
                }
                <span class="cov0" title="0">return toRPCErr(err)</span>
        }
        <span class="cov0" title="0">if a.trInfo != nil </span><span class="cov0" title="0">{
                a.mu.Lock()
                if a.trInfo.tr != nil </span><span class="cov0" title="0">{
                        a.trInfo.tr.LazyLog(&amp;payload{sent: false, msg: m}, true)
                }</span>
                <span class="cov0" title="0">a.mu.Unlock()</span>
        }
        <span class="cov0" title="0">for _, sh := range a.statsHandlers </span><span class="cov0" title="0">{
                sh.HandleRPC(a.ctx, &amp;stats.InPayload{
                        Client:   true,
                        RecvTime: time.Now(),
                        Payload:  m,
                        // TODO truncate large payload.
                        Data:       payInfo.uncompressedBytes,
                        WireLength: payInfo.wireLength + headerLen,
                        Length:     len(payInfo.uncompressedBytes),
                })
        }</span>
        <span class="cov0" title="0">if channelz.IsOn() </span><span class="cov0" title="0">{
                a.t.IncrMsgRecv()
        }</span>
        <span class="cov0" title="0">if cs.desc.ServerStreams </span><span class="cov0" title="0">{
                // Subsequent messages should be received by subsequent RecvMsg calls.
                return nil
        }</span>
        // Special handling for non-server-stream rpcs.
        // This recv expects EOF or errors, so we don't collect inPayload.
        <span class="cov0" title="0">err = recv(a.p, cs.codec, a.s, a.dc, m, *cs.callInfo.maxReceiveMessageSize, nil, a.decomp)
        if err == nil </span><span class="cov0" title="0">{
                return toRPCErr(errors.New("grpc: client streaming protocol violation: get &lt;nil&gt;, want &lt;EOF&gt;"))
        }</span>
        <span class="cov0" title="0">if err == io.EOF </span><span class="cov0" title="0">{
                return a.s.Status().Err() // non-server streaming Recv returns nil on success
        }</span>
        <span class="cov0" title="0">return toRPCErr(err)</span>
}

func (a *csAttempt) finish(err error) <span class="cov0" title="0">{
        a.mu.Lock()
        if a.finished </span><span class="cov0" title="0">{
                a.mu.Unlock()
                return
        }</span>
        <span class="cov0" title="0">a.finished = true
        if err == io.EOF </span><span class="cov0" title="0">{
                // Ending a stream with EOF indicates a success.
                err = nil
        }</span>
        <span class="cov0" title="0">var tr metadata.MD
        if a.s != nil </span><span class="cov0" title="0">{
                a.t.CloseStream(a.s, err)
                tr = a.s.Trailer()
        }</span>

        <span class="cov0" title="0">if a.done != nil </span><span class="cov0" title="0">{
                br := false
                if a.s != nil </span><span class="cov0" title="0">{
                        br = a.s.BytesReceived()
                }</span>
                <span class="cov0" title="0">a.done(balancer.DoneInfo{
                        Err:           err,
                        Trailer:       tr,
                        BytesSent:     a.s != nil,
                        BytesReceived: br,
                        ServerLoad:    balancerload.Parse(tr),
                })</span>
        }
        <span class="cov0" title="0">for _, sh := range a.statsHandlers </span><span class="cov0" title="0">{
                end := &amp;stats.End{
                        Client:    true,
                        BeginTime: a.beginTime,
                        EndTime:   time.Now(),
                        Trailer:   tr,
                        Error:     err,
                }
                sh.HandleRPC(a.ctx, end)
        }</span>
        <span class="cov0" title="0">if a.trInfo != nil &amp;&amp; a.trInfo.tr != nil </span><span class="cov0" title="0">{
                if err == nil </span><span class="cov0" title="0">{
                        a.trInfo.tr.LazyPrintf("RPC: [OK]")
                }</span> else<span class="cov0" title="0"> {
                        a.trInfo.tr.LazyPrintf("RPC: [%v]", err)
                        a.trInfo.tr.SetError()
                }</span>
                <span class="cov0" title="0">a.trInfo.tr.Finish()
                a.trInfo.tr = nil</span>
        }
        <span class="cov0" title="0">a.mu.Unlock()</span>
}

// newClientStream creates a ClientStream with the specified transport, on the
// given addrConn.
//
// It's expected that the given transport is either the same one in addrConn, or
// is already closed. To avoid race, transport is specified separately, instead
// of using ac.transpot.
//
// Main difference between this and ClientConn.NewStream:
// - no retry
// - no service config (or wait for service config)
// - no tracing or stats
func newNonRetryClientStream(ctx context.Context, desc *StreamDesc, method string, t transport.ClientTransport, ac *addrConn, opts ...CallOption) (_ ClientStream, err error) <span class="cov0" title="0">{
        if t == nil </span><span class="cov0" title="0">{
                // TODO: return RPC error here?
                return nil, errors.New("transport provided is nil")
        }</span>
        // defaultCallInfo contains unnecessary info(i.e. failfast, maxRetryRPCBufferSize), so we just initialize an empty struct.
        <span class="cov0" title="0">c := &amp;callInfo{}

        // Possible context leak:
        // The cancel function for the child context we create will only be called
        // when RecvMsg returns a non-nil error, if the ClientConn is closed, or if
        // an error is generated by SendMsg.
        // https://github.com/grpc/grpc-go/issues/1818.
        ctx, cancel := context.WithCancel(ctx)
        defer func() </span><span class="cov0" title="0">{
                if err != nil </span><span class="cov0" title="0">{
                        cancel()
                }</span>
        }()

        <span class="cov0" title="0">for _, o := range opts </span><span class="cov0" title="0">{
                if err := o.before(c); err != nil </span><span class="cov0" title="0">{
                        return nil, toRPCErr(err)
                }</span>
        }
        <span class="cov0" title="0">c.maxReceiveMessageSize = getMaxSize(nil, c.maxReceiveMessageSize, defaultClientMaxReceiveMessageSize)
        c.maxSendMessageSize = getMaxSize(nil, c.maxSendMessageSize, defaultServerMaxSendMessageSize)
        if err := setCallInfoCodec(c); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov0" title="0">callHdr := &amp;transport.CallHdr{
                Host:           ac.cc.authority,
                Method:         method,
                ContentSubtype: c.contentSubtype,
        }

        // Set our outgoing compression according to the UseCompressor CallOption, if
        // set.  In that case, also find the compressor from the encoding package.
        // Otherwise, use the compressor configured by the WithCompressor DialOption,
        // if set.
        var cp Compressor
        var comp encoding.Compressor
        if ct := c.compressorType; ct != "" </span><span class="cov0" title="0">{
                callHdr.SendCompress = ct
                if ct != encoding.Identity </span><span class="cov0" title="0">{
                        comp = encoding.GetCompressor(ct)
                        if comp == nil </span><span class="cov0" title="0">{
                                return nil, status.Errorf(codes.Internal, "grpc: Compressor is not installed for requested grpc-encoding %q", ct)
                        }</span>
                }
        } else<span class="cov0" title="0"> if ac.cc.dopts.cp != nil </span><span class="cov0" title="0">{
                callHdr.SendCompress = ac.cc.dopts.cp.Type()
                cp = ac.cc.dopts.cp
        }</span>
        <span class="cov0" title="0">if c.creds != nil </span><span class="cov0" title="0">{
                callHdr.Creds = c.creds
        }</span>

        // Use a special addrConnStream to avoid retry.
        <span class="cov0" title="0">as := &amp;addrConnStream{
                callHdr:  callHdr,
                ac:       ac,
                ctx:      ctx,
                cancel:   cancel,
                opts:     opts,
                callInfo: c,
                desc:     desc,
                codec:    c.codec,
                cp:       cp,
                comp:     comp,
                t:        t,
        }

        s, err := as.t.NewStream(as.ctx, as.callHdr)
        if err != nil </span><span class="cov0" title="0">{
                err = toRPCErr(err)
                return nil, err
        }</span>
        <span class="cov0" title="0">as.s = s
        as.p = &amp;parser{r: s}
        ac.incrCallsStarted()
        if desc != unaryStreamDesc </span><span class="cov0" title="0">{
                // Listen on cc and stream contexts to cleanup when the user closes the
                // ClientConn or cancels the stream context.  In all other cases, an error
                // should already be injected into the recv buffer by the transport, which
                // the client will eventually receive, and then we will cancel the stream's
                // context in clientStream.finish.
                go func() </span><span class="cov0" title="0">{
                        select </span>{
                        case &lt;-ac.ctx.Done():<span class="cov0" title="0">
                                as.finish(status.Error(codes.Canceled, "grpc: the SubConn is closing"))</span>
                        case &lt;-ctx.Done():<span class="cov0" title="0">
                                as.finish(toRPCErr(ctx.Err()))</span>
                        }
                }()
        }
        <span class="cov0" title="0">return as, nil</span>
}

type addrConnStream struct {
        s         *transport.Stream
        ac        *addrConn
        callHdr   *transport.CallHdr
        cancel    context.CancelFunc
        opts      []CallOption
        callInfo  *callInfo
        t         transport.ClientTransport
        ctx       context.Context
        sentLast  bool
        desc      *StreamDesc
        codec     baseCodec
        cp        Compressor
        comp      encoding.Compressor
        decompSet bool
        dc        Decompressor
        decomp    encoding.Compressor
        p         *parser
        mu        sync.Mutex
        finished  bool
}

func (as *addrConnStream) Header() (metadata.MD, error) <span class="cov0" title="0">{
        m, err := as.s.Header()
        if err != nil </span><span class="cov0" title="0">{
                as.finish(toRPCErr(err))
        }</span>
        <span class="cov0" title="0">return m, err</span>
}

func (as *addrConnStream) Trailer() metadata.MD <span class="cov0" title="0">{
        return as.s.Trailer()
}</span>

func (as *addrConnStream) CloseSend() error <span class="cov0" title="0">{
        if as.sentLast </span><span class="cov0" title="0">{
                // TODO: return an error and finish the stream instead, due to API misuse?
                return nil
        }</span>
        <span class="cov0" title="0">as.sentLast = true

        as.t.Write(as.s, nil, nil, &amp;transport.Options{Last: true})
        // Always return nil; io.EOF is the only error that might make sense
        // instead, but there is no need to signal the client to call RecvMsg
        // as the only use left for the stream after CloseSend is to call
        // RecvMsg.  This also matches historical behavior.
        return nil</span>
}

func (as *addrConnStream) Context() context.Context <span class="cov0" title="0">{
        return as.s.Context()
}</span>

func (as *addrConnStream) SendMsg(m interface{}) (err error) <span class="cov0" title="0">{
        defer func() </span><span class="cov0" title="0">{
                if err != nil &amp;&amp; err != io.EOF </span><span class="cov0" title="0">{
                        // Call finish on the client stream for errors generated by this SendMsg
                        // call, as these indicate problems created by this client.  (Transport
                        // errors are converted to an io.EOF error in csAttempt.sendMsg; the real
                        // error will be returned from RecvMsg eventually in that case, or be
                        // retried.)
                        as.finish(err)
                }</span>
        }()
        <span class="cov0" title="0">if as.sentLast </span><span class="cov0" title="0">{
                return status.Errorf(codes.Internal, "SendMsg called after CloseSend")
        }</span>
        <span class="cov0" title="0">if !as.desc.ClientStreams </span><span class="cov0" title="0">{
                as.sentLast = true
        }</span>

        // load hdr, payload, data
        <span class="cov0" title="0">hdr, payld, _, err := prepareMsg(m, as.codec, as.cp, as.comp)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        // TODO(dfawley): should we be checking len(data) instead?
        <span class="cov0" title="0">if len(payld) &gt; *as.callInfo.maxSendMessageSize </span><span class="cov0" title="0">{
                return status.Errorf(codes.ResourceExhausted, "trying to send message larger than max (%d vs. %d)", len(payld), *as.callInfo.maxSendMessageSize)
        }</span>

        <span class="cov0" title="0">if err := as.t.Write(as.s, hdr, payld, &amp;transport.Options{Last: !as.desc.ClientStreams}); err != nil </span><span class="cov0" title="0">{
                if !as.desc.ClientStreams </span><span class="cov0" title="0">{
                        // For non-client-streaming RPCs, we return nil instead of EOF on error
                        // because the generated code requires it.  finish is not called; RecvMsg()
                        // will call it with the stream's status independently.
                        return nil
                }</span>
                <span class="cov0" title="0">return io.EOF</span>
        }

        <span class="cov0" title="0">if channelz.IsOn() </span><span class="cov0" title="0">{
                as.t.IncrMsgSent()
        }</span>
        <span class="cov0" title="0">return nil</span>
}

func (as *addrConnStream) RecvMsg(m interface{}) (err error) <span class="cov0" title="0">{
        defer func() </span><span class="cov0" title="0">{
                if err != nil || !as.desc.ServerStreams </span><span class="cov0" title="0">{
                        // err != nil or non-server-streaming indicates end of stream.
                        as.finish(err)
                }</span>
        }()

        <span class="cov0" title="0">if !as.decompSet </span><span class="cov0" title="0">{
                // Block until we receive headers containing received message encoding.
                if ct := as.s.RecvCompress(); ct != "" &amp;&amp; ct != encoding.Identity </span><span class="cov0" title="0">{
                        if as.dc == nil || as.dc.Type() != ct </span><span class="cov0" title="0">{
                                // No configured decompressor, or it does not match the incoming
                                // message encoding; attempt to find a registered compressor that does.
                                as.dc = nil
                                as.decomp = encoding.GetCompressor(ct)
                        }</span>
                } else<span class="cov0" title="0"> {
                        // No compression is used; disable our decompressor.
                        as.dc = nil
                }</span>
                // Only initialize this state once per stream.
                <span class="cov0" title="0">as.decompSet = true</span>
        }
        <span class="cov0" title="0">err = recv(as.p, as.codec, as.s, as.dc, m, *as.callInfo.maxReceiveMessageSize, nil, as.decomp)
        if err != nil </span><span class="cov0" title="0">{
                if err == io.EOF </span><span class="cov0" title="0">{
                        if statusErr := as.s.Status().Err(); statusErr != nil </span><span class="cov0" title="0">{
                                return statusErr
                        }</span>
                        <span class="cov0" title="0">return io.EOF</span> // indicates successful end of stream.
                }
                <span class="cov0" title="0">return toRPCErr(err)</span>
        }

        <span class="cov0" title="0">if channelz.IsOn() </span><span class="cov0" title="0">{
                as.t.IncrMsgRecv()
        }</span>
        <span class="cov0" title="0">if as.desc.ServerStreams </span><span class="cov0" title="0">{
                // Subsequent messages should be received by subsequent RecvMsg calls.
                return nil
        }</span>

        // Special handling for non-server-stream rpcs.
        // This recv expects EOF or errors, so we don't collect inPayload.
        <span class="cov0" title="0">err = recv(as.p, as.codec, as.s, as.dc, m, *as.callInfo.maxReceiveMessageSize, nil, as.decomp)
        if err == nil </span><span class="cov0" title="0">{
                return toRPCErr(errors.New("grpc: client streaming protocol violation: get &lt;nil&gt;, want &lt;EOF&gt;"))
        }</span>
        <span class="cov0" title="0">if err == io.EOF </span><span class="cov0" title="0">{
                return as.s.Status().Err() // non-server streaming Recv returns nil on success
        }</span>
        <span class="cov0" title="0">return toRPCErr(err)</span>
}

func (as *addrConnStream) finish(err error) <span class="cov0" title="0">{
        as.mu.Lock()
        if as.finished </span><span class="cov0" title="0">{
                as.mu.Unlock()
                return
        }</span>
        <span class="cov0" title="0">as.finished = true
        if err == io.EOF </span><span class="cov0" title="0">{
                // Ending a stream with EOF indicates a success.
                err = nil
        }</span>
        <span class="cov0" title="0">if as.s != nil </span><span class="cov0" title="0">{
                as.t.CloseStream(as.s, err)
        }</span>

        <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                as.ac.incrCallsFailed()
        }</span> else<span class="cov0" title="0"> {
                as.ac.incrCallsSucceeded()
        }</span>
        <span class="cov0" title="0">as.cancel()
        as.mu.Unlock()</span>
}

// ServerStream defines the server-side behavior of a streaming RPC.
//
// Errors returned from ServerStream methods are compatible with the status
// package.  However, the status code will often not match the RPC status as
// seen by the client application, and therefore, should not be relied upon for
// this purpose.
type ServerStream interface {
        // SetHeader sets the header metadata. It may be called multiple times.
        // When call multiple times, all the provided metadata will be merged.
        // All the metadata will be sent out when one of the following happens:
        //  - ServerStream.SendHeader() is called;
        //  - The first response is sent out;
        //  - An RPC status is sent out (error or success).
        SetHeader(metadata.MD) error
        // SendHeader sends the header metadata.
        // The provided md and headers set by SetHeader() will be sent.
        // It fails if called multiple times.
        SendHeader(metadata.MD) error
        // SetTrailer sets the trailer metadata which will be sent with the RPC status.
        // When called more than once, all the provided metadata will be merged.
        SetTrailer(metadata.MD)
        // Context returns the context for this stream.
        Context() context.Context
        // SendMsg sends a message. On error, SendMsg aborts the stream and the
        // error is returned directly.
        //
        // SendMsg blocks until:
        //   - There is sufficient flow control to schedule m with the transport, or
        //   - The stream is done, or
        //   - The stream breaks.
        //
        // SendMsg does not wait until the message is received by the client. An
        // untimely stream closure may result in lost messages.
        //
        // It is safe to have a goroutine calling SendMsg and another goroutine
        // calling RecvMsg on the same stream at the same time, but it is not safe
        // to call SendMsg on the same stream in different goroutines.
        SendMsg(m interface{}) error
        // RecvMsg blocks until it receives a message into m or the stream is
        // done. It returns io.EOF when the client has performed a CloseSend. On
        // any non-EOF error, the stream is aborted and the error contains the
        // RPC status.
        //
        // It is safe to have a goroutine calling SendMsg and another goroutine
        // calling RecvMsg on the same stream at the same time, but it is not
        // safe to call RecvMsg on the same stream in different goroutines.
        RecvMsg(m interface{}) error
}

// serverStream implements a server side Stream.
type serverStream struct {
        ctx   context.Context
        t     transport.ServerTransport
        s     *transport.Stream
        p     *parser
        codec baseCodec

        cp     Compressor
        dc     Decompressor
        comp   encoding.Compressor
        decomp encoding.Compressor

        maxReceiveMessageSize int
        maxSendMessageSize    int
        trInfo                *traceInfo

        statsHandler []stats.Handler

        binlog binarylog.MethodLogger
        // serverHeaderBinlogged indicates whether server header has been logged. It
        // will happen when one of the following two happens: stream.SendHeader(),
        // stream.Send().
        //
        // It's only checked in send and sendHeader, doesn't need to be
        // synchronized.
        serverHeaderBinlogged bool

        mu sync.Mutex // protects trInfo.tr after the service handler runs.
}

func (ss *serverStream) Context() context.Context <span class="cov0" title="0">{
        return ss.ctx
}</span>

func (ss *serverStream) SetHeader(md metadata.MD) error <span class="cov0" title="0">{
        if md.Len() == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">err := imetadata.Validate(md)
        if err != nil </span><span class="cov0" title="0">{
                return status.Error(codes.Internal, err.Error())
        }</span>
        <span class="cov0" title="0">return ss.s.SetHeader(md)</span>
}

func (ss *serverStream) SendHeader(md metadata.MD) error <span class="cov0" title="0">{
        err := imetadata.Validate(md)
        if err != nil </span><span class="cov0" title="0">{
                return status.Error(codes.Internal, err.Error())
        }</span>

        <span class="cov0" title="0">err = ss.t.WriteHeader(ss.s, md)
        if ss.binlog != nil &amp;&amp; !ss.serverHeaderBinlogged </span><span class="cov0" title="0">{
                h, _ := ss.s.Header()
                ss.binlog.Log(&amp;binarylog.ServerHeader{
                        Header: h,
                })
                ss.serverHeaderBinlogged = true
        }</span>
        <span class="cov0" title="0">return err</span>
}

func (ss *serverStream) SetTrailer(md metadata.MD) <span class="cov0" title="0">{
        if md.Len() == 0 </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov0" title="0">if err := imetadata.Validate(md); err != nil </span><span class="cov0" title="0">{
                logger.Errorf("stream: failed to validate md when setting trailer, err: %v", err)
        }</span>
        <span class="cov0" title="0">ss.s.SetTrailer(md)</span>
}

func (ss *serverStream) SendMsg(m interface{}) (err error) <span class="cov0" title="0">{
        defer func() </span><span class="cov0" title="0">{
                if ss.trInfo != nil </span><span class="cov0" title="0">{
                        ss.mu.Lock()
                        if ss.trInfo.tr != nil </span><span class="cov0" title="0">{
                                if err == nil </span><span class="cov0" title="0">{
                                        ss.trInfo.tr.LazyLog(&amp;payload{sent: true, msg: m}, true)
                                }</span> else<span class="cov0" title="0"> {
                                        ss.trInfo.tr.LazyLog(&amp;fmtStringer{"%v", []interface{}{err}}, true)
                                        ss.trInfo.tr.SetError()
                                }</span>
                        }
                        <span class="cov0" title="0">ss.mu.Unlock()</span>
                }
                <span class="cov0" title="0">if err != nil &amp;&amp; err != io.EOF </span><span class="cov0" title="0">{
                        st, _ := status.FromError(toRPCErr(err))
                        ss.t.WriteStatus(ss.s, st)
                        // Non-user specified status was sent out. This should be an error
                        // case (as a server side Cancel maybe).
                        //
                        // This is not handled specifically now. User will return a final
                        // status from the service handler, we will log that error instead.
                        // This behavior is similar to an interceptor.
                }</span>
                <span class="cov0" title="0">if channelz.IsOn() &amp;&amp; err == nil </span><span class="cov0" title="0">{
                        ss.t.IncrMsgSent()
                }</span>
        }()

        // load hdr, payload, data
        <span class="cov0" title="0">hdr, payload, data, err := prepareMsg(m, ss.codec, ss.cp, ss.comp)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        // TODO(dfawley): should we be checking len(data) instead?
        <span class="cov0" title="0">if len(payload) &gt; ss.maxSendMessageSize </span><span class="cov0" title="0">{
                return status.Errorf(codes.ResourceExhausted, "trying to send message larger than max (%d vs. %d)", len(payload), ss.maxSendMessageSize)
        }</span>
        <span class="cov0" title="0">if err := ss.t.Write(ss.s, hdr, payload, &amp;transport.Options{Last: false}); err != nil </span><span class="cov0" title="0">{
                return toRPCErr(err)
        }</span>
        <span class="cov0" title="0">if ss.binlog != nil </span><span class="cov0" title="0">{
                if !ss.serverHeaderBinlogged </span><span class="cov0" title="0">{
                        h, _ := ss.s.Header()
                        ss.binlog.Log(&amp;binarylog.ServerHeader{
                                Header: h,
                        })
                        ss.serverHeaderBinlogged = true
                }</span>
                <span class="cov0" title="0">ss.binlog.Log(&amp;binarylog.ServerMessage{
                        Message: data,
                })</span>
        }
        <span class="cov0" title="0">if len(ss.statsHandler) != 0 </span><span class="cov0" title="0">{
                for _, sh := range ss.statsHandler </span><span class="cov0" title="0">{
                        sh.HandleRPC(ss.s.Context(), outPayload(false, m, data, payload, time.Now()))
                }</span>
        }
        <span class="cov0" title="0">return nil</span>
}

func (ss *serverStream) RecvMsg(m interface{}) (err error) <span class="cov0" title="0">{
        defer func() </span><span class="cov0" title="0">{
                if ss.trInfo != nil </span><span class="cov0" title="0">{
                        ss.mu.Lock()
                        if ss.trInfo.tr != nil </span><span class="cov0" title="0">{
                                if err == nil </span><span class="cov0" title="0">{
                                        ss.trInfo.tr.LazyLog(&amp;payload{sent: false, msg: m}, true)
                                }</span> else<span class="cov0" title="0"> if err != io.EOF </span><span class="cov0" title="0">{
                                        ss.trInfo.tr.LazyLog(&amp;fmtStringer{"%v", []interface{}{err}}, true)
                                        ss.trInfo.tr.SetError()
                                }</span>
                        }
                        <span class="cov0" title="0">ss.mu.Unlock()</span>
                }
                <span class="cov0" title="0">if err != nil &amp;&amp; err != io.EOF </span><span class="cov0" title="0">{
                        st, _ := status.FromError(toRPCErr(err))
                        ss.t.WriteStatus(ss.s, st)
                        // Non-user specified status was sent out. This should be an error
                        // case (as a server side Cancel maybe).
                        //
                        // This is not handled specifically now. User will return a final
                        // status from the service handler, we will log that error instead.
                        // This behavior is similar to an interceptor.
                }</span>
                <span class="cov0" title="0">if channelz.IsOn() &amp;&amp; err == nil </span><span class="cov0" title="0">{
                        ss.t.IncrMsgRecv()
                }</span>
        }()
        <span class="cov0" title="0">var payInfo *payloadInfo
        if len(ss.statsHandler) != 0 || ss.binlog != nil </span><span class="cov0" title="0">{
                payInfo = &amp;payloadInfo{}
        }</span>
        <span class="cov0" title="0">if err := recv(ss.p, ss.codec, ss.s, ss.dc, m, ss.maxReceiveMessageSize, payInfo, ss.decomp); err != nil </span><span class="cov0" title="0">{
                if err == io.EOF </span><span class="cov0" title="0">{
                        if ss.binlog != nil </span><span class="cov0" title="0">{
                                ss.binlog.Log(&amp;binarylog.ClientHalfClose{})
                        }</span>
                        <span class="cov0" title="0">return err</span>
                }
                <span class="cov0" title="0">if err == io.ErrUnexpectedEOF </span><span class="cov0" title="0">{
                        err = status.Errorf(codes.Internal, io.ErrUnexpectedEOF.Error())
                }</span>
                <span class="cov0" title="0">return toRPCErr(err)</span>
        }
        <span class="cov0" title="0">if len(ss.statsHandler) != 0 </span><span class="cov0" title="0">{
                for _, sh := range ss.statsHandler </span><span class="cov0" title="0">{
                        sh.HandleRPC(ss.s.Context(), &amp;stats.InPayload{
                                RecvTime: time.Now(),
                                Payload:  m,
                                // TODO truncate large payload.
                                Data:       payInfo.uncompressedBytes,
                                WireLength: payInfo.wireLength + headerLen,
                                Length:     len(payInfo.uncompressedBytes),
                        })
                }</span>
        }
        <span class="cov0" title="0">if ss.binlog != nil </span><span class="cov0" title="0">{
                ss.binlog.Log(&amp;binarylog.ClientMessage{
                        Message: payInfo.uncompressedBytes,
                })
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// MethodFromServerStream returns the method string for the input stream.
// The returned string is in the format of "/service/method".
func MethodFromServerStream(stream ServerStream) (string, bool) <span class="cov0" title="0">{
        return Method(stream.Context())
}</span>

// prepareMsg returns the hdr, payload and data
// using the compressors passed or using the
// passed preparedmsg
func prepareMsg(m interface{}, codec baseCodec, cp Compressor, comp encoding.Compressor) (hdr, payload, data []byte, err error) <span class="cov0" title="0">{
        if preparedMsg, ok := m.(*PreparedMsg); ok </span><span class="cov0" title="0">{
                return preparedMsg.hdr, preparedMsg.payload, preparedMsg.encodedData, nil
        }</span>
        // The input interface is not a prepared msg.
        // Marshal and Compress the data at this point
        <span class="cov0" title="0">data, err = encode(codec, m)
        if err != nil </span><span class="cov0" title="0">{
                return nil, nil, nil, err
        }</span>
        <span class="cov0" title="0">compData, err := compress(data, cp, comp)
        if err != nil </span><span class="cov0" title="0">{
                return nil, nil, nil, err
        }</span>
        <span class="cov0" title="0">hdr, payload = msgHeader(data, compData)
        return hdr, payload, data, nil</span>
}
</pre>
		
		<pre class="file" id="file138" style="display: none">/*
 *
 * Copyright 2017 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package bufconn provides a net.Conn implemented by a buffer and related
// dialing and listening functionality.
package bufconn

import (
        "context"
        "fmt"
        "io"
        "net"
        "sync"
        "time"
)

// Listener implements a net.Listener that creates local, buffered net.Conns
// via its Accept and Dial method.
type Listener struct {
        mu   sync.Mutex
        sz   int
        ch   chan net.Conn
        done chan struct{}
}

// Implementation of net.Error providing timeout
type netErrorTimeout struct {
        error
}

func (e netErrorTimeout) Timeout() bool   <span class="cov8" title="1">{ return true }</span>
func (e netErrorTimeout) Temporary() bool <span class="cov0" title="0">{ return false }</span>

var errClosed = fmt.Errorf("closed")
var errTimeout net.Error = netErrorTimeout{error: fmt.Errorf("i/o timeout")}

// Listen returns a Listener that can only be contacted by its own Dialers and
// creates buffered connections between the two.
func Listen(sz int) *Listener <span class="cov8" title="1">{
        return &amp;Listener{sz: sz, ch: make(chan net.Conn), done: make(chan struct{})}
}</span>

// Accept blocks until Dial is called, then returns a net.Conn for the server
// half of the connection.
func (l *Listener) Accept() (net.Conn, error) <span class="cov8" title="1">{
        select </span>{
        case &lt;-l.done:<span class="cov8" title="1">
                return nil, errClosed</span>
        case c := &lt;-l.ch:<span class="cov8" title="1">
                return c, nil</span>
        }
}

// Close stops the listener.
func (l *Listener) Close() error <span class="cov8" title="1">{
        l.mu.Lock()
        defer l.mu.Unlock()
        select </span>{
        case &lt;-l.done:<span class="cov0" title="0">
                // Already closed.
                break</span>
        default:<span class="cov8" title="1">
                close(l.done)</span>
        }
        <span class="cov8" title="1">return nil</span>
}

// Addr reports the address of the listener.
func (l *Listener) Addr() net.Addr <span class="cov0" title="0">{ return addr{} }</span>

// Dial creates an in-memory full-duplex network connection, unblocks Accept by
// providing it the server half of the connection, and returns the client half
// of the connection.
func (l *Listener) Dial() (net.Conn, error) <span class="cov8" title="1">{
        return l.DialContext(context.Background())
}</span>

// DialContext creates an in-memory full-duplex network connection, unblocks Accept by
// providing it the server half of the connection, and returns the client half
// of the connection.  If ctx is Done, returns ctx.Err()
func (l *Listener) DialContext(ctx context.Context) (net.Conn, error) <span class="cov8" title="1">{
        p1, p2 := newPipe(l.sz), newPipe(l.sz)
        select </span>{
        case &lt;-ctx.Done():<span class="cov0" title="0">
                return nil, ctx.Err()</span>
        case &lt;-l.done:<span class="cov8" title="1">
                return nil, errClosed</span>
        case l.ch &lt;- &amp;conn{p1, p2}:<span class="cov8" title="1">
                return &amp;conn{p2, p1}, nil</span>
        }
}

type pipe struct {
        mu sync.Mutex

        // buf contains the data in the pipe.  It is a ring buffer of fixed capacity,
        // with r and w pointing to the offset to read and write, respsectively.
        //
        // Data is read between [r, w) and written to [w, r), wrapping around the end
        // of the slice if necessary.
        //
        // The buffer is empty if r == len(buf), otherwise if r == w, it is full.
        //
        // w and r are always in the range [0, cap(buf)) and [0, len(buf)].
        buf  []byte
        w, r int

        wwait sync.Cond
        rwait sync.Cond

        // Indicate that a write/read timeout has occurred
        wtimedout bool
        rtimedout bool

        wtimer *time.Timer
        rtimer *time.Timer

        closed      bool
        writeClosed bool
}

func newPipe(sz int) *pipe <span class="cov8" title="1">{
        p := &amp;pipe{buf: make([]byte, 0, sz)}
        p.wwait.L = &amp;p.mu
        p.rwait.L = &amp;p.mu

        p.wtimer = time.AfterFunc(0, func() </span>{<span class="cov8" title="1">}</span>)
        <span class="cov8" title="1">p.rtimer = time.AfterFunc(0, func() </span>{<span class="cov8" title="1">}</span>)
        <span class="cov8" title="1">return p</span>
}

func (p *pipe) empty() bool <span class="cov8" title="1">{
        return p.r == len(p.buf)
}</span>

func (p *pipe) full() bool <span class="cov8" title="1">{
        return p.r &lt; len(p.buf) &amp;&amp; p.r == p.w
}</span>

func (p *pipe) Read(b []byte) (n int, err error) <span class="cov8" title="1">{
        p.mu.Lock()
        defer p.mu.Unlock()
        // Block until p has data.
        for </span><span class="cov8" title="1">{
                if p.closed </span><span class="cov8" title="1">{
                        return 0, io.ErrClosedPipe
                }</span>
                <span class="cov8" title="1">if !p.empty() </span><span class="cov8" title="1">{
                        break</span>
                }
                <span class="cov8" title="1">if p.writeClosed </span><span class="cov0" title="0">{
                        return 0, io.EOF
                }</span>
                <span class="cov8" title="1">if p.rtimedout </span><span class="cov8" title="1">{
                        return 0, errTimeout
                }</span>

                <span class="cov8" title="1">p.rwait.Wait()</span>
        }
        <span class="cov8" title="1">wasFull := p.full()

        n = copy(b, p.buf[p.r:len(p.buf)])
        p.r += n
        if p.r == cap(p.buf) </span><span class="cov8" title="1">{
                p.r = 0
                p.buf = p.buf[:p.w]
        }</span>

        // Signal a blocked writer, if any
        <span class="cov8" title="1">if wasFull </span><span class="cov8" title="1">{
                p.wwait.Signal()
        }</span>

        <span class="cov8" title="1">return n, nil</span>
}

func (p *pipe) Write(b []byte) (n int, err error) <span class="cov8" title="1">{
        p.mu.Lock()
        defer p.mu.Unlock()
        if p.closed </span><span class="cov8" title="1">{
                return 0, io.ErrClosedPipe
        }</span>
        <span class="cov8" title="1">for len(b) &gt; 0 </span><span class="cov8" title="1">{
                // Block until p is not full.
                for </span><span class="cov8" title="1">{
                        if p.closed || p.writeClosed </span><span class="cov8" title="1">{
                                return 0, io.ErrClosedPipe
                        }</span>
                        <span class="cov8" title="1">if !p.full() </span><span class="cov8" title="1">{
                                break</span>
                        }
                        <span class="cov8" title="1">if p.wtimedout </span><span class="cov8" title="1">{
                                return 0, errTimeout
                        }</span>

                        <span class="cov8" title="1">p.wwait.Wait()</span>
                }
                <span class="cov8" title="1">wasEmpty := p.empty()

                end := cap(p.buf)
                if p.w &lt; p.r </span><span class="cov8" title="1">{
                        end = p.r
                }</span>
                <span class="cov8" title="1">x := copy(p.buf[p.w:end], b)
                b = b[x:]
                n += x
                p.w += x
                if p.w &gt; len(p.buf) </span><span class="cov8" title="1">{
                        p.buf = p.buf[:p.w]
                }</span>
                <span class="cov8" title="1">if p.w == cap(p.buf) </span><span class="cov8" title="1">{
                        p.w = 0
                }</span>

                // Signal a blocked reader, if any.
                <span class="cov8" title="1">if wasEmpty </span><span class="cov8" title="1">{
                        p.rwait.Signal()
                }</span>
        }
        <span class="cov8" title="1">return n, nil</span>
}

func (p *pipe) Close() error <span class="cov8" title="1">{
        p.mu.Lock()
        defer p.mu.Unlock()
        p.closed = true
        // Signal all blocked readers and writers to return an error.
        p.rwait.Broadcast()
        p.wwait.Broadcast()
        return nil
}</span>

func (p *pipe) closeWrite() error <span class="cov8" title="1">{
        p.mu.Lock()
        defer p.mu.Unlock()
        p.writeClosed = true
        // Signal all blocked readers and writers to return an error.
        p.rwait.Broadcast()
        p.wwait.Broadcast()
        return nil
}</span>

type conn struct {
        io.Reader
        io.Writer
}

func (c *conn) Close() error <span class="cov8" title="1">{
        err1 := c.Reader.(*pipe).Close()
        err2 := c.Writer.(*pipe).closeWrite()
        if err1 != nil </span><span class="cov0" title="0">{
                return err1
        }</span>
        <span class="cov8" title="1">return err2</span>
}

func (c *conn) SetDeadline(t time.Time) error <span class="cov0" title="0">{
        c.SetReadDeadline(t)
        c.SetWriteDeadline(t)
        return nil
}</span>

func (c *conn) SetReadDeadline(t time.Time) error <span class="cov8" title="1">{
        p := c.Reader.(*pipe)
        p.mu.Lock()
        defer p.mu.Unlock()
        p.rtimer.Stop()
        p.rtimedout = false
        if !t.IsZero() </span><span class="cov8" title="1">{
                p.rtimer = time.AfterFunc(time.Until(t), func() </span><span class="cov8" title="1">{
                        p.mu.Lock()
                        defer p.mu.Unlock()
                        p.rtimedout = true
                        p.rwait.Broadcast()
                }</span>)
        }
        <span class="cov8" title="1">return nil</span>
}

func (c *conn) SetWriteDeadline(t time.Time) error <span class="cov8" title="1">{
        p := c.Writer.(*pipe)
        p.mu.Lock()
        defer p.mu.Unlock()
        p.wtimer.Stop()
        p.wtimedout = false
        if !t.IsZero() </span><span class="cov8" title="1">{
                p.wtimer = time.AfterFunc(time.Until(t), func() </span><span class="cov8" title="1">{
                        p.mu.Lock()
                        defer p.mu.Unlock()
                        p.wtimedout = true
                        p.wwait.Broadcast()
                }</span>)
        }
        <span class="cov8" title="1">return nil</span>
}

func (*conn) LocalAddr() net.Addr  <span class="cov0" title="0">{ return addr{} }</span>
func (*conn) RemoteAddr() net.Addr <span class="cov0" title="0">{ return addr{} }</span>

type addr struct{}

func (addr) Network() string <span class="cov0" title="0">{ return "bufconn" }</span>
func (addr) String() string  <span class="cov0" title="0">{ return "bufconn" }</span>
</pre>
		
		<pre class="file" id="file139" style="display: none">/*
 *
 * Copyright 2022 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package test

import (
        "testing"

        "google.golang.org/grpc/resolver/manual"
        "google.golang.org/grpc/serviceconfig"
)

// parseServiceConfig is a test helper which uses the manual resolver to parse
// the given service config. It calls t.Fatal() if service config parsing fails.
func parseServiceConfig(t *testing.T, r *manual.Resolver, sc string) *serviceconfig.ParseResult <span class="cov8" title="1">{
        t.Helper()

        scpr := r.CC.ParseServiceConfig(sc)
        if scpr.Err != nil </span><span class="cov0" title="0">{
                t.Fatalf("Failed to parse service config %q: %v", sc, scpr.Err)
        }</span>
        <span class="cov8" title="1">return scpr</span>
}
</pre>
		
		<pre class="file" id="file140" style="display: none">/*
 * Copyright 2018 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package test

import (
        "bytes"
        "fmt"
        "io"
        "net"
        "strings"
        "sync"
        "time"

        "golang.org/x/net/http2"
        "golang.org/x/net/http2/hpack"
)

type listenerWrapper struct {
        net.Listener
        mu  sync.Mutex
        rcw *rawConnWrapper
}

func listenWithConnControl(network, address string) (net.Listener, error) <span class="cov8" title="1">{
        l, err := net.Listen(network, address)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return &amp;listenerWrapper{Listener: l}, nil</span>
}

// Accept blocks until Dial is called, then returns a net.Conn for the server
// half of the connection.
func (l *listenerWrapper) Accept() (net.Conn, error) <span class="cov8" title="1">{
        c, err := l.Listener.Accept()
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">l.mu.Lock()
        l.rcw = newRawConnWrapperFromConn(c)
        l.mu.Unlock()
        return c, nil</span>
}

func (l *listenerWrapper) getLastConn() *rawConnWrapper <span class="cov8" title="1">{
        l.mu.Lock()
        defer l.mu.Unlock()
        return l.rcw
}</span>

type dialerWrapper struct {
        c   net.Conn
        rcw *rawConnWrapper
}

func (d *dialerWrapper) dialer(target string, t time.Duration) (net.Conn, error) <span class="cov8" title="1">{
        c, err := net.DialTimeout("tcp", target, t)
        d.c = c
        d.rcw = newRawConnWrapperFromConn(c)
        return c, err
}</span>

func (d *dialerWrapper) getRawConnWrapper() *rawConnWrapper <span class="cov8" title="1">{
        return d.rcw
}</span>

type rawConnWrapper struct {
        cc io.ReadWriteCloser
        fr *http2.Framer

        // writing headers:
        headerBuf bytes.Buffer
        hpackEnc  *hpack.Encoder

        // reading frames:
        frc    chan http2.Frame
        frErrc chan error
}

func newRawConnWrapperFromConn(cc io.ReadWriteCloser) *rawConnWrapper <span class="cov8" title="1">{
        rcw := &amp;rawConnWrapper{
                cc:     cc,
                frc:    make(chan http2.Frame, 1),
                frErrc: make(chan error, 1),
        }
        rcw.hpackEnc = hpack.NewEncoder(&amp;rcw.headerBuf)
        rcw.fr = http2.NewFramer(cc, cc)
        rcw.fr.ReadMetaHeaders = hpack.NewDecoder(4096 /*initialHeaderTableSize*/, nil)

        return rcw
}</span>

func (rcw *rawConnWrapper) Close() error <span class="cov0" title="0">{
        return rcw.cc.Close()
}</span>

func (rcw *rawConnWrapper) encodeHeaderField(k, v string) error <span class="cov8" title="1">{
        err := rcw.hpackEnc.WriteField(hpack.HeaderField{Name: k, Value: v})
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("HPACK encoding error for %q/%q: %v", k, v, err)
        }</span>
        <span class="cov8" title="1">return nil</span>
}

// encodeRawHeader is for usage on both client and server side to construct header based on the input
// key, value pairs.
func (rcw *rawConnWrapper) encodeRawHeader(headers ...string) []byte <span class="cov8" title="1">{
        if len(headers)%2 == 1 </span><span class="cov0" title="0">{
                panic("odd number of kv args")</span>
        }

        <span class="cov8" title="1">rcw.headerBuf.Reset()

        pseudoCount := map[string]int{}
        var keys []string
        vals := map[string][]string{}

        for len(headers) &gt; 0 </span><span class="cov8" title="1">{
                k, v := headers[0], headers[1]
                headers = headers[2:]
                if _, ok := vals[k]; !ok </span><span class="cov8" title="1">{
                        keys = append(keys, k)
                }</span>
                <span class="cov8" title="1">if strings.HasPrefix(k, ":") </span><span class="cov0" title="0">{
                        pseudoCount[k]++
                        if pseudoCount[k] == 1 </span><span class="cov0" title="0">{
                                vals[k] = []string{v}
                        }</span> else<span class="cov0" title="0"> {
                                // Allows testing of invalid headers w/ dup pseudo fields.
                                vals[k] = append(vals[k], v)
                        }</span>
                } else<span class="cov8" title="1"> {
                        vals[k] = append(vals[k], v)
                }</span>
        }
        <span class="cov8" title="1">for _, k := range keys </span><span class="cov8" title="1">{
                for _, v := range vals[k] </span><span class="cov8" title="1">{
                        rcw.encodeHeaderField(k, v)
                }</span>
        }
        <span class="cov8" title="1">return rcw.headerBuf.Bytes()</span>
}

// encodeHeader is for usage on client side to write request header.
//
// encodeHeader encodes headers and returns their HPACK bytes. headers
// must contain an even number of key/value pairs.  There may be
// multiple pairs for keys (e.g. "cookie").  The :method, :path, and
// :scheme headers default to GET, / and https.
func (rcw *rawConnWrapper) encodeHeader(headers ...string) []byte <span class="cov8" title="1">{
        if len(headers)%2 == 1 </span><span class="cov0" title="0">{
                panic("odd number of kv args")</span>
        }

        <span class="cov8" title="1">rcw.headerBuf.Reset()

        if len(headers) == 0 </span><span class="cov0" title="0">{
                // Fast path, mostly for benchmarks, so test code doesn't pollute
                // profiles when we're looking to improve server allocations.
                rcw.encodeHeaderField(":method", "GET")
                rcw.encodeHeaderField(":path", "/")
                rcw.encodeHeaderField(":scheme", "https")
                return rcw.headerBuf.Bytes()
        }</span>

        <span class="cov8" title="1">if len(headers) == 2 &amp;&amp; headers[0] == ":method" </span><span class="cov0" title="0">{
                // Another fast path for benchmarks.
                rcw.encodeHeaderField(":method", headers[1])
                rcw.encodeHeaderField(":path", "/")
                rcw.encodeHeaderField(":scheme", "https")
                return rcw.headerBuf.Bytes()
        }</span>

        <span class="cov8" title="1">pseudoCount := map[string]int{}
        keys := []string{":method", ":path", ":scheme"}
        vals := map[string][]string{
                ":method": {"GET"},
                ":path":   {"/"},
                ":scheme": {"https"},
        }
        for len(headers) &gt; 0 </span><span class="cov8" title="1">{
                k, v := headers[0], headers[1]
                headers = headers[2:]
                if _, ok := vals[k]; !ok </span><span class="cov8" title="1">{
                        keys = append(keys, k)
                }</span>
                <span class="cov8" title="1">if strings.HasPrefix(k, ":") </span><span class="cov0" title="0">{
                        pseudoCount[k]++
                        if pseudoCount[k] == 1 </span><span class="cov0" title="0">{
                                vals[k] = []string{v}
                        }</span> else<span class="cov0" title="0"> {
                                // Allows testing of invalid headers w/ dup pseudo fields.
                                vals[k] = append(vals[k], v)
                        }</span>
                } else<span class="cov8" title="1"> {
                        vals[k] = append(vals[k], v)
                }</span>
        }
        <span class="cov8" title="1">for _, k := range keys </span><span class="cov8" title="1">{
                for _, v := range vals[k] </span><span class="cov8" title="1">{
                        rcw.encodeHeaderField(k, v)
                }</span>
        }
        <span class="cov8" title="1">return rcw.headerBuf.Bytes()</span>
}

func (rcw *rawConnWrapper) writeHeaders(p http2.HeadersFrameParam) error <span class="cov8" title="1">{
        if err := rcw.fr.WriteHeaders(p); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("error writing HEADERS: %v", err)
        }</span>
        <span class="cov8" title="1">return nil</span>
}

func (rcw *rawConnWrapper) writeRSTStream(streamID uint32, code http2.ErrCode) error <span class="cov8" title="1">{
        if err := rcw.fr.WriteRSTStream(streamID, code); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("error writing RST_STREAM: %v", err)
        }</span>
        <span class="cov8" title="1">return nil</span>
}

func (rcw *rawConnWrapper) writeGoAway(maxStreamID uint32, code http2.ErrCode, debugData []byte) error <span class="cov8" title="1">{
        if err := rcw.fr.WriteGoAway(maxStreamID, code, debugData); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("error writing GoAway: %v", err)
        }</span>
        <span class="cov8" title="1">return nil</span>
}

func (rcw *rawConnWrapper) writeRawFrame(t http2.FrameType, flags http2.Flags, streamID uint32, payload []byte) error <span class="cov8" title="1">{
        if err := rcw.fr.WriteRawFrame(t, flags, streamID, payload); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("error writing Raw Frame: %v", err)
        }</span>
        <span class="cov8" title="1">return nil</span>
}
</pre>
		
		<pre class="file" id="file141" style="display: none">/*
 * Copyright 2016 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// Package test contains tests.
package test

import (
        "bytes"
        "errors"
        "io"
        "strings"
        "testing"
        "time"

        "golang.org/x/net/http2"
        "golang.org/x/net/http2/hpack"
)

// This is a subset of http2's serverTester type.
//
// serverTester wraps a io.ReadWriter (acting like the underlying
// network connection) and provides utility methods to read and write
// http2 frames.
//
// NOTE(bradfitz): this could eventually be exported somewhere. Others
// have asked for it too. For now I'm still experimenting with the
// API and don't feel like maintaining a stable testing API.

type serverTester struct {
        cc io.ReadWriteCloser // client conn
        t  testing.TB
        fr *http2.Framer

        // writing headers:
        headerBuf bytes.Buffer
        hpackEnc  *hpack.Encoder

        // reading frames:
        frc    chan http2.Frame
        frErrc chan error
}

func newServerTesterFromConn(t testing.TB, cc io.ReadWriteCloser) *serverTester <span class="cov8" title="1">{
        st := &amp;serverTester{
                t:      t,
                cc:     cc,
                frc:    make(chan http2.Frame, 1),
                frErrc: make(chan error, 1),
        }
        st.hpackEnc = hpack.NewEncoder(&amp;st.headerBuf)
        st.fr = http2.NewFramer(cc, cc)
        st.fr.ReadMetaHeaders = hpack.NewDecoder(4096 /*initialHeaderTableSize*/, nil)

        return st
}</span>

func (st *serverTester) readFrame() (http2.Frame, error) <span class="cov8" title="1">{
        go func() </span><span class="cov8" title="1">{
                fr, err := st.fr.ReadFrame()
                if err != nil </span><span class="cov0" title="0">{
                        st.frErrc &lt;- err
                }</span> else<span class="cov8" title="1"> {
                        st.frc &lt;- fr
                }</span>
        }()
        <span class="cov8" title="1">t := time.NewTimer(2 * time.Second)
        defer t.Stop()
        select </span>{
        case f := &lt;-st.frc:<span class="cov8" title="1">
                return f, nil</span>
        case err := &lt;-st.frErrc:<span class="cov0" title="0">
                return nil, err</span>
        case &lt;-t.C:<span class="cov0" title="0">
                return nil, errors.New("timeout waiting for frame")</span>
        }
}

// greet initiates the client's HTTP/2 connection into a state where
// frames may be sent.
func (st *serverTester) greet() <span class="cov8" title="1">{
        st.writePreface()
        st.writeInitialSettings()
        st.wantSettings()
        st.writeSettingsAck()
        for </span><span class="cov8" title="1">{
                f, err := st.readFrame()
                if err != nil </span><span class="cov0" title="0">{
                        st.t.Fatal(err)
                }</span>
                <span class="cov8" title="1">switch f := f.(type) </span>{
                case *http2.WindowUpdateFrame:<span class="cov8" title="1"></span>
                        // grpc's transport/http2_server sends this
                        // before the settings ack. The Go http2
                        // server uses a setting instead.
                case *http2.SettingsFrame:<span class="cov8" title="1">
                        if f.IsAck() </span><span class="cov8" title="1">{
                                return
                        }</span>
                        <span class="cov0" title="0">st.t.Fatalf("during greet, got non-ACK settings frame")</span>
                default:<span class="cov0" title="0">
                        st.t.Fatalf("during greet, unexpected frame type %T", f)</span>
                }
        }
}

func (st *serverTester) writePreface() <span class="cov8" title="1">{
        n, err := st.cc.Write([]byte(http2.ClientPreface))
        if err != nil </span><span class="cov0" title="0">{
                st.t.Fatalf("Error writing client preface: %v", err)
        }</span>
        <span class="cov8" title="1">if n != len(http2.ClientPreface) </span><span class="cov0" title="0">{
                st.t.Fatalf("Writing client preface, wrote %d bytes; want %d", n, len(http2.ClientPreface))
        }</span>
}

func (st *serverTester) writeInitialSettings() <span class="cov8" title="1">{
        if err := st.fr.WriteSettings(); err != nil </span><span class="cov0" title="0">{
                st.t.Fatalf("Error writing initial SETTINGS frame from client to server: %v", err)
        }</span>
}

func (st *serverTester) writeSettingsAck() <span class="cov8" title="1">{
        if err := st.fr.WriteSettingsAck(); err != nil </span><span class="cov0" title="0">{
                st.t.Fatalf("Error writing ACK of server's SETTINGS: %v", err)
        }</span>
}

func (st *serverTester) wantRSTStream(errCode http2.ErrCode) *http2.RSTStreamFrame <span class="cov8" title="1">{
        f, err := st.readFrame()
        if err != nil </span><span class="cov0" title="0">{
                st.t.Fatalf("Error while expecting an RST frame: %v", err)
        }</span>
        <span class="cov8" title="1">sf, ok := f.(*http2.RSTStreamFrame)
        if !ok </span><span class="cov0" title="0">{
                st.t.Fatalf("got a %T; want *http2.RSTStreamFrame", f)
        }</span>
        <span class="cov8" title="1">if sf.ErrCode != errCode </span><span class="cov0" title="0">{
                st.t.Fatalf("expected RST error code '%v', got '%v'", errCode.String(), sf.ErrCode.String())
        }</span>
        <span class="cov8" title="1">return sf</span>
}

func (st *serverTester) wantSettings() *http2.SettingsFrame <span class="cov8" title="1">{
        f, err := st.readFrame()
        if err != nil </span><span class="cov0" title="0">{
                st.t.Fatalf("Error while expecting a SETTINGS frame: %v", err)
        }</span>
        <span class="cov8" title="1">sf, ok := f.(*http2.SettingsFrame)
        if !ok </span><span class="cov0" title="0">{
                st.t.Fatalf("got a %T; want *SettingsFrame", f)
        }</span>
        <span class="cov8" title="1">return sf</span>
}

// wait for any activity from the server
func (st *serverTester) wantAnyFrame() http2.Frame <span class="cov8" title="1">{
        f, err := st.fr.ReadFrame()
        if err != nil </span><span class="cov0" title="0">{
                st.t.Fatal(err)
        }</span>
        <span class="cov8" title="1">return f</span>
}

func (st *serverTester) encodeHeaderField(k, v string) <span class="cov8" title="1">{
        err := st.hpackEnc.WriteField(hpack.HeaderField{Name: k, Value: v})
        if err != nil </span><span class="cov0" title="0">{
                st.t.Fatalf("HPACK encoding error for %q/%q: %v", k, v, err)
        }</span>
}

// encodeHeader encodes headers and returns their HPACK bytes. headers
// must contain an even number of key/value pairs.  There may be
// multiple pairs for keys (e.g. "cookie").  The :method, :path, and
// :scheme headers default to GET, / and https.
func (st *serverTester) encodeHeader(headers ...string) []byte <span class="cov8" title="1">{
        if len(headers)%2 == 1 </span><span class="cov0" title="0">{
                panic("odd number of kv args")</span>
        }

        <span class="cov8" title="1">st.headerBuf.Reset()

        if len(headers) == 0 </span><span class="cov0" title="0">{
                // Fast path, mostly for benchmarks, so test code doesn't pollute
                // profiles when we're looking to improve server allocations.
                st.encodeHeaderField(":method", "GET")
                st.encodeHeaderField(":path", "/")
                st.encodeHeaderField(":scheme", "https")
                return st.headerBuf.Bytes()
        }</span>

        <span class="cov8" title="1">if len(headers) == 2 &amp;&amp; headers[0] == ":method" </span><span class="cov0" title="0">{
                // Another fast path for benchmarks.
                st.encodeHeaderField(":method", headers[1])
                st.encodeHeaderField(":path", "/")
                st.encodeHeaderField(":scheme", "https")
                return st.headerBuf.Bytes()
        }</span>

        <span class="cov8" title="1">pseudoCount := map[string]int{}
        keys := []string{":method", ":path", ":scheme"}
        vals := map[string][]string{
                ":method": {"GET"},
                ":path":   {"/"},
                ":scheme": {"https"},
        }
        for len(headers) &gt; 0 </span><span class="cov8" title="1">{
                k, v := headers[0], headers[1]
                headers = headers[2:]
                if _, ok := vals[k]; !ok </span><span class="cov8" title="1">{
                        keys = append(keys, k)
                }</span>
                <span class="cov8" title="1">if strings.HasPrefix(k, ":") </span><span class="cov8" title="1">{
                        pseudoCount[k]++
                        if pseudoCount[k] == 1 </span><span class="cov8" title="1">{
                                vals[k] = []string{v}
                        }</span> else<span class="cov0" title="0"> {
                                // Allows testing of invalid headers w/ dup pseudo fields.
                                vals[k] = append(vals[k], v)
                        }</span>
                } else<span class="cov8" title="1"> {
                        vals[k] = append(vals[k], v)
                }</span>
        }
        <span class="cov8" title="1">for _, k := range keys </span><span class="cov8" title="1">{
                for _, v := range vals[k] </span><span class="cov8" title="1">{
                        st.encodeHeaderField(k, v)
                }</span>
        }
        <span class="cov8" title="1">return st.headerBuf.Bytes()</span>
}

func (st *serverTester) writeHeadersGRPC(streamID uint32, path string, endStream bool) <span class="cov8" title="1">{
        st.writeHeaders(http2.HeadersFrameParam{
                StreamID: streamID,
                BlockFragment: st.encodeHeader(
                        ":method", "POST",
                        ":path", path,
                        "content-type", "application/grpc",
                        "te", "trailers",
                ),
                EndStream:  endStream,
                EndHeaders: true,
        })
}</span>

func (st *serverTester) writeHeaders(p http2.HeadersFrameParam) <span class="cov8" title="1">{
        if err := st.fr.WriteHeaders(p); err != nil </span><span class="cov0" title="0">{
                st.t.Fatalf("Error writing HEADERS: %v", err)
        }</span>
}

func (st *serverTester) writeData(streamID uint32, endStream bool, data []byte) <span class="cov8" title="1">{
        if err := st.fr.WriteData(streamID, endStream, data); err != nil </span><span class="cov0" title="0">{
                st.t.Fatalf("Error writing DATA: %v", err)
        }</span>
}

func (st *serverTester) writeRSTStream(streamID uint32, code http2.ErrCode) <span class="cov8" title="1">{
        if err := st.fr.WriteRSTStream(streamID, code); err != nil </span><span class="cov0" title="0">{
                st.t.Fatalf("Error writing RST_STREAM: %v", err)
        }</span>
}
</pre>
		
		<pre class="file" id="file142" style="display: none">/*
 *
 * Copyright 2015 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package grpc

import (
        "bytes"
        "fmt"
        "io"
        "net"
        "strings"
        "sync"
        "time"

        "golang.org/x/net/trace"
)

// EnableTracing controls whether to trace RPCs using the golang.org/x/net/trace package.
// This should only be set before any RPCs are sent or received by this program.
var EnableTracing bool

// methodFamily returns the trace family for the given method.
// It turns "/pkg.Service/GetFoo" into "pkg.Service".
func methodFamily(m string) string <span class="cov8" title="1">{
        m = strings.TrimPrefix(m, "/") // remove leading slash
        if i := strings.Index(m, "/"); i &gt;= 0 </span><span class="cov8" title="1">{
                m = m[:i] // remove everything from second slash
        }</span>
        <span class="cov8" title="1">return m</span>
}

// traceInfo contains tracing information for an RPC.
type traceInfo struct {
        tr        trace.Trace
        firstLine firstLine
}

// firstLine is the first line of an RPC trace.
// It may be mutated after construction; remoteAddr specifically may change
// during client-side use.
type firstLine struct {
        mu         sync.Mutex
        client     bool // whether this is a client (outgoing) RPC
        remoteAddr net.Addr
        deadline   time.Duration // may be zero
}

func (f *firstLine) SetRemoteAddr(addr net.Addr) <span class="cov0" title="0">{
        f.mu.Lock()
        f.remoteAddr = addr
        f.mu.Unlock()
}</span>

func (f *firstLine) String() string <span class="cov0" title="0">{
        f.mu.Lock()
        defer f.mu.Unlock()

        var line bytes.Buffer
        io.WriteString(&amp;line, "RPC: ")
        if f.client </span><span class="cov0" title="0">{
                io.WriteString(&amp;line, "to")
        }</span> else<span class="cov0" title="0"> {
                io.WriteString(&amp;line, "from")
        }</span>
        <span class="cov0" title="0">fmt.Fprintf(&amp;line, " %v deadline:", f.remoteAddr)
        if f.deadline != 0 </span><span class="cov0" title="0">{
                fmt.Fprint(&amp;line, f.deadline)
        }</span> else<span class="cov0" title="0"> {
                io.WriteString(&amp;line, "none")
        }</span>
        <span class="cov0" title="0">return line.String()</span>
}

const truncateSize = 100

func truncate(x string, l int) string <span class="cov0" title="0">{
        if l &gt; len(x) </span><span class="cov0" title="0">{
                return x
        }</span>
        <span class="cov0" title="0">return x[:l]</span>
}

// payload represents an RPC request or response payload.
type payload struct {
        sent bool        // whether this is an outgoing payload
        msg  interface{} // e.g. a proto.Message
        // TODO(dsymonds): add stringifying info to codec, and limit how much we hold here?
}

func (p payload) String() string <span class="cov0" title="0">{
        if p.sent </span><span class="cov0" title="0">{
                return truncate(fmt.Sprintf("sent: %v", p.msg), truncateSize)
        }</span>
        <span class="cov0" title="0">return truncate(fmt.Sprintf("recv: %v", p.msg), truncateSize)</span>
}

type fmtStringer struct {
        format string
        a      []interface{}
}

func (f *fmtStringer) String() string <span class="cov0" title="0">{
        return fmt.Sprintf(f.format, f.a...)
}</span>

type stringer string

func (s stringer) String() string <span class="cov0" title="0">{ return string(s) }</span>
</pre>
		
		<pre class="file" id="file143" style="display: none">/*
 *
 * Copyright 2022 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package bootstrap provides the functionality to register possible options
// for aspects of the xDS client through the bootstrap file.
//
// Experimental
//
// Notice: This package is EXPERIMENTAL and may be changed or removed
// in a later release.
package bootstrap

import (
        "encoding/json"

        "google.golang.org/grpc/credentials"
)

// registry is a map from credential type name to Credential builder.
var registry = make(map[string]Credentials)

// Credentials interface encapsulates a credentials.Bundle builder
// that can be used for communicating with the xDS Management server.
type Credentials interface {
        // Build returns a credential bundle associated with this credential.
        Build(config json.RawMessage) (credentials.Bundle, error)
        // Name returns the credential name associated with this credential.
        Name() string
}

// RegisterCredentials registers Credentials used for connecting to the xds
// management server.
//
// NOTE: this function must only be called during initialization time (i.e. in
// an init() function), and is not thread-safe. If multiple credentials are
// registered with the same name, the one registered last will take effect.
func RegisterCredentials(c Credentials) <span class="cov8" title="1">{
        registry[c.Name()] = c
}</span>

// GetCredentials returns the credentials associated with a given name.
// If no credentials are registered with the name, nil will be returned.
func GetCredentials(name string) Credentials <span class="cov8" title="1">{
        if c, ok := registry[name]; ok </span><span class="cov8" title="1">{
                return c
        }</span>

        <span class="cov0" title="0">return nil</span>
}
</pre>
		
		<pre class="file" id="file144" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package csds implements features to dump the status (xDS responses) the
// xds_client is using.
//
// Notice: This package is EXPERIMENTAL and may be changed or removed in a later
// release.
package csds

import (
        "context"
        "io"

        v3adminpb "github.com/envoyproxy/go-control-plane/envoy/admin/v3"
        v2corepb "github.com/envoyproxy/go-control-plane/envoy/api/v2/core"
        v3corepb "github.com/envoyproxy/go-control-plane/envoy/config/core/v3"
        v3statusgrpc "github.com/envoyproxy/go-control-plane/envoy/service/status/v3"
        v3statuspb "github.com/envoyproxy/go-control-plane/envoy/service/status/v3"
        "github.com/golang/protobuf/proto"
        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/grpclog"
        "google.golang.org/grpc/status"
        "google.golang.org/grpc/xds/internal/xdsclient"
        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource"
        "google.golang.org/protobuf/types/known/timestamppb"

        _ "google.golang.org/grpc/xds/internal/xdsclient/controller/version/v2" // Register v2 xds_client.
        _ "google.golang.org/grpc/xds/internal/xdsclient/controller/version/v3" // Register v3 xds_client.
)

var (
        logger       = grpclog.Component("xds")
        newXDSClient = func() xdsclient.XDSClient <span class="cov0" title="0">{
                c, err := xdsclient.New()
                if err != nil </span><span class="cov0" title="0">{
                        logger.Warningf("failed to create xds client: %v", err)
                        return nil
                }</span>
                <span class="cov0" title="0">return c</span>
        }
)

const (
        listenerTypeURL    = "envoy.config.listener.v3.Listener"
        routeConfigTypeURL = "envoy.config.route.v3.RouteConfiguration"
        clusterTypeURL     = "envoy.config.cluster.v3.Cluster"
        endpointsTypeURL   = "envoy.config.endpoint.v3.ClusterLoadAssignment"
)

// ClientStatusDiscoveryServer implementations interface ClientStatusDiscoveryServiceServer.
type ClientStatusDiscoveryServer struct {
        // xdsClient will always be the same in practice. But we keep a copy in each
        // server instance for testing.
        xdsClient xdsclient.XDSClient
}

// NewClientStatusDiscoveryServer returns an implementation of the CSDS server that can be
// registered on a gRPC server.
func NewClientStatusDiscoveryServer() (*ClientStatusDiscoveryServer, error) <span class="cov8" title="1">{
        return &amp;ClientStatusDiscoveryServer{xdsClient: newXDSClient()}, nil
}</span>

// StreamClientStatus implementations interface ClientStatusDiscoveryServiceServer.
func (s *ClientStatusDiscoveryServer) StreamClientStatus(stream v3statusgrpc.ClientStatusDiscoveryService_StreamClientStatusServer) error <span class="cov8" title="1">{
        for </span><span class="cov8" title="1">{
                req, err := stream.Recv()
                if err == io.EOF </span><span class="cov0" title="0">{
                        return nil
                }</span>
                <span class="cov8" title="1">if err != nil </span><span class="cov8" title="1">{
                        return err
                }</span>
                <span class="cov8" title="1">resp, err := s.buildClientStatusRespForReq(req)
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov8" title="1">if err := stream.Send(resp); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
        }
}

// FetchClientStatus implementations interface ClientStatusDiscoveryServiceServer.
func (s *ClientStatusDiscoveryServer) FetchClientStatus(_ context.Context, req *v3statuspb.ClientStatusRequest) (*v3statuspb.ClientStatusResponse, error) <span class="cov0" title="0">{
        return s.buildClientStatusRespForReq(req)
}</span>

// buildClientStatusRespForReq fetches the status from the client, and returns
// the response to be sent back to xdsclient.
//
// If it returns an error, the error is a status error.
func (s *ClientStatusDiscoveryServer) buildClientStatusRespForReq(req *v3statuspb.ClientStatusRequest) (*v3statuspb.ClientStatusResponse, error) <span class="cov8" title="1">{
        if s.xdsClient == nil </span><span class="cov8" title="1">{
                return &amp;v3statuspb.ClientStatusResponse{}, nil
        }</span>
        // Field NodeMatchers is unsupported, by design
        // https://github.com/grpc/proposal/blob/master/A40-csds-support.md#detail-node-matching.
        <span class="cov8" title="1">if len(req.NodeMatchers) != 0 </span><span class="cov0" title="0">{
                return nil, status.Errorf(codes.InvalidArgument, "node_matchers are not supported, request contains node_matchers: %v", req.NodeMatchers)
        }</span>

        <span class="cov8" title="1">lds := dumpToGenericXdsConfig(listenerTypeURL, s.xdsClient.DumpLDS)
        rds := dumpToGenericXdsConfig(routeConfigTypeURL, s.xdsClient.DumpRDS)
        cds := dumpToGenericXdsConfig(clusterTypeURL, s.xdsClient.DumpCDS)
        eds := dumpToGenericXdsConfig(endpointsTypeURL, s.xdsClient.DumpEDS)
        configs := make([]*v3statuspb.ClientConfig_GenericXdsConfig, 0, len(lds)+len(rds)+len(cds)+len(eds))
        configs = append(configs, lds...)
        configs = append(configs, rds...)
        configs = append(configs, cds...)
        configs = append(configs, eds...)

        ret := &amp;v3statuspb.ClientStatusResponse{
                Config: []*v3statuspb.ClientConfig{
                        {
                                Node:              nodeProtoToV3(s.xdsClient.BootstrapConfig().XDSServer.NodeProto),
                                GenericXdsConfigs: configs,
                        },
                },
        }
        return ret, nil</span>
}

// Close cleans up the resources.
func (s *ClientStatusDiscoveryServer) Close() <span class="cov8" title="1">{
        if s.xdsClient != nil </span><span class="cov8" title="1">{
                s.xdsClient.Close()
        }</span>
}

// nodeProtoToV3 converts the given proto into a v3.Node. n is from bootstrap
// config, it can be either v2.Node or v3.Node.
//
// If n is already a v3.Node, return it.
// If n is v2.Node, marshal and unmarshal it to v3.
// Otherwise, return nil.
//
// The default case (not v2 or v3) is nil, instead of error, because the
// resources in the response are more important than the node. The worst case is
// that the user will receive no Node info, but will still get resources.
func nodeProtoToV3(n proto.Message) *v3corepb.Node <span class="cov8" title="1">{
        var node *v3corepb.Node
        switch nn := n.(type) </span>{
        case *v3corepb.Node:<span class="cov8" title="1">
                node = nn</span>
        case *v2corepb.Node:<span class="cov8" title="1">
                v2, err := proto.Marshal(nn)
                if err != nil </span><span class="cov0" title="0">{
                        logger.Warningf("Failed to marshal node (%v): %v", n, err)
                        break</span>
                }
                <span class="cov8" title="1">node = new(v3corepb.Node)
                if err := proto.Unmarshal(v2, node); err != nil </span><span class="cov0" title="0">{
                        logger.Warningf("Failed to unmarshal node (%v): %v", v2, err)
                }</span>
        default:<span class="cov8" title="1">
                logger.Warningf("node from bootstrap is %#v, only v2.Node and v3.Node are supported", nn)</span>
        }
        <span class="cov8" title="1">return node</span>
}

func dumpToGenericXdsConfig(typeURL string, dumpF func() map[string]xdsresource.UpdateWithMD) []*v3statuspb.ClientConfig_GenericXdsConfig <span class="cov8" title="1">{
        dump := dumpF()
        ret := make([]*v3statuspb.ClientConfig_GenericXdsConfig, 0, len(dump))
        for name, d := range dump </span><span class="cov8" title="1">{
                config := &amp;v3statuspb.ClientConfig_GenericXdsConfig{
                        TypeUrl:      typeURL,
                        Name:         name,
                        VersionInfo:  d.MD.Version,
                        XdsConfig:    d.Raw,
                        LastUpdated:  timestamppb.New(d.MD.Timestamp),
                        ClientStatus: serviceStatusToProto(d.MD.Status),
                }
                if errState := d.MD.ErrState; errState != nil </span><span class="cov8" title="1">{
                        config.ErrorState = &amp;v3adminpb.UpdateFailureState{
                                LastUpdateAttempt: timestamppb.New(errState.Timestamp),
                                Details:           errState.Err.Error(),
                                VersionInfo:       errState.Version,
                        }
                }</span>
                <span class="cov8" title="1">ret = append(ret, config)</span>
        }
        <span class="cov8" title="1">return ret</span>
}

func serviceStatusToProto(serviceStatus xdsresource.ServiceStatus) v3adminpb.ClientResourceStatus <span class="cov8" title="1">{
        switch serviceStatus </span>{
        case xdsresource.ServiceStatusUnknown:<span class="cov0" title="0">
                return v3adminpb.ClientResourceStatus_UNKNOWN</span>
        case xdsresource.ServiceStatusRequested:<span class="cov8" title="1">
                return v3adminpb.ClientResourceStatus_REQUESTED</span>
        case xdsresource.ServiceStatusNotExist:<span class="cov0" title="0">
                return v3adminpb.ClientResourceStatus_DOES_NOT_EXIST</span>
        case xdsresource.ServiceStatusACKed:<span class="cov8" title="1">
                return v3adminpb.ClientResourceStatus_ACKED</span>
        case xdsresource.ServiceStatusNACKed:<span class="cov8" title="1">
                return v3adminpb.ClientResourceStatus_NACKED</span>
        default:<span class="cov0" title="0">
                return v3adminpb.ClientResourceStatus_UNKNOWN</span>
        }
}
</pre>
		
		<pre class="file" id="file145" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package googledirectpath implements a resolver that configures xds to make
// cloud to prod directpath connection.
//
// It's a combo of DNS and xDS resolvers. It delegates to DNS if
// - not on GCE, or
// - xDS bootstrap env var is set (so this client needs to do normal xDS, not
// direct path, and clients with this scheme is not part of the xDS mesh).
package googledirectpath

import (
        "fmt"
        "time"

        "google.golang.org/grpc"
        "google.golang.org/grpc/credentials/google"
        "google.golang.org/grpc/grpclog"
        "google.golang.org/grpc/internal/envconfig"
        "google.golang.org/grpc/internal/googlecloud"
        internalgrpclog "google.golang.org/grpc/internal/grpclog"
        "google.golang.org/grpc/internal/grpcrand"
        "google.golang.org/grpc/resolver"
        _ "google.golang.org/grpc/xds" // To register xds resolvers and balancers.
        "google.golang.org/grpc/xds/internal/xdsclient"
        "google.golang.org/grpc/xds/internal/xdsclient/bootstrap"
        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource/version"
        "google.golang.org/protobuf/types/known/structpb"

        v3corepb "github.com/envoyproxy/go-control-plane/envoy/config/core/v3"
)

const (
        c2pScheme = "google-c2p-experimental"

        tdURL          = "dns:///directpath-pa.googleapis.com"
        httpReqTimeout = 10 * time.Second
        zoneURL        = "http://metadata.google.internal/computeMetadata/v1/instance/zone"
        ipv6URL        = "http://metadata.google.internal/computeMetadata/v1/instance/network-interfaces/0/ipv6s"

        gRPCUserAgentName               = "gRPC Go"
        clientFeatureNoOverprovisioning = "envoy.lb.does_not_support_overprovisioning"
        ipv6CapableMetadataName         = "TRAFFICDIRECTOR_DIRECTPATH_C2P_IPV6_CAPABLE"

        logPrefix = "[google-c2p-resolver]"

        dnsName, xdsName = "dns", "xds"
)

// For overriding in unittests.
var (
        onGCE = googlecloud.OnGCE

        newClientWithConfig = func(config *bootstrap.Config) (xdsclient.XDSClient, error) <span class="cov0" title="0">{
                return xdsclient.NewWithConfig(config)
        }</span>

        logger = internalgrpclog.NewPrefixLogger(grpclog.Component("directpath"), logPrefix)
)

func init() <span class="cov8" title="1">{
        resolver.Register(c2pResolverBuilder{})
}</span>

type c2pResolverBuilder struct{}

func (c2pResolverBuilder) Build(t resolver.Target, cc resolver.ClientConn, opts resolver.BuildOptions) (resolver.Resolver, error) <span class="cov8" title="1">{
        if !runDirectPath() </span><span class="cov8" title="1">{
                // If not xDS, fallback to DNS.
                t.Scheme = dnsName
                return resolver.Get(dnsName).Build(t, cc, opts)
        }</span>

        // Note that the following calls to getZone() and getIPv6Capable() does I/O,
        // and has 10 seconds timeout each.
        //
        // This should be fine in most of the cases. In certain error cases, this
        // could block Dial() for up to 10 seconds (each blocking call has its own
        // goroutine).
        <span class="cov8" title="1">zoneCh, ipv6CapableCh := make(chan string), make(chan bool)
        go func() </span><span class="cov8" title="1">{ zoneCh &lt;- getZone(httpReqTimeout) }</span>()
        <span class="cov8" title="1">go func() </span><span class="cov8" title="1">{ ipv6CapableCh &lt;- getIPv6Capable(httpReqTimeout) }</span>()

        <span class="cov8" title="1">balancerName := envconfig.C2PResolverTestOnlyTrafficDirectorURI
        if balancerName == "" </span><span class="cov8" title="1">{
                balancerName = tdURL
        }</span>
        <span class="cov8" title="1">config := &amp;bootstrap.Config{
                XDSServer: &amp;bootstrap.ServerConfig{
                        ServerURI:    balancerName,
                        Creds:        grpc.WithCredentialsBundle(google.NewDefaultCredentials()),
                        TransportAPI: version.TransportV3,
                        NodeProto:    newNode(&lt;-zoneCh, &lt;-ipv6CapableCh),
                },
                ClientDefaultListenerResourceNameTemplate: "%s",
        }

        // Create singleton xds client with this config. The xds client will be
        // used by the xds resolver later.
        xdsC, err := newClientWithConfig(config)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to start xDS client: %v", err)
        }</span>

        // Create and return an xDS resolver.
        <span class="cov8" title="1">t.Scheme = xdsName
        xdsR, err := resolver.Get(xdsName).Build(t, cc, opts)
        if err != nil </span><span class="cov0" title="0">{
                xdsC.Close()
                return nil, err
        }</span>
        <span class="cov8" title="1">return &amp;c2pResolver{
                Resolver: xdsR,
                client:   xdsC,
        }, nil</span>
}

func (c2pResolverBuilder) Scheme() string <span class="cov8" title="1">{
        return c2pScheme
}</span>

type c2pResolver struct {
        resolver.Resolver
        client xdsclient.XDSClient
}

func (r *c2pResolver) Close() <span class="cov8" title="1">{
        r.Resolver.Close()
        r.client.Close()
}</span>

var ipv6EnabledMetadata = &amp;structpb.Struct{
        Fields: map[string]*structpb.Value{
                ipv6CapableMetadataName: structpb.NewBoolValue(true),
        },
}

var id = fmt.Sprintf("C2P-%d", grpcrand.Int())

// newNode makes a copy of defaultNode, and populate it's Metadata and
// Locality fields.
func newNode(zone string, ipv6Capable bool) *v3corepb.Node <span class="cov8" title="1">{
        ret := &amp;v3corepb.Node{
                // Not all required fields are set in defaultNote. Metadata will be set
                // if ipv6 is enabled. Locality will be set to the value from metadata.
                Id:                   id,
                UserAgentName:        gRPCUserAgentName,
                UserAgentVersionType: &amp;v3corepb.Node_UserAgentVersion{UserAgentVersion: grpc.Version},
                ClientFeatures:       []string{clientFeatureNoOverprovisioning},
        }
        ret.Locality = &amp;v3corepb.Locality{Zone: zone}
        if ipv6Capable </span><span class="cov8" title="1">{
                ret.Metadata = ipv6EnabledMetadata
        }</span>
        <span class="cov8" title="1">return ret</span>
}

// runDirectPath returns whether this resolver should use direct path.
//
// direct path is enabled if this client is running on GCE, and the normal xDS
// is not used (bootstrap env vars are not set).
func runDirectPath() bool <span class="cov8" title="1">{
        return envconfig.XDSBootstrapFileName == "" &amp;&amp; envconfig.XDSBootstrapFileContent == "" &amp;&amp; onGCE()
}</span>
</pre>
		
		<pre class="file" id="file146" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package googledirectpath

import (
        "bytes"
        "fmt"
        "io/ioutil"
        "net/http"
        "net/url"
        "sync"
        "time"
)

func getFromMetadata(timeout time.Duration, urlStr string) ([]byte, error) <span class="cov0" title="0">{
        parsedURL, err := url.Parse(urlStr)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">client := &amp;http.Client{Timeout: timeout}
        req := &amp;http.Request{
                Method: http.MethodGet,
                URL:    parsedURL,
                Header: http.Header{"Metadata-Flavor": {"Google"}},
        }
        resp, err := client.Do(req)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed communicating with metadata server: %v", err)
        }</span>
        <span class="cov0" title="0">defer resp.Body.Close()
        if resp.StatusCode != http.StatusOK </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("metadata server returned resp with non-OK: %v", resp)
        }</span>
        <span class="cov0" title="0">body, err := ioutil.ReadAll(resp.Body)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed reading from metadata server: %v", err)
        }</span>
        <span class="cov0" title="0">return body, nil</span>
}

var (
        zone     string
        zoneOnce sync.Once
)

// Defined as var to be overridden in tests.
var getZone = func(timeout time.Duration) string <span class="cov0" title="0">{
        zoneOnce.Do(func() </span><span class="cov0" title="0">{
                qualifiedZone, err := getFromMetadata(timeout, zoneURL)
                if err != nil </span><span class="cov0" title="0">{
                        logger.Warningf("could not discover instance zone: %v", err)
                        return
                }</span>
                <span class="cov0" title="0">i := bytes.LastIndexByte(qualifiedZone, '/')
                if i == -1 </span><span class="cov0" title="0">{
                        logger.Warningf("could not parse zone from metadata server: %s", qualifiedZone)
                        return
                }</span>
                <span class="cov0" title="0">zone = string(qualifiedZone[i+1:])</span>
        })
        <span class="cov0" title="0">return zone</span>
}

var (
        ipv6Capable     bool
        ipv6CapableOnce sync.Once
)

// Defined as var to be overridden in tests.
var getIPv6Capable = func(timeout time.Duration) bool <span class="cov0" title="0">{
        ipv6CapableOnce.Do(func() </span><span class="cov0" title="0">{
                _, err := getFromMetadata(timeout, ipv6URL)
                if err != nil </span><span class="cov0" title="0">{
                        logger.Warningf("could not discover ipv6 capability: %v", err)
                        return
                }</span>
                <span class="cov0" title="0">ipv6Capable = true</span>
        })
        <span class="cov0" title="0">return ipv6Capable</span>
}
</pre>
		
		<pre class="file" id="file147" style="display: none">/*
 * Copyright 2019 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// Package cdsbalancer implements a balancer to handle CDS responses.
package cdsbalancer

import (
        "encoding/json"
        "errors"
        "fmt"

        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/balancer/base"
        "google.golang.org/grpc/connectivity"
        "google.golang.org/grpc/credentials"
        "google.golang.org/grpc/credentials/tls/certprovider"
        "google.golang.org/grpc/internal/buffer"
        xdsinternal "google.golang.org/grpc/internal/credentials/xds"
        "google.golang.org/grpc/internal/envconfig"
        "google.golang.org/grpc/internal/grpclog"
        "google.golang.org/grpc/internal/grpcsync"
        "google.golang.org/grpc/internal/pretty"
        internalserviceconfig "google.golang.org/grpc/internal/serviceconfig"
        "google.golang.org/grpc/resolver"
        "google.golang.org/grpc/serviceconfig"
        "google.golang.org/grpc/xds/internal/balancer/clusterresolver"
        "google.golang.org/grpc/xds/internal/balancer/outlierdetection"
        "google.golang.org/grpc/xds/internal/balancer/ringhash"
        "google.golang.org/grpc/xds/internal/xdsclient"
        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource"
)

const (
        cdsName = "cds_experimental"
)

var (
        errBalancerClosed = errors.New("cdsBalancer is closed")

        // newChildBalancer is a helper function to build a new cluster_resolver
        // balancer and will be overridden in unittests.
        newChildBalancer = func(cc balancer.ClientConn, opts balancer.BuildOptions) (balancer.Balancer, error) <span class="cov0" title="0">{
                builder := balancer.Get(clusterresolver.Name)
                if builder == nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("xds: no balancer builder with name %v", clusterresolver.Name)
                }</span>
                // We directly pass the parent clientConn to the underlying
                // cluster_resolver balancer because the cdsBalancer does not deal with
                // subConns.
                <span class="cov0" title="0">return builder.Build(cc, opts), nil</span>
        }
        buildProvider = buildProviderFunc
)

func init() <span class="cov8" title="1">{
        balancer.Register(bb{})
}</span>

// bb implements the balancer.Builder interface to help build a cdsBalancer.
// It also implements the balancer.ConfigParser interface to help parse the
// JSON service config, to be passed to the cdsBalancer.
type bb struct{}

// Build creates a new CDS balancer with the ClientConn.
func (bb) Build(cc balancer.ClientConn, opts balancer.BuildOptions) balancer.Balancer <span class="cov8" title="1">{
        b := &amp;cdsBalancer{
                bOpts:    opts,
                updateCh: buffer.NewUnbounded(),
                closed:   grpcsync.NewEvent(),
                done:     grpcsync.NewEvent(),
                xdsHI:    xdsinternal.NewHandshakeInfo(nil, nil),
        }
        b.logger = prefixLogger((b))
        b.logger.Infof("Created")
        var creds credentials.TransportCredentials
        switch </span>{
        case opts.DialCreds != nil:<span class="cov8" title="1">
                creds = opts.DialCreds</span>
        case opts.CredsBundle != nil:<span class="cov0" title="0">
                creds = opts.CredsBundle.TransportCredentials()</span>
        }
        <span class="cov8" title="1">if xc, ok := creds.(interface{ UsesXDS() bool }); ok &amp;&amp; xc.UsesXDS() </span><span class="cov8" title="1">{
                b.xdsCredsInUse = true
        }</span>
        <span class="cov8" title="1">b.logger.Infof("xDS credentials in use: %v", b.xdsCredsInUse)
        b.clusterHandler = newClusterHandler(b)
        b.ccw = &amp;ccWrapper{
                ClientConn: cc,
                xdsHI:      b.xdsHI,
        }
        go b.run()
        return b</span>
}

// Name returns the name of balancers built by this builder.
func (bb) Name() string <span class="cov8" title="1">{
        return cdsName
}</span>

// lbConfig represents the loadBalancingConfig section of the service config
// for the cdsBalancer.
type lbConfig struct {
        serviceconfig.LoadBalancingConfig
        ClusterName string `json:"Cluster"`
}

// ParseConfig parses the JSON load balancer config provided into an
// internal form or returns an error if the config is invalid.
func (bb) ParseConfig(c json.RawMessage) (serviceconfig.LoadBalancingConfig, error) <span class="cov8" title="1">{
        var cfg lbConfig
        if err := json.Unmarshal(c, &amp;cfg); err != nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("xds: unable to unmarshal lbconfig: %s, error: %v", string(c), err)
        }</span>
        <span class="cov8" title="1">return &amp;cfg, nil</span>
}

// ccUpdate wraps a clientConn update received from gRPC (pushed from the
// xdsResolver). A valid clusterName causes the cdsBalancer to register a CDS
// watcher with the xdsClient, while a non-nil error causes it to cancel the
// existing watch and propagate the error to the underlying cluster_resolver
// balancer.
type ccUpdate struct {
        clusterName string
        err         error
}

// scUpdate wraps a subConn update received from gRPC. This is directly passed
// on to the cluster_resolver balancer.
type scUpdate struct {
        subConn balancer.SubConn
        state   balancer.SubConnState
}

type exitIdle struct{}

// cdsBalancer implements a CDS based LB policy. It instantiates a
// cluster_resolver balancer to further resolve the serviceName received from
// CDS, into localities and endpoints. Implements the balancer.Balancer
// interface which is exposed to gRPC and implements the balancer.ClientConn
// interface which is exposed to the cluster_resolver balancer.
type cdsBalancer struct {
        ccw            *ccWrapper            // ClientConn interface passed to child LB.
        bOpts          balancer.BuildOptions // BuildOptions passed to child LB.
        updateCh       *buffer.Unbounded     // Channel for gRPC and xdsClient updates.
        xdsClient      xdsclient.XDSClient   // xDS client to watch Cluster resource.
        clusterHandler *clusterHandler       // To watch the clusters.
        childLB        balancer.Balancer
        logger         *grpclog.PrefixLogger
        closed         *grpcsync.Event
        done           *grpcsync.Event

        // The certificate providers are cached here to that they can be closed when
        // a new provider is to be created.
        cachedRoot     certprovider.Provider
        cachedIdentity certprovider.Provider
        xdsHI          *xdsinternal.HandshakeInfo
        xdsCredsInUse  bool
}

// handleClientConnUpdate handles a ClientConnUpdate received from gRPC. Good
// updates lead to registration of a CDS watch. Updates with error lead to
// cancellation of existing watch and propagation of the same error to the
// cluster_resolver balancer.
func (b *cdsBalancer) handleClientConnUpdate(update *ccUpdate) <span class="cov8" title="1">{
        // We first handle errors, if any, and then proceed with handling the
        // update, only if the status quo has changed.
        if err := update.err; err != nil </span><span class="cov8" title="1">{
                b.handleErrorFromUpdate(err, true)
                return
        }</span>
        <span class="cov8" title="1">b.clusterHandler.updateRootCluster(update.clusterName)</span>
}

// handleSecurityConfig processes the security configuration received from the
// management server, creates appropriate certificate provider plugins, and
// updates the HandhakeInfo which is added as an address attribute in
// NewSubConn() calls.
func (b *cdsBalancer) handleSecurityConfig(config *xdsresource.SecurityConfig) error <span class="cov8" title="1">{
        // If xdsCredentials are not in use, i.e, the user did not want to get
        // security configuration from an xDS server, we should not be acting on the
        // received security config here. Doing so poses a security threat.
        if !b.xdsCredsInUse </span><span class="cov8" title="1">{
                return nil
        }</span>

        // Security config being nil is a valid case where the management server has
        // not sent any security configuration. The xdsCredentials implementation
        // handles this by delegating to its fallback credentials.
        <span class="cov8" title="1">if config == nil </span><span class="cov8" title="1">{
                // We need to explicitly set the fields to nil here since this might be
                // a case of switching from a good security configuration to an empty
                // one where fallback credentials are to be used.
                b.xdsHI.SetRootCertProvider(nil)
                b.xdsHI.SetIdentityCertProvider(nil)
                b.xdsHI.SetSANMatchers(nil)
                return nil
        }</span>

        <span class="cov8" title="1">bc := b.xdsClient.BootstrapConfig()
        if bc == nil || bc.CertProviderConfigs == nil </span><span class="cov8" title="1">{
                // Bootstrap did not find any certificate provider configs, but the user
                // has specified xdsCredentials and the management server has sent down
                // security configuration.
                return errors.New("xds: certificate_providers config missing in bootstrap file")
        }</span>
        <span class="cov8" title="1">cpc := bc.CertProviderConfigs

        // A root provider is required whether we are using TLS or mTLS.
        rootProvider, err := buildProvider(cpc, config.RootInstanceName, config.RootCertName, false, true)
        if err != nil </span><span class="cov8" title="1">{
                return err
        }</span>

        // The identity provider is only present when using mTLS.
        <span class="cov8" title="1">var identityProvider certprovider.Provider
        if name, cert := config.IdentityInstanceName, config.IdentityCertName; name != "" </span><span class="cov8" title="1">{
                var err error
                identityProvider, err = buildProvider(cpc, name, cert, true, false)
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
        }

        // Close the old providers and cache the new ones.
        <span class="cov8" title="1">if b.cachedRoot != nil </span><span class="cov8" title="1">{
                b.cachedRoot.Close()
        }</span>
        <span class="cov8" title="1">if b.cachedIdentity != nil </span><span class="cov0" title="0">{
                b.cachedIdentity.Close()
        }</span>
        <span class="cov8" title="1">b.cachedRoot = rootProvider
        b.cachedIdentity = identityProvider

        // We set all fields here, even if some of them are nil, since they
        // could have been non-nil earlier.
        b.xdsHI.SetRootCertProvider(rootProvider)
        b.xdsHI.SetIdentityCertProvider(identityProvider)
        b.xdsHI.SetSANMatchers(config.SubjectAltNameMatchers)
        return nil</span>
}

func buildProviderFunc(configs map[string]*certprovider.BuildableConfig, instanceName, certName string, wantIdentity, wantRoot bool) (certprovider.Provider, error) <span class="cov8" title="1">{
        cfg, ok := configs[instanceName]
        if !ok </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("certificate provider instance %q not found in bootstrap file", instanceName)
        }</span>
        <span class="cov8" title="1">provider, err := cfg.Build(certprovider.BuildOptions{
                CertName:     certName,
                WantIdentity: wantIdentity,
                WantRoot:     wantRoot,
        })
        if err != nil </span><span class="cov0" title="0">{
                // This error is not expected since the bootstrap process parses the
                // config and makes sure that it is acceptable to the plugin. Still, it
                // is possible that the plugin parses the config successfully, but its
                // Build() method errors out.
                return nil, fmt.Errorf("xds: failed to get security plugin instance (%+v): %v", cfg, err)
        }</span>
        <span class="cov8" title="1">return provider, nil</span>
}

func outlierDetectionToConfig(od *xdsresource.OutlierDetection) outlierdetection.LBConfig <span class="cov8" title="1">{ // Already validated - no need to return error
        if od == nil </span><span class="cov8" title="1">{
                // "If the outlier_detection field is not set in the Cluster message, a
                // "no-op" outlier_detection config will be generated, with interval set
                // to the maximum possible value and all other fields unset." - A50
                return outlierdetection.LBConfig{
                        Interval: 1&lt;&lt;63 - 1,
                }
        }</span>

        // "if the enforcing_success_rate field is set to 0, the config
        // success_rate_ejection field will be null and all success_rate_* fields
        // will be ignored." - A50
        <span class="cov8" title="1">var sre *outlierdetection.SuccessRateEjection
        if od.EnforcingSuccessRate != 0 </span><span class="cov8" title="1">{
                sre = &amp;outlierdetection.SuccessRateEjection{
                        StdevFactor:           od.SuccessRateStdevFactor,
                        EnforcementPercentage: od.EnforcingSuccessRate,
                        MinimumHosts:          od.SuccessRateMinimumHosts,
                        RequestVolume:         od.SuccessRateRequestVolume,
                }
        }</span>

        // "If the enforcing_failure_percent field is set to 0 or null, the config
        // failure_percent_ejection field will be null and all failure_percent_*
        // fields will be ignored." - A50
        <span class="cov8" title="1">var fpe *outlierdetection.FailurePercentageEjection
        if od.EnforcingFailurePercentage != 0 </span><span class="cov8" title="1">{
                fpe = &amp;outlierdetection.FailurePercentageEjection{
                        Threshold:             od.FailurePercentageThreshold,
                        EnforcementPercentage: od.EnforcingFailurePercentage,
                        MinimumHosts:          od.FailurePercentageMinimumHosts,
                        RequestVolume:         od.FailurePercentageRequestVolume,
                }
        }</span>

        <span class="cov8" title="1">return outlierdetection.LBConfig{
                Interval:                  od.Interval,
                BaseEjectionTime:          od.BaseEjectionTime,
                MaxEjectionTime:           od.MaxEjectionTime,
                MaxEjectionPercent:        od.MaxEjectionPercent,
                SuccessRateEjection:       sre,
                FailurePercentageEjection: fpe,
        }</span>
}

// handleWatchUpdate handles a watch update from the xDS Client. Good updates
// lead to clientConn updates being invoked on the underlying cluster_resolver balancer.
func (b *cdsBalancer) handleWatchUpdate(update clusterHandlerUpdate) <span class="cov8" title="1">{
        if err := update.err; err != nil </span><span class="cov8" title="1">{
                b.logger.Warningf("Watch error from xds-client %p: %v", b.xdsClient, err)
                b.handleErrorFromUpdate(err, false)
                return
        }</span>

        <span class="cov8" title="1">b.logger.Infof("Watch update from xds-client %p, content: %+v, security config: %v", b.xdsClient, pretty.ToJSON(update.updates), pretty.ToJSON(update.securityCfg))

        // Process the security config from the received update before building the
        // child policy or forwarding the update to it. We do this because the child
        // policy may try to create a new subConn inline. Processing the security
        // configuration here and setting up the handshakeInfo will make sure that
        // such attempts are handled properly.
        if err := b.handleSecurityConfig(update.securityCfg); err != nil </span><span class="cov8" title="1">{
                // If the security config is invalid, for example, if the provider
                // instance is not found in the bootstrap config, we need to put the
                // channel in transient failure.
                b.logger.Warningf("Invalid security config update from xds-client %p: %v", b.xdsClient, err)
                b.handleErrorFromUpdate(err, false)
                return
        }</span>

        // The first good update from the watch API leads to the instantiation of an
        // cluster_resolver balancer. Further updates/errors are propagated to the existing
        // cluster_resolver balancer.
        <span class="cov8" title="1">if b.childLB == nil </span><span class="cov8" title="1">{
                childLB, err := newChildBalancer(b.ccw, b.bOpts)
                if err != nil </span><span class="cov0" title="0">{
                        b.logger.Errorf("Failed to create child policy of type %s, %v", clusterresolver.Name, err)
                        return
                }</span>
                <span class="cov8" title="1">b.childLB = childLB
                b.logger.Infof("Created child policy %p of type %s", b.childLB, clusterresolver.Name)</span>
        }

        <span class="cov8" title="1">dms := make([]clusterresolver.DiscoveryMechanism, len(update.updates))
        for i, cu := range update.updates </span><span class="cov8" title="1">{
                switch cu.ClusterType </span>{
                case xdsresource.ClusterTypeEDS:<span class="cov8" title="1">
                        dms[i] = clusterresolver.DiscoveryMechanism{
                                Type:                  clusterresolver.DiscoveryMechanismTypeEDS,
                                Cluster:               cu.ClusterName,
                                EDSServiceName:        cu.EDSServiceName,
                                MaxConcurrentRequests: cu.MaxRequests,
                        }
                        if cu.LRSServerConfig == xdsresource.ClusterLRSServerSelf </span><span class="cov8" title="1">{
                                bootstrapConfig := b.xdsClient.BootstrapConfig()
                                parsedName := xdsresource.ParseName(cu.ClusterName)
                                if parsedName.Scheme == xdsresource.FederationScheme </span><span class="cov0" title="0">{
                                        // Is a federation resource name, find the corresponding
                                        // authority server config.
                                        if cfg, ok := bootstrapConfig.Authorities[parsedName.Authority]; ok </span><span class="cov0" title="0">{
                                                dms[i].LoadReportingServer = cfg.XDSServer
                                        }</span>
                                } else<span class="cov8" title="1"> {
                                        // Not a federation resource name, use the default
                                        // authority.
                                        dms[i].LoadReportingServer = bootstrapConfig.XDSServer
                                }</span>
                        }
                case xdsresource.ClusterTypeLogicalDNS:<span class="cov0" title="0">
                        dms[i] = clusterresolver.DiscoveryMechanism{
                                Type:        clusterresolver.DiscoveryMechanismTypeLogicalDNS,
                                Cluster:     cu.ClusterName,
                                DNSHostname: cu.DNSHostName,
                        }</span>
                default:<span class="cov0" title="0">
                        b.logger.Infof("unexpected cluster type %v when handling update from cluster handler", cu.ClusterType)</span>
                }
                <span class="cov8" title="1">if envconfig.XDSOutlierDetection </span><span class="cov8" title="1">{
                        dms[i].OutlierDetection = outlierDetectionToConfig(cu.OutlierDetection)
                }</span>
        }
        <span class="cov8" title="1">lbCfg := &amp;clusterresolver.LBConfig{
                DiscoveryMechanisms: dms,
        }

        // lbPolicy is set only when the policy is ringhash. The default (when it's
        // not set) is roundrobin. And similarly, we only need to set XDSLBPolicy
        // for ringhash (it also defaults to roundrobin).
        if lbp := update.lbPolicy; lbp != nil </span><span class="cov8" title="1">{
                lbCfg.XDSLBPolicy = &amp;internalserviceconfig.BalancerConfig{
                        Name: ringhash.Name,
                        Config: &amp;ringhash.LBConfig{
                                MinRingSize: lbp.MinimumRingSize,
                                MaxRingSize: lbp.MaximumRingSize,
                        },
                }
        }</span>

        <span class="cov8" title="1">ccState := balancer.ClientConnState{
                ResolverState:  xdsclient.SetClient(resolver.State{}, b.xdsClient),
                BalancerConfig: lbCfg,
        }
        if err := b.childLB.UpdateClientConnState(ccState); err != nil </span><span class="cov0" title="0">{
                b.logger.Errorf("xds: cluster_resolver balancer.UpdateClientConnState(%+v) returned error: %v", ccState, err)
        }</span>
}

// run is a long-running goroutine which handles all updates from gRPC. All
// methods which are invoked directly by gRPC or xdsClient simply push an
// update onto a channel which is read and acted upon right here.
func (b *cdsBalancer) run() <span class="cov8" title="1">{
        for </span><span class="cov8" title="1">{
                select </span>{
                case u := &lt;-b.updateCh.Get():<span class="cov8" title="1">
                        b.updateCh.Load()
                        switch update := u.(type) </span>{
                        case *ccUpdate:<span class="cov8" title="1">
                                b.handleClientConnUpdate(update)</span>
                        case *scUpdate:<span class="cov8" title="1">
                                // SubConn updates are passthrough and are simply handed over to
                                // the underlying cluster_resolver balancer.
                                if b.childLB == nil </span><span class="cov0" title="0">{
                                        b.logger.Errorf("xds: received scUpdate {%+v} with no cluster_resolver balancer", update)
                                        break</span>
                                }
                                <span class="cov8" title="1">b.childLB.UpdateSubConnState(update.subConn, update.state)</span>
                        case exitIdle:<span class="cov8" title="1">
                                if b.childLB == nil </span><span class="cov0" title="0">{
                                        b.logger.Errorf("xds: received ExitIdle with no child balancer")
                                        break</span>
                                }
                                // This implementation assumes the child balancer supports
                                // ExitIdle (but still checks for the interface's existence to
                                // avoid a panic if not).  If the child does not, no subconns
                                // will be connected.
                                <span class="cov8" title="1">if ei, ok := b.childLB.(balancer.ExitIdler); ok </span><span class="cov8" title="1">{
                                        ei.ExitIdle()
                                }</span>
                        }
                case u := &lt;-b.clusterHandler.updateChannel:<span class="cov8" title="1">
                        b.handleWatchUpdate(u)</span>
                case &lt;-b.closed.Done():<span class="cov8" title="1">
                        b.clusterHandler.close()
                        if b.childLB != nil </span><span class="cov8" title="1">{
                                b.childLB.Close()
                                b.childLB = nil
                        }</span>
                        <span class="cov8" title="1">if b.cachedRoot != nil </span><span class="cov8" title="1">{
                                b.cachedRoot.Close()
                        }</span>
                        <span class="cov8" title="1">if b.cachedIdentity != nil </span><span class="cov8" title="1">{
                                b.cachedIdentity.Close()
                        }</span>
                        <span class="cov8" title="1">b.logger.Infof("Shutdown")
                        b.done.Fire()
                        return</span>
                }
        }
}

// handleErrorFromUpdate handles both the error from parent ClientConn (from
// resolver) and the error from xds client (from the watcher). fromParent is
// true if error is from parent ClientConn.
//
// If the error is connection error, it's passed down to the child policy.
// Nothing needs to be done in CDS (e.g. it doesn't go into fallback).
//
// If the error is resource-not-found:
// - If it's from resolver, it means LDS resources were removed. The CDS watch
// should be canceled.
// - If it's from xds client, it means CDS resource were removed. The CDS
// watcher should keep watching.
//
// In both cases, the error will be forwarded to the child balancer. And if
// error is resource-not-found, the child balancer will stop watching EDS.
func (b *cdsBalancer) handleErrorFromUpdate(err error, fromParent bool) <span class="cov8" title="1">{
        // This is not necessary today, because xds client never sends connection
        // errors.
        if fromParent &amp;&amp; xdsresource.ErrType(err) == xdsresource.ErrorTypeResourceNotFound </span><span class="cov8" title="1">{
                b.clusterHandler.close()
        }</span>
        <span class="cov8" title="1">if b.childLB != nil </span><span class="cov8" title="1">{
                if xdsresource.ErrType(err) != xdsresource.ErrorTypeConnection </span><span class="cov8" title="1">{
                        // Connection errors will be sent to the child balancers directly.
                        // There's no need to forward them.
                        b.childLB.ResolverError(err)
                }</span>
        } else<span class="cov8" title="1"> {
                // If child balancer was never created, fail the RPCs with
                // errors.
                b.ccw.UpdateState(balancer.State{
                        ConnectivityState: connectivity.TransientFailure,
                        Picker:            base.NewErrPicker(err),
                })
        }</span>
}

// UpdateClientConnState receives the serviceConfig (which contains the
// clusterName to watch for in CDS) and the xdsClient object from the
// xdsResolver.
func (b *cdsBalancer) UpdateClientConnState(state balancer.ClientConnState) error <span class="cov8" title="1">{
        if b.closed.HasFired() </span><span class="cov8" title="1">{
                b.logger.Warningf("xds: received ClientConnState {%+v} after cdsBalancer was closed", state)
                return errBalancerClosed
        }</span>

        <span class="cov8" title="1">if b.xdsClient == nil </span><span class="cov8" title="1">{
                c := xdsclient.FromResolverState(state.ResolverState)
                if c == nil </span><span class="cov8" title="1">{
                        return balancer.ErrBadResolverState
                }</span>
                <span class="cov8" title="1">b.xdsClient = c</span>
        }

        <span class="cov8" title="1">b.logger.Infof("Received update from resolver, balancer config: %+v", pretty.ToJSON(state.BalancerConfig))
        // The errors checked here should ideally never happen because the
        // ServiceConfig in this case is prepared by the xdsResolver and is not
        // something that is received on the wire.
        lbCfg, ok := state.BalancerConfig.(*lbConfig)
        if !ok </span><span class="cov0" title="0">{
                b.logger.Warningf("xds: unexpected LoadBalancingConfig type: %T", state.BalancerConfig)
                return balancer.ErrBadResolverState
        }</span>
        <span class="cov8" title="1">if lbCfg.ClusterName == "" </span><span class="cov0" title="0">{
                b.logger.Warningf("xds: no clusterName found in LoadBalancingConfig: %+v", lbCfg)
                return balancer.ErrBadResolverState
        }</span>
        <span class="cov8" title="1">b.updateCh.Put(&amp;ccUpdate{clusterName: lbCfg.ClusterName})
        return nil</span>
}

// ResolverError handles errors reported by the xdsResolver.
func (b *cdsBalancer) ResolverError(err error) <span class="cov8" title="1">{
        if b.closed.HasFired() </span><span class="cov8" title="1">{
                b.logger.Warningf("xds: received resolver error {%v} after cdsBalancer was closed", err)
                return
        }</span>
        <span class="cov8" title="1">b.updateCh.Put(&amp;ccUpdate{err: err})</span>
}

// UpdateSubConnState handles subConn updates from gRPC.
func (b *cdsBalancer) UpdateSubConnState(sc balancer.SubConn, state balancer.SubConnState) <span class="cov8" title="1">{
        if b.closed.HasFired() </span><span class="cov8" title="1">{
                b.logger.Warningf("xds: received subConn update {%v, %v} after cdsBalancer was closed", sc, state)
                return
        }</span>
        <span class="cov8" title="1">b.updateCh.Put(&amp;scUpdate{subConn: sc, state: state})</span>
}

// Close cancels the CDS watch, closes the child policy and closes the
// cdsBalancer.
func (b *cdsBalancer) Close() <span class="cov8" title="1">{
        b.closed.Fire()
        &lt;-b.done.Done()
}</span>

func (b *cdsBalancer) ExitIdle() <span class="cov8" title="1">{
        b.updateCh.Put(exitIdle{})
}</span>

// ccWrapper wraps the balancer.ClientConn passed to the CDS balancer at
// creation and intercepts the NewSubConn() and UpdateAddresses() call from the
// child policy to add security configuration required by xDS credentials.
//
// Other methods of the balancer.ClientConn interface are not overridden and
// hence get the original implementation.
type ccWrapper struct {
        balancer.ClientConn

        // The certificate providers in this HandshakeInfo are updated based on the
        // received security configuration in the Cluster resource.
        xdsHI *xdsinternal.HandshakeInfo
}

// NewSubConn intercepts NewSubConn() calls from the child policy and adds an
// address attribute which provides all information required by the xdsCreds
// handshaker to perform the TLS handshake.
func (ccw *ccWrapper) NewSubConn(addrs []resolver.Address, opts balancer.NewSubConnOptions) (balancer.SubConn, error) <span class="cov8" title="1">{
        newAddrs := make([]resolver.Address, len(addrs))
        for i, addr := range addrs </span><span class="cov8" title="1">{
                newAddrs[i] = xdsinternal.SetHandshakeInfo(addr, ccw.xdsHI)
        }</span>
        <span class="cov8" title="1">return ccw.ClientConn.NewSubConn(newAddrs, opts)</span>
}

func (ccw *ccWrapper) UpdateAddresses(sc balancer.SubConn, addrs []resolver.Address) <span class="cov8" title="1">{
        newAddrs := make([]resolver.Address, len(addrs))
        for i, addr := range addrs </span><span class="cov8" title="1">{
                newAddrs[i] = xdsinternal.SetHandshakeInfo(addr, ccw.xdsHI)
        }</span>
        <span class="cov8" title="1">ccw.ClientConn.UpdateAddresses(sc, newAddrs)</span>
}
</pre>
		
		<pre class="file" id="file148" style="display: none">/*
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package cdsbalancer

import (
        "errors"
        "sync"

        "google.golang.org/grpc/xds/internal/xdsclient"
        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource"
)

const maxDepth = 16

var (
        errNotReceivedUpdate = errors.New("tried to construct a cluster update on a cluster that has not received an update")
        errExceedsMaxDepth   = errors.New("aggregate cluster graph exceeds max depth")
)

// clusterHandlerUpdate wraps the information received from the registered CDS
// watcher. A non-nil error is propagated to the underlying cluster_resolver
// balancer. A valid update results in creating a new cluster_resolver balancer
// (if one doesn't already exist) and pushing the update to it.
type clusterHandlerUpdate struct {
        // securityCfg is the Security Config from the top (root) cluster.
        securityCfg *xdsresource.SecurityConfig
        // lbPolicy is the lb policy from the top (root) cluster.
        //
        // Currently, we only support roundrobin or ringhash, and since roundrobin
        // does need configs, this is only set to the ringhash config, if the policy
        // is ringhash. In the future, if we support more policies, we can make this
        // an interface, and set it to config of the other policies.
        lbPolicy *xdsresource.ClusterLBPolicyRingHash

        // updates is a list of ClusterUpdates from all the leaf clusters.
        updates []xdsresource.ClusterUpdate
        err     error
}

// clusterHandler will be given a name representing a cluster. It will then
// update the CDS policy constantly with a list of Clusters to pass down to
// XdsClusterResolverLoadBalancingPolicyConfig in a stream like fashion.
type clusterHandler struct {
        parent *cdsBalancer

        // A mutex to protect entire tree of clusters.
        clusterMutex    sync.Mutex
        rootClusterName string

        createdClusters map[string]*clusterNode

        // A way to ping CDS Balancer about any updates or errors to a Node in the
        // tree. This will either get called from this handler constructing an
        // update or from a child with an error. Capacity of one as the only update
        // CDS Balancer cares about is the most recent update.
        updateChannel chan clusterHandlerUpdate
}

func newClusterHandler(parent *cdsBalancer) *clusterHandler <span class="cov8" title="1">{
        return &amp;clusterHandler{
                parent:          parent,
                updateChannel:   make(chan clusterHandlerUpdate, 1),
                createdClusters: make(map[string]*clusterNode),
        }
}</span>

func (ch *clusterHandler) updateRootCluster(rootClusterName string) <span class="cov8" title="1">{
        ch.clusterMutex.Lock()
        defer ch.clusterMutex.Unlock()
        if ch.createdClusters[ch.rootClusterName] == nil </span><span class="cov8" title="1">{
                // Construct a root node on first update.
                createClusterNode(rootClusterName, ch.parent.xdsClient, ch, 0)
                ch.rootClusterName = rootClusterName
                return
        }</span>
        // Check if root cluster was changed. If it was, delete old one and start
        // new one, if not do nothing.
        <span class="cov8" title="1">if rootClusterName != ch.rootClusterName </span><span class="cov8" title="1">{
                ch.createdClusters[ch.rootClusterName].delete()
                createClusterNode(rootClusterName, ch.parent.xdsClient, ch, 0)
                ch.rootClusterName = rootClusterName
        }</span>
}

// This function tries to construct a cluster update to send to CDS.
func (ch *clusterHandler) constructClusterUpdate() <span class="cov8" title="1">{
        if ch.createdClusters[ch.rootClusterName] == nil </span><span class="cov8" title="1">{
                // If root is nil, this handler is closed, ignore the update.
                return
        }</span>
        <span class="cov8" title="1">clusterUpdate, err := ch.createdClusters[ch.rootClusterName].constructClusterUpdate(make(map[string]bool))
        if err != nil </span><span class="cov8" title="1">{
                // If there was an error received no op, as this can mean one of the
                // children hasn't received an update yet, or the graph continued to
                // stay in an error state. If the graph continues to stay in an error
                // state, no new error needs to be written to the update buffer as that
                // would be redundant information.
                return
        }</span>
        <span class="cov8" title="1">if clusterUpdate == nil </span><span class="cov8" title="1">{
                // This means that there was an aggregated cluster with no EDS or DNS as
                // leaf nodes. No update to be written.
                return
        }</span>
        // For a ClusterUpdate, the only update CDS cares about is the most
        // recent one, so opportunistically drain the update channel before
        // sending the new update.
        <span class="cov8" title="1">select </span>{
        case &lt;-ch.updateChannel:<span class="cov0" title="0"></span>
        default:<span class="cov8" title="1"></span>
        }
        <span class="cov8" title="1">ch.updateChannel &lt;- clusterHandlerUpdate{
                securityCfg: ch.createdClusters[ch.rootClusterName].clusterUpdate.SecurityCfg,
                lbPolicy:    ch.createdClusters[ch.rootClusterName].clusterUpdate.LBPolicy,
                updates:     clusterUpdate,
        }</span>
}

// close() is meant to be called by CDS when the CDS balancer is closed, and it
// cancels the watches for every cluster in the cluster tree.
func (ch *clusterHandler) close() <span class="cov8" title="1">{
        ch.clusterMutex.Lock()
        defer ch.clusterMutex.Unlock()
        if ch.createdClusters[ch.rootClusterName] == nil </span><span class="cov8" title="1">{
                return
        }</span>
        <span class="cov8" title="1">ch.createdClusters[ch.rootClusterName].delete()
        ch.rootClusterName = ""</span>
}

// This logically represents a cluster. This handles all the logic for starting
// and stopping a cluster watch, handling any updates, and constructing a list
// recursively for the ClusterHandler.
type clusterNode struct {
        // A way to cancel the watch for the cluster.
        cancelFunc func()

        // A list of children, as the Node can be an aggregate Cluster.
        children []string

        // A ClusterUpdate in order to build a list of cluster updates for CDS to
        // send down to child XdsClusterResolverLoadBalancingPolicy.
        clusterUpdate xdsresource.ClusterUpdate

        // This boolean determines whether this Node has received an update or not.
        // This isn't the best practice, but this will protect a list of Cluster
        // Updates from being constructed if a cluster in the tree has not received
        // an update yet.
        receivedUpdate bool

        clusterHandler *clusterHandler

        depth    int32
        refCount int32

        // maxDepthErr is set if this cluster node is an aggregate cluster and has a
        // child that causes the graph to exceed the maximum depth allowed. This is
        // used to show a cluster graph as being in an error state when it constructs
        // a cluster update.
        maxDepthErr error
}

// CreateClusterNode creates a cluster node from a given clusterName. This will
// also start the watch for that cluster.
func createClusterNode(clusterName string, xdsClient xdsclient.XDSClient, topLevelHandler *clusterHandler, depth int32) <span class="cov8" title="1">{
        // If the cluster has already been created, simply return, which ignores
        // duplicates.
        if topLevelHandler.createdClusters[clusterName] != nil </span><span class="cov8" title="1">{
                topLevelHandler.createdClusters[clusterName].refCount++
                return
        }</span>
        <span class="cov8" title="1">c := &amp;clusterNode{
                clusterHandler: topLevelHandler,
                depth:          depth,
                refCount:       1,
        }
        // Communicate with the xds client here.
        topLevelHandler.parent.logger.Infof("CDS watch started on %v", clusterName)
        cancel := xdsClient.WatchCluster(clusterName, c.handleResp)
        c.cancelFunc = func() </span><span class="cov8" title="1">{
                topLevelHandler.parent.logger.Infof("CDS watch canceled on %v", clusterName)
                cancel()
        }</span>
        <span class="cov8" title="1">topLevelHandler.createdClusters[clusterName] = c</span>
}

// This function cancels the cluster watch on the cluster and all of it's
// children.
func (c *clusterNode) delete() <span class="cov8" title="1">{
        c.refCount--
        if c.refCount == 0 </span><span class="cov8" title="1">{
                c.cancelFunc()
                delete(c.clusterHandler.createdClusters, c.clusterUpdate.ClusterName)
                for _, child := range c.children </span><span class="cov8" title="1">{
                        if c.clusterHandler.createdClusters[child] != nil </span><span class="cov8" title="1">{
                                c.clusterHandler.createdClusters[child].delete()
                        }</span>
                }
        }
}

// Construct cluster update (potentially a list of ClusterUpdates) for a node.
func (c *clusterNode) constructClusterUpdate(clustersSeen map[string]bool) ([]xdsresource.ClusterUpdate, error) <span class="cov8" title="1">{
        // If the cluster has not yet received an update, the cluster update is not
        // yet ready.
        if !c.receivedUpdate </span><span class="cov8" title="1">{
                return nil, errNotReceivedUpdate
        }</span>
        <span class="cov8" title="1">if c.maxDepthErr != nil </span><span class="cov8" title="1">{
                return nil, c.maxDepthErr
        }</span>
        // Ignore duplicates. It's ok to ignore duplicates because the second
        // occurrence of a cluster will never be used. I.e. in [C, D, C], the second
        // C will never be used (the only way to fall back to lower priority D is if
        // C is down, which means second C will never be chosen). Thus, [C, D, C] is
        // logically equivalent to [C, D].
        <span class="cov8" title="1">if clustersSeen[c.clusterUpdate.ClusterName] </span><span class="cov8" title="1">{
                return []xdsresource.ClusterUpdate{}, nil
        }</span>
        <span class="cov8" title="1">clustersSeen[c.clusterUpdate.ClusterName] = true

        // Base case - LogicalDNS or EDS. Both of these cluster types will be tied
        // to a single ClusterUpdate.
        if c.clusterUpdate.ClusterType != xdsresource.ClusterTypeAggregate </span><span class="cov8" title="1">{
                return []xdsresource.ClusterUpdate{c.clusterUpdate}, nil
        }</span>

        // If an aggregate construct a list by recursively calling down to all of
        // it's children.
        <span class="cov8" title="1">var childrenUpdates []xdsresource.ClusterUpdate
        for _, child := range c.children </span><span class="cov8" title="1">{
                childUpdateList, err := c.clusterHandler.createdClusters[child].constructClusterUpdate(clustersSeen)
                if err != nil </span><span class="cov8" title="1">{
                        return nil, err
                }</span>
                <span class="cov8" title="1">childrenUpdates = append(childrenUpdates, childUpdateList...)</span>
        }
        <span class="cov8" title="1">return childrenUpdates, nil</span>
}

// handleResp handles a xds response for a particular cluster. This function
// also handles any logic with regards to any child state that may have changed.
// At the end of the handleResp(), the clusterUpdate will be pinged in certain
// situations to try and construct an update to send back to CDS.
func (c *clusterNode) handleResp(clusterUpdate xdsresource.ClusterUpdate, err error) <span class="cov8" title="1">{
        c.clusterHandler.clusterMutex.Lock()
        defer c.clusterHandler.clusterMutex.Unlock()
        if err != nil </span><span class="cov8" title="1">{ // Write this error for run() to pick up in CDS LB policy.
                // For a ClusterUpdate, the only update CDS cares about is the most
                // recent one, so opportunistically drain the update channel before
                // sending the new update.
                select </span>{
                case &lt;-c.clusterHandler.updateChannel:<span class="cov0" title="0"></span>
                default:<span class="cov8" title="1"></span>
                }
                <span class="cov8" title="1">c.clusterHandler.updateChannel &lt;- clusterHandlerUpdate{err: err}
                c.receivedUpdate = false
                c.maxDepthErr = nil
                return</span>
        }

        <span class="cov8" title="1">c.receivedUpdate = true
        c.clusterUpdate = clusterUpdate

        // If the cluster was a leaf node, if the cluster update received had change
        // in the cluster update then the overall cluster update would change and
        // there is a possibility for the overall update to build so ping cluster
        // handler to return. Also, if there was any children from previously,
        // delete the children, as the cluster type is no longer an aggregate
        // cluster.
        if clusterUpdate.ClusterType != xdsresource.ClusterTypeAggregate </span><span class="cov8" title="1">{
                for _, child := range c.children </span><span class="cov8" title="1">{
                        c.clusterHandler.createdClusters[child].delete()
                }</span>
                <span class="cov8" title="1">c.children = nil
                c.maxDepthErr = nil
                // This is an update in the one leaf node, should try to send an update
                // to the parent CDS balancer.
                //
                // Note that this update might be a duplicate from the previous one.
                // Because the update contains not only the cluster name to watch, but
                // also the extra fields (e.g. security config). There's no good way to
                // compare all the fields.
                c.clusterHandler.constructClusterUpdate()
                return</span>
        }

        // Aggregate cluster handling.
        <span class="cov8" title="1">if len(clusterUpdate.PrioritizedClusterNames) &gt;= 1 </span><span class="cov8" title="1">{
                if c.depth == maxDepth-1 </span><span class="cov8" title="1">{
                        // For a ClusterUpdate, the only update CDS cares about is the most
                        // recent one, so opportunistically drain the update channel before
                        // sending the new update.
                        select </span>{
                        case &lt;-c.clusterHandler.updateChannel:<span class="cov0" title="0"></span>
                        default:<span class="cov8" title="1"></span>
                        }
                        <span class="cov8" title="1">c.clusterHandler.updateChannel &lt;- clusterHandlerUpdate{err: errExceedsMaxDepth}
                        c.children = []string{}
                        c.maxDepthErr = errExceedsMaxDepth
                        return</span>
                }
        }

        <span class="cov8" title="1">newChildren := make(map[string]bool)
        for _, childName := range clusterUpdate.PrioritizedClusterNames </span><span class="cov8" title="1">{
                newChildren[childName] = true
        }</span>

        // These booleans help determine whether this callback will ping the overall
        // clusterHandler to try and construct an update to send back to CDS. This
        // will be determined by whether there would be a change in the overall
        // clusterUpdate for the whole tree (ex. change in clusterUpdate for current
        // cluster or a deleted child) and also if there's even a possibility for
        // the update to build (ex. if a child is created and a watch is started,
        // that child hasn't received an update yet due to the mutex lock on this
        // callback).
        <span class="cov8" title="1">var createdChild bool

        // This map will represent the current children of the cluster. It will be
        // first added to in order to represent the new children. It will then have
        // any children deleted that are no longer present.
        mapCurrentChildren := make(map[string]bool)
        for _, child := range c.children </span><span class="cov8" title="1">{
                mapCurrentChildren[child] = true
        }</span>

        // Add and construct any new child nodes.
        <span class="cov8" title="1">for child := range newChildren </span><span class="cov8" title="1">{
                if _, inChildrenAlready := mapCurrentChildren[child]; !inChildrenAlready </span><span class="cov8" title="1">{
                        createClusterNode(child, c.clusterHandler.parent.xdsClient, c.clusterHandler, c.depth+1)
                }</span>
        }

        // Delete any child nodes no longer in the aggregate cluster's children.
        <span class="cov8" title="1">for child := range mapCurrentChildren </span><span class="cov8" title="1">{
                if _, stillAChild := newChildren[child]; !stillAChild </span><span class="cov8" title="1">{
                        c.clusterHandler.createdClusters[child].delete()
                        delete(mapCurrentChildren, child)
                }</span>
        }

        <span class="cov8" title="1">c.children = clusterUpdate.PrioritizedClusterNames

        c.maxDepthErr = nil
        // If the cluster is an aggregate cluster, if this callback created any new
        // child cluster nodes, then there's no possibility for a full cluster
        // update to successfully build, as those created children will not have
        // received an update yet. Even if this update did not delete a child, there
        // is still a possibility for the cluster update to build, as the aggregate
        // cluster can ignore duplicated children and thus the update can fill out
        // the full cluster update tree.
        if !createdChild </span><span class="cov8" title="1">{
                c.clusterHandler.constructClusterUpdate()
        }</span>
}
</pre>
		
		<pre class="file" id="file149" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package cdsbalancer

import (
        "fmt"

        "google.golang.org/grpc/grpclog"
        internalgrpclog "google.golang.org/grpc/internal/grpclog"
)

const prefix = "[cds-lb %p] "

var logger = grpclog.Component("xds")

func prefixLogger(p *cdsBalancer) *internalgrpclog.PrefixLogger <span class="cov8" title="1">{
        return internalgrpclog.NewPrefixLogger(logger, fmt.Sprintf(prefix, p))
}</span>
</pre>
		
		<pre class="file" id="file150" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package clusterimpl implements the xds_cluster_impl balancing policy. It
// handles the cluster features (e.g. circuit_breaking, RPC dropping).
//
// Note that it doesn't handle name resolution, which is done by policy
// xds_cluster_resolver.
package clusterimpl

import (
        "encoding/json"
        "fmt"
        "sync"
        "sync/atomic"

        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/connectivity"
        "google.golang.org/grpc/internal"
        "google.golang.org/grpc/internal/buffer"
        "google.golang.org/grpc/internal/grpclog"
        "google.golang.org/grpc/internal/grpcsync"
        "google.golang.org/grpc/internal/pretty"
        "google.golang.org/grpc/resolver"
        "google.golang.org/grpc/serviceconfig"
        xdsinternal "google.golang.org/grpc/xds/internal"
        "google.golang.org/grpc/xds/internal/balancer/loadstore"
        "google.golang.org/grpc/xds/internal/xdsclient"
        "google.golang.org/grpc/xds/internal/xdsclient/bootstrap"
        "google.golang.org/grpc/xds/internal/xdsclient/load"
)

const (
        // Name is the name of the cluster_impl balancer.
        Name                   = "xds_cluster_impl_experimental"
        defaultRequestCountMax = 1024
)

func init() <span class="cov8" title="1">{
        balancer.Register(bb{})
}</span>

type bb struct{}

func (bb) Build(cc balancer.ClientConn, bOpts balancer.BuildOptions) balancer.Balancer <span class="cov8" title="1">{
        b := &amp;clusterImplBalancer{
                ClientConn:      cc,
                bOpts:           bOpts,
                closed:          grpcsync.NewEvent(),
                done:            grpcsync.NewEvent(),
                loadWrapper:     loadstore.NewWrapper(),
                scWrappers:      make(map[balancer.SubConn]*scWrapper),
                pickerUpdateCh:  buffer.NewUnbounded(),
                requestCountMax: defaultRequestCountMax,
        }
        b.logger = prefixLogger(b)
        go b.run()
        b.logger.Infof("Created")
        return b
}</span>

func (bb) Name() string <span class="cov8" title="1">{
        return Name
}</span>

func (bb) ParseConfig(c json.RawMessage) (serviceconfig.LoadBalancingConfig, error) <span class="cov0" title="0">{
        return parseConfig(c)
}</span>

type clusterImplBalancer struct {
        balancer.ClientConn

        // mu guarantees mutual exclusion between Close() and handling of picker
        // update to the parent ClientConn in run(). It's to make sure that the
        // run() goroutine doesn't send picker update to parent after the balancer
        // is closed.
        //
        // It's only used by the run() goroutine, but not the other exported
        // functions. Because the exported functions are guaranteed to be
        // synchronized with Close().
        mu     sync.Mutex
        closed *grpcsync.Event
        done   *grpcsync.Event

        bOpts     balancer.BuildOptions
        logger    *grpclog.PrefixLogger
        xdsClient xdsclient.XDSClient

        config           *LBConfig
        childLB          balancer.Balancer
        cancelLoadReport func()
        edsServiceName   string
        lrsServer        *bootstrap.ServerConfig
        loadWrapper      *loadstore.Wrapper

        clusterNameMu sync.Mutex
        clusterName   string

        scWrappersMu sync.Mutex
        // The SubConns passed to the child policy are wrapped in a wrapper, to keep
        // locality ID. But when the parent ClientConn sends updates, it's going to
        // give the original SubConn, not the wrapper. But the child policies only
        // know about the wrapper, so when forwarding SubConn updates, they must be
        // sent for the wrappers.
        //
        // This keeps a map from original SubConn to wrapper, so that when
        // forwarding the SubConn state update, the child policy will get the
        // wrappers.
        scWrappers map[balancer.SubConn]*scWrapper

        // childState/drops/requestCounter keeps the state used by the most recently
        // generated picker. All fields can only be accessed in run(). And run() is
        // the only goroutine that sends picker to the parent ClientConn. All
        // requests to update picker need to be sent to pickerUpdateCh.
        childState            balancer.State
        dropCategories        []DropConfig // The categories for drops.
        drops                 []*dropper
        requestCounterCluster string // The cluster name for the request counter.
        requestCounterService string // The service name for the request counter.
        requestCounter        *xdsclient.ClusterRequestsCounter
        requestCountMax       uint32
        pickerUpdateCh        *buffer.Unbounded
}

// updateLoadStore checks the config for load store, and decides whether it
// needs to restart the load reporting stream.
func (b *clusterImplBalancer) updateLoadStore(newConfig *LBConfig) error <span class="cov8" title="1">{
        var updateLoadClusterAndService bool

        // ClusterName is different, restart. ClusterName is from ClusterName and
        // EDSServiceName.
        clusterName := b.getClusterName()
        if clusterName != newConfig.Cluster </span><span class="cov8" title="1">{
                updateLoadClusterAndService = true
                b.setClusterName(newConfig.Cluster)
                clusterName = newConfig.Cluster
        }</span>
        <span class="cov8" title="1">if b.edsServiceName != newConfig.EDSServiceName </span><span class="cov8" title="1">{
                updateLoadClusterAndService = true
                b.edsServiceName = newConfig.EDSServiceName
        }</span>
        <span class="cov8" title="1">if updateLoadClusterAndService </span><span class="cov8" title="1">{
                // This updates the clusterName and serviceName that will be reported
                // for the loads. The update here is too early, the perfect timing is
                // when the picker is updated with the new connection. But from this
                // balancer's point of view, it's impossible to tell.
                //
                // On the other hand, this will almost never happen. Each LRS policy
                // shouldn't get updated config. The parent should do a graceful switch
                // when the clusterName or serviceName is changed.
                b.loadWrapper.UpdateClusterAndService(clusterName, b.edsServiceName)
        }</span>

        <span class="cov8" title="1">var (
                stopOldLoadReport  bool
                startNewLoadReport bool
        )

        // Check if it's necessary to restart load report.
        if b.lrsServer == nil </span><span class="cov8" title="1">{
                if newConfig.LoadReportingServer != nil </span><span class="cov8" title="1">{
                        // Old is nil, new is not nil, start new LRS.
                        b.lrsServer = newConfig.LoadReportingServer
                        startNewLoadReport = true
                }</span>
                // Old is nil, new is nil, do nothing.
        } else<span class="cov8" title="1"> if newConfig.LoadReportingServer == nil </span><span class="cov8" title="1">{
                // Old is not nil, new is nil, stop old, don't start new.
                b.lrsServer = newConfig.LoadReportingServer
                stopOldLoadReport = true
        }</span> else<span class="cov8" title="1"> {
                // Old is not nil, new is not nil, compare string values, if
                // different, stop old and start new.
                if *b.lrsServer != *newConfig.LoadReportingServer </span><span class="cov8" title="1">{
                        b.lrsServer = newConfig.LoadReportingServer
                        stopOldLoadReport = true
                        startNewLoadReport = true
                }</span>
        }

        <span class="cov8" title="1">if stopOldLoadReport </span><span class="cov8" title="1">{
                if b.cancelLoadReport != nil </span><span class="cov8" title="1">{
                        b.cancelLoadReport()
                        b.cancelLoadReport = nil
                        if !startNewLoadReport </span><span class="cov8" title="1">{
                                // If a new LRS stream will be started later, no need to update
                                // it to nil here.
                                b.loadWrapper.UpdateLoadStore(nil)
                        }</span>
                }
        }
        <span class="cov8" title="1">if startNewLoadReport </span><span class="cov8" title="1">{
                var loadStore *load.Store
                if b.xdsClient != nil </span><span class="cov8" title="1">{
                        loadStore, b.cancelLoadReport = b.xdsClient.ReportLoad(b.lrsServer)
                }</span>
                <span class="cov8" title="1">b.loadWrapper.UpdateLoadStore(loadStore)</span>
        }

        <span class="cov8" title="1">return nil</span>
}

func (b *clusterImplBalancer) UpdateClientConnState(s balancer.ClientConnState) error <span class="cov8" title="1">{
        if b.closed.HasFired() </span><span class="cov0" title="0">{
                b.logger.Warningf("xds: received ClientConnState {%+v} after clusterImplBalancer was closed", s)
                return nil
        }</span>

        <span class="cov8" title="1">b.logger.Infof("Received update from resolver, balancer config: %+v", pretty.ToJSON(s.BalancerConfig))
        newConfig, ok := s.BalancerConfig.(*LBConfig)
        if !ok </span><span class="cov0" title="0">{
                return fmt.Errorf("unexpected balancer config with type: %T", s.BalancerConfig)
        }</span>

        // Need to check for potential errors at the beginning of this function, so
        // that on errors, we reject the whole config, instead of applying part of
        // it.
        <span class="cov8" title="1">bb := balancer.Get(newConfig.ChildPolicy.Name)
        if bb == nil </span><span class="cov0" title="0">{
                return fmt.Errorf("balancer %q not registered", newConfig.ChildPolicy.Name)
        }</span>

        <span class="cov8" title="1">if b.xdsClient == nil </span><span class="cov8" title="1">{
                c := xdsclient.FromResolverState(s.ResolverState)
                if c == nil </span><span class="cov0" title="0">{
                        return balancer.ErrBadResolverState
                }</span>
                <span class="cov8" title="1">b.xdsClient = c</span>
        }

        // Update load reporting config. This needs to be done before updating the
        // child policy because we need the loadStore from the updated client to be
        // passed to the ccWrapper, so that the next picker from the child policy
        // will pick up the new loadStore.
        <span class="cov8" title="1">if err := b.updateLoadStore(newConfig); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        // If child policy is a different type, recreate the sub-balancer.
        <span class="cov8" title="1">if b.config == nil || b.config.ChildPolicy.Name != newConfig.ChildPolicy.Name </span><span class="cov8" title="1">{
                if b.childLB != nil </span><span class="cov0" title="0">{
                        b.childLB.Close()
                }</span>
                <span class="cov8" title="1">b.childLB = bb.Build(b, b.bOpts)</span>
        }
        <span class="cov8" title="1">b.config = newConfig

        if b.childLB == nil </span><span class="cov0" title="0">{
                // This is not an expected situation, and should be super rare in
                // practice.
                //
                // When this happens, we already applied all the other configurations
                // (drop/circuit breaking), but there's no child policy. This balancer
                // will be stuck, and we report the error to the parent.
                return fmt.Errorf("child policy is nil, this means balancer %q's Build() returned nil", newConfig.ChildPolicy.Name)
        }</span>

        // Notify run() of this new config, in case drop and request counter need
        // update (which means a new picker needs to be generated).
        <span class="cov8" title="1">b.pickerUpdateCh.Put(newConfig)

        // Addresses and sub-balancer config are sent to sub-balancer.
        return b.childLB.UpdateClientConnState(balancer.ClientConnState{
                ResolverState:  s.ResolverState,
                BalancerConfig: b.config.ChildPolicy.Config,
        })</span>
}

func (b *clusterImplBalancer) ResolverError(err error) <span class="cov0" title="0">{
        if b.closed.HasFired() </span><span class="cov0" title="0">{
                b.logger.Warningf("xds: received resolver error {%+v} after clusterImplBalancer was closed", err)
                return
        }</span>

        <span class="cov0" title="0">if b.childLB != nil </span><span class="cov0" title="0">{
                b.childLB.ResolverError(err)
        }</span>
}

func (b *clusterImplBalancer) UpdateSubConnState(sc balancer.SubConn, s balancer.SubConnState) <span class="cov8" title="1">{
        if b.closed.HasFired() </span><span class="cov0" title="0">{
                b.logger.Warningf("xds: received subconn state change {%+v, %+v} after clusterImplBalancer was closed", sc, s)
                return
        }</span>

        // Trigger re-resolution when a SubConn turns transient failure. This is
        // necessary for the LogicalDNS in cluster_resolver policy to re-resolve.
        //
        // Note that this happens not only for the addresses from DNS, but also for
        // EDS (cluster_impl doesn't know if it's DNS or EDS, only the parent
        // knows). The parent priority policy is configured to ignore re-resolution
        // signal from the EDS children.
        <span class="cov8" title="1">if s.ConnectivityState == connectivity.TransientFailure </span><span class="cov8" title="1">{
                b.ClientConn.ResolveNow(resolver.ResolveNowOptions{})
        }</span>

        <span class="cov8" title="1">b.scWrappersMu.Lock()
        if scw, ok := b.scWrappers[sc]; ok </span><span class="cov8" title="1">{
                sc = scw
                if s.ConnectivityState == connectivity.Shutdown </span><span class="cov0" title="0">{
                        // Remove this SubConn from the map on Shutdown.
                        delete(b.scWrappers, scw.SubConn)
                }</span>
        }
        <span class="cov8" title="1">b.scWrappersMu.Unlock()
        if b.childLB != nil </span><span class="cov8" title="1">{
                b.childLB.UpdateSubConnState(sc, s)
        }</span>
}

func (b *clusterImplBalancer) Close() <span class="cov8" title="1">{
        b.mu.Lock()
        b.closed.Fire()
        b.mu.Unlock()

        if b.childLB != nil </span><span class="cov8" title="1">{
                b.childLB.Close()
                b.childLB = nil
        }</span>
        <span class="cov8" title="1">&lt;-b.done.Done()
        b.logger.Infof("Shutdown")</span>
}

func (b *clusterImplBalancer) ExitIdle() <span class="cov0" title="0">{
        if b.childLB == nil </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov0" title="0">if ei, ok := b.childLB.(balancer.ExitIdler); ok </span><span class="cov0" title="0">{
                ei.ExitIdle()
                return
        }</span>
        // Fallback for children that don't support ExitIdle -- connect to all
        // SubConns.
        <span class="cov0" title="0">for _, sc := range b.scWrappers </span><span class="cov0" title="0">{
                sc.Connect()
        }</span>
}

// Override methods to accept updates from the child LB.

func (b *clusterImplBalancer) UpdateState(state balancer.State) <span class="cov8" title="1">{
        // Instead of updating parent ClientConn inline, send state to run().
        b.pickerUpdateCh.Put(state)
}</span>

func (b *clusterImplBalancer) setClusterName(n string) <span class="cov8" title="1">{
        b.clusterNameMu.Lock()
        defer b.clusterNameMu.Unlock()
        b.clusterName = n
}</span>

func (b *clusterImplBalancer) getClusterName() string <span class="cov8" title="1">{
        b.clusterNameMu.Lock()
        defer b.clusterNameMu.Unlock()
        return b.clusterName
}</span>

// scWrapper is a wrapper of SubConn with locality ID. The locality ID can be
// retrieved from the addresses when creating SubConn.
//
// All SubConns passed to the child policies are wrapped in this, so that the
// picker can get the localityID from the picked SubConn, and do load reporting.
//
// After wrapping, all SubConns to and from the parent ClientConn (e.g. for
// SubConn state update, update/remove SubConn) must be the original SubConns.
// All SubConns to and from the child policy (NewSubConn, forwarding SubConn
// state update) must be the wrapper. The balancer keeps a map from the original
// SubConn to the wrapper for this purpose.
type scWrapper struct {
        balancer.SubConn
        // locality needs to be atomic because it can be updated while being read by
        // the picker.
        locality atomic.Value // type xdsinternal.LocalityID
}

func (scw *scWrapper) updateLocalityID(lID xdsinternal.LocalityID) <span class="cov8" title="1">{
        scw.locality.Store(lID)
}</span>

func (scw *scWrapper) localityID() xdsinternal.LocalityID <span class="cov8" title="1">{
        lID, _ := scw.locality.Load().(xdsinternal.LocalityID)
        return lID
}</span>

func (b *clusterImplBalancer) NewSubConn(addrs []resolver.Address, opts balancer.NewSubConnOptions) (balancer.SubConn, error) <span class="cov8" title="1">{
        clusterName := b.getClusterName()
        newAddrs := make([]resolver.Address, len(addrs))
        var lID xdsinternal.LocalityID
        for i, addr := range addrs </span><span class="cov8" title="1">{
                newAddrs[i] = internal.SetXDSHandshakeClusterName(addr, clusterName)
                lID = xdsinternal.GetLocalityID(newAddrs[i])
        }</span>
        <span class="cov8" title="1">sc, err := b.ClientConn.NewSubConn(newAddrs, opts)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        // Wrap this SubConn in a wrapper, and add it to the map.
        <span class="cov8" title="1">b.scWrappersMu.Lock()
        ret := &amp;scWrapper{SubConn: sc}
        ret.updateLocalityID(lID)
        b.scWrappers[sc] = ret
        b.scWrappersMu.Unlock()
        return ret, nil</span>
}

func (b *clusterImplBalancer) RemoveSubConn(sc balancer.SubConn) <span class="cov8" title="1">{
        scw, ok := sc.(*scWrapper)
        if !ok </span><span class="cov0" title="0">{
                b.ClientConn.RemoveSubConn(sc)
                return
        }</span>
        // Remove the original SubConn from the parent ClientConn.
        //
        // Note that we don't remove this SubConn from the scWrappers map. We will
        // need it to forward the final SubConn state Shutdown to the child policy.
        //
        // This entry is kept in the map until it's state is changes to Shutdown,
        // and will be deleted in UpdateSubConnState().
        <span class="cov8" title="1">b.ClientConn.RemoveSubConn(scw.SubConn)</span>
}

func (b *clusterImplBalancer) UpdateAddresses(sc balancer.SubConn, addrs []resolver.Address) <span class="cov0" title="0">{
        clusterName := b.getClusterName()
        newAddrs := make([]resolver.Address, len(addrs))
        var lID xdsinternal.LocalityID
        for i, addr := range addrs </span><span class="cov0" title="0">{
                newAddrs[i] = internal.SetXDSHandshakeClusterName(addr, clusterName)
                lID = xdsinternal.GetLocalityID(newAddrs[i])
        }</span>
        <span class="cov0" title="0">if scw, ok := sc.(*scWrapper); ok </span><span class="cov0" title="0">{
                scw.updateLocalityID(lID)
                // Need to get the original SubConn from the wrapper before calling
                // parent ClientConn.
                sc = scw.SubConn
        }</span>
        <span class="cov0" title="0">b.ClientConn.UpdateAddresses(sc, newAddrs)</span>
}

type dropConfigs struct {
        drops           []*dropper
        requestCounter  *xdsclient.ClusterRequestsCounter
        requestCountMax uint32
}

// handleDropAndRequestCount compares drop and request counter in newConfig with
// the one currently used by picker. It returns a new dropConfigs if a new
// picker needs to be generated, otherwise it returns nil.
func (b *clusterImplBalancer) handleDropAndRequestCount(newConfig *LBConfig) *dropConfigs <span class="cov8" title="1">{
        // Compare new drop config. And update picker if it's changed.
        var updatePicker bool
        if !equalDropCategories(b.dropCategories, newConfig.DropCategories) </span><span class="cov8" title="1">{
                b.dropCategories = newConfig.DropCategories
                b.drops = make([]*dropper, 0, len(newConfig.DropCategories))
                for _, c := range newConfig.DropCategories </span><span class="cov8" title="1">{
                        b.drops = append(b.drops, newDropper(c))
                }</span>
                <span class="cov8" title="1">updatePicker = true</span>
        }

        // Compare cluster name. And update picker if it's changed, because circuit
        // breaking's stream counter will be different.
        <span class="cov8" title="1">if b.requestCounterCluster != newConfig.Cluster || b.requestCounterService != newConfig.EDSServiceName </span><span class="cov8" title="1">{
                b.requestCounterCluster = newConfig.Cluster
                b.requestCounterService = newConfig.EDSServiceName
                b.requestCounter = xdsclient.GetClusterRequestsCounter(newConfig.Cluster, newConfig.EDSServiceName)
                updatePicker = true
        }</span>
        // Compare upper bound of stream count. And update picker if it's changed.
        // This is also for circuit breaking.
        <span class="cov8" title="1">var newRequestCountMax uint32 = 1024
        if newConfig.MaxConcurrentRequests != nil </span><span class="cov8" title="1">{
                newRequestCountMax = *newConfig.MaxConcurrentRequests
        }</span>
        <span class="cov8" title="1">if b.requestCountMax != newRequestCountMax </span><span class="cov8" title="1">{
                b.requestCountMax = newRequestCountMax
                updatePicker = true
        }</span>

        <span class="cov8" title="1">if !updatePicker </span><span class="cov8" title="1">{
                return nil
        }</span>
        <span class="cov8" title="1">return &amp;dropConfigs{
                drops:           b.drops,
                requestCounter:  b.requestCounter,
                requestCountMax: b.requestCountMax,
        }</span>
}

func (b *clusterImplBalancer) run() <span class="cov8" title="1">{
        defer b.done.Fire()
        for </span><span class="cov8" title="1">{
                select </span>{
                case update := &lt;-b.pickerUpdateCh.Get():<span class="cov8" title="1">
                        b.pickerUpdateCh.Load()
                        b.mu.Lock()
                        if b.closed.HasFired() </span><span class="cov8" title="1">{
                                b.mu.Unlock()
                                return
                        }</span>
                        <span class="cov8" title="1">switch u := update.(type) </span>{
                        case balancer.State:<span class="cov8" title="1">
                                b.childState = u
                                b.ClientConn.UpdateState(balancer.State{
                                        ConnectivityState: b.childState.ConnectivityState,
                                        Picker: newPicker(b.childState, &amp;dropConfigs{
                                                drops:           b.drops,
                                                requestCounter:  b.requestCounter,
                                                requestCountMax: b.requestCountMax,
                                        }, b.loadWrapper),
                                })</span>
                        case *LBConfig:<span class="cov8" title="1">
                                dc := b.handleDropAndRequestCount(u)
                                if dc != nil &amp;&amp; b.childState.Picker != nil </span><span class="cov8" title="1">{
                                        b.ClientConn.UpdateState(balancer.State{
                                                ConnectivityState: b.childState.ConnectivityState,
                                                Picker:            newPicker(b.childState, dc, b.loadWrapper),
                                        })
                                }</span>
                        }
                        <span class="cov8" title="1">b.mu.Unlock()</span>
                case &lt;-b.closed.Done():<span class="cov8" title="1">
                        if b.cancelLoadReport != nil </span><span class="cov8" title="1">{
                                b.cancelLoadReport()
                                b.cancelLoadReport = nil
                        }</span>
                        <span class="cov8" title="1">return</span>
                }
        }
}
</pre>
		
		<pre class="file" id="file151" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package clusterimpl

import (
        "encoding/json"

        internalserviceconfig "google.golang.org/grpc/internal/serviceconfig"
        "google.golang.org/grpc/serviceconfig"
        "google.golang.org/grpc/xds/internal/xdsclient/bootstrap"
)

// DropConfig contains the category, and drop ratio.
type DropConfig struct {
        Category           string
        RequestsPerMillion uint32
}

// LBConfig is the balancer config for cluster_impl balancer.
type LBConfig struct {
        serviceconfig.LoadBalancingConfig `json:"-"`

        Cluster        string `json:"cluster,omitempty"`
        EDSServiceName string `json:"edsServiceName,omitempty"`
        // LoadReportingServer is the LRS server to send load reports to. If not
        // present, load reporting will be disabled.
        LoadReportingServer   *bootstrap.ServerConfig               `json:"lrsLoadReportingServer,omitempty"`
        MaxConcurrentRequests *uint32                               `json:"maxConcurrentRequests,omitempty"`
        DropCategories        []DropConfig                          `json:"dropCategories,omitempty"`
        ChildPolicy           *internalserviceconfig.BalancerConfig `json:"childPolicy,omitempty"`
}

func parseConfig(c json.RawMessage) (*LBConfig, error) <span class="cov8" title="1">{
        var cfg LBConfig
        if err := json.Unmarshal(c, &amp;cfg); err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return &amp;cfg, nil</span>
}

func equalDropCategories(a, b []DropConfig) bool <span class="cov8" title="1">{
        if len(a) != len(b) </span><span class="cov8" title="1">{
                return false
        }</span>
        <span class="cov8" title="1">for i := range a </span><span class="cov8" title="1">{
                if a[i] != b[i] </span><span class="cov8" title="1">{
                        return false
                }</span>
        }
        <span class="cov8" title="1">return true</span>
}
</pre>
		
		<pre class="file" id="file152" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package clusterimpl

import (
        "fmt"

        "google.golang.org/grpc/grpclog"
        internalgrpclog "google.golang.org/grpc/internal/grpclog"
)

const prefix = "[xds-cluster-impl-lb %p] "

var logger = grpclog.Component("xds")

func prefixLogger(p *clusterImplBalancer) *internalgrpclog.PrefixLogger <span class="cov8" title="1">{
        return internalgrpclog.NewPrefixLogger(logger, fmt.Sprintf(prefix, p))
}</span>
</pre>
		
		<pre class="file" id="file153" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package clusterimpl

import (
        orcapb "github.com/cncf/xds/go/xds/data/orca/v3"
        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/connectivity"
        "google.golang.org/grpc/internal/wrr"
        "google.golang.org/grpc/status"
        "google.golang.org/grpc/xds/internal/xdsclient"
        "google.golang.org/grpc/xds/internal/xdsclient/load"
)

// NewRandomWRR is used when calculating drops. It's exported so that tests can
// override it.
var NewRandomWRR = wrr.NewRandom

const million = 1000000

type dropper struct {
        category string
        w        wrr.WRR
}

// greatest common divisor (GCD) via Euclidean algorithm
func gcd(a, b uint32) uint32 <span class="cov8" title="1">{
        for b != 0 </span><span class="cov8" title="1">{
                t := b
                b = a % b
                a = t
        }</span>
        <span class="cov8" title="1">return a</span>
}

func newDropper(c DropConfig) *dropper <span class="cov8" title="1">{
        w := NewRandomWRR()
        gcdv := gcd(c.RequestsPerMillion, million)
        // Return true for RequestPerMillion, false for the rest.
        w.Add(true, int64(c.RequestsPerMillion/gcdv))
        w.Add(false, int64((million-c.RequestsPerMillion)/gcdv))

        return &amp;dropper{
                category: c.Category,
                w:        w,
        }
}</span>

func (d *dropper) drop() (ret bool) <span class="cov8" title="1">{
        return d.w.Next().(bool)
}</span>

const (
        serverLoadCPUName    = "cpu_utilization"
        serverLoadMemoryName = "mem_utilization"
)

// loadReporter wraps the methods from the loadStore that are used here.
type loadReporter interface {
        CallStarted(locality string)
        CallFinished(locality string, err error)
        CallServerLoad(locality, name string, val float64)
        CallDropped(locality string)
}

// Picker implements RPC drop, circuit breaking drop and load reporting.
type picker struct {
        drops     []*dropper
        s         balancer.State
        loadStore loadReporter
        counter   *xdsclient.ClusterRequestsCounter
        countMax  uint32
}

func newPicker(s balancer.State, config *dropConfigs, loadStore load.PerClusterReporter) *picker <span class="cov8" title="1">{
        return &amp;picker{
                drops:     config.drops,
                s:         s,
                loadStore: loadStore,
                counter:   config.requestCounter,
                countMax:  config.requestCountMax,
        }
}</span>

func (d *picker) Pick(info balancer.PickInfo) (balancer.PickResult, error) <span class="cov8" title="1">{
        // Don't drop unless the inner picker is READY. Similar to
        // https://github.com/grpc/grpc-go/issues/2622.
        if d.s.ConnectivityState == connectivity.Ready </span><span class="cov8" title="1">{
                // Check if this RPC should be dropped by category.
                for _, dp := range d.drops </span><span class="cov8" title="1">{
                        if dp.drop() </span><span class="cov8" title="1">{
                                if d.loadStore != nil </span><span class="cov8" title="1">{
                                        d.loadStore.CallDropped(dp.category)
                                }</span>
                                <span class="cov8" title="1">return balancer.PickResult{}, status.Errorf(codes.Unavailable, "RPC is dropped")</span>
                        }
                }
        }

        // Check if this RPC should be dropped by circuit breaking.
        <span class="cov8" title="1">if d.counter != nil </span><span class="cov8" title="1">{
                if err := d.counter.StartRequest(d.countMax); err != nil </span><span class="cov8" title="1">{
                        // Drops by circuit breaking are reported with empty category. They
                        // will be reported only in total drops, but not in per category.
                        if d.loadStore != nil </span><span class="cov8" title="1">{
                                d.loadStore.CallDropped("")
                        }</span>
                        <span class="cov8" title="1">return balancer.PickResult{}, status.Errorf(codes.Unavailable, err.Error())</span>
                }
        }

        <span class="cov8" title="1">var lIDStr string
        pr, err := d.s.Picker.Pick(info)
        if scw, ok := pr.SubConn.(*scWrapper); ok </span><span class="cov8" title="1">{
                // This OK check also covers the case err!=nil, because SubConn will be
                // nil.
                pr.SubConn = scw.SubConn
                var e error
                // If locality ID isn't found in the wrapper, an empty locality ID will
                // be used.
                lIDStr, e = scw.localityID().ToString()
                if e != nil </span><span class="cov0" title="0">{
                        logger.Infof("failed to marshal LocalityID: %#v, loads won't be reported", scw.localityID())
                }</span>
        }

        <span class="cov8" title="1">if err != nil </span><span class="cov8" title="1">{
                if d.counter != nil </span><span class="cov8" title="1">{
                        // Release one request count if this pick fails.
                        d.counter.EndRequest()
                }</span>
                <span class="cov8" title="1">return pr, err</span>
        }

        <span class="cov8" title="1">if d.loadStore != nil </span><span class="cov8" title="1">{
                d.loadStore.CallStarted(lIDStr)
                oldDone := pr.Done
                pr.Done = func(info balancer.DoneInfo) </span><span class="cov8" title="1">{
                        if oldDone != nil </span><span class="cov0" title="0">{
                                oldDone(info)
                        }</span>
                        <span class="cov8" title="1">d.loadStore.CallFinished(lIDStr, info.Err)

                        load, ok := info.ServerLoad.(*orcapb.OrcaLoadReport)
                        if !ok </span><span class="cov8" title="1">{
                                return
                        }</span>
                        <span class="cov0" title="0">d.loadStore.CallServerLoad(lIDStr, serverLoadCPUName, load.CpuUtilization)
                        d.loadStore.CallServerLoad(lIDStr, serverLoadMemoryName, load.MemUtilization)
                        for n, c := range load.RequestCost </span><span class="cov0" title="0">{
                                d.loadStore.CallServerLoad(lIDStr, n, c)
                        }</span>
                        <span class="cov0" title="0">for n, c := range load.Utilization </span><span class="cov0" title="0">{
                                d.loadStore.CallServerLoad(lIDStr, n, c)
                        }</span>
                }
        }

        <span class="cov8" title="1">if d.counter != nil </span><span class="cov8" title="1">{
                // Update Done() so that when the RPC finishes, the request count will
                // be released.
                oldDone := pr.Done
                pr.Done = func(doneInfo balancer.DoneInfo) </span><span class="cov8" title="1">{
                        d.counter.EndRequest()
                        if oldDone != nil </span><span class="cov8" title="1">{
                                oldDone(doneInfo)
                        }</span>
                }
        }

        <span class="cov8" title="1">return pr, err</span>
}
</pre>
		
		<pre class="file" id="file154" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package clustermanager

import (
        "fmt"
        "sync"

        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/balancer/base"
        "google.golang.org/grpc/connectivity"
        "google.golang.org/grpc/internal/grpclog"
)

type subBalancerState struct {
        state balancer.State
        // stateToAggregate is the connectivity state used only for state
        // aggregation. It could be different from state.ConnectivityState. For
        // example when a sub-balancer transitions from TransientFailure to
        // connecting, state.ConnectivityState is Connecting, but stateToAggregate
        // is still TransientFailure.
        stateToAggregate connectivity.State
}

func (s *subBalancerState) String() string <span class="cov8" title="1">{
        return fmt.Sprintf("picker:%p,state:%v,stateToAggregate:%v", s.state.Picker, s.state.ConnectivityState, s.stateToAggregate)
}</span>

type balancerStateAggregator struct {
        cc     balancer.ClientConn
        logger *grpclog.PrefixLogger

        mu sync.Mutex
        // If started is false, no updates should be sent to the parent cc. A closed
        // sub-balancer could still send pickers to this aggregator. This makes sure
        // that no updates will be forwarded to parent when the whole balancer group
        // and states aggregator is closed.
        started bool
        // All balancer IDs exist as keys in this map, even if balancer group is not
        // started.
        //
        // If an ID is not in map, it's either removed or never added.
        idToPickerState map[string]*subBalancerState
        // Set when UpdateState call propagation is paused.
        pauseUpdateState bool
        // Set when UpdateState call propagation is paused and an UpdateState call
        // is suppressed.
        needUpdateStateOnResume bool
}

func newBalancerStateAggregator(cc balancer.ClientConn, logger *grpclog.PrefixLogger) *balancerStateAggregator <span class="cov8" title="1">{
        return &amp;balancerStateAggregator{
                cc:              cc,
                logger:          logger,
                idToPickerState: make(map[string]*subBalancerState),
        }
}</span>

// Start starts the aggregator. It can be called after Close to restart the
// aggretator.
func (bsa *balancerStateAggregator) start() <span class="cov8" title="1">{
        bsa.mu.Lock()
        defer bsa.mu.Unlock()
        bsa.started = true
}</span>

// Close closes the aggregator. When the aggregator is closed, it won't call
// parent ClientConn to update balancer state.
func (bsa *balancerStateAggregator) close() <span class="cov0" title="0">{
        bsa.mu.Lock()
        defer bsa.mu.Unlock()
        bsa.started = false
        bsa.clearStates()
}</span>

// add adds a sub-balancer state with weight. It adds a place holder, and waits
// for the real sub-balancer to update state.
//
// This is called when there's a new child.
func (bsa *balancerStateAggregator) add(id string) <span class="cov8" title="1">{
        bsa.mu.Lock()
        defer bsa.mu.Unlock()
        bsa.idToPickerState[id] = &amp;subBalancerState{
                // Start everything in CONNECTING, so if one of the sub-balancers
                // reports TransientFailure, the RPCs will still wait for the other
                // sub-balancers.
                state: balancer.State{
                        ConnectivityState: connectivity.Connecting,
                        Picker:            base.NewErrPicker(balancer.ErrNoSubConnAvailable),
                },
                stateToAggregate: connectivity.Connecting,
        }
}</span>

// remove removes the sub-balancer state. Future updates from this sub-balancer,
// if any, will be ignored.
//
// This is called when a child is removed.
func (bsa *balancerStateAggregator) remove(id string) <span class="cov8" title="1">{
        bsa.mu.Lock()
        defer bsa.mu.Unlock()
        if _, ok := bsa.idToPickerState[id]; !ok </span><span class="cov0" title="0">{
                return
        }</span>
        // Remove id and picker from picker map. This also results in future updates
        // for this ID to be ignored.
        <span class="cov8" title="1">delete(bsa.idToPickerState, id)</span>
}

// pauseStateUpdates causes UpdateState calls to not propagate to the parent
// ClientConn.  The last state will be remembered and propagated when
// ResumeStateUpdates is called.
func (bsa *balancerStateAggregator) pauseStateUpdates() <span class="cov8" title="1">{
        bsa.mu.Lock()
        defer bsa.mu.Unlock()
        bsa.pauseUpdateState = true
        bsa.needUpdateStateOnResume = false
}</span>

// resumeStateUpdates will resume propagating UpdateState calls to the parent,
// and call UpdateState on the parent if any UpdateState call was suppressed.
func (bsa *balancerStateAggregator) resumeStateUpdates() <span class="cov8" title="1">{
        bsa.mu.Lock()
        defer bsa.mu.Unlock()
        bsa.pauseUpdateState = false
        if bsa.needUpdateStateOnResume </span><span class="cov8" title="1">{
                bsa.cc.UpdateState(bsa.build())
        }</span>
}

// UpdateState is called to report a balancer state change from sub-balancer.
// It's usually called by the balancer group.
//
// It calls parent ClientConn's UpdateState with the new aggregated state.
func (bsa *balancerStateAggregator) UpdateState(id string, state balancer.State) <span class="cov8" title="1">{
        bsa.mu.Lock()
        defer bsa.mu.Unlock()
        pickerSt, ok := bsa.idToPickerState[id]
        if !ok </span><span class="cov0" title="0">{
                // All state starts with an entry in pickStateMap. If ID is not in map,
                // it's either removed, or never existed.
                return
        }</span>
        <span class="cov8" title="1">if !(pickerSt.state.ConnectivityState == connectivity.TransientFailure &amp;&amp; state.ConnectivityState == connectivity.Connecting) </span><span class="cov8" title="1">{
                // If old state is TransientFailure, and new state is Connecting, don't
                // update the state, to prevent the aggregated state from being always
                // CONNECTING. Otherwise, stateToAggregate is the same as
                // state.ConnectivityState.
                pickerSt.stateToAggregate = state.ConnectivityState
        }</span>
        <span class="cov8" title="1">pickerSt.state = state

        if !bsa.started </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov8" title="1">if bsa.pauseUpdateState </span><span class="cov8" title="1">{
                // If updates are paused, do not call UpdateState, but remember that we
                // need to call it when they are resumed.
                bsa.needUpdateStateOnResume = true
                return
        }</span>
        <span class="cov8" title="1">bsa.cc.UpdateState(bsa.build())</span>
}

// clearState Reset everything to init state (Connecting) but keep the entry in
// map (to keep the weight).
//
// Caller must hold bsa.mu.
func (bsa *balancerStateAggregator) clearStates() <span class="cov0" title="0">{
        for _, pState := range bsa.idToPickerState </span><span class="cov0" title="0">{
                pState.state = balancer.State{
                        ConnectivityState: connectivity.Connecting,
                        Picker:            base.NewErrPicker(balancer.ErrNoSubConnAvailable),
                }
                pState.stateToAggregate = connectivity.Connecting
        }</span>
}

// buildAndUpdate combines the sub-state from each sub-balancer into one state,
// and update it to parent ClientConn.
func (bsa *balancerStateAggregator) buildAndUpdate() <span class="cov8" title="1">{
        bsa.mu.Lock()
        defer bsa.mu.Unlock()
        if !bsa.started </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov8" title="1">if bsa.pauseUpdateState </span><span class="cov8" title="1">{
                // If updates are paused, do not call UpdateState, but remember that we
                // need to call it when they are resumed.
                bsa.needUpdateStateOnResume = true
                return
        }</span>
        <span class="cov0" title="0">bsa.cc.UpdateState(bsa.build())</span>
}

// build combines sub-states into one. The picker will do a child pick.
//
// Caller must hold bsa.mu.
func (bsa *balancerStateAggregator) build() balancer.State <span class="cov8" title="1">{
        // TODO: the majority of this function (and UpdateState) is exactly the same
        // as weighted_target's state aggregator. Try to make a general utility
        // function/struct to handle the logic.
        //
        // One option: make a SubBalancerState that handles Update(State), including
        // handling the special connecting after ready, as in UpdateState(). Then a
        // function to calculate the aggregated connectivity state as in this
        // function.
        //
        // TODO: use balancer.ConnectivityStateEvaluator to calculate the aggregated
        // state.
        var readyN, connectingN, idleN int
        for _, ps := range bsa.idToPickerState </span><span class="cov8" title="1">{
                switch ps.stateToAggregate </span>{
                case connectivity.Ready:<span class="cov8" title="1">
                        readyN++</span>
                case connectivity.Connecting:<span class="cov8" title="1">
                        connectingN++</span>
                case connectivity.Idle:<span class="cov8" title="1">
                        idleN++</span>
                }
        }
        <span class="cov8" title="1">var aggregatedState connectivity.State
        switch </span>{
        case readyN &gt; 0:<span class="cov8" title="1">
                aggregatedState = connectivity.Ready</span>
        case connectingN &gt; 0:<span class="cov8" title="1">
                aggregatedState = connectivity.Connecting</span>
        case idleN &gt; 0:<span class="cov8" title="1">
                aggregatedState = connectivity.Idle</span>
        default:<span class="cov8" title="1">
                aggregatedState = connectivity.TransientFailure</span>
        }

        // The picker's return error might not be consistent with the
        // aggregatedState. Because for this LB policy, we want to always build
        // picker with all sub-pickers (not only ready sub-pickers), so even if the
        // overall state is Ready, pick for certain RPCs can behave like Connecting
        // or TransientFailure.
        <span class="cov8" title="1">bsa.logger.Infof("Child pickers: %+v", bsa.idToPickerState)
        return balancer.State{
                ConnectivityState: aggregatedState,
                Picker:            newPickerGroup(bsa.idToPickerState),
        }</span>
}
</pre>
		
		<pre class="file" id="file155" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package clustermanager implements the cluster manager LB policy for xds.
package clustermanager

import (
        "encoding/json"
        "fmt"

        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/grpclog"
        "google.golang.org/grpc/internal/balancergroup"
        internalgrpclog "google.golang.org/grpc/internal/grpclog"
        "google.golang.org/grpc/internal/hierarchy"
        "google.golang.org/grpc/internal/pretty"
        "google.golang.org/grpc/resolver"
        "google.golang.org/grpc/serviceconfig"
)

const balancerName = "xds_cluster_manager_experimental"

func init() <span class="cov8" title="1">{
        balancer.Register(bb{})
}</span>

type bb struct{}

func (bb) Build(cc balancer.ClientConn, opts balancer.BuildOptions) balancer.Balancer <span class="cov8" title="1">{
        b := &amp;bal{}
        b.logger = prefixLogger(b)
        b.stateAggregator = newBalancerStateAggregator(cc, b.logger)
        b.stateAggregator.start()
        b.bg = balancergroup.New(cc, opts, b.stateAggregator, b.logger)
        b.bg.Start()
        b.logger.Infof("Created")
        return b
}</span>

func (bb) Name() string <span class="cov8" title="1">{
        return balancerName
}</span>

func (bb) ParseConfig(c json.RawMessage) (serviceconfig.LoadBalancingConfig, error) <span class="cov8" title="1">{
        return parseConfig(c)
}</span>

type bal struct {
        logger *internalgrpclog.PrefixLogger

        // TODO: make this package not dependent on xds specific code. Same as for
        // weighted target balancer.
        bg              *balancergroup.BalancerGroup
        stateAggregator *balancerStateAggregator

        children map[string]childConfig
}

func (b *bal) updateChildren(s balancer.ClientConnState, newConfig *lbConfig) <span class="cov8" title="1">{
        update := false
        addressesSplit := hierarchy.Group(s.ResolverState.Addresses)

        // Remove sub-pickers and sub-balancers that are not in the new cluster list.
        for name := range b.children </span><span class="cov8" title="1">{
                if _, ok := newConfig.Children[name]; !ok </span><span class="cov8" title="1">{
                        b.stateAggregator.remove(name)
                        b.bg.Remove(name)
                        update = true
                }</span>
        }

        // For sub-balancers in the new cluster list,
        // - add to balancer group if it's new,
        // - forward the address/balancer config update.
        <span class="cov8" title="1">for name, newT := range newConfig.Children </span><span class="cov8" title="1">{
                if _, ok := b.children[name]; !ok </span><span class="cov8" title="1">{
                        // If this is a new sub-balancer, add it to the picker map.
                        b.stateAggregator.add(name)
                        // Then add to the balancer group.
                        b.bg.Add(name, balancer.Get(newT.ChildPolicy.Name))
                }</span> else<span class="cov8" title="1"> {
                        // Already present, check for type change and if so send down a new builder.
                        if newT.ChildPolicy.Name != b.children[name].ChildPolicy.Name </span><span class="cov8" title="1">{
                                b.bg.UpdateBuilder(name, balancer.Get(newT.ChildPolicy.Name))
                        }</span>
                }
                // TODO: handle error? How to aggregate errors and return?
                <span class="cov8" title="1">_ = b.bg.UpdateClientConnState(name, balancer.ClientConnState{
                        ResolverState: resolver.State{
                                Addresses:     addressesSplit[name],
                                ServiceConfig: s.ResolverState.ServiceConfig,
                                Attributes:    s.ResolverState.Attributes,
                        },
                        BalancerConfig: newT.ChildPolicy.Config,
                })</span>
        }

        <span class="cov8" title="1">b.children = newConfig.Children
        if update </span><span class="cov8" title="1">{
                b.stateAggregator.buildAndUpdate()
        }</span>
}

func (b *bal) UpdateClientConnState(s balancer.ClientConnState) error <span class="cov8" title="1">{
        newConfig, ok := s.BalancerConfig.(*lbConfig)
        if !ok </span><span class="cov0" title="0">{
                return fmt.Errorf("unexpected balancer config with type: %T", s.BalancerConfig)
        }</span>
        <span class="cov8" title="1">b.logger.Infof("update with config %+v, resolver state %+v", pretty.ToJSON(s.BalancerConfig), s.ResolverState)

        b.stateAggregator.pauseStateUpdates()
        defer b.stateAggregator.resumeStateUpdates()
        b.updateChildren(s, newConfig)
        return nil</span>
}

func (b *bal) ResolverError(err error) <span class="cov0" title="0">{
        b.bg.ResolverError(err)
}</span>

func (b *bal) UpdateSubConnState(sc balancer.SubConn, state balancer.SubConnState) <span class="cov8" title="1">{
        b.bg.UpdateSubConnState(sc, state)
}</span>

func (b *bal) Close() <span class="cov0" title="0">{
        b.stateAggregator.close()
        b.bg.Close()
        b.logger.Infof("Shutdown")
}</span>

func (b *bal) ExitIdle() <span class="cov0" title="0">{
        b.bg.ExitIdle()
}</span>

const prefix = "[xds-cluster-manager-lb %p] "

var logger = grpclog.Component("xds")

func prefixLogger(p *bal) *internalgrpclog.PrefixLogger <span class="cov8" title="1">{
        return internalgrpclog.NewPrefixLogger(logger, fmt.Sprintf(prefix, p))
}</span>
</pre>
		
		<pre class="file" id="file156" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package clustermanager

import (
        "encoding/json"

        internalserviceconfig "google.golang.org/grpc/internal/serviceconfig"
        "google.golang.org/grpc/serviceconfig"
)

type childConfig struct {
        // ChildPolicy is the child policy and it's config.
        ChildPolicy *internalserviceconfig.BalancerConfig
}

// lbConfig is the balancer config for xds routing policy.
type lbConfig struct {
        serviceconfig.LoadBalancingConfig
        Children map[string]childConfig
}

func parseConfig(c json.RawMessage) (*lbConfig, error) <span class="cov8" title="1">{
        cfg := &amp;lbConfig{}
        if err := json.Unmarshal(c, cfg); err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>

        <span class="cov8" title="1">return cfg, nil</span>
}
</pre>
		
		<pre class="file" id="file157" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package clustermanager

import (
        "context"

        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/status"
)

// pickerGroup contains a list of pickers. If the picker isn't ready, the pick
// will be queued.
type pickerGroup struct {
        pickers map[string]balancer.Picker
}

func newPickerGroup(idToPickerState map[string]*subBalancerState) *pickerGroup <span class="cov8" title="1">{
        pickers := make(map[string]balancer.Picker)
        for id, st := range idToPickerState </span><span class="cov8" title="1">{
                pickers[id] = st.state.Picker
        }</span>
        <span class="cov8" title="1">return &amp;pickerGroup{
                pickers: pickers,
        }</span>
}

func (pg *pickerGroup) Pick(info balancer.PickInfo) (balancer.PickResult, error) <span class="cov8" title="1">{
        cluster := getPickedCluster(info.Ctx)
        if p := pg.pickers[cluster]; p != nil </span><span class="cov8" title="1">{
                return p.Pick(info)
        }</span>
        <span class="cov8" title="1">return balancer.PickResult{}, status.Errorf(codes.Unavailable, "unknown cluster selected for RPC: %q", cluster)</span>
}

type clusterKey struct{}

func getPickedCluster(ctx context.Context) string <span class="cov8" title="1">{
        cluster, _ := ctx.Value(clusterKey{}).(string)
        return cluster
}</span>

// GetPickedClusterForTesting returns the cluster in the context; to be used
// for testing only.
func GetPickedClusterForTesting(ctx context.Context) string <span class="cov0" title="0">{
        return getPickedCluster(ctx)
}</span>

// SetPickedCluster adds the selected cluster to the context for the
// xds_cluster_manager LB policy to pick.
func SetPickedCluster(ctx context.Context, cluster string) context.Context <span class="cov8" title="1">{
        return context.WithValue(ctx, clusterKey{}, cluster)
}</span>
</pre>
		
		<pre class="file" id="file158" style="display: none">/*
 *
 * Copyright 2019 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package clusterresolver contains EDS balancer implementation.
package clusterresolver

import (
        "encoding/json"
        "errors"
        "fmt"
        "strings"

        "google.golang.org/grpc/attributes"
        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/balancer/base"
        "google.golang.org/grpc/balancer/roundrobin"
        "google.golang.org/grpc/connectivity"
        "google.golang.org/grpc/internal/buffer"
        "google.golang.org/grpc/internal/grpclog"
        "google.golang.org/grpc/internal/grpcsync"
        "google.golang.org/grpc/internal/pretty"
        "google.golang.org/grpc/resolver"
        "google.golang.org/grpc/serviceconfig"
        "google.golang.org/grpc/xds/internal/balancer/priority"
        "google.golang.org/grpc/xds/internal/balancer/ringhash"
        "google.golang.org/grpc/xds/internal/xdsclient"
        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource"
)

// Name is the name of the cluster_resolver balancer.
const Name = "cluster_resolver_experimental"

var (
        errBalancerClosed = errors.New("cdsBalancer is closed")
        newChildBalancer  = func(bb balancer.Builder, cc balancer.ClientConn, o balancer.BuildOptions) balancer.Balancer <span class="cov8" title="1">{
                return bb.Build(cc, o)
        }</span>
)

func init() <span class="cov8" title="1">{
        balancer.Register(bb{})
}</span>

type bb struct{}

// Build helps implement the balancer.Builder interface.
func (bb) Build(cc balancer.ClientConn, opts balancer.BuildOptions) balancer.Balancer <span class="cov8" title="1">{
        priorityBuilder := balancer.Get(priority.Name)
        if priorityBuilder == nil </span><span class="cov0" title="0">{
                logger.Errorf("priority balancer is needed but not registered")
                return nil
        }</span>
        <span class="cov8" title="1">priorityConfigParser, ok := priorityBuilder.(balancer.ConfigParser)
        if !ok </span><span class="cov0" title="0">{
                logger.Errorf("priority balancer builder is not a config parser")
                return nil
        }</span>

        <span class="cov8" title="1">b := &amp;clusterResolverBalancer{
                bOpts:    opts,
                updateCh: buffer.NewUnbounded(),
                closed:   grpcsync.NewEvent(),
                done:     grpcsync.NewEvent(),

                priorityBuilder:      priorityBuilder,
                priorityConfigParser: priorityConfigParser,
        }
        b.logger = prefixLogger(b)
        b.logger.Infof("Created")

        b.resourceWatcher = newResourceResolver(b)
        b.cc = &amp;ccWrapper{
                ClientConn:      cc,
                resourceWatcher: b.resourceWatcher,
        }

        go b.run()
        return b</span>
}

func (bb) Name() string <span class="cov8" title="1">{
        return Name
}</span>

func (bb) ParseConfig(c json.RawMessage) (serviceconfig.LoadBalancingConfig, error) <span class="cov8" title="1">{
        var cfg LBConfig
        if err := json.Unmarshal(c, &amp;cfg); err != nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("unable to unmarshal balancer config %s into cluster-resolver config, error: %v", string(c), err)
        }</span>
        <span class="cov8" title="1">if lbp := cfg.XDSLBPolicy; lbp != nil &amp;&amp; !strings.EqualFold(lbp.Name, roundrobin.Name) &amp;&amp; !strings.EqualFold(lbp.Name, ringhash.Name) </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("unsupported child policy with name %q, not one of {%q,%q}", lbp.Name, roundrobin.Name, ringhash.Name)
        }</span>
        <span class="cov8" title="1">return &amp;cfg, nil</span>
}

// ccUpdate wraps a clientConn update received from gRPC (pushed from the
// xdsResolver).
type ccUpdate struct {
        state balancer.ClientConnState
        err   error
}

// scUpdate wraps a subConn update received from gRPC. This is directly passed
// on to the child balancer.
type scUpdate struct {
        subConn balancer.SubConn
        state   balancer.SubConnState
}

type exitIdle struct{}

// clusterResolverBalancer manages xdsClient and the actual EDS balancer implementation that
// does load balancing.
//
// It currently has only an clusterResolverBalancer. Later, we may add fallback.
type clusterResolverBalancer struct {
        cc              balancer.ClientConn
        bOpts           balancer.BuildOptions
        updateCh        *buffer.Unbounded // Channel for updates from gRPC.
        resourceWatcher *resourceResolver
        logger          *grpclog.PrefixLogger
        closed          *grpcsync.Event
        done            *grpcsync.Event

        priorityBuilder      balancer.Builder
        priorityConfigParser balancer.ConfigParser

        config          *LBConfig
        configRaw       *serviceconfig.ParseResult
        xdsClient       xdsclient.XDSClient    // xDS client to watch EDS resource.
        attrsWithClient *attributes.Attributes // Attributes with xdsClient attached to be passed to the child policies.

        child               balancer.Balancer
        priorities          []priorityConfig
        watchUpdateReceived bool
}

// handleClientConnUpdate handles a ClientConnUpdate received from gRPC. Good
// updates lead to registration of EDS and DNS watches. Updates with error lead
// to cancellation of existing watch and propagation of the same error to the
// child balancer.
func (b *clusterResolverBalancer) handleClientConnUpdate(update *ccUpdate) <span class="cov8" title="1">{
        // We first handle errors, if any, and then proceed with handling the
        // update, only if the status quo has changed.
        if err := update.err; err != nil </span><span class="cov8" title="1">{
                b.handleErrorFromUpdate(err, true)
                return
        }</span>

        <span class="cov8" title="1">b.logger.Infof("Receive update from resolver, balancer config: %v", pretty.ToJSON(update.state.BalancerConfig))
        cfg, _ := update.state.BalancerConfig.(*LBConfig)
        if cfg == nil </span><span class="cov0" title="0">{
                b.logger.Warningf("xds: unexpected LoadBalancingConfig type: %T", update.state.BalancerConfig)
                return
        }</span>

        <span class="cov8" title="1">b.config = cfg
        b.configRaw = update.state.ResolverState.ServiceConfig
        b.resourceWatcher.updateMechanisms(cfg.DiscoveryMechanisms)

        if !b.watchUpdateReceived </span><span class="cov8" title="1">{
                // If update was not received, wait for it.
                return
        }</span>
        // If eds resp was received before this, the child policy was created. We
        // need to generate a new balancer config and send it to the child, because
        // certain fields (unrelated to EDS watch) might have changed.
        <span class="cov8" title="1">if err := b.updateChildConfig(); err != nil </span><span class="cov0" title="0">{
                b.logger.Warningf("failed to update child policy config: %v", err)
        }</span>
}

// handleWatchUpdate handles a watch update from the xDS Client. Good updates
// lead to clientConn updates being invoked on the underlying child balancer.
func (b *clusterResolverBalancer) handleWatchUpdate(update *resourceUpdate) <span class="cov8" title="1">{
        if err := update.err; err != nil </span><span class="cov8" title="1">{
                b.logger.Warningf("Watch error from xds-client %p: %v", b.xdsClient, err)
                b.handleErrorFromUpdate(err, false)
                return
        }</span>

        <span class="cov8" title="1">b.logger.Infof("resource update: %+v", pretty.ToJSON(update.priorities))
        b.watchUpdateReceived = true
        b.priorities = update.priorities

        // A new EDS update triggers new child configs (e.g. different priorities
        // for the priority balancer), and new addresses (the endpoints come from
        // the EDS response).
        if err := b.updateChildConfig(); err != nil </span><span class="cov0" title="0">{
                b.logger.Warningf("failed to update child policy's balancer config: %v", err)
        }</span>
}

// updateChildConfig builds a balancer config from eb's cached eds resp and
// service config, and sends that to the child balancer. Note that it also
// generates the addresses, because the endpoints come from the EDS resp.
//
// If child balancer doesn't already exist, one will be created.
func (b *clusterResolverBalancer) updateChildConfig() error <span class="cov8" title="1">{
        // Child was build when the first EDS resp was received, so we just build
        // the config and addresses.
        if b.child == nil </span><span class="cov8" title="1">{
                b.child = newChildBalancer(b.priorityBuilder, b.cc, b.bOpts)
        }</span>

        <span class="cov8" title="1">childCfgBytes, addrs, err := buildPriorityConfigJSON(b.priorities, b.config.XDSLBPolicy)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to build priority balancer config: %v", err)
        }</span>
        <span class="cov8" title="1">childCfg, err := b.priorityConfigParser.ParseConfig(childCfgBytes)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to parse generated priority balancer config, this should never happen because the config is generated: %v", err)
        }</span>
        <span class="cov8" title="1">b.logger.Infof("build balancer config: %v", pretty.ToJSON(childCfg))
        return b.child.UpdateClientConnState(balancer.ClientConnState{
                ResolverState: resolver.State{
                        Addresses:     addrs,
                        ServiceConfig: b.configRaw,
                        Attributes:    b.attrsWithClient,
                },
                BalancerConfig: childCfg,
        })</span>
}

// handleErrorFromUpdate handles both the error from parent ClientConn (from CDS
// balancer) and the error from xds client (from the watcher). fromParent is
// true if error is from parent ClientConn.
//
// If the error is connection error, it should be handled for fallback purposes.
//
// If the error is resource-not-found:
// - If it's from CDS balancer (shows as a resolver error), it means LDS or CDS
// resources were removed. The EDS watch should be canceled.
// - If it's from xds client, it means EDS resource were removed. The EDS
// watcher should keep watching.
// In both cases, the sub-balancers will be receive the error.
func (b *clusterResolverBalancer) handleErrorFromUpdate(err error, fromParent bool) <span class="cov8" title="1">{
        b.logger.Warningf("Received error: %v", err)
        if fromParent &amp;&amp; xdsresource.ErrType(err) == xdsresource.ErrorTypeResourceNotFound </span><span class="cov8" title="1">{
                // This is an error from the parent ClientConn (can be the parent CDS
                // balancer), and is a resource-not-found error. This means the resource
                // (can be either LDS or CDS) was removed. Stop the EDS watch.
                b.resourceWatcher.stop()
        }</span>
        <span class="cov8" title="1">if b.child != nil </span><span class="cov8" title="1">{
                b.child.ResolverError(err)
        }</span> else<span class="cov0" title="0"> {
                // If eds balancer was never created, fail the RPCs with errors.
                b.cc.UpdateState(balancer.State{
                        ConnectivityState: connectivity.TransientFailure,
                        Picker:            base.NewErrPicker(err),
                })
        }</span>

}

// run is a long-running goroutine which handles all updates from gRPC and
// xdsClient. All methods which are invoked directly by gRPC or xdsClient simply
// push an update onto a channel which is read and acted upon right here.
func (b *clusterResolverBalancer) run() <span class="cov8" title="1">{
        for </span><span class="cov8" title="1">{
                select </span>{
                case u := &lt;-b.updateCh.Get():<span class="cov8" title="1">
                        b.updateCh.Load()
                        switch update := u.(type) </span>{
                        case *ccUpdate:<span class="cov8" title="1">
                                b.handleClientConnUpdate(update)</span>
                        case *scUpdate:<span class="cov8" title="1">
                                // SubConn updates are simply handed over to the underlying
                                // child balancer.
                                if b.child == nil </span><span class="cov0" title="0">{
                                        b.logger.Errorf("xds: received scUpdate {%+v} with no child balancer", update)
                                        break</span>
                                }
                                <span class="cov8" title="1">b.child.UpdateSubConnState(update.subConn, update.state)</span>
                        case exitIdle:<span class="cov0" title="0">
                                if b.child == nil </span><span class="cov0" title="0">{
                                        b.logger.Errorf("xds: received ExitIdle with no child balancer")
                                        break</span>
                                }
                                // This implementation assumes the child balancer supports
                                // ExitIdle (but still checks for the interface's existence to
                                // avoid a panic if not).  If the child does not, no subconns
                                // will be connected.
                                <span class="cov0" title="0">if ei, ok := b.child.(balancer.ExitIdler); ok </span><span class="cov0" title="0">{
                                        ei.ExitIdle()
                                }</span>
                        }
                case u := &lt;-b.resourceWatcher.updateChannel:<span class="cov8" title="1">
                        b.handleWatchUpdate(u)</span>

                // Close results in cancellation of the EDS watch and closing of the
                // underlying child policy and is the only way to exit this goroutine.
                case &lt;-b.closed.Done():<span class="cov8" title="1">
                        b.resourceWatcher.stop()

                        if b.child != nil </span><span class="cov8" title="1">{
                                b.child.Close()
                                b.child = nil
                        }</span>
                        // This is the *ONLY* point of return from this function.
                        <span class="cov8" title="1">b.logger.Infof("Shutdown")
                        b.done.Fire()
                        return</span>
                }
        }
}

// Following are methods to implement the balancer interface.

// UpdateClientConnState receives the serviceConfig (which contains the
// clusterName to watch for in CDS) and the xdsClient object from the
// xdsResolver.
func (b *clusterResolverBalancer) UpdateClientConnState(state balancer.ClientConnState) error <span class="cov8" title="1">{
        if b.closed.HasFired() </span><span class="cov0" title="0">{
                b.logger.Warningf("xds: received ClientConnState {%+v} after clusterResolverBalancer was closed", state)
                return errBalancerClosed
        }</span>

        <span class="cov8" title="1">if b.xdsClient == nil </span><span class="cov8" title="1">{
                c := xdsclient.FromResolverState(state.ResolverState)
                if c == nil </span><span class="cov0" title="0">{
                        return balancer.ErrBadResolverState
                }</span>
                <span class="cov8" title="1">b.xdsClient = c
                b.attrsWithClient = state.ResolverState.Attributes</span>
        }

        <span class="cov8" title="1">b.updateCh.Put(&amp;ccUpdate{state: state})
        return nil</span>
}

// ResolverError handles errors reported by the xdsResolver.
func (b *clusterResolverBalancer) ResolverError(err error) <span class="cov8" title="1">{
        if b.closed.HasFired() </span><span class="cov0" title="0">{
                b.logger.Warningf("xds: received resolver error {%v} after clusterResolverBalancer was closed", err)
                return
        }</span>
        <span class="cov8" title="1">b.updateCh.Put(&amp;ccUpdate{err: err})</span>
}

// UpdateSubConnState handles subConn updates from gRPC.
func (b *clusterResolverBalancer) UpdateSubConnState(sc balancer.SubConn, state balancer.SubConnState) <span class="cov8" title="1">{
        if b.closed.HasFired() </span><span class="cov0" title="0">{
                b.logger.Warningf("xds: received subConn update {%v, %v} after clusterResolverBalancer was closed", sc, state)
                return
        }</span>
        <span class="cov8" title="1">b.updateCh.Put(&amp;scUpdate{subConn: sc, state: state})</span>
}

// Close closes the cdsBalancer and the underlying child balancer.
func (b *clusterResolverBalancer) Close() <span class="cov8" title="1">{
        b.closed.Fire()
        &lt;-b.done.Done()
}</span>

func (b *clusterResolverBalancer) ExitIdle() <span class="cov0" title="0">{
        b.updateCh.Put(exitIdle{})
}</span>

// ccWrapper overrides ResolveNow(), so that re-resolution from the child
// policies will trigger the DNS resolver in cluster_resolver balancer.
type ccWrapper struct {
        balancer.ClientConn
        resourceWatcher *resourceResolver
}

func (c *ccWrapper) ResolveNow(resolver.ResolveNowOptions) <span class="cov8" title="1">{
        c.resourceWatcher.resolveNow()
}</span>
</pre>
		
		<pre class="file" id="file159" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package clusterresolver

import (
        "bytes"
        "encoding/json"
        "fmt"

        internalserviceconfig "google.golang.org/grpc/internal/serviceconfig"
        "google.golang.org/grpc/serviceconfig"
        "google.golang.org/grpc/xds/internal/balancer/outlierdetection"
        "google.golang.org/grpc/xds/internal/xdsclient/bootstrap"
)

// DiscoveryMechanismType is the type of discovery mechanism.
type DiscoveryMechanismType int

const (
        // DiscoveryMechanismTypeEDS is eds.
        DiscoveryMechanismTypeEDS DiscoveryMechanismType = iota // `json:"EDS"`
        // DiscoveryMechanismTypeLogicalDNS is DNS.
        DiscoveryMechanismTypeLogicalDNS // `json:"LOGICAL_DNS"`
)

// MarshalJSON marshals a DiscoveryMechanismType to a quoted json string.
//
// This is necessary to handle enum (as strings) from JSON.
//
// Note that this needs to be defined on the type not pointer, otherwise the
// variables of this type will marshal to int not string.
func (t DiscoveryMechanismType) MarshalJSON() ([]byte, error) <span class="cov8" title="1">{
        buffer := bytes.NewBufferString(`"`)
        switch t </span>{
        case DiscoveryMechanismTypeEDS:<span class="cov8" title="1">
                buffer.WriteString("EDS")</span>
        case DiscoveryMechanismTypeLogicalDNS:<span class="cov8" title="1">
                buffer.WriteString("LOGICAL_DNS")</span>
        }
        <span class="cov8" title="1">buffer.WriteString(`"`)
        return buffer.Bytes(), nil</span>
}

// UnmarshalJSON unmarshals a quoted json string to the DiscoveryMechanismType.
func (t *DiscoveryMechanismType) UnmarshalJSON(b []byte) error <span class="cov8" title="1">{
        var s string
        err := json.Unmarshal(b, &amp;s)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov8" title="1">switch s </span>{
        case "EDS":<span class="cov8" title="1">
                *t = DiscoveryMechanismTypeEDS</span>
        case "LOGICAL_DNS":<span class="cov8" title="1">
                *t = DiscoveryMechanismTypeLogicalDNS</span>
        default:<span class="cov8" title="1">
                return fmt.Errorf("unable to unmarshal string %q to type DiscoveryMechanismType", s)</span>
        }
        <span class="cov8" title="1">return nil</span>
}

// DiscoveryMechanism is the discovery mechanism, can be either EDS or DNS.
//
// For DNS, the ClientConn target will be used for name resolution.
//
// For EDS, if EDSServiceName is not empty, it will be used for watching. If
// EDSServiceName is empty, Cluster will be used.
type DiscoveryMechanism struct {
        // Cluster is the cluster name.
        Cluster string `json:"cluster,omitempty"`
        // LoadReportingServer is the LRS server to send load reports to. If not
        // present, load reporting will be disabled.
        LoadReportingServer *bootstrap.ServerConfig `json:"lrsLoadReportingServer,omitempty"`
        // MaxConcurrentRequests is the maximum number of outstanding requests can
        // be made to the upstream cluster. Default is 1024.
        MaxConcurrentRequests *uint32 `json:"maxConcurrentRequests,omitempty"`
        // Type is the discovery mechanism type.
        Type DiscoveryMechanismType `json:"type,omitempty"`
        // EDSServiceName is the EDS service name, as returned in CDS. May be unset
        // if not specified in CDS. For type EDS only.
        //
        // This is used for EDS watch if set. If unset, Cluster is used for EDS
        // watch.
        EDSServiceName string `json:"edsServiceName,omitempty"`
        // DNSHostname is the DNS name to resolve in "host:port" form. For type
        // LOGICAL_DNS only.
        DNSHostname string `json:"dnsHostname,omitempty"`
        // OutlierDetection is the Outlier Detection LB configuration for this
        // priority.
        OutlierDetection outlierdetection.LBConfig `json:"outlierDetection,omitempty"`
}

// Equal returns whether the DiscoveryMechanism is the same with the parameter.
func (dm DiscoveryMechanism) Equal(b DiscoveryMechanism) bool <span class="cov8" title="1">{
        switch </span>{
        case dm.Cluster != b.Cluster:<span class="cov8" title="1">
                return false</span>
        case !equalUint32P(dm.MaxConcurrentRequests, b.MaxConcurrentRequests):<span class="cov8" title="1">
                return false</span>
        case dm.Type != b.Type:<span class="cov0" title="0">
                return false</span>
        case dm.EDSServiceName != b.EDSServiceName:<span class="cov8" title="1">
                return false</span>
        case dm.DNSHostname != b.DNSHostname:<span class="cov0" title="0">
                return false</span>
        case !dm.OutlierDetection.EqualIgnoringChildPolicy(&amp;b.OutlierDetection):<span class="cov0" title="0">
                return false</span>
        }

        <span class="cov8" title="1">if dm.LoadReportingServer == nil &amp;&amp; b.LoadReportingServer == nil </span><span class="cov8" title="1">{
                return true
        }</span>
        <span class="cov8" title="1">if (dm.LoadReportingServer != nil) != (b.LoadReportingServer != nil) </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov8" title="1">return dm.LoadReportingServer.String() == b.LoadReportingServer.String()</span>
}

func equalUint32P(a, b *uint32) bool <span class="cov8" title="1">{
        if a == nil &amp;&amp; b == nil </span><span class="cov8" title="1">{
                return true
        }</span>
        <span class="cov8" title="1">if a == nil || b == nil </span><span class="cov8" title="1">{
                return false
        }</span>
        <span class="cov8" title="1">return *a == *b</span>
}

// LBConfig is the config for cluster resolver balancer.
type LBConfig struct {
        serviceconfig.LoadBalancingConfig `json:"-"`
        // DiscoveryMechanisms is an ordered list of discovery mechanisms.
        //
        // Must have at least one element. Results from each discovery mechanism are
        // concatenated together in successive priorities.
        DiscoveryMechanisms []DiscoveryMechanism `json:"discoveryMechanisms,omitempty"`

        // XDSLBPolicy specifies the policy for locality picking and endpoint picking.
        //
        // Note that it's not normal balancing policy, and it can only be either
        // ROUND_ROBIN or RING_HASH.
        //
        // For ROUND_ROBIN, the policy name will be "ROUND_ROBIN", and the config
        // will be empty. This sets the locality-picking policy to weighted_target
        // and the endpoint-picking policy to round_robin.
        //
        // For RING_HASH, the policy name will be "RING_HASH", and the config will
        // be lb config for the ring_hash_experimental LB Policy. ring_hash policy
        // is responsible for both locality picking and endpoint picking.
        XDSLBPolicy *internalserviceconfig.BalancerConfig `json:"xdsLbPolicy,omitempty"`
}
</pre>
		
		<pre class="file" id="file160" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package clusterresolver

import (
        "encoding/json"
        "fmt"
        "sort"

        "google.golang.org/grpc/balancer/roundrobin"
        "google.golang.org/grpc/balancer/weightedroundrobin"
        "google.golang.org/grpc/balancer/weightedtarget"
        "google.golang.org/grpc/internal/envconfig"
        "google.golang.org/grpc/internal/hierarchy"
        internalserviceconfig "google.golang.org/grpc/internal/serviceconfig"
        "google.golang.org/grpc/resolver"
        "google.golang.org/grpc/xds/internal"
        "google.golang.org/grpc/xds/internal/balancer/clusterimpl"
        "google.golang.org/grpc/xds/internal/balancer/outlierdetection"
        "google.golang.org/grpc/xds/internal/balancer/priority"
        "google.golang.org/grpc/xds/internal/balancer/ringhash"
        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource"
)

const million = 1000000

// priorityConfig is config for one priority. For example, if there an EDS and a
// DNS, the priority list will be [priorityConfig{EDS}, priorityConfig{DNS}].
//
// Each priorityConfig corresponds to one discovery mechanism from the LBConfig
// generated by the CDS balancer. The CDS balancer resolves the cluster name to
// an ordered list of discovery mechanisms (if the top cluster is an aggregated
// cluster), one for each underlying cluster.
type priorityConfig struct {
        mechanism DiscoveryMechanism
        // edsResp is set only if type is EDS.
        edsResp xdsresource.EndpointsUpdate
        // addresses is set only if type is DNS.
        addresses []string
        // Each discovery mechanism has a name generator so that the child policies
        // can reuse names between updates (EDS updates for example).
        childNameGen *nameGenerator
}

// buildPriorityConfigJSON builds balancer config for the passed in
// priorities.
//
// The built tree of balancers (see test for the output struct).
//
// If xds lb policy is ROUND_ROBIN, the children will be weighted_target for
// locality picking, and round_robin for endpoint picking.
//
//                                   ┌────────┐
//                                   │priority│
//                                   └┬──────┬┘
//                                    │      │
//                        ┌───────────▼┐    ┌▼───────────┐
//                        │cluster_impl│    │cluster_impl│
//                        └─┬──────────┘    └──────────┬─┘
//                          │                          │
//           ┌──────────────▼─┐                      ┌─▼──────────────┐
//           │locality_picking│                      │locality_picking│
//           └┬──────────────┬┘                      └┬──────────────┬┘
//            │              │                        │              │
//          ┌─▼─┐          ┌─▼─┐                    ┌─▼─┐          ┌─▼─┐
//          │LRS│          │LRS│                    │LRS│          │LRS│
//          └─┬─┘          └─┬─┘                    └─┬─┘          └─┬─┘
//            │              │                        │              │
// ┌──────────▼─────┐  ┌─────▼──────────┐  ┌──────────▼─────┐  ┌─────▼──────────┐
// │endpoint_picking│  │endpoint_picking│  │endpoint_picking│  │endpoint_picking│
// └────────────────┘  └────────────────┘  └────────────────┘  └────────────────┘
//
// If xds lb policy is RING_HASH, the children will be just a ring_hash policy.
// The endpoints from all localities will be flattened to one addresses list,
// and the ring_hash policy will pick endpoints from it.
//
//           ┌────────┐
//           │priority│
//           └┬──────┬┘
//            │      │
// ┌──────────▼─┐  ┌─▼──────────┐
// │cluster_impl│  │cluster_impl│
// └──────┬─────┘  └─────┬──────┘
//        │              │
// ┌──────▼─────┐  ┌─────▼──────┐
// │ ring_hash  │  │ ring_hash  │
// └────────────┘  └────────────┘
//
// If endpointPickingPolicy is nil, roundrobin will be used.
//
// Custom locality picking policy isn't support, and weighted_target is always
// used.
func buildPriorityConfigJSON(priorities []priorityConfig, xdsLBPolicy *internalserviceconfig.BalancerConfig) ([]byte, []resolver.Address, error) <span class="cov8" title="1">{
        pc, addrs, err := buildPriorityConfig(priorities, xdsLBPolicy)
        if err != nil </span><span class="cov0" title="0">{
                return nil, nil, fmt.Errorf("failed to build priority config: %v", err)
        }</span>
        <span class="cov8" title="1">ret, err := json.Marshal(pc)
        if err != nil </span><span class="cov0" title="0">{
                return nil, nil, fmt.Errorf("failed to marshal built priority config struct into json: %v", err)
        }</span>
        <span class="cov8" title="1">return ret, addrs, nil</span>
}

func buildPriorityConfig(priorities []priorityConfig, xdsLBPolicy *internalserviceconfig.BalancerConfig) (*priority.LBConfig, []resolver.Address, error) <span class="cov8" title="1">{
        var (
                retConfig = &amp;priority.LBConfig{Children: make(map[string]*priority.Child)}
                retAddrs  []resolver.Address
        )
        for _, p := range priorities </span><span class="cov8" title="1">{
                switch p.mechanism.Type </span>{
                case DiscoveryMechanismTypeEDS:<span class="cov8" title="1">
                        names, configs, addrs, err := buildClusterImplConfigForEDS(p.childNameGen, p.edsResp, p.mechanism, xdsLBPolicy)
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, nil, err
                        }</span>
                        <span class="cov8" title="1">retConfig.Priorities = append(retConfig.Priorities, names...)
                        retAddrs = append(retAddrs, addrs...)
                        var odCfgs map[string]*outlierdetection.LBConfig
                        if envconfig.XDSOutlierDetection </span><span class="cov8" title="1">{
                                odCfgs = convertClusterImplMapToOutlierDetection(configs, p.mechanism.OutlierDetection)
                                for n, c := range odCfgs </span><span class="cov8" title="1">{
                                        retConfig.Children[n] = &amp;priority.Child{
                                                Config: &amp;internalserviceconfig.BalancerConfig{Name: outlierdetection.Name, Config: c},
                                                // Ignore all re-resolution from EDS children.
                                                IgnoreReresolutionRequests: true,
                                        }
                                }</span>
                                <span class="cov8" title="1">continue</span>
                        }
                        <span class="cov8" title="1">for n, c := range configs </span><span class="cov8" title="1">{
                                retConfig.Children[n] = &amp;priority.Child{
                                        Config: &amp;internalserviceconfig.BalancerConfig{Name: clusterimpl.Name, Config: c},
                                        // Ignore all re-resolution from EDS children.
                                        IgnoreReresolutionRequests: true,
                                }

                        }</span>
                case DiscoveryMechanismTypeLogicalDNS:<span class="cov8" title="1">
                        name, config, addrs := buildClusterImplConfigForDNS(p.childNameGen, p.addresses, p.mechanism)
                        retConfig.Priorities = append(retConfig.Priorities, name)
                        retAddrs = append(retAddrs, addrs...)
                        var odCfg *outlierdetection.LBConfig
                        if envconfig.XDSOutlierDetection </span><span class="cov8" title="1">{
                                odCfg = makeClusterImplOutlierDetectionChild(config, p.mechanism.OutlierDetection)
                                retConfig.Children[name] = &amp;priority.Child{
                                        Config: &amp;internalserviceconfig.BalancerConfig{Name: outlierdetection.Name, Config: odCfg},
                                        // Not ignore re-resolution from DNS children, they will trigger
                                        // DNS to re-resolve.
                                        IgnoreReresolutionRequests: false,
                                }
                                continue</span>
                        }
                        <span class="cov8" title="1">retConfig.Children[name] = &amp;priority.Child{
                                Config: &amp;internalserviceconfig.BalancerConfig{Name: clusterimpl.Name, Config: config},
                                // Not ignore re-resolution from DNS children, they will trigger
                                // DNS to re-resolve.
                                IgnoreReresolutionRequests: false,
                        }</span>
                }
        }
        <span class="cov8" title="1">return retConfig, retAddrs, nil</span>
}

func convertClusterImplMapToOutlierDetection(ciCfgs map[string]*clusterimpl.LBConfig, odCfg outlierdetection.LBConfig) map[string]*outlierdetection.LBConfig <span class="cov8" title="1">{
        odCfgs := make(map[string]*outlierdetection.LBConfig, len(ciCfgs))
        for n, c := range ciCfgs </span><span class="cov8" title="1">{
                odCfgs[n] = makeClusterImplOutlierDetectionChild(c, odCfg)
        }</span>
        <span class="cov8" title="1">return odCfgs</span>
}

func makeClusterImplOutlierDetectionChild(ciCfg *clusterimpl.LBConfig, odCfg outlierdetection.LBConfig) *outlierdetection.LBConfig <span class="cov8" title="1">{
        odCfgRet := odCfg
        odCfgRet.ChildPolicy = &amp;internalserviceconfig.BalancerConfig{Name: clusterimpl.Name, Config: ciCfg}
        return &amp;odCfgRet
}</span>

func buildClusterImplConfigForDNS(g *nameGenerator, addrStrs []string, mechanism DiscoveryMechanism) (string, *clusterimpl.LBConfig, []resolver.Address) <span class="cov8" title="1">{
        // Endpoint picking policy for DNS is hardcoded to pick_first.
        const childPolicy = "pick_first"
        retAddrs := make([]resolver.Address, 0, len(addrStrs))
        pName := fmt.Sprintf("priority-%v", g.prefix)
        for _, addrStr := range addrStrs </span><span class="cov8" title="1">{
                retAddrs = append(retAddrs, hierarchy.Set(resolver.Address{Addr: addrStr}, []string{pName}))
        }</span>
        <span class="cov8" title="1">return pName, &amp;clusterimpl.LBConfig{
                Cluster:     mechanism.Cluster,
                ChildPolicy: &amp;internalserviceconfig.BalancerConfig{Name: childPolicy},
        }, retAddrs</span>
}

// buildClusterImplConfigForEDS returns a list of cluster_impl configs, one for
// each priority, sorted by priority, and the addresses for each priority (with
// hierarchy attributes set).
//
// For example, if there are two priorities, the returned values will be
// - ["p0", "p1"]
// - map{"p0":p0_config, "p1":p1_config}
// - [p0_address_0, p0_address_1, p1_address_0, p1_address_1]
//   - p0 addresses' hierarchy attributes are set to p0
func buildClusterImplConfigForEDS(g *nameGenerator, edsResp xdsresource.EndpointsUpdate, mechanism DiscoveryMechanism, xdsLBPolicy *internalserviceconfig.BalancerConfig) ([]string, map[string]*clusterimpl.LBConfig, []resolver.Address, error) <span class="cov8" title="1">{
        drops := make([]clusterimpl.DropConfig, 0, len(edsResp.Drops))
        for _, d := range edsResp.Drops </span><span class="cov8" title="1">{
                drops = append(drops, clusterimpl.DropConfig{
                        Category:           d.Category,
                        RequestsPerMillion: d.Numerator * million / d.Denominator,
                })
        }</span>

        <span class="cov8" title="1">priorities := groupLocalitiesByPriority(edsResp.Localities)
        retNames := g.generate(priorities)
        retConfigs := make(map[string]*clusterimpl.LBConfig, len(retNames))
        var retAddrs []resolver.Address
        for i, pName := range retNames </span><span class="cov8" title="1">{
                priorityLocalities := priorities[i]
                cfg, addrs, err := priorityLocalitiesToClusterImpl(priorityLocalities, pName, mechanism, drops, xdsLBPolicy)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, nil, nil, err
                }</span>
                <span class="cov8" title="1">retConfigs[pName] = cfg
                retAddrs = append(retAddrs, addrs...)</span>
        }
        <span class="cov8" title="1">return retNames, retConfigs, retAddrs, nil</span>
}

// groupLocalitiesByPriority returns the localities grouped by priority.
//
// The returned list is sorted from higher priority to lower. Each item in the
// list is a group of localities.
//
// For example, for L0-p0, L1-p0, L2-p1, results will be
// - [[L0, L1], [L2]]
func groupLocalitiesByPriority(localities []xdsresource.Locality) [][]xdsresource.Locality <span class="cov8" title="1">{
        var priorityIntSlice []int
        priorities := make(map[int][]xdsresource.Locality)
        for _, locality := range localities </span><span class="cov8" title="1">{
                priority := int(locality.Priority)
                priorities[priority] = append(priorities[priority], locality)
                priorityIntSlice = append(priorityIntSlice, priority)
        }</span>
        // Sort the priorities based on the int value, deduplicate, and then turn
        // the sorted list into a string list. This will be child names, in priority
        // order.
        <span class="cov8" title="1">sort.Ints(priorityIntSlice)
        priorityIntSliceDeduped := dedupSortedIntSlice(priorityIntSlice)
        ret := make([][]xdsresource.Locality, 0, len(priorityIntSliceDeduped))
        for _, p := range priorityIntSliceDeduped </span><span class="cov8" title="1">{
                ret = append(ret, priorities[p])
        }</span>
        <span class="cov8" title="1">return ret</span>
}

func dedupSortedIntSlice(a []int) []int <span class="cov8" title="1">{
        if len(a) == 0 </span><span class="cov8" title="1">{
                return a
        }</span>
        <span class="cov8" title="1">i, j := 0, 1
        for ; j &lt; len(a); j++ </span><span class="cov8" title="1">{
                if a[i] == a[j] </span><span class="cov8" title="1">{
                        continue</span>
                }
                <span class="cov8" title="1">i++
                if i != j </span><span class="cov8" title="1">{
                        a[i] = a[j]
                }</span>
        }
        <span class="cov8" title="1">return a[:i+1]</span>
}

// rrBalancerConfig is a const roundrobin config, used as child of
// weighted-roundrobin. To avoid allocating memory everytime.
var rrBalancerConfig = &amp;internalserviceconfig.BalancerConfig{Name: roundrobin.Name}

// priorityLocalitiesToClusterImpl takes a list of localities (with the same
// priority), and generates a cluster impl policy config, and a list of
// addresses.
func priorityLocalitiesToClusterImpl(localities []xdsresource.Locality, priorityName string, mechanism DiscoveryMechanism, drops []clusterimpl.DropConfig, xdsLBPolicy *internalserviceconfig.BalancerConfig) (*clusterimpl.LBConfig, []resolver.Address, error) <span class="cov8" title="1">{
        clusterImplCfg := &amp;clusterimpl.LBConfig{
                Cluster:               mechanism.Cluster,
                EDSServiceName:        mechanism.EDSServiceName,
                LoadReportingServer:   mechanism.LoadReportingServer,
                MaxConcurrentRequests: mechanism.MaxConcurrentRequests,
                DropCategories:        drops,
                // ChildPolicy is not set. Will be set based on xdsLBPolicy
        }

        if xdsLBPolicy == nil || xdsLBPolicy.Name == roundrobin.Name </span><span class="cov8" title="1">{
                // If lb policy is ROUND_ROBIN:
                // - locality-picking policy is weighted_target
                // - endpoint-picking policy is round_robin
                logger.Infof("xds lb policy is %q, building config with weighted_target + round_robin", roundrobin.Name)
                // Child of weighted_target is hardcoded to round_robin.
                wtConfig, addrs := localitiesToWeightedTarget(localities, priorityName, rrBalancerConfig)
                clusterImplCfg.ChildPolicy = &amp;internalserviceconfig.BalancerConfig{Name: weightedtarget.Name, Config: wtConfig}
                return clusterImplCfg, addrs, nil
        }</span>

        <span class="cov8" title="1">if xdsLBPolicy.Name == ringhash.Name </span><span class="cov8" title="1">{
                // If lb policy is RIHG_HASH, will build one ring_hash policy as child.
                // The endpoints from all localities will be flattened to one addresses
                // list, and the ring_hash policy will pick endpoints from it.
                logger.Infof("xds lb policy is %q, building config with ring_hash", ringhash.Name)
                addrs := localitiesToRingHash(localities, priorityName)
                // Set child to ring_hash, note that the ring_hash config is from
                // xdsLBPolicy.
                clusterImplCfg.ChildPolicy = &amp;internalserviceconfig.BalancerConfig{Name: ringhash.Name, Config: xdsLBPolicy.Config}
                return clusterImplCfg, addrs, nil
        }</span>

        <span class="cov8" title="1">return nil, nil, fmt.Errorf("unsupported xds LB policy %q, not one of {%q,%q}", xdsLBPolicy.Name, roundrobin.Name, ringhash.Name)</span>
}

// localitiesToRingHash takes a list of localities (with the same priority), and
// generates a list of addresses.
//
// The addresses have path hierarchy set to [priority-name], so priority knows
// which child policy they are for.
func localitiesToRingHash(localities []xdsresource.Locality, priorityName string) []resolver.Address <span class="cov8" title="1">{
        var addrs []resolver.Address
        for _, locality := range localities </span><span class="cov8" title="1">{
                var lw uint32 = 1
                if locality.Weight != 0 </span><span class="cov8" title="1">{
                        lw = locality.Weight
                }</span>
                <span class="cov8" title="1">localityStr, err := locality.ID.ToString()
                if err != nil </span><span class="cov0" title="0">{
                        localityStr = fmt.Sprintf("%+v", locality.ID)
                }</span>
                <span class="cov8" title="1">for _, endpoint := range locality.Endpoints </span><span class="cov8" title="1">{
                        // Filter out all "unhealthy" endpoints (unknown and healthy are
                        // both considered to be healthy:
                        // https://www.envoyproxy.io/docs/envoy/latest/api-v2/api/v2/core/health_check.proto#envoy-api-enum-core-healthstatus).
                        if endpoint.HealthStatus != xdsresource.EndpointHealthStatusHealthy &amp;&amp; endpoint.HealthStatus != xdsresource.EndpointHealthStatusUnknown </span><span class="cov0" title="0">{
                                continue</span>
                        }

                        <span class="cov8" title="1">var ew uint32 = 1
                        if endpoint.Weight != 0 </span><span class="cov8" title="1">{
                                ew = endpoint.Weight
                        }</span>

                        // The weight of each endpoint is locality_weight * endpoint_weight.
                        <span class="cov8" title="1">ai := weightedroundrobin.AddrInfo{Weight: lw * ew}
                        addr := weightedroundrobin.SetAddrInfo(resolver.Address{Addr: endpoint.Address}, ai)
                        addr = hierarchy.Set(addr, []string{priorityName, localityStr})
                        addr = internal.SetLocalityID(addr, locality.ID)
                        addrs = append(addrs, addr)</span>
                }
        }
        <span class="cov8" title="1">return addrs</span>
}

// localitiesToWeightedTarget takes a list of localities (with the same
// priority), and generates a weighted target config, and list of addresses.
//
// The addresses have path hierarchy set to [priority-name, locality-name], so
// priority and weighted target know which child policy they are for.
func localitiesToWeightedTarget(localities []xdsresource.Locality, priorityName string, childPolicy *internalserviceconfig.BalancerConfig) (*weightedtarget.LBConfig, []resolver.Address) <span class="cov8" title="1">{
        weightedTargets := make(map[string]weightedtarget.Target)
        var addrs []resolver.Address
        for _, locality := range localities </span><span class="cov8" title="1">{
                localityStr, err := locality.ID.ToString()
                if err != nil </span><span class="cov0" title="0">{
                        localityStr = fmt.Sprintf("%+v", locality.ID)
                }</span>
                <span class="cov8" title="1">weightedTargets[localityStr] = weightedtarget.Target{Weight: locality.Weight, ChildPolicy: childPolicy}
                for _, endpoint := range locality.Endpoints </span><span class="cov8" title="1">{
                        // Filter out all "unhealthy" endpoints (unknown and healthy are
                        // both considered to be healthy:
                        // https://www.envoyproxy.io/docs/envoy/latest/api-v2/api/v2/core/health_check.proto#envoy-api-enum-core-healthstatus).
                        if endpoint.HealthStatus != xdsresource.EndpointHealthStatusHealthy &amp;&amp; endpoint.HealthStatus != xdsresource.EndpointHealthStatusUnknown </span><span class="cov8" title="1">{
                                continue</span>
                        }

                        <span class="cov8" title="1">addr := resolver.Address{Addr: endpoint.Address}
                        if childPolicy.Name == weightedroundrobin.Name &amp;&amp; endpoint.Weight != 0 </span><span class="cov8" title="1">{
                                ai := weightedroundrobin.AddrInfo{Weight: endpoint.Weight}
                                addr = weightedroundrobin.SetAddrInfo(addr, ai)
                        }</span>
                        <span class="cov8" title="1">addr = hierarchy.Set(addr, []string{priorityName, localityStr})
                        addr = internal.SetLocalityID(addr, locality.ID)
                        addrs = append(addrs, addr)</span>
                }
        }
        <span class="cov8" title="1">return &amp;weightedtarget.LBConfig{Targets: weightedTargets}, addrs</span>
}
</pre>
		
		<pre class="file" id="file161" style="display: none">/*
 *
 * Copyright 2022 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package clusterresolver

import (
        "fmt"

        "google.golang.org/grpc/xds/internal"
        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource"
)

// nameGenerator generates a child name for a list of priorities (each priority
// is a list of localities).
//
// The purpose of this generator is to reuse names between updates. So the
// struct keeps state between generate() calls, and a later generate() might
// return names returned by the previous call.
type nameGenerator struct {
        existingNames map[internal.LocalityID]string
        prefix        uint64
        nextID        uint64
}

func newNameGenerator(prefix uint64) *nameGenerator <span class="cov8" title="1">{
        return &amp;nameGenerator{prefix: prefix}
}</span>

// generate returns a list of names for the given list of priorities.
//
// Each priority is a list of localities. The name for the priority is picked as
// - for each locality in this priority, if it exists in the existing names,
// this priority will reuse the name
// - if no reusable name is found for this priority, a new name is generated
//
// For example:
// - update 1: [[L1], [L2], [L3]] --&gt; ["0", "1", "2"]
// - update 2: [[L1], [L2], [L3]] --&gt; ["0", "1", "2"]
// - update 3: [[L1, L2], [L3]] --&gt; ["0", "2"]   (Two priorities were merged)
// - update 4: [[L1], [L4]] --&gt; ["0", "3",]      (A priority was split, and a new priority was added)
func (ng *nameGenerator) generate(priorities [][]xdsresource.Locality) []string <span class="cov8" title="1">{
        var ret []string
        usedNames := make(map[string]bool)
        newNames := make(map[internal.LocalityID]string)
        for _, priority := range priorities </span><span class="cov8" title="1">{
                var nameFound string
                for _, locality := range priority </span><span class="cov8" title="1">{
                        if name, ok := ng.existingNames[locality.ID]; ok </span><span class="cov8" title="1">{
                                if !usedNames[name] </span><span class="cov8" title="1">{
                                        nameFound = name
                                        // Found a name to use. No need to process the remaining
                                        // localities.
                                        break</span>
                                }
                        }
                }

                <span class="cov8" title="1">if nameFound == "" </span><span class="cov8" title="1">{
                        // No appropriate used name is found. Make a new name.
                        nameFound = fmt.Sprintf("priority-%d-%d", ng.prefix, ng.nextID)
                        ng.nextID++
                }</span>

                <span class="cov8" title="1">ret = append(ret, nameFound)
                // All localities in this priority share the same name. Add them all to
                // the new map.
                for _, l := range priority </span><span class="cov8" title="1">{
                        newNames[l.ID] = nameFound
                }</span>
                <span class="cov8" title="1">usedNames[nameFound] = true</span>
        }
        <span class="cov8" title="1">ng.existingNames = newNames
        return ret</span>
}
</pre>
		
		<pre class="file" id="file162" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package clusterresolver

import (
        "fmt"

        "google.golang.org/grpc/grpclog"
        internalgrpclog "google.golang.org/grpc/internal/grpclog"
)

const prefix = "[xds-cluster-resolver-lb %p] "

var logger = grpclog.Component("xds")

func prefixLogger(p *clusterResolverBalancer) *internalgrpclog.PrefixLogger <span class="cov8" title="1">{
        return internalgrpclog.NewPrefixLogger(logger, fmt.Sprintf(prefix, p))
}</span>
</pre>
		
		<pre class="file" id="file163" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package clusterresolver

import (
        "sync"

        "google.golang.org/grpc/xds/internal/xdsclient"
        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource"
)

// resourceUpdate is a combined update from all the resources, in the order of
// priority. For example, it can be {EDS, EDS, DNS}.
type resourceUpdate struct {
        priorities []priorityConfig
        err        error
}

type discoveryMechanism interface {
        lastUpdate() (interface{}, bool)
        resolveNow()
        stop()
}

// discoveryMechanismKey is {type+resource_name}, it's used as the map key, so
// that the same resource resolver can be reused (e.g. when there are two
// mechanisms, both for the same EDS resource, but has different circuit
// breaking config.
type discoveryMechanismKey struct {
        typ  DiscoveryMechanismType
        name string
}

// resolverMechanismTuple is needed to keep the resolver and the discovery
// mechanism together, because resolvers can be shared. And we need the
// mechanism for fields like circuit breaking, LRS etc when generating the
// balancer config.
type resolverMechanismTuple struct {
        dm    DiscoveryMechanism
        dmKey discoveryMechanismKey
        r     discoveryMechanism

        childNameGen *nameGenerator
}

type resourceResolver struct {
        parent        *clusterResolverBalancer
        updateChannel chan *resourceUpdate

        // mu protects the slice and map, and content of the resolvers in the slice.
        mu         sync.Mutex
        mechanisms []DiscoveryMechanism
        children   []resolverMechanismTuple
        // childrenMap's value only needs the resolver implementation (type
        // discoveryMechanism) and the childNameGen. The other two fields are not
        // used.
        //
        // TODO(cleanup): maybe we can make a new type with just the necessary
        // fields, and use it here instead.
        childrenMap map[discoveryMechanismKey]resolverMechanismTuple
        // Each new discovery mechanism needs a child name generator to reuse child
        // policy names. But to make sure the names across discover mechanism
        // doesn't conflict, we need a seq ID. This ID is incremented for each new
        // discover mechanism.
        childNameGeneratorSeqID uint64
}

func newResourceResolver(parent *clusterResolverBalancer) *resourceResolver <span class="cov8" title="1">{
        return &amp;resourceResolver{
                parent:        parent,
                updateChannel: make(chan *resourceUpdate, 1),
                childrenMap:   make(map[discoveryMechanismKey]resolverMechanismTuple),
        }
}</span>

func equalDiscoveryMechanisms(a, b []DiscoveryMechanism) bool <span class="cov8" title="1">{
        if len(a) != len(b) </span><span class="cov8" title="1">{
                return false
        }</span>
        <span class="cov8" title="1">for i, aa := range a </span><span class="cov8" title="1">{
                bb := b[i]
                if !aa.Equal(bb) </span><span class="cov8" title="1">{
                        return false
                }</span>
        }
        <span class="cov8" title="1">return true</span>
}

func (rr *resourceResolver) updateMechanisms(mechanisms []DiscoveryMechanism) <span class="cov8" title="1">{
        rr.mu.Lock()
        defer rr.mu.Unlock()
        if equalDiscoveryMechanisms(rr.mechanisms, mechanisms) </span><span class="cov8" title="1">{
                return
        }</span>
        <span class="cov8" title="1">rr.mechanisms = mechanisms
        rr.children = make([]resolverMechanismTuple, len(mechanisms))
        newDMs := make(map[discoveryMechanismKey]bool)

        // Start one watch for each new discover mechanism {type+resource_name}.
        for i, dm := range mechanisms </span><span class="cov8" title="1">{
                switch dm.Type </span>{
                case DiscoveryMechanismTypeEDS:<span class="cov8" title="1">
                        // If EDSServiceName is not set, use the cluster name as EDS service
                        // name to watch.
                        nameToWatch := dm.EDSServiceName
                        if nameToWatch == "" </span><span class="cov8" title="1">{
                                nameToWatch = dm.Cluster
                        }</span>
                        <span class="cov8" title="1">dmKey := discoveryMechanismKey{typ: dm.Type, name: nameToWatch}
                        newDMs[dmKey] = true

                        r, ok := rr.childrenMap[dmKey]
                        if !ok </span><span class="cov8" title="1">{
                                r = resolverMechanismTuple{
                                        dm:           dm,
                                        dmKey:        dmKey,
                                        r:            newEDSResolver(nameToWatch, rr.parent.xdsClient, rr),
                                        childNameGen: newNameGenerator(rr.childNameGeneratorSeqID),
                                }
                                rr.childrenMap[dmKey] = r
                                rr.childNameGeneratorSeqID++
                        }</span> else<span class="cov8" title="1"> {
                                // If this is not new, keep the fields (especially
                                // childNameGen), and only update the DiscoveryMechanism.
                                //
                                // Note that the same dmKey doesn't mean the same
                                // DiscoveryMechanism. There are fields (e.g.
                                // MaxConcurrentRequests) in DiscoveryMechanism that are not
                                // copied to dmKey, we need to keep those updated.
                                r.dm = dm
                        }</span>
                        <span class="cov8" title="1">rr.children[i] = r</span>
                case DiscoveryMechanismTypeLogicalDNS:<span class="cov8" title="1">
                        // Name to resolve in DNS is the hostname, not the ClientConn
                        // target.
                        dmKey := discoveryMechanismKey{typ: dm.Type, name: dm.DNSHostname}
                        newDMs[dmKey] = true

                        r, ok := rr.childrenMap[dmKey]
                        if !ok </span><span class="cov8" title="1">{
                                r = resolverMechanismTuple{
                                        dm:           dm,
                                        dmKey:        dmKey,
                                        r:            newDNSResolver(dm.DNSHostname, rr),
                                        childNameGen: newNameGenerator(rr.childNameGeneratorSeqID),
                                }
                                rr.childrenMap[dmKey] = r
                                rr.childNameGeneratorSeqID++
                        }</span> else<span class="cov0" title="0"> {
                                r.dm = dm
                        }</span>
                        <span class="cov8" title="1">rr.children[i] = r</span>
                }
        }
        // Stop the resources that were removed.
        <span class="cov8" title="1">for dm, r := range rr.childrenMap </span><span class="cov8" title="1">{
                if !newDMs[dm] </span><span class="cov8" title="1">{
                        delete(rr.childrenMap, dm)
                        r.r.stop()
                }</span>
        }
        // Regenerate even if there's no change in discovery mechanism, in case
        // priority order changed.
        <span class="cov8" title="1">rr.generate()</span>
}

// resolveNow is typically called to trigger re-resolve of DNS. The EDS
// resolveNow() is a noop.
func (rr *resourceResolver) resolveNow() <span class="cov8" title="1">{
        rr.mu.Lock()
        defer rr.mu.Unlock()
        for _, r := range rr.childrenMap </span><span class="cov8" title="1">{
                r.r.resolveNow()
        }</span>
}

func (rr *resourceResolver) stop() <span class="cov8" title="1">{
        rr.mu.Lock()
        defer rr.mu.Unlock()
        for dm, r := range rr.childrenMap </span><span class="cov8" title="1">{
                delete(rr.childrenMap, dm)
                r.r.stop()
        }</span>
        <span class="cov8" title="1">rr.mechanisms = nil
        rr.children = nil</span>
}

// generate collects all the updates from all the resolvers, and push the
// combined result into the update channel. It only pushes the update when all
// the child resolvers have received at least one update, otherwise it will
// wait.
//
// caller must hold rr.mu.
func (rr *resourceResolver) generate() <span class="cov8" title="1">{
        var ret []priorityConfig
        for _, rDM := range rr.children </span><span class="cov8" title="1">{
                u, ok := rDM.r.lastUpdate()
                if !ok </span><span class="cov8" title="1">{
                        // Don't send updates to parent until all resolvers have update to
                        // send.
                        return
                }</span>
                <span class="cov8" title="1">switch uu := u.(type) </span>{
                case xdsresource.EndpointsUpdate:<span class="cov8" title="1">
                        ret = append(ret, priorityConfig{mechanism: rDM.dm, edsResp: uu, childNameGen: rDM.childNameGen})</span>
                case []string:<span class="cov8" title="1">
                        ret = append(ret, priorityConfig{mechanism: rDM.dm, addresses: uu, childNameGen: rDM.childNameGen})</span>
                }
        }
        <span class="cov8" title="1">select </span>{
        case &lt;-rr.updateChannel:<span class="cov0" title="0"></span>
        default:<span class="cov8" title="1"></span>
        }
        <span class="cov8" title="1">rr.updateChannel &lt;- &amp;resourceUpdate{priorities: ret}</span>
}

type edsDiscoveryMechanism struct {
        cancel func()

        update         xdsresource.EndpointsUpdate
        updateReceived bool
}

func (er *edsDiscoveryMechanism) lastUpdate() (interface{}, bool) <span class="cov8" title="1">{
        if !er.updateReceived </span><span class="cov8" title="1">{
                return nil, false
        }</span>
        <span class="cov8" title="1">return er.update, true</span>
}

func (er *edsDiscoveryMechanism) resolveNow() {<span class="cov8" title="1">
}</span>

func (er *edsDiscoveryMechanism) stop() <span class="cov8" title="1">{
        er.cancel()
}</span>

// newEDSResolver starts the EDS watch on the given xds client.
func newEDSResolver(nameToWatch string, xdsc xdsclient.XDSClient, topLevelResolver *resourceResolver) *edsDiscoveryMechanism <span class="cov8" title="1">{
        ret := &amp;edsDiscoveryMechanism{}
        topLevelResolver.parent.logger.Infof("EDS watch started on %v", nameToWatch)
        cancel := xdsc.WatchEndpoints(nameToWatch, func(update xdsresource.EndpointsUpdate, err error) </span><span class="cov8" title="1">{
                topLevelResolver.mu.Lock()
                defer topLevelResolver.mu.Unlock()
                if err != nil </span><span class="cov8" title="1">{
                        select </span>{
                        case &lt;-topLevelResolver.updateChannel:<span class="cov0" title="0"></span>
                        default:<span class="cov8" title="1"></span>
                        }
                        <span class="cov8" title="1">topLevelResolver.updateChannel &lt;- &amp;resourceUpdate{err: err}
                        return</span>
                }
                <span class="cov8" title="1">ret.update = update
                ret.updateReceived = true
                topLevelResolver.generate()</span>
        })
        <span class="cov8" title="1">ret.cancel = func() </span><span class="cov8" title="1">{
                topLevelResolver.parent.logger.Infof("EDS watch canceled on %v", nameToWatch)
                cancel()
        }</span>
        <span class="cov8" title="1">return ret</span>
}
</pre>
		
		<pre class="file" id="file164" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package clusterresolver

import (
        "fmt"

        "google.golang.org/grpc/resolver"
        "google.golang.org/grpc/serviceconfig"
)

var (
        newDNS = func(target resolver.Target, cc resolver.ClientConn, opts resolver.BuildOptions) (resolver.Resolver, error) <span class="cov0" title="0">{
                // The dns resolver is registered by the grpc package. So, this call to
                // resolver.Get() is never expected to return nil.
                return resolver.Get("dns").Build(target, cc, opts)
        }</span>
)

// dnsDiscoveryMechanism watches updates for the given DNS hostname.
//
// It implements resolver.ClientConn interface to work with the DNS resolver.
type dnsDiscoveryMechanism struct {
        target           string
        topLevelResolver *resourceResolver
        r                resolver.Resolver

        addrs          []string
        updateReceived bool
}

func newDNSResolver(target string, topLevelResolver *resourceResolver) *dnsDiscoveryMechanism <span class="cov8" title="1">{
        ret := &amp;dnsDiscoveryMechanism{
                target:           target,
                topLevelResolver: topLevelResolver,
        }
        r, err := newDNS(resolver.Target{Scheme: "dns", Endpoint: target}, ret, resolver.BuildOptions{})
        if err != nil </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-topLevelResolver.updateChannel:<span class="cov0" title="0"></span>
                default:<span class="cov0" title="0"></span>
                }
                <span class="cov0" title="0">topLevelResolver.updateChannel &lt;- &amp;resourceUpdate{err: err}</span>
        }
        <span class="cov8" title="1">ret.r = r
        return ret</span>
}

func (dr *dnsDiscoveryMechanism) lastUpdate() (interface{}, bool) <span class="cov8" title="1">{
        if !dr.updateReceived </span><span class="cov8" title="1">{
                return nil, false
        }</span>
        <span class="cov8" title="1">return dr.addrs, true</span>
}

func (dr *dnsDiscoveryMechanism) resolveNow() <span class="cov8" title="1">{
        dr.r.ResolveNow(resolver.ResolveNowOptions{})
}</span>

func (dr *dnsDiscoveryMechanism) stop() <span class="cov8" title="1">{
        dr.r.Close()
}</span>

// dnsDiscoveryMechanism needs to implement resolver.ClientConn interface to receive
// updates from the real DNS resolver.

func (dr *dnsDiscoveryMechanism) UpdateState(state resolver.State) error <span class="cov8" title="1">{
        dr.topLevelResolver.mu.Lock()
        defer dr.topLevelResolver.mu.Unlock()
        addrs := make([]string, len(state.Addresses))
        for i, a := range state.Addresses </span><span class="cov8" title="1">{
                addrs[i] = a.Addr
        }</span>
        <span class="cov8" title="1">dr.addrs = addrs
        dr.updateReceived = true
        dr.topLevelResolver.generate()
        return nil</span>
}

func (dr *dnsDiscoveryMechanism) ReportError(err error) <span class="cov8" title="1">{
        select </span>{
        case &lt;-dr.topLevelResolver.updateChannel:<span class="cov0" title="0"></span>
        default:<span class="cov8" title="1"></span>
        }
        <span class="cov8" title="1">dr.topLevelResolver.updateChannel &lt;- &amp;resourceUpdate{err: err}</span>
}

func (dr *dnsDiscoveryMechanism) NewAddress(addresses []resolver.Address) <span class="cov0" title="0">{
        dr.UpdateState(resolver.State{Addresses: addresses})
}</span>

func (dr *dnsDiscoveryMechanism) NewServiceConfig(string) {<span class="cov0" title="0">
        // This method is deprecated, and service config isn't supported.
}</span>

func (dr *dnsDiscoveryMechanism) ParseServiceConfig(string) *serviceconfig.ParseResult <span class="cov0" title="0">{
        return &amp;serviceconfig.ParseResult{Err: fmt.Errorf("service config not supported")}
}</span>
</pre>
		
		<pre class="file" id="file165" style="display: none">/*
 * Copyright 2019 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// Package orca implements Open Request Cost Aggregation.
package orca

import (
        orcapb "github.com/cncf/xds/go/xds/data/orca/v3"
        "github.com/golang/protobuf/proto"
        "google.golang.org/grpc/grpclog"
        "google.golang.org/grpc/internal/balancerload"
        "google.golang.org/grpc/metadata"
)

const mdKey = "X-Endpoint-Load-Metrics-Bin"

var logger = grpclog.Component("xds")

// toBytes converts a orca load report into bytes.
func toBytes(r *orcapb.OrcaLoadReport) []byte <span class="cov8" title="1">{
        if r == nil </span><span class="cov8" title="1">{
                return nil
        }</span>

        <span class="cov8" title="1">b, err := proto.Marshal(r)
        if err != nil </span><span class="cov0" title="0">{
                logger.Warningf("orca: failed to marshal load report: %v", err)
                return nil
        }</span>
        <span class="cov8" title="1">return b</span>
}

// ToMetadata converts a orca load report into grpc metadata.
func ToMetadata(r *orcapb.OrcaLoadReport) metadata.MD <span class="cov8" title="1">{
        b := toBytes(r)
        if b == nil </span><span class="cov8" title="1">{
                return nil
        }</span>
        <span class="cov8" title="1">return metadata.Pairs(mdKey, string(b))</span>
}

// fromBytes reads load report bytes and converts it to orca.
func fromBytes(b []byte) *orcapb.OrcaLoadReport <span class="cov8" title="1">{
        ret := new(orcapb.OrcaLoadReport)
        if err := proto.Unmarshal(b, ret); err != nil </span><span class="cov0" title="0">{
                logger.Warningf("orca: failed to unmarshal load report: %v", err)
                return nil
        }</span>
        <span class="cov8" title="1">return ret</span>
}

// FromMetadata reads load report from metadata and converts it to orca.
//
// It returns nil if report is not found in metadata.
func FromMetadata(md metadata.MD) *orcapb.OrcaLoadReport <span class="cov8" title="1">{
        vs := md.Get(mdKey)
        if len(vs) == 0 </span><span class="cov8" title="1">{
                return nil
        }</span>
        <span class="cov8" title="1">return fromBytes([]byte(vs[0]))</span>
}

type loadParser struct{}

func (*loadParser) Parse(md metadata.MD) interface{} <span class="cov0" title="0">{
        return FromMetadata(md)
}</span>

func init() <span class="cov8" title="1">{
        balancerload.SetParser(&amp;loadParser{})
}</span>
</pre>
		
		<pre class="file" id="file166" style="display: none">/*
 *
 * Copyright 2022 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package outlierdetection provides an implementation of the outlier detection
// LB policy, as defined in
// https://github.com/grpc/proposal/blob/master/A50-xds-outlier-detection.md.
package outlierdetection

import (
        "encoding/json"
        "errors"
        "fmt"

        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/internal"
        "google.golang.org/grpc/internal/envconfig"
        "google.golang.org/grpc/serviceconfig"
)

// Name is the name of the outlier detection balancer.
const Name = "outlier_detection_experimental"

func init() <span class="cov8" title="1">{
        if envconfig.XDSOutlierDetection </span><span class="cov0" title="0">{
                balancer.Register(bb{})
        }</span>
        // TODO: Remove these once the Outlier Detection env var is removed.
        <span class="cov8" title="1">internal.RegisterOutlierDetectionBalancerForTesting = func() </span><span class="cov0" title="0">{
                balancer.Register(bb{})
        }</span>
        <span class="cov8" title="1">internal.UnregisterOutlierDetectionBalancerForTesting = func() </span><span class="cov0" title="0">{
                internal.BalancerUnregister(Name)
        }</span>
}

type bb struct{}

func (bb) Build(cc balancer.ClientConn, bOpts balancer.BuildOptions) balancer.Balancer <span class="cov0" title="0">{
        return nil
}</span>

func (bb) ParseConfig(s json.RawMessage) (serviceconfig.LoadBalancingConfig, error) <span class="cov8" title="1">{
        var lbCfg *LBConfig
        if err := json.Unmarshal(s, &amp;lbCfg); err != nil </span><span class="cov8" title="1">{ // Validates child config if present as well.
                return nil, fmt.Errorf("xds: unable to unmarshal LBconfig: %s, error: %v", string(s), err)
        }</span>

        // Note: in the xds flow, these validations will never fail. The xdsclient
        // performs the same validations as here on the xds Outlier Detection
        // resource before parsing into the internal struct which gets marshaled
        // into JSON before calling this function. A50 defines two separate places
        // for these validations to take place, the xdsclient and this ParseConfig
        // method. "When parsing a config from JSON, if any of these requirements is
        // violated, that should be treated as a parsing error." - A50

        <span class="cov8" title="1">switch </span>{
        // "The google.protobuf.Duration fields interval, base_ejection_time, and
        // max_ejection_time must obey the restrictions in the
        // google.protobuf.Duration documentation and they must have non-negative
        // values." - A50
        // Approximately 290 years is the maximum time that time.Duration (int64)
        // can represent. The restrictions on the protobuf.Duration field are to be
        // within +-10000 years. Thus, just check for negative values.
        case lbCfg.Interval &lt; 0:<span class="cov8" title="1">
                return nil, fmt.Errorf("OutlierDetectionLoadBalancingConfig.interval = %s; must be &gt;= 0", lbCfg.Interval)</span>
        case lbCfg.BaseEjectionTime &lt; 0:<span class="cov8" title="1">
                return nil, fmt.Errorf("OutlierDetectionLoadBalancingConfig.base_ejection_time = %s; must be &gt;= 0", lbCfg.BaseEjectionTime)</span>
        case lbCfg.MaxEjectionTime &lt; 0:<span class="cov8" title="1">
                return nil, fmt.Errorf("OutlierDetectionLoadBalancingConfig.max_ejection_time = %s; must be &gt;= 0", lbCfg.MaxEjectionTime)</span>
        // "The fields max_ejection_percent,
        // success_rate_ejection.enforcement_percentage,
        // failure_percentage_ejection.threshold, and
        // failure_percentage.enforcement_percentage must have values less than or
        // equal to 100." - A50
        case lbCfg.MaxEjectionPercent &gt; 100:<span class="cov8" title="1">
                return nil, fmt.Errorf("OutlierDetectionLoadBalancingConfig.max_ejection_percent = %v; must be &lt;= 100", lbCfg.MaxEjectionPercent)</span>
        case lbCfg.SuccessRateEjection != nil &amp;&amp; lbCfg.SuccessRateEjection.EnforcementPercentage &gt; 100:<span class="cov8" title="1">
                return nil, fmt.Errorf("OutlierDetectionLoadBalancingConfig.SuccessRateEjection.enforcement_percentage = %v; must be &lt;= 100", lbCfg.SuccessRateEjection.EnforcementPercentage)</span>
        case lbCfg.FailurePercentageEjection != nil &amp;&amp; lbCfg.FailurePercentageEjection.Threshold &gt; 100:<span class="cov8" title="1">
                return nil, fmt.Errorf("OutlierDetectionLoadBalancingConfig.FailurePercentageEjection.threshold = %v; must be &lt;= 100", lbCfg.FailurePercentageEjection.Threshold)</span>
        case lbCfg.FailurePercentageEjection != nil &amp;&amp; lbCfg.FailurePercentageEjection.EnforcementPercentage &gt; 100:<span class="cov8" title="1">
                return nil, fmt.Errorf("OutlierDetectionLoadBalancingConfig.FailurePercentageEjection.enforcement_percentage = %v; must be &lt;= 100", lbCfg.FailurePercentageEjection.EnforcementPercentage)</span>
        case lbCfg.ChildPolicy == nil:<span class="cov8" title="1">
                return nil, errors.New("OutlierDetectionLoadBalancingConfig.child_policy must be present")</span>
        }

        <span class="cov8" title="1">return lbCfg, nil</span>
}

func (bb) Name() string <span class="cov0" title="0">{
        return Name
}</span>
</pre>
		
		<pre class="file" id="file167" style="display: none">/*
 *
 * Copyright 2022 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package outlierdetection

import (
        "time"

        internalserviceconfig "google.golang.org/grpc/internal/serviceconfig"
        "google.golang.org/grpc/serviceconfig"
)

// SuccessRateEjection is parameters for the success rate ejection algorithm.
// This algorithm monitors the request success rate for all endpoints and ejects
// individual endpoints whose success rates are statistical outliers.
type SuccessRateEjection struct {
        // StddevFactor is used to determine the ejection threshold for
        // success rate outlier ejection. The ejection threshold is the difference
        // between the mean success rate, and the product of this factor and the
        // standard deviation of the mean success rate: mean - (stdev *
        // success_rate_stdev_factor). This factor is divided by a thousand to get a
        // double. That is, if the desired factor is 1.9, the runtime value should
        // be 1900. Defaults to 1900.
        StdevFactor uint32 `json:"stdevFactor,omitempty"`
        // EnforcementPercentage is the % chance that a host will be actually ejected
        // when an outlier status is detected through success rate statistics. This
        // setting can be used to disable ejection or to ramp it up slowly. Defaults
        // to 100.
        EnforcementPercentage uint32 `json:"enforcementPercentage,omitempty"`
        // MinimumHosts is the number of hosts in a cluster that must have enough
        // request volume to detect success rate outliers. If the number of hosts is
        // less than this setting, outlier detection via success rate statistics is
        // not performed for any host in the cluster. Defaults to 5.
        MinimumHosts uint32 `json:"minimumHosts,omitempty"`
        // RequestVolume is the minimum number of total requests that must be
        // collected in one interval (as defined by the interval duration above) to
        // include this host in success rate based outlier detection. If the volume
        // is lower than this setting, outlier detection via success rate statistics
        // is not performed for that host. Defaults to 100.
        RequestVolume uint32 `json:"requestVolume,omitempty"`
}

// Equal returns whether the SuccessRateEjection is the same with the parameter.
func (sre *SuccessRateEjection) Equal(sre2 *SuccessRateEjection) bool <span class="cov8" title="1">{
        if sre == nil &amp;&amp; sre2 == nil </span><span class="cov8" title="1">{
                return true
        }</span>
        <span class="cov8" title="1">if (sre != nil) != (sre2 != nil) </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov8" title="1">if sre.StdevFactor != sre2.StdevFactor </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov8" title="1">if sre.EnforcementPercentage != sre2.EnforcementPercentage </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov8" title="1">if sre.MinimumHosts != sre2.MinimumHosts </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov8" title="1">return sre.RequestVolume == sre2.RequestVolume</span>
}

// FailurePercentageEjection is parameters for the failure percentage algorithm.
// This algorithm ejects individual endpoints whose failure rate is greater than
// some threshold, independently of any other endpoint.
type FailurePercentageEjection struct {
        // Threshold is the failure percentage to use when determining failure
        // percentage-based outlier detection. If the failure percentage of a given
        // host is greater than or equal to this value, it will be ejected. Defaults
        // to 85.
        Threshold uint32 `json:"threshold,omitempty"`
        // EnforcementPercentage is the % chance that a host will be actually
        // ejected when an outlier status is detected through failure percentage
        // statistics. This setting can be used to disable ejection or to ramp it up
        // slowly. Defaults to 0.
        EnforcementPercentage uint32 `json:"enforcementPercentage,omitempty"`
        // MinimumHosts is the minimum number of hosts in a cluster in order to
        // perform failure percentage-based ejection. If the total number of hosts
        // in the cluster is less than this value, failure percentage-based ejection
        // will not be performed. Defaults to 5.
        MinimumHosts uint32 `json:"minimumHosts,omitempty"`
        // RequestVolume is the minimum number of total requests that must be
        // collected in one interval (as defined by the interval duration above) to
        // perform failure percentage-based ejection for this host. If the volume is
        // lower than this setting, failure percentage-based ejection will not be
        // performed for this host. Defaults to 50.
        RequestVolume uint32 `json:"requestVolume,omitempty"`
}

// Equal returns whether the FailurePercentageEjection is the same with the
// parameter.
func (fpe *FailurePercentageEjection) Equal(fpe2 *FailurePercentageEjection) bool <span class="cov8" title="1">{
        if fpe == nil &amp;&amp; fpe2 == nil </span><span class="cov8" title="1">{
                return true
        }</span>
        <span class="cov8" title="1">if (fpe != nil) != (fpe2 != nil) </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov8" title="1">if fpe.Threshold != fpe2.Threshold </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov8" title="1">if fpe.EnforcementPercentage != fpe2.EnforcementPercentage </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov8" title="1">if fpe.MinimumHosts != fpe2.MinimumHosts </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov8" title="1">return fpe.RequestVolume == fpe2.RequestVolume</span>
}

// LBConfig is the config for the outlier detection balancer.
type LBConfig struct {
        serviceconfig.LoadBalancingConfig `json:"-"`
        // Interval is the time interval between ejection analysis sweeps. This can
        // result in both new ejections as well as addresses being returned to
        // service. Defaults to 10s.
        Interval time.Duration `json:"interval,omitempty"`
        // BaseEjectionTime is the base time that a host is ejected for. The real
        // time is equal to the base time multiplied by the number of times the host
        // has been ejected and is capped by MaxEjectionTime. Defaults to 30s.
        BaseEjectionTime time.Duration `json:"baseEjectionTime,omitempty"`
        // MaxEjectionTime is the maximum time that an address is ejected for. If
        // not specified, the default value (300s) or the BaseEjectionTime value is
        // applied, whichever is larger.
        MaxEjectionTime time.Duration `json:"maxEjectionTime,omitempty"`
        // MaxEjectionPercent is the maximum % of an upstream cluster that can be
        // ejected due to outlier detection. Defaults to 10% but will eject at least
        // one host regardless of the value.
        MaxEjectionPercent uint32 `json:"maxEjectionPercent,omitempty"`
        // SuccessRateEjection is the parameters for the success rate ejection
        // algorithm. If set, success rate ejections will be performed.
        SuccessRateEjection *SuccessRateEjection `json:"successRateEjection,omitempty"`
        // FailurePercentageEjection is the parameters for the failure percentage
        // algorithm. If set, failure rate ejections will be performed.
        FailurePercentageEjection *FailurePercentageEjection `json:"failurePercentageEjection,omitempty"`
        // ChildPolicy is the config for the child policy.
        ChildPolicy *internalserviceconfig.BalancerConfig `json:"childPolicy,omitempty"`
}

// EqualIgnoringChildPolicy returns whether the LBConfig is same with the
// parameter outside of the child policy, only comparing the Outlier Detection
// specific configuration.
func (lbc *LBConfig) EqualIgnoringChildPolicy(lbc2 *LBConfig) bool <span class="cov8" title="1">{
        if lbc == nil &amp;&amp; lbc2 == nil </span><span class="cov0" title="0">{
                return true
        }</span>
        <span class="cov8" title="1">if (lbc != nil) != (lbc2 != nil) </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov8" title="1">if lbc.Interval != lbc2.Interval </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov8" title="1">if lbc.BaseEjectionTime != lbc2.BaseEjectionTime </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov8" title="1">if lbc.MaxEjectionTime != lbc2.MaxEjectionTime </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov8" title="1">if lbc.MaxEjectionPercent != lbc2.MaxEjectionPercent </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov8" title="1">if !lbc.SuccessRateEjection.Equal(lbc2.SuccessRateEjection) </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov8" title="1">return lbc.FailurePercentageEjection.Equal(lbc2.FailurePercentageEjection)</span>
}
</pre>
		
		<pre class="file" id="file168" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package priority implements the priority balancer.
//
// This balancer will be kept in internal until we use it in the xds balancers,
// and are confident its functionalities are stable. It will then be exported
// for more users.
package priority

import (
        "encoding/json"
        "fmt"
        "sync"
        "time"

        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/balancer/base"
        "google.golang.org/grpc/connectivity"
        "google.golang.org/grpc/internal/balancergroup"
        "google.golang.org/grpc/internal/buffer"
        "google.golang.org/grpc/internal/grpclog"
        "google.golang.org/grpc/internal/grpcsync"
        "google.golang.org/grpc/internal/hierarchy"
        "google.golang.org/grpc/internal/pretty"
        "google.golang.org/grpc/resolver"
        "google.golang.org/grpc/serviceconfig"
)

// Name is the name of the priority balancer.
const Name = "priority_experimental"

func init() <span class="cov8" title="1">{
        balancer.Register(bb{})
}</span>

type bb struct{}

func (bb) Build(cc balancer.ClientConn, bOpts balancer.BuildOptions) balancer.Balancer <span class="cov8" title="1">{
        b := &amp;priorityBalancer{
                cc:                       cc,
                done:                     grpcsync.NewEvent(),
                children:                 make(map[string]*childBalancer),
                childBalancerStateUpdate: buffer.NewUnbounded(),
        }

        b.logger = prefixLogger(b)
        b.bg = balancergroup.New(cc, bOpts, b, b.logger)
        b.bg.Start()
        go b.run()
        b.logger.Infof("Created")
        return b
}</span>

func (b bb) ParseConfig(s json.RawMessage) (serviceconfig.LoadBalancingConfig, error) <span class="cov0" title="0">{
        return parseConfig(s)
}</span>

func (bb) Name() string <span class="cov8" title="1">{
        return Name
}</span>

// timerWrapper wraps a timer with a boolean. So that when a race happens
// between AfterFunc and Stop, the func is guaranteed to not execute.
type timerWrapper struct {
        stopped bool
        timer   *time.Timer
}

type priorityBalancer struct {
        logger                   *grpclog.PrefixLogger
        cc                       balancer.ClientConn
        bg                       *balancergroup.BalancerGroup
        done                     *grpcsync.Event
        childBalancerStateUpdate *buffer.Unbounded

        mu         sync.Mutex
        childInUse string
        // priorities is a list of child names from higher to lower priority.
        priorities []string
        // children is a map from child name to sub-balancers.
        children map[string]*childBalancer

        // Set during UpdateClientConnState when calling into sub-balancers.
        // Prevents child updates from recomputing the active priority or sending
        // an update of the aggregated picker to the parent.  Cleared after all
        // sub-balancers have finished UpdateClientConnState, after which
        // syncPriority is called manually.
        inhibitPickerUpdates bool
}

func (b *priorityBalancer) UpdateClientConnState(s balancer.ClientConnState) error <span class="cov8" title="1">{
        b.logger.Infof("Received update from resolver, balancer config: %+v", pretty.ToJSON(s.BalancerConfig))
        newConfig, ok := s.BalancerConfig.(*LBConfig)
        if !ok </span><span class="cov0" title="0">{
                return fmt.Errorf("unexpected balancer config with type: %T", s.BalancerConfig)
        }</span>
        <span class="cov8" title="1">addressesSplit := hierarchy.Group(s.ResolverState.Addresses)

        b.mu.Lock()
        // Create and remove children, since we know all children from the config
        // are used by some priority.
        for name, newSubConfig := range newConfig.Children </span><span class="cov8" title="1">{
                bb := balancer.Get(newSubConfig.Config.Name)
                if bb == nil </span><span class="cov0" title="0">{
                        b.logger.Errorf("balancer name %v from config is not registered", newSubConfig.Config.Name)
                        continue</span>
                }

                <span class="cov8" title="1">currentChild, ok := b.children[name]
                if !ok </span><span class="cov8" title="1">{
                        // This is a new child, add it to the children list. But note that
                        // the balancer isn't built, because this child can be a low
                        // priority. If necessary, it will be built when syncing priorities.
                        cb := newChildBalancer(name, b, bb)
                        cb.updateConfig(newSubConfig, resolver.State{
                                Addresses:     addressesSplit[name],
                                ServiceConfig: s.ResolverState.ServiceConfig,
                                Attributes:    s.ResolverState.Attributes,
                        })
                        b.children[name] = cb
                        continue</span>
                }

                // This is not a new child. But the config/addresses could change.

                // The balancing policy name is changed, close the old child. But don't
                // rebuild, rebuild will happen when syncing priorities.
                <span class="cov8" title="1">if currentChild.bb.Name() != bb.Name() </span><span class="cov8" title="1">{
                        currentChild.stop()
                        currentChild.updateBuilder(bb)
                }</span>

                // Update config and address, but note that this doesn't send the
                // updates to non-started child balancers (the child balancer might not
                // be built, if it's a low priority).
                <span class="cov8" title="1">currentChild.updateConfig(newSubConfig, resolver.State{
                        Addresses:     addressesSplit[name],
                        ServiceConfig: s.ResolverState.ServiceConfig,
                        Attributes:    s.ResolverState.Attributes,
                })</span>
        }
        // Remove child from children if it's not in new config.
        <span class="cov8" title="1">for name, oldChild := range b.children </span><span class="cov8" title="1">{
                if _, ok := newConfig.Children[name]; !ok </span><span class="cov8" title="1">{
                        oldChild.stop()
                }</span>
        }

        // Update priorities and handle priority changes.
        <span class="cov8" title="1">b.priorities = newConfig.Priorities

        // Everything was removed by the update.
        if len(b.priorities) == 0 </span><span class="cov8" title="1">{
                b.childInUse = ""
                b.cc.UpdateState(balancer.State{
                        ConnectivityState: connectivity.TransientFailure,
                        Picker:            base.NewErrPicker(ErrAllPrioritiesRemoved),
                })
                b.mu.Unlock()
                return nil
        }</span>

        // This will sync the states of all children to the new updated
        // priorities. Includes starting/stopping child balancers when necessary.
        // Block picker updates until all children have had a chance to call
        // UpdateState to prevent races where, e.g., the active priority reports
        // transient failure but a higher priority may have reported something that
        // made it active, and if the transient failure update is handled first,
        // RPCs could fail.
        <span class="cov8" title="1">b.inhibitPickerUpdates = true
        // Add an item to queue to notify us when the current items in the queue
        // are done and syncPriority has been called.
        done := make(chan struct{})
        b.childBalancerStateUpdate.Put(resumePickerUpdates{done: done})
        b.mu.Unlock()
        &lt;-done

        return nil</span>
}

func (b *priorityBalancer) ResolverError(err error) <span class="cov0" title="0">{
        b.bg.ResolverError(err)
}</span>

func (b *priorityBalancer) UpdateSubConnState(sc balancer.SubConn, state balancer.SubConnState) <span class="cov8" title="1">{
        b.bg.UpdateSubConnState(sc, state)
}</span>

func (b *priorityBalancer) Close() <span class="cov8" title="1">{
        b.bg.Close()

        b.mu.Lock()
        defer b.mu.Unlock()
        b.done.Fire()
        // Clear states of the current child in use, so if there's a race in picker
        // update, it will be dropped.
        b.childInUse = ""
        // Stop the child policies, this is necessary to stop the init timers in the
        // children.
        for _, child := range b.children </span><span class="cov8" title="1">{
                child.stop()
        }</span>
}

func (b *priorityBalancer) ExitIdle() <span class="cov0" title="0">{
        b.bg.ExitIdle()
}</span>

// UpdateState implements balancergroup.BalancerStateAggregator interface. The
// balancer group sends new connectivity state and picker here.
func (b *priorityBalancer) UpdateState(childName string, state balancer.State) <span class="cov8" title="1">{
        b.childBalancerStateUpdate.Put(childBalancerState{
                name: childName,
                s:    state,
        })
}</span>

type childBalancerState struct {
        name string
        s    balancer.State
}

type resumePickerUpdates struct {
        done chan struct{}
}

// run handles child update in a separate goroutine, so if the child sends
// updates inline (when called by parent), it won't cause deadlocks (by trying
// to hold the same mutex).
func (b *priorityBalancer) run() <span class="cov8" title="1">{
        for </span><span class="cov8" title="1">{
                select </span>{
                case u := &lt;-b.childBalancerStateUpdate.Get():<span class="cov8" title="1">
                        b.childBalancerStateUpdate.Load()
                        // Needs to handle state update in a goroutine, because each state
                        // update needs to start/close child policy, could result in
                        // deadlock.
                        b.mu.Lock()
                        if b.done.HasFired() </span><span class="cov0" title="0">{
                                return
                        }</span>
                        <span class="cov8" title="1">switch s := u.(type) </span>{
                        case childBalancerState:<span class="cov8" title="1">
                                b.handleChildStateUpdate(s.name, s.s)</span>
                        case resumePickerUpdates:<span class="cov8" title="1">
                                b.inhibitPickerUpdates = false
                                b.syncPriority(b.childInUse)
                                close(s.done)</span>
                        }
                        <span class="cov8" title="1">b.mu.Unlock()</span>
                case &lt;-b.done.Done():<span class="cov8" title="1">
                        return</span>
                }
        }
}
</pre>
		
		<pre class="file" id="file169" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package priority

import (
        "time"

        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/balancer/base"
        "google.golang.org/grpc/connectivity"
        "google.golang.org/grpc/resolver"
        "google.golang.org/grpc/serviceconfig"
)

type childBalancer struct {
        name   string
        parent *priorityBalancer
        bb     *ignoreResolveNowBalancerBuilder

        ignoreReresolutionRequests bool
        config                     serviceconfig.LoadBalancingConfig
        rState                     resolver.State

        started bool
        // This is set when the child reports TransientFailure, and unset when it
        // reports Ready or Idle. It is used to decide whether the failover timer
        // should start when the child is transitioning into Connecting. The timer
        // will be restarted if the child has not reported TF more recently than it
        // reported Ready or Idle.
        reportedTF bool
        // The latest state the child balancer provided.
        state balancer.State
        // The timer to give a priority some time to connect. And if the priority
        // doesn't go into Ready/Failure, the next priority will be started.
        initTimer *timerWrapper
}

// newChildBalancer creates a child balancer place holder, but doesn't
// build/start the child balancer.
func newChildBalancer(name string, parent *priorityBalancer, bb balancer.Builder) *childBalancer <span class="cov8" title="1">{
        return &amp;childBalancer{
                name:    name,
                parent:  parent,
                bb:      newIgnoreResolveNowBalancerBuilder(bb, false),
                started: false,
                // Start with the connecting state and picker with re-pick error, so
                // that when a priority switch causes this child picked before it's
                // balancing policy is created, a re-pick will happen.
                state: balancer.State{
                        ConnectivityState: connectivity.Connecting,
                        Picker:            base.NewErrPicker(balancer.ErrNoSubConnAvailable),
                },
        }
}</span>

// updateBuilder updates builder for the child, but doesn't build.
func (cb *childBalancer) updateBuilder(bb balancer.Builder) <span class="cov8" title="1">{
        cb.bb = newIgnoreResolveNowBalancerBuilder(bb, cb.ignoreReresolutionRequests)
}</span>

// updateConfig sets childBalancer's config and state, but doesn't send update to
// the child balancer unless it is started.
func (cb *childBalancer) updateConfig(child *Child, rState resolver.State) <span class="cov8" title="1">{
        cb.ignoreReresolutionRequests = child.IgnoreReresolutionRequests
        cb.config = child.Config.Config
        cb.rState = rState
        if cb.started </span><span class="cov8" title="1">{
                cb.sendUpdate()
        }</span>
}

// start builds the child balancer if it's not already started.
//
// It doesn't do it directly. It asks the balancer group to build it.
func (cb *childBalancer) start() <span class="cov8" title="1">{
        if cb.started </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov8" title="1">cb.started = true
        cb.parent.bg.Add(cb.name, cb.bb)
        cb.startInitTimer()
        cb.sendUpdate()</span>
}

// sendUpdate sends the addresses and config to the child balancer.
func (cb *childBalancer) sendUpdate() <span class="cov8" title="1">{
        cb.bb.updateIgnoreResolveNow(cb.ignoreReresolutionRequests)
        // TODO: return and aggregate the returned error in the parent.
        err := cb.parent.bg.UpdateClientConnState(cb.name, balancer.ClientConnState{
                ResolverState:  cb.rState,
                BalancerConfig: cb.config,
        })
        if err != nil </span><span class="cov8" title="1">{
                cb.parent.logger.Warningf("failed to update ClientConn state for child %v: %v", cb.name, err)
        }</span>
}

// stop stops the child balancer and resets the state.
//
// It doesn't do it directly. It asks the balancer group to remove it.
//
// Note that the underlying balancer group could keep the child in a cache.
func (cb *childBalancer) stop() <span class="cov8" title="1">{
        if !cb.started </span><span class="cov8" title="1">{
                return
        }</span>
        <span class="cov8" title="1">cb.stopInitTimer()
        cb.parent.bg.Remove(cb.name)
        cb.started = false
        cb.state = balancer.State{
                ConnectivityState: connectivity.Connecting,
                Picker:            base.NewErrPicker(balancer.ErrNoSubConnAvailable),
        }
        // Clear child.reportedTF, so that if this child is started later, it will
        // be given time to connect.
        cb.reportedTF = false</span>
}

func (cb *childBalancer) startInitTimer() <span class="cov8" title="1">{
        if cb.initTimer != nil </span><span class="cov8" title="1">{
                return
        }</span>
        // Need this local variable to capture timerW in the AfterFunc closure
        // to check the stopped boolean.
        <span class="cov8" title="1">timerW := &amp;timerWrapper{}
        cb.initTimer = timerW
        timerW.timer = time.AfterFunc(DefaultPriorityInitTimeout, func() </span><span class="cov8" title="1">{
                cb.parent.mu.Lock()
                defer cb.parent.mu.Unlock()
                if timerW.stopped </span><span class="cov0" title="0">{
                        return
                }</span>
                <span class="cov8" title="1">cb.initTimer = nil
                // Re-sync the priority. This will switch to the next priority if
                // there's any. Note that it's important sync() is called after setting
                // initTimer to nil.
                cb.parent.syncPriority("")</span>
        })
}

func (cb *childBalancer) stopInitTimer() <span class="cov8" title="1">{
        timerW := cb.initTimer
        if timerW == nil </span><span class="cov8" title="1">{
                return
        }</span>
        <span class="cov8" title="1">cb.initTimer = nil
        timerW.stopped = true
        timerW.timer.Stop()</span>
}
</pre>
		
		<pre class="file" id="file170" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package priority

import (
        "errors"
        "time"

        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/connectivity"
)

var (
        // ErrAllPrioritiesRemoved is returned by the picker when there's no priority available.
        ErrAllPrioritiesRemoved = errors.New("no priority is provided, all priorities are removed")
        // DefaultPriorityInitTimeout is the timeout after which if a priority is
        // not READY, the next will be started. It's exported to be overridden by
        // tests.
        DefaultPriorityInitTimeout = 10 * time.Second
)

// syncPriority handles priority after a config update or a child balancer
// connectivity state update. It makes sure the balancer state (started or not)
// is in sync with the priorities (even in tricky cases where a child is moved
// from a priority to another).
//
// It's guaranteed that after this function returns:
// - If some child is READY, it is childInUse, and all lower priorities are
// closed.
// - If some child is newly started(in Connecting for the first time), it is
// childInUse, and all lower priorities are closed.
// - Otherwise, the lowest priority is childInUse (none of the children is
// ready, and the overall state is not ready).
//
// Steps:
// - If all priorities were deleted, unset childInUse (to an empty string), and
// set parent ClientConn to TransientFailure
// - Otherwise, Scan all children from p0, and check balancer stats:
//   - For any of the following cases:
//     - If balancer is not started (not built), this is either a new child with
//       high priority, or a new builder for an existing child.
//     - If balancer is Connecting and has non-nil initTimer (meaning it
//       transitioned from Ready or Idle to connecting, not from TF, so we
//       should give it init-time to connect).
//     - If balancer is READY or IDLE
//     - If this is the lowest priority
//   - do the following:
//     - if this is not the old childInUse, override picker so old picker is no
//       longer used.
//     - switch to it (because all higher priorities are neither new or Ready)
//     - forward the new addresses and config
//
// Caller must hold b.mu.
func (b *priorityBalancer) syncPriority(childUpdating string) <span class="cov8" title="1">{
        if b.inhibitPickerUpdates </span><span class="cov8" title="1">{
                b.logger.Infof("Skipping update from child with name %q", childUpdating)
                return
        }</span>
        <span class="cov8" title="1">for p, name := range b.priorities </span><span class="cov8" title="1">{
                child, ok := b.children[name]
                if !ok </span><span class="cov0" title="0">{
                        b.logger.Warningf("child with name %q is not found in children", name)
                        continue</span>
                }

                <span class="cov8" title="1">if !child.started ||
                        child.state.ConnectivityState == connectivity.Ready ||
                        child.state.ConnectivityState == connectivity.Idle ||
                        (child.state.ConnectivityState == connectivity.Connecting &amp;&amp; child.initTimer != nil) ||
                        p == len(b.priorities)-1 </span><span class="cov8" title="1">{
                        if b.childInUse != child.name || child.name == childUpdating </span><span class="cov8" title="1">{
                                b.logger.Warningf("childInUse, childUpdating: %q, %q", b.childInUse, child.name)
                                // If we switch children or the child in use just updated its
                                // picker, push the child's picker to the parent.
                                b.cc.UpdateState(child.state)
                        }</span>
                        <span class="cov8" title="1">b.logger.Infof("switching to (%q, %v) in syncPriority", child.name, p)
                        b.switchToChild(child, p)
                        break</span>
                }
        }
}

// Stop priorities [p+1, lowest].
//
// Caller must hold b.mu.
func (b *priorityBalancer) stopSubBalancersLowerThanPriority(p int) <span class="cov8" title="1">{
        for i := p + 1; i &lt; len(b.priorities); i++ </span><span class="cov8" title="1">{
                name := b.priorities[i]
                child, ok := b.children[name]
                if !ok </span><span class="cov0" title="0">{
                        b.logger.Warningf("child with name %q is not found in children", name)
                        continue</span>
                }
                <span class="cov8" title="1">child.stop()</span>
        }
}

// switchToChild does the following:
// - stop all child with lower priorities
// - if childInUse is not this child
//   - set childInUse to this child
//   - if this child is not started, start it
//
// Note that it does NOT send the current child state (picker) to the parent
// ClientConn. The caller needs to send it if necessary.
//
// this can be called when
// 1. first update, start p0
// 2. an update moves a READY child from a lower priority to higher
// 2. a different builder is updated for this child
// 3. a high priority goes Failure, start next
// 4. a high priority init timeout, start next
//
// Caller must hold b.mu.
func (b *priorityBalancer) switchToChild(child *childBalancer, priority int) <span class="cov8" title="1">{
        // Stop lower priorities even if childInUse is same as this child. It's
        // possible this child was moved from a priority to another.
        b.stopSubBalancersLowerThanPriority(priority)

        // If this child is already in use, do nothing.
        //
        // This can happen:
        // - all priorities are not READY, an config update always triggers switch
        // to the lowest. In this case, the lowest child could still be connecting,
        // so we don't stop the init timer.
        // - a high priority is READY, an config update always triggers switch to
        // it.
        if b.childInUse == child.name &amp;&amp; child.started </span><span class="cov8" title="1">{
                return
        }</span>
        <span class="cov8" title="1">b.childInUse = child.name

        if !child.started </span><span class="cov8" title="1">{
                child.start()
        }</span>
}

// handleChildStateUpdate start/close priorities based on the connectivity
// state.
func (b *priorityBalancer) handleChildStateUpdate(childName string, s balancer.State) <span class="cov8" title="1">{
        // Update state in child. The updated picker will be sent to parent later if
        // necessary.
        child, ok := b.children[childName]
        if !ok </span><span class="cov0" title="0">{
                b.logger.Warningf("priority: child balancer not found for child %v", childName)
                return
        }</span>
        <span class="cov8" title="1">child.state = s

        // We start/stop the init timer of this child based on the new connectivity
        // state. syncPriority() later will need the init timer (to check if it's
        // nil or not) to decide which child to switch to.
        switch s.ConnectivityState </span>{
        case connectivity.Ready, connectivity.Idle:<span class="cov8" title="1">
                child.reportedTF = false
                child.stopInitTimer()</span>
        case connectivity.TransientFailure:<span class="cov8" title="1">
                child.reportedTF = true
                child.stopInitTimer()</span>
        case connectivity.Connecting:<span class="cov8" title="1">
                if !child.reportedTF </span><span class="cov8" title="1">{
                        child.startInitTimer()
                }</span>
        default:<span class="cov0" title="0"></span>
                // New state is Shutdown, should never happen. Don't forward.
        }

        <span class="cov8" title="1">child.parent.syncPriority(childName)</span>
}
</pre>
		
		<pre class="file" id="file171" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package priority

import (
        "encoding/json"
        "fmt"

        internalserviceconfig "google.golang.org/grpc/internal/serviceconfig"
        "google.golang.org/grpc/serviceconfig"
)

// Child is a child of priority balancer.
type Child struct {
        Config                     *internalserviceconfig.BalancerConfig `json:"config,omitempty"`
        IgnoreReresolutionRequests bool                                  `json:"ignoreReresolutionRequests,omitempty"`
}

// LBConfig represents priority balancer's config.
type LBConfig struct {
        serviceconfig.LoadBalancingConfig `json:"-"`

        // Children is a map from the child balancer names to their configs. Child
        // names can be found in field Priorities.
        Children map[string]*Child `json:"children,omitempty"`
        // Priorities is a list of child balancer names. They are sorted from
        // highest priority to low. The type/config for each child can be found in
        // field Children, with the balancer name as the key.
        Priorities []string `json:"priorities,omitempty"`
}

func parseConfig(c json.RawMessage) (*LBConfig, error) <span class="cov8" title="1">{
        var cfg LBConfig
        if err := json.Unmarshal(c, &amp;cfg); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov8" title="1">prioritiesSet := make(map[string]bool)
        for _, name := range cfg.Priorities </span><span class="cov8" title="1">{
                if _, ok := cfg.Children[name]; !ok </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("LB policy name %q found in Priorities field (%v) is not found in Children field (%+v)", name, cfg.Priorities, cfg.Children)
                }</span>
                <span class="cov8" title="1">prioritiesSet[name] = true</span>
        }
        <span class="cov8" title="1">for name := range cfg.Children </span><span class="cov8" title="1">{
                if _, ok := prioritiesSet[name]; !ok </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("LB policy name %q found in Children field (%v) is not found in Priorities field (%+v)", name, cfg.Children, cfg.Priorities)
                }</span>
        }
        <span class="cov8" title="1">return &amp;cfg, nil</span>
}
</pre>
		
		<pre class="file" id="file172" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package priority

import (
        "sync/atomic"

        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/resolver"
)

type ignoreResolveNowBalancerBuilder struct {
        balancer.Builder
        ignoreResolveNow *uint32
}

// If `ignore` is true, all `ResolveNow()` from the balancer built from this
// builder will be ignored.
//
// `ignore` can be updated later by `updateIgnoreResolveNow`, and the update
// will be propagated to all the old and new balancers built with this.
func newIgnoreResolveNowBalancerBuilder(bb balancer.Builder, ignore bool) *ignoreResolveNowBalancerBuilder <span class="cov8" title="1">{
        ret := &amp;ignoreResolveNowBalancerBuilder{
                Builder:          bb,
                ignoreResolveNow: new(uint32),
        }
        ret.updateIgnoreResolveNow(ignore)
        return ret
}</span>

func (irnbb *ignoreResolveNowBalancerBuilder) updateIgnoreResolveNow(b bool) <span class="cov8" title="1">{
        if b </span><span class="cov8" title="1">{
                atomic.StoreUint32(irnbb.ignoreResolveNow, 1)
                return
        }</span>
        <span class="cov8" title="1">atomic.StoreUint32(irnbb.ignoreResolveNow, 0)</span>

}

func (irnbb *ignoreResolveNowBalancerBuilder) Build(cc balancer.ClientConn, opts balancer.BuildOptions) balancer.Balancer <span class="cov8" title="1">{
        return irnbb.Builder.Build(&amp;ignoreResolveNowClientConn{
                ClientConn:       cc,
                ignoreResolveNow: irnbb.ignoreResolveNow,
        }, opts)
}</span>

type ignoreResolveNowClientConn struct {
        balancer.ClientConn
        ignoreResolveNow *uint32
}

func (i ignoreResolveNowClientConn) ResolveNow(o resolver.ResolveNowOptions) <span class="cov8" title="1">{
        if atomic.LoadUint32(i.ignoreResolveNow) != 0 </span><span class="cov8" title="1">{
                return
        }</span>
        <span class="cov8" title="1">i.ClientConn.ResolveNow(o)</span>
}
</pre>
		
		<pre class="file" id="file173" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package priority

import (
        "fmt"

        "google.golang.org/grpc/grpclog"
        internalgrpclog "google.golang.org/grpc/internal/grpclog"
)

const prefix = "[priority-lb %p] "

var logger = grpclog.Component("xds")

func prefixLogger(p *priorityBalancer) *internalgrpclog.PrefixLogger <span class="cov8" title="1">{
        return internalgrpclog.NewPrefixLogger(logger, fmt.Sprintf(prefix, p))
}</span>
</pre>
		
		<pre class="file" id="file174" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package priority

func equalStringSlice(a, b []string) bool <span class="cov8" title="1">{
        if len(a) != len(b) </span><span class="cov8" title="1">{
                return false
        }</span>
        <span class="cov8" title="1">for i := range a </span><span class="cov8" title="1">{
                if a[i] != b[i] </span><span class="cov0" title="0">{
                        return false
                }</span>
        }
        <span class="cov8" title="1">return true</span>
}
</pre>
		
		<pre class="file" id="file175" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package ringhash

import (
        "encoding/json"
        "fmt"

        "google.golang.org/grpc/serviceconfig"
)

// LBConfig is the balancer config for ring_hash balancer.
type LBConfig struct {
        serviceconfig.LoadBalancingConfig `json:"-"`

        MinRingSize uint64 `json:"minRingSize,omitempty"`
        MaxRingSize uint64 `json:"maxRingSize,omitempty"`
}

const (
        defaultMinSize = 1024
        defaultMaxSize = 8 * 1024 * 1024 // 8M
)

func parseConfig(c json.RawMessage) (*LBConfig, error) <span class="cov8" title="1">{
        var cfg LBConfig
        if err := json.Unmarshal(c, &amp;cfg); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">if cfg.MinRingSize == 0 </span><span class="cov8" title="1">{
                cfg.MinRingSize = defaultMinSize
        }</span>
        <span class="cov8" title="1">if cfg.MaxRingSize == 0 </span><span class="cov8" title="1">{
                cfg.MaxRingSize = defaultMaxSize
        }</span>
        <span class="cov8" title="1">if cfg.MinRingSize &gt; cfg.MaxRingSize </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("min %v is greater than max %v", cfg.MinRingSize, cfg.MaxRingSize)
        }</span>
        <span class="cov8" title="1">return &amp;cfg, nil</span>
}
</pre>
		
		<pre class="file" id="file176" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package ringhash

import (
        "fmt"

        "google.golang.org/grpc/grpclog"
        internalgrpclog "google.golang.org/grpc/internal/grpclog"
)

const prefix = "[ring-hash-lb %p] "

var logger = grpclog.Component("xds")

func prefixLogger(p *ringhashBalancer) *internalgrpclog.PrefixLogger <span class="cov8" title="1">{
        return internalgrpclog.NewPrefixLogger(logger, fmt.Sprintf(prefix, p))
}</span>
</pre>
		
		<pre class="file" id="file177" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package ringhash

import (
        "fmt"

        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/connectivity"
        "google.golang.org/grpc/internal/grpclog"
        "google.golang.org/grpc/status"
)

type picker struct {
        ring   *ring
        logger *grpclog.PrefixLogger
}

func newPicker(ring *ring, logger *grpclog.PrefixLogger) *picker <span class="cov8" title="1">{
        return &amp;picker{ring: ring, logger: logger}
}</span>

// handleRICSResult is the return type of handleRICS. It's needed to wrap the
// returned error from Pick() in a struct. With this, if the return values are
// `balancer.PickResult, error, bool`, linter complains because error is not the
// last return value.
type handleRICSResult struct {
        pr  balancer.PickResult
        err error
}

// handleRICS generates pick result if the entry is in Ready, Idle, Connecting
// or Shutdown. TransientFailure will be handled specifically after this
// function returns.
//
// The first return value indicates if the state is in Ready, Idle, Connecting
// or Shutdown. If it's true, the PickResult and error should be returned from
// Pick() as is.
func (p *picker) handleRICS(e *ringEntry) (handleRICSResult, bool) <span class="cov8" title="1">{
        switch state := e.sc.effectiveState(); state </span>{
        case connectivity.Ready:<span class="cov8" title="1">
                return handleRICSResult{pr: balancer.PickResult{SubConn: e.sc.sc}}, true</span>
        case connectivity.Idle:<span class="cov8" title="1">
                // Trigger Connect() and queue the pick.
                e.sc.queueConnect()
                return handleRICSResult{err: balancer.ErrNoSubConnAvailable}, true</span>
        case connectivity.Connecting:<span class="cov8" title="1">
                return handleRICSResult{err: balancer.ErrNoSubConnAvailable}, true</span>
        case connectivity.TransientFailure:<span class="cov8" title="1">
                // Return ok==false, so TransientFailure will be handled afterwards.
                return handleRICSResult{}, false</span>
        case connectivity.Shutdown:<span class="cov0" title="0">
                // Shutdown can happen in a race where the old picker is called. A new
                // picker should already be sent.
                return handleRICSResult{err: balancer.ErrNoSubConnAvailable}, true</span>
        default:<span class="cov0" title="0">
                // Should never reach this. All the connectivity states are already
                // handled in the cases.
                p.logger.Errorf("SubConn has undefined connectivity state: %v", state)
                return handleRICSResult{err: status.Errorf(codes.Unavailable, "SubConn has undefined connectivity state: %v", state)}, true</span>
        }
}

func (p *picker) Pick(info balancer.PickInfo) (balancer.PickResult, error) <span class="cov8" title="1">{
        e := p.ring.pick(getRequestHash(info.Ctx))
        if hr, ok := p.handleRICS(e); ok </span><span class="cov8" title="1">{
                return hr.pr, hr.err
        }</span>
        // ok was false, the entry is in transient failure.
        <span class="cov8" title="1">return p.handleTransientFailure(e)</span>
}

func (p *picker) handleTransientFailure(e *ringEntry) (balancer.PickResult, error) <span class="cov8" title="1">{
        // Queue a connect on the first picked SubConn.
        e.sc.queueConnect()

        // Find next entry in the ring, skipping duplicate SubConns.
        e2 := nextSkippingDuplicates(p.ring, e)
        if e2 == nil </span><span class="cov0" title="0">{
                // There's no next entry available, fail the pick.
                return balancer.PickResult{}, fmt.Errorf("the only SubConn is in Transient Failure")
        }</span>

        // For the second SubConn, also check Ready/Idle/Connecting as if it's the
        // first entry.
        <span class="cov8" title="1">if hr, ok := p.handleRICS(e2); ok </span><span class="cov8" title="1">{
                return hr.pr, hr.err
        }</span>

        // The second SubConn is also in TransientFailure. Queue a connect on it.
        <span class="cov8" title="1">e2.sc.queueConnect()

        // If it gets here, this is after the second SubConn, and the second SubConn
        // was in TransientFailure.
        //
        // Loop over all other SubConns:
        // - If all SubConns so far are all TransientFailure, trigger Connect() on
        // the TransientFailure SubConns, and keep going.
        // - If there's one SubConn that's not in TransientFailure, keep checking
        // the remaining SubConns (in case there's a Ready, which will be returned),
        // but don't not trigger Connect() on the other SubConns.
        var firstNonFailedFound bool
        for ee := nextSkippingDuplicates(p.ring, e2); ee != e; ee = nextSkippingDuplicates(p.ring, ee) </span><span class="cov8" title="1">{
                scState := ee.sc.effectiveState()
                if scState == connectivity.Ready </span><span class="cov8" title="1">{
                        return balancer.PickResult{SubConn: ee.sc.sc}, nil
                }</span>
                <span class="cov8" title="1">if firstNonFailedFound </span><span class="cov8" title="1">{
                        continue</span>
                }
                <span class="cov8" title="1">if scState == connectivity.TransientFailure </span><span class="cov8" title="1">{
                        // This will queue a connect.
                        ee.sc.queueConnect()
                        continue</span>
                }
                // This is a SubConn in a non-failure state. We continue to check the
                // other SubConns, but remember that there was a non-failed SubConn
                // seen. After this, Pick() will never trigger any SubConn to Connect().
                <span class="cov8" title="1">firstNonFailedFound = true
                if scState == connectivity.Idle </span><span class="cov8" title="1">{
                        // This is the first non-failed SubConn, and it is in a real Idle
                        // state. Trigger it to Connect().
                        ee.sc.queueConnect()
                }</span>
        }
        <span class="cov8" title="1">return balancer.PickResult{}, fmt.Errorf("no connection is Ready")</span>
}

// nextSkippingDuplicates finds the next entry in the ring, with a different
// subconn from the given entry.
func nextSkippingDuplicates(ring *ring, entry *ringEntry) *ringEntry <span class="cov8" title="1">{
        for next := ring.next(entry); next != entry; next = ring.next(next) </span><span class="cov8" title="1">{
                if next.sc != entry.sc </span><span class="cov8" title="1">{
                        return next
                }</span>
        }
        // There's no qualifying next entry.
        <span class="cov8" title="1">return nil</span>
}

// nextSkippingDuplicatesSubConn finds the next subconn in the ring, that's
// different from the given subconn.
func nextSkippingDuplicatesSubConn(ring *ring, sc *subConn) *subConn <span class="cov8" title="1">{
        var entry *ringEntry
        for _, it := range ring.items </span><span class="cov8" title="1">{
                if it.sc == sc </span><span class="cov8" title="1">{
                        entry = it
                        break</span>
                }
        }
        <span class="cov8" title="1">if entry == nil </span><span class="cov0" title="0">{
                // If the given subconn is not in the ring (e.g. it was deleted), return
                // the first one.
                if len(ring.items) &gt; 0 </span><span class="cov0" title="0">{
                        return ring.items[0].sc
                }</span>
                <span class="cov0" title="0">return nil</span>
        }
        <span class="cov8" title="1">ee := nextSkippingDuplicates(ring, entry)
        if ee == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">return ee.sc</span>
}
</pre>
		
		<pre class="file" id="file178" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package ringhash

import (
        "math"
        "sort"
        "strconv"

        xxhash "github.com/cespare/xxhash/v2"
        "google.golang.org/grpc/resolver"
)

type ring struct {
        items []*ringEntry
}

type subConnWithWeight struct {
        sc     *subConn
        weight float64
}

type ringEntry struct {
        idx  int
        hash uint64
        sc   *subConn
}

// newRing creates a ring from the subConns stored in the AddressMap. The ring
// size is limited by the passed in max/min.
//
// ring entries will be created for each subConn, and subConn with high weight
// (specified by the address) may have multiple entries.
//
// For example, for subConns with weights {a:3, b:3, c:4}, a generated ring of
// size 10 could be:
// - {idx:0 hash:3689675255460411075  b}
// - {idx:1 hash:4262906501694543955  c}
// - {idx:2 hash:5712155492001633497  c}
// - {idx:3 hash:8050519350657643659  b}
// - {idx:4 hash:8723022065838381142  b}
// - {idx:5 hash:11532782514799973195 a}
// - {idx:6 hash:13157034721563383607 c}
// - {idx:7 hash:14468677667651225770 c}
// - {idx:8 hash:17336016884672388720 a}
// - {idx:9 hash:18151002094784932496 a}
//
// To pick from a ring, a binary search will be done for the given target hash,
// and first item with hash &gt;= given hash will be returned.
//
// Must be called with a non-empty subConns map.
func newRing(subConns *resolver.AddressMap, minRingSize, maxRingSize uint64) *ring <span class="cov8" title="1">{
        // https://github.com/envoyproxy/envoy/blob/765c970f06a4c962961a0e03a467e165b276d50f/source/common/upstream/ring_hash_lb.cc#L114
        normalizedWeights, minWeight := normalizeWeights(subConns)

        // Normalized weights for {3,3,4} is {0.3,0.3,0.4}.

        // Scale up the size of the ring such that the least-weighted host gets a
        // whole number of hashes on the ring.
        //
        // Note that size is limited by the input max/min.
        scale := math.Min(math.Ceil(minWeight*float64(minRingSize))/minWeight, float64(maxRingSize))
        ringSize := math.Ceil(scale)
        items := make([]*ringEntry, 0, int(ringSize))

        // For each entry, scale*weight nodes are generated in the ring.
        //
        // Not all of these are whole numbers. E.g. for weights {a:3,b:3,c:4}, if
        // ring size is 7, scale is 6.66. The numbers of nodes will be
        // {a,a,b,b,c,c,c}.
        //
        // A hash is generated for each item, and later the results will be sorted
        // based on the hash.
        var (
                idx       int
                targetIdx float64
        )
        for _, scw := range normalizedWeights </span><span class="cov8" title="1">{
                targetIdx += scale * scw.weight
                for float64(idx) &lt; targetIdx </span><span class="cov8" title="1">{
                        h := xxhash.Sum64String(scw.sc.addr + strconv.Itoa(idx))
                        items = append(items, &amp;ringEntry{idx: idx, hash: h, sc: scw.sc})
                        idx++
                }</span>
        }

        // Sort items based on hash, to prepare for binary search.
        <span class="cov8" title="1">sort.Slice(items, func(i, j int) bool </span><span class="cov8" title="1">{ return items[i].hash &lt; items[j].hash }</span>)
        <span class="cov8" title="1">for i, ii := range items </span><span class="cov8" title="1">{
                ii.idx = i
        }</span>
        <span class="cov8" title="1">return &amp;ring{items: items}</span>
}

// normalizeWeights divides all the weights by the sum, so that the total weight
// is 1.
//
// Must be called with a non-empty subConns map.
func normalizeWeights(subConns *resolver.AddressMap) ([]subConnWithWeight, float64) <span class="cov8" title="1">{
        var weightSum uint32
        keys := subConns.Keys()
        for _, a := range keys </span><span class="cov8" title="1">{
                weightSum += getWeightAttribute(a)
        }</span>
        <span class="cov8" title="1">ret := make([]subConnWithWeight, 0, len(keys))
        min := float64(1.0)
        for _, a := range keys </span><span class="cov8" title="1">{
                v, _ := subConns.Get(a)
                scInfo := v.(*subConn)
                // getWeightAttribute() returns 1 if the weight attribute is not found
                // on the address. And since this function is guaranteed to be called
                // with a non-empty subConns map, weightSum is guaranteed to be
                // non-zero. So, we need not worry about divide a by zero error here.
                nw := float64(getWeightAttribute(a)) / float64(weightSum)
                ret = append(ret, subConnWithWeight{sc: scInfo, weight: nw})
                if nw &lt; min </span><span class="cov8" title="1">{
                        min = nw
                }</span>
        }
        // Sort the addresses to return consistent results.
        //
        // Note: this might not be necessary, but this makes sure the ring is
        // consistent as long as the addresses are the same, for example, in cases
        // where an address is added and then removed, the RPCs will still pick the
        // same old SubConn.
        <span class="cov8" title="1">sort.Slice(ret, func(i, j int) bool </span><span class="cov8" title="1">{ return ret[i].sc.addr &lt; ret[j].sc.addr }</span>)
        <span class="cov8" title="1">return ret, min</span>
}

// pick does a binary search. It returns the item with smallest index i that
// r.items[i].hash &gt;= h.
func (r *ring) pick(h uint64) *ringEntry <span class="cov8" title="1">{
        i := sort.Search(len(r.items), func(i int) bool </span><span class="cov8" title="1">{ return r.items[i].hash &gt;= h }</span>)
        <span class="cov8" title="1">if i == len(r.items) </span><span class="cov0" title="0">{
                // If not found, and h is greater than the largest hash, return the
                // first item.
                i = 0
        }</span>
        <span class="cov8" title="1">return r.items[i]</span>
}

// next returns the next entry.
func (r *ring) next(e *ringEntry) *ringEntry <span class="cov8" title="1">{
        return r.items[(e.idx+1)%len(r.items)]
}</span>
</pre>
		
		<pre class="file" id="file179" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package ringhash implements the ringhash balancer.
package ringhash

import (
        "encoding/json"
        "errors"
        "fmt"
        "sync"

        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/balancer/base"
        "google.golang.org/grpc/balancer/weightedroundrobin"
        "google.golang.org/grpc/connectivity"
        "google.golang.org/grpc/internal/grpclog"
        "google.golang.org/grpc/internal/pretty"
        "google.golang.org/grpc/resolver"
        "google.golang.org/grpc/serviceconfig"
)

// Name is the name of the ring_hash balancer.
const Name = "ring_hash_experimental"

func init() <span class="cov8" title="1">{
        balancer.Register(bb{})
}</span>

type bb struct{}

func (bb) Build(cc balancer.ClientConn, bOpts balancer.BuildOptions) balancer.Balancer <span class="cov8" title="1">{
        b := &amp;ringhashBalancer{
                cc:       cc,
                subConns: resolver.NewAddressMap(),
                scStates: make(map[balancer.SubConn]*subConn),
                csEvltr:  &amp;connectivityStateEvaluator{},
        }
        b.logger = prefixLogger(b)
        b.logger.Infof("Created")
        return b
}</span>

func (bb) Name() string <span class="cov8" title="1">{
        return Name
}</span>

func (bb) ParseConfig(c json.RawMessage) (serviceconfig.LoadBalancingConfig, error) <span class="cov0" title="0">{
        return parseConfig(c)
}</span>

type subConn struct {
        addr   string
        weight uint32
        sc     balancer.SubConn

        mu sync.RWMutex
        // This is the actual state of this SubConn (as updated by the ClientConn).
        // The effective state can be different, see comment of attemptedToConnect.
        state connectivity.State
        // failing is whether this SubConn is in a failing state. A subConn is
        // considered to be in a failing state if it was previously in
        // TransientFailure.
        //
        // This affects the effective connectivity state of this SubConn, e.g.
        // - if the actual state is Idle or Connecting, but this SubConn is failing,
        // the effective state is TransientFailure.
        //
        // This is used in pick(). E.g. if a subConn is Idle, but has failing as
        // true, pick() will
        // - consider this SubConn as TransientFailure, and check the state of the
        // next SubConn.
        // - trigger Connect() (note that normally a SubConn in real
        // TransientFailure cannot Connect())
        //
        // A subConn starts in non-failing (failing is false). A transition to
        // TransientFailure sets failing to true (and it stays true). A transition
        // to Ready sets failing to false.
        failing bool
        // connectQueued is true if a Connect() was queued for this SubConn while
        // it's not in Idle (most likely was in TransientFailure). A Connect() will
        // be triggered on this SubConn when it turns Idle.
        //
        // When connectivity state is updated to Idle for this SubConn, if
        // connectQueued is true, Connect() will be called on the SubConn.
        connectQueued bool
        // attemptingToConnect indicates if this subconn is attempting to connect.
        // It's set when queueConnect is called. It's unset when the state is
        // changed to Ready/Shutdown, or Idle (and if connectQueued is false).
        attemptingToConnect bool
}

// setState updates the state of this SubConn.
//
// It also handles the queued Connect(). If the new state is Idle, and a
// Connect() was queued, this SubConn will be triggered to Connect().
func (sc *subConn) setState(s connectivity.State) <span class="cov8" title="1">{
        sc.mu.Lock()
        defer sc.mu.Unlock()
        switch s </span>{
        case connectivity.Idle:<span class="cov8" title="1">
                // Trigger Connect() if new state is Idle, and there is a queued connect.
                if sc.connectQueued </span><span class="cov8" title="1">{
                        sc.connectQueued = false
                        sc.sc.Connect()
                }</span> else<span class="cov8" title="1"> {
                        sc.attemptingToConnect = false
                }</span>
        case connectivity.Connecting:<span class="cov8" title="1">
                // Clear connectQueued if the SubConn isn't failing. This state
                // transition is unlikely to happen, but handle this just in case.
                sc.connectQueued = false</span>
        case connectivity.Ready:<span class="cov8" title="1">
                // Clear connectQueued if the SubConn isn't failing. This state
                // transition is unlikely to happen, but handle this just in case.
                sc.connectQueued = false
                sc.attemptingToConnect = false
                // Set to a non-failing state.
                sc.failing = false</span>
        case connectivity.TransientFailure:<span class="cov8" title="1">
                // Set to a failing state.
                sc.failing = true</span>
        case connectivity.Shutdown:<span class="cov0" title="0">
                sc.attemptingToConnect = false</span>
        }
        <span class="cov8" title="1">sc.state = s</span>
}

// effectiveState returns the effective state of this SubConn. It can be
// different from the actual state, e.g. Idle while the subConn is failing is
// considered TransientFailure. Read comment of field failing for other cases.
func (sc *subConn) effectiveState() connectivity.State <span class="cov8" title="1">{
        sc.mu.RLock()
        defer sc.mu.RUnlock()
        if sc.failing &amp;&amp; (sc.state == connectivity.Idle || sc.state == connectivity.Connecting) </span><span class="cov8" title="1">{
                return connectivity.TransientFailure
        }</span>
        <span class="cov8" title="1">return sc.state</span>
}

// queueConnect sets a boolean so that when the SubConn state changes to Idle,
// it's Connect() will be triggered. If the SubConn state is already Idle, it
// will just call Connect().
func (sc *subConn) queueConnect() <span class="cov8" title="1">{
        sc.mu.Lock()
        defer sc.mu.Unlock()
        sc.attemptingToConnect = true
        if sc.state == connectivity.Idle </span><span class="cov8" title="1">{
                sc.sc.Connect()
                return
        }</span>
        // Queue this connect, and when this SubConn switches back to Idle (happens
        // after backoff in TransientFailure), it will Connect().
        <span class="cov8" title="1">sc.connectQueued = true</span>
}

func (sc *subConn) isAttemptingToConnect() bool <span class="cov8" title="1">{
        sc.mu.Lock()
        defer sc.mu.Unlock()
        return sc.attemptingToConnect
}</span>

type ringhashBalancer struct {
        cc     balancer.ClientConn
        logger *grpclog.PrefixLogger

        config   *LBConfig
        subConns *resolver.AddressMap // Map from resolver.Address to `*subConn`.
        scStates map[balancer.SubConn]*subConn

        // ring is always in sync with subConns. When subConns change, a new ring is
        // generated. Note that address weights updates (they are keys in the
        // subConns map) also regenerates the ring.
        ring    *ring
        picker  balancer.Picker
        csEvltr *connectivityStateEvaluator
        state   connectivity.State

        resolverErr error // the last error reported by the resolver; cleared on successful resolution
        connErr     error // the last connection error; cleared upon leaving TransientFailure
}

// updateAddresses creates new SubConns and removes SubConns, based on the
// address update.
//
// The return value is whether the new address list is different from the
// previous. True if
// - an address was added
// - an address was removed
// - an address's weight was updated
//
// Note that this function doesn't trigger SubConn connecting, so all the new
// SubConn states are Idle.
func (b *ringhashBalancer) updateAddresses(addrs []resolver.Address) bool <span class="cov8" title="1">{
        var addrsUpdated bool
        // addrsSet is the set converted from addrs, used for quick lookup.
        addrsSet := resolver.NewAddressMap()
        for _, addr := range addrs </span><span class="cov8" title="1">{
                addrsSet.Set(addr, true)
                newWeight := getWeightAttribute(addr)
                if val, ok := b.subConns.Get(addr); !ok </span><span class="cov8" title="1">{
                        sc, err := b.cc.NewSubConn([]resolver.Address{addr}, balancer.NewSubConnOptions{HealthCheckEnabled: true})
                        if err != nil </span><span class="cov0" title="0">{
                                logger.Warningf("base.baseBalancer: failed to create new SubConn: %v", err)
                                continue</span>
                        }
                        <span class="cov8" title="1">scs := &amp;subConn{addr: addr.Addr, weight: newWeight, sc: sc}
                        scs.setState(connectivity.Idle)
                        b.state = b.csEvltr.recordTransition(connectivity.Shutdown, connectivity.Idle)
                        b.subConns.Set(addr, scs)
                        b.scStates[sc] = scs
                        addrsUpdated = true</span>
                } else<span class="cov8" title="1"> {
                        // We have seen this address before and created a subConn for it. If the
                        // weight associated with the address has changed, update the subConns map
                        // with the new weight. This will be used when a new ring is created.
                        //
                        // There is no need to call UpdateAddresses on the subConn at this point
                        // since *only* the weight attribute has changed, and that does not affect
                        // subConn uniqueness.
                        scInfo := val.(*subConn)
                        if oldWeight := scInfo.weight; oldWeight != newWeight </span><span class="cov8" title="1">{
                                scInfo.weight = newWeight
                                b.subConns.Set(addr, scInfo)
                                // Return true to force recreation of the ring.
                                addrsUpdated = true
                        }</span>
                }
        }
        <span class="cov8" title="1">for _, addr := range b.subConns.Keys() </span><span class="cov8" title="1">{
                // addr was removed by resolver.
                if _, ok := addrsSet.Get(addr); !ok </span><span class="cov8" title="1">{
                        v, _ := b.subConns.Get(addr)
                        scInfo := v.(*subConn)
                        b.cc.RemoveSubConn(scInfo.sc)
                        b.subConns.Delete(addr)
                        addrsUpdated = true
                        // Keep the state of this sc in b.scStates until sc's state becomes Shutdown.
                        // The entry will be deleted in UpdateSubConnState.
                }</span>
        }
        <span class="cov8" title="1">return addrsUpdated</span>
}

func (b *ringhashBalancer) UpdateClientConnState(s balancer.ClientConnState) error <span class="cov8" title="1">{
        b.logger.Infof("Received update from resolver, balancer config: %+v", pretty.ToJSON(s.BalancerConfig))
        newConfig, ok := s.BalancerConfig.(*LBConfig)
        if !ok </span><span class="cov0" title="0">{
                return fmt.Errorf("unexpected balancer config with type: %T", s.BalancerConfig)
        }</span>

        // If addresses were updated, whether it resulted in SubConn
        // creation/deletion, or just weight update, we need to regenerate the ring
        // and send a new picker.
        <span class="cov8" title="1">regenerateRing := b.updateAddresses(s.ResolverState.Addresses)

        // If the ring configuration has changed, we need to regenerate the ring and
        // send a new picker.
        if b.config == nil || b.config.MinRingSize != newConfig.MinRingSize || b.config.MaxRingSize != newConfig.MaxRingSize </span><span class="cov8" title="1">{
                regenerateRing = true
        }</span>
        <span class="cov8" title="1">b.config = newConfig

        // If resolver state contains no addresses, return an error so ClientConn
        // will trigger re-resolve. Also records this as an resolver error, so when
        // the overall state turns transient failure, the error message will have
        // the zero address information.
        if len(s.ResolverState.Addresses) == 0 </span><span class="cov0" title="0">{
                b.ResolverError(errors.New("produced zero addresses"))
                return balancer.ErrBadResolverState
        }</span>

        <span class="cov8" title="1">if regenerateRing </span><span class="cov8" title="1">{
                // Ring creation is guaranteed to not fail because we call newRing()
                // with a non-empty subConns map.
                b.ring = newRing(b.subConns, b.config.MinRingSize, b.config.MaxRingSize)
                b.regeneratePicker()
                b.cc.UpdateState(balancer.State{ConnectivityState: b.state, Picker: b.picker})
        }</span>

        // Successful resolution; clear resolver error and return nil.
        <span class="cov8" title="1">b.resolverErr = nil
        return nil</span>
}

func (b *ringhashBalancer) ResolverError(err error) <span class="cov0" title="0">{
        b.resolverErr = err
        if b.subConns.Len() == 0 </span><span class="cov0" title="0">{
                b.state = connectivity.TransientFailure
        }</span>

        <span class="cov0" title="0">if b.state != connectivity.TransientFailure </span><span class="cov0" title="0">{
                // The picker will not change since the balancer does not currently
                // report an error.
                return
        }</span>
        <span class="cov0" title="0">b.regeneratePicker()
        b.cc.UpdateState(balancer.State{
                ConnectivityState: b.state,
                Picker:            b.picker,
        })</span>
}

// UpdateSubConnState updates the per-SubConn state stored in the ring, and also
// the aggregated state.
//
// It triggers an update to cc when:
// - the new state is TransientFailure, to update the error message
//   - it's possible that this is a noop, but sending an extra update is easier
//   than comparing errors
// - the aggregated state is changed
//   - the same picker will be sent again, but this update may trigger a re-pick
//   for some RPCs.
func (b *ringhashBalancer) UpdateSubConnState(sc balancer.SubConn, state balancer.SubConnState) <span class="cov8" title="1">{
        s := state.ConnectivityState
        b.logger.Infof("handle SubConn state change: %p, %v", sc, s)
        scs, ok := b.scStates[sc]
        if !ok </span><span class="cov0" title="0">{
                b.logger.Infof("got state changes for an unknown SubConn: %p, %v", sc, s)
                return
        }</span>
        <span class="cov8" title="1">oldSCState := scs.effectiveState()
        scs.setState(s)
        newSCState := scs.effectiveState()

        var sendUpdate bool
        oldBalancerState := b.state
        b.state = b.csEvltr.recordTransition(oldSCState, newSCState)
        if oldBalancerState != b.state </span><span class="cov8" title="1">{
                sendUpdate = true
        }</span>

        <span class="cov8" title="1">switch s </span>{
        case connectivity.Idle:<span class="cov8" title="1"></span>
                // No need to send an update. No queued RPC can be unblocked. If the
                // overall state changed because of this, sendUpdate is already true.
        case connectivity.Connecting:<span class="cov8" title="1"></span>
                // No need to send an update. No queued RPC can be unblocked. If the
                // overall state changed because of this, sendUpdate is already true.
        case connectivity.Ready:<span class="cov8" title="1">
                // Resend the picker, there's no need to regenerate the picker because
                // the ring didn't change.
                sendUpdate = true</span>
        case connectivity.TransientFailure:<span class="cov8" title="1">
                // Save error to be reported via picker.
                b.connErr = state.ConnectionError
                // Regenerate picker to update error message.
                b.regeneratePicker()
                sendUpdate = true</span>
        case connectivity.Shutdown:<span class="cov0" title="0">
                // When an address was removed by resolver, b called RemoveSubConn but
                // kept the sc's state in scStates. Remove state for this sc here.
                delete(b.scStates, sc)</span>
        }

        <span class="cov8" title="1">if sendUpdate </span><span class="cov8" title="1">{
                b.cc.UpdateState(balancer.State{ConnectivityState: b.state, Picker: b.picker})
        }</span>

        <span class="cov8" title="1">switch b.state </span>{
        case connectivity.Connecting, connectivity.TransientFailure:<span class="cov8" title="1">
                // When overall state is TransientFailure, we need to make sure at least
                // one SubConn is attempting to connect, otherwise this balancer may
                // never get picks if the parent is priority.
                //
                // Because we report Connecting as the overall state when only one
                // SubConn is in TransientFailure, we do the same check for Connecting
                // here.
                //
                // Note that this check also covers deleting SubConns due to address
                // change. E.g. if the SubConn attempting to connect is deleted, and the
                // overall state is TF. Since there must be at least one SubConn
                // attempting to connect, we need to trigger one. But since the deleted
                // SubConn will eventually send a shutdown update, this code will run
                // and trigger the next SubConn to connect.
                for _, v := range b.subConns.Values() </span><span class="cov8" title="1">{
                        sc := v.(*subConn)
                        if sc.isAttemptingToConnect() </span><span class="cov8" title="1">{
                                return
                        }</span>
                }
                // Trigger a SubConn (this updated SubConn's next SubConn in the ring)
                // to connect if nobody is attempting to connect.
                <span class="cov8" title="1">sc := nextSkippingDuplicatesSubConn(b.ring, scs)
                if sc != nil </span><span class="cov8" title="1">{
                        sc.queueConnect()
                }</span>
        }
}

// mergeErrors builds an error from the last connection error and the last
// resolver error.  Must only be called if b.state is TransientFailure.
func (b *ringhashBalancer) mergeErrors() error <span class="cov8" title="1">{
        // connErr must always be non-nil unless there are no SubConns, in which
        // case resolverErr must be non-nil.
        if b.connErr == nil </span><span class="cov8" title="1">{
                return fmt.Errorf("last resolver error: %v", b.resolverErr)
        }</span>
        <span class="cov0" title="0">if b.resolverErr == nil </span><span class="cov0" title="0">{
                return fmt.Errorf("last connection error: %v", b.connErr)
        }</span>
        <span class="cov0" title="0">return fmt.Errorf("last connection error: %v; last resolver error: %v", b.connErr, b.resolverErr)</span>
}

func (b *ringhashBalancer) regeneratePicker() <span class="cov8" title="1">{
        if b.state == connectivity.TransientFailure </span><span class="cov8" title="1">{
                b.picker = base.NewErrPicker(b.mergeErrors())
                return
        }</span>
        <span class="cov8" title="1">b.picker = newPicker(b.ring, b.logger)</span>
}

func (b *ringhashBalancer) Close() {<span class="cov0" title="0">}</span>

// connectivityStateEvaluator takes the connectivity states of multiple SubConns
// and returns one aggregated connectivity state.
//
// It's not thread safe.
type connectivityStateEvaluator struct {
        sum  uint64
        nums [5]uint64
}

// recordTransition records state change happening in subConn and based on that
// it evaluates what aggregated state should be.
//
// - If there is at least one subchannel in READY state, report READY.
// - If there are 2 or more subchannels in TRANSIENT_FAILURE state, report TRANSIENT_FAILURE.
// - If there is at least one subchannel in CONNECTING state, report CONNECTING.
// - If there is one subchannel in TRANSIENT_FAILURE and there is more than one subchannel, report state CONNECTING.
// - If there is at least one subchannel in Idle state, report Idle.
// - Otherwise, report TRANSIENT_FAILURE.
//
// Note that if there are 1 connecting, 2 transient failure, the overall state
// is transient failure. This is because the second transient failure is a
// fallback of the first failing SubConn, and we want to report transient
// failure to failover to the lower priority.
func (cse *connectivityStateEvaluator) recordTransition(oldState, newState connectivity.State) connectivity.State <span class="cov8" title="1">{
        // Update counters.
        for idx, state := range []connectivity.State{oldState, newState} </span><span class="cov8" title="1">{
                updateVal := 2*uint64(idx) - 1 // -1 for oldState and +1 for new.
                cse.nums[state] += updateVal
        }</span>
        <span class="cov8" title="1">if oldState == connectivity.Shutdown </span><span class="cov8" title="1">{
                // There's technically no transition from Shutdown. But we record a
                // Shutdown-&gt;Idle transition when a new SubConn is created.
                cse.sum++
        }</span>
        <span class="cov8" title="1">if newState == connectivity.Shutdown </span><span class="cov0" title="0">{
                cse.sum--
        }</span>

        <span class="cov8" title="1">if cse.nums[connectivity.Ready] &gt; 0 </span><span class="cov8" title="1">{
                return connectivity.Ready
        }</span>
        <span class="cov8" title="1">if cse.nums[connectivity.TransientFailure] &gt; 1 </span><span class="cov8" title="1">{
                return connectivity.TransientFailure
        }</span>
        <span class="cov8" title="1">if cse.nums[connectivity.Connecting] &gt; 0 </span><span class="cov8" title="1">{
                return connectivity.Connecting
        }</span>
        <span class="cov8" title="1">if cse.nums[connectivity.TransientFailure] &gt; 0 &amp;&amp; cse.sum &gt; 1 </span><span class="cov8" title="1">{
                return connectivity.Connecting
        }</span>
        <span class="cov8" title="1">if cse.nums[connectivity.Idle] &gt; 0 </span><span class="cov8" title="1">{
                return connectivity.Idle
        }</span>
        <span class="cov0" title="0">return connectivity.TransientFailure</span>
}

// getWeightAttribute is a convenience function which returns the value of the
// weight attribute stored in the BalancerAttributes field of addr, using the
// weightedroundrobin package.
//
// When used in the xDS context, the weight attribute is guaranteed to be
// non-zero. But, when used in a non-xDS context, the weight attribute could be
// unset. A Default of 1 is used in the latter case.
func getWeightAttribute(addr resolver.Address) uint32 <span class="cov8" title="1">{
        w := weightedroundrobin.GetAddrInfo(addr).Weight
        if w == 0 </span><span class="cov8" title="1">{
                return 1
        }</span>
        <span class="cov8" title="1">return w</span>
}
</pre>
		
		<pre class="file" id="file180" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package ringhash

import "context"

type clusterKey struct{}

func getRequestHash(ctx context.Context) uint64 <span class="cov8" title="1">{
        requestHash, _ := ctx.Value(clusterKey{}).(uint64)
        return requestHash
}</span>

// GetRequestHashForTesting returns the request hash in the context; to be used
// for testing only.
func GetRequestHashForTesting(ctx context.Context) uint64 <span class="cov0" title="0">{
        return getRequestHash(ctx)
}</span>

// SetRequestHash adds the request hash to the context for use in Ring Hash Load
// Balancing.
func SetRequestHash(ctx context.Context, requestHash uint64) context.Context <span class="cov8" title="1">{
        return context.WithValue(ctx, clusterKey{}, requestHash)
}</span>
</pre>
		
		<pre class="file" id="file181" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package rls implements the RLS cluster specifier plugin.
package rls

import (
        "encoding/json"
        "fmt"

        "github.com/golang/protobuf/proto"
        "github.com/golang/protobuf/ptypes"
        "google.golang.org/grpc/balancer"
        "google.golang.org/grpc/internal"
        "google.golang.org/grpc/internal/envconfig"
        rlspb "google.golang.org/grpc/internal/proto/grpc_lookup_v1"
        "google.golang.org/grpc/xds/internal/clusterspecifier"
        "google.golang.org/protobuf/encoding/protojson"
        "google.golang.org/protobuf/types/known/anypb"
)

func init() <span class="cov8" title="1">{
        if envconfig.XDSRLS </span><span class="cov0" title="0">{
                clusterspecifier.Register(rls{})
        }</span>

        // TODO: Remove these once the RLS env var is removed.
        <span class="cov8" title="1">internal.RegisterRLSClusterSpecifierPluginForTesting = func() </span><span class="cov0" title="0">{
                clusterspecifier.Register(rls{})
        }</span>
        <span class="cov8" title="1">internal.UnregisterRLSClusterSpecifierPluginForTesting = func() </span><span class="cov0" title="0">{
                for _, typeURL := range rls.TypeURLs(rls{}) </span><span class="cov0" title="0">{
                        clusterspecifier.UnregisterForTesting(typeURL)
                }</span>
        }
}

type rls struct{}

func (rls) TypeURLs() []string <span class="cov8" title="1">{
        return []string{"type.googleapis.com/grpc.lookup.v1.RouteLookupClusterSpecifier"}
}</span>

// lbConfigJSON is the RLS LB Policies configuration in JSON format.
// RouteLookupConfig will be a raw JSON string from the passed in proto
// configuration, and the other fields will be hardcoded.
type lbConfigJSON struct {
        RouteLookupConfig                json.RawMessage              `json:"routeLookupConfig"`
        ChildPolicy                      []map[string]json.RawMessage `json:"childPolicy"`
        ChildPolicyConfigTargetFieldName string                       `json:"childPolicyConfigTargetFieldName"`
}

func (rls) ParseClusterSpecifierConfig(cfg proto.Message) (clusterspecifier.BalancerConfig, error) <span class="cov8" title="1">{
        if cfg == nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("rls_csp: nil configuration message provided")
        }</span>
        <span class="cov8" title="1">any, ok := cfg.(*anypb.Any)
        if !ok </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("rls_csp: error parsing config %v: unknown type %T", cfg, cfg)
        }</span>
        <span class="cov8" title="1">rlcs := new(rlspb.RouteLookupClusterSpecifier)

        if err := ptypes.UnmarshalAny(any, rlcs); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("rls_csp: error parsing config %v: %v", cfg, err)
        }</span>
        <span class="cov8" title="1">rlcJSON, err := protojson.Marshal(rlcs.GetRouteLookupConfig())
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("rls_csp: error marshaling route lookup config: %v: %v", rlcs.GetRouteLookupConfig(), err)
        }</span>
        <span class="cov8" title="1">lbCfgJSON := &amp;lbConfigJSON{
                RouteLookupConfig: rlcJSON, // "JSON form of RouteLookupClusterSpecifier.config" - RLS in xDS Design Doc
                ChildPolicy: []map[string]json.RawMessage{
                        {
                                "cds_experimental": json.RawMessage("{}"),
                        },
                },
                ChildPolicyConfigTargetFieldName: "cluster",
        }

        rawJSON, err := json.Marshal(lbCfgJSON)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("rls_csp: error marshaling load balancing config %v: %v", lbCfgJSON, err)
        }</span>

        <span class="cov8" title="1">rlsBB := balancer.Get(internal.RLSLoadBalancingPolicyName)
        if rlsBB == nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("RLS LB policy not registered")
        }</span>
        <span class="cov8" title="1">if _, err = rlsBB.(balancer.ConfigParser).ParseConfig(rawJSON); err != nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("rls_csp: validation error from rls lb policy parsing %v", err)
        }</span>

        <span class="cov0" title="0">return clusterspecifier.BalancerConfig{{internal.RLSLoadBalancingPolicyName: lbCfgJSON}}, nil</span>
}
</pre>
		
		<pre class="file" id="file182" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package fault implements the Envoy Fault Injection HTTP filter.
package fault

import (
        "context"
        "errors"
        "fmt"
        "io"
        "strconv"
        "sync/atomic"
        "time"

        "github.com/golang/protobuf/proto"
        "github.com/golang/protobuf/ptypes"
        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/internal/grpcrand"
        iresolver "google.golang.org/grpc/internal/resolver"
        "google.golang.org/grpc/metadata"
        "google.golang.org/grpc/status"
        "google.golang.org/grpc/xds/internal/httpfilter"
        "google.golang.org/protobuf/types/known/anypb"

        cpb "github.com/envoyproxy/go-control-plane/envoy/extensions/filters/common/fault/v3"
        fpb "github.com/envoyproxy/go-control-plane/envoy/extensions/filters/http/fault/v3"
        tpb "github.com/envoyproxy/go-control-plane/envoy/type/v3"
)

const headerAbortHTTPStatus = "x-envoy-fault-abort-request"
const headerAbortGRPCStatus = "x-envoy-fault-abort-grpc-request"
const headerAbortPercentage = "x-envoy-fault-abort-request-percentage"

const headerDelayPercentage = "x-envoy-fault-delay-request-percentage"
const headerDelayDuration = "x-envoy-fault-delay-request"

var statusMap = map[int]codes.Code{
        400: codes.Internal,
        401: codes.Unauthenticated,
        403: codes.PermissionDenied,
        404: codes.Unimplemented,
        429: codes.Unavailable,
        502: codes.Unavailable,
        503: codes.Unavailable,
        504: codes.Unavailable,
}

func init() <span class="cov8" title="1">{
        httpfilter.Register(builder{})
}</span>

type builder struct {
}

type config struct {
        httpfilter.FilterConfig
        config *fpb.HTTPFault
}

func (builder) TypeURLs() []string <span class="cov8" title="1">{
        return []string{"type.googleapis.com/envoy.extensions.filters.http.fault.v3.HTTPFault"}
}</span>

// Parsing is the same for the base config and the override config.
func parseConfig(cfg proto.Message) (httpfilter.FilterConfig, error) <span class="cov8" title="1">{
        if cfg == nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("fault: nil configuration message provided")
        }</span>
        <span class="cov8" title="1">any, ok := cfg.(*anypb.Any)
        if !ok </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("fault: error parsing config %v: unknown type %T", cfg, cfg)
        }</span>
        <span class="cov8" title="1">msg := new(fpb.HTTPFault)
        if err := ptypes.UnmarshalAny(any, msg); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("fault: error parsing config %v: %v", cfg, err)
        }</span>
        <span class="cov8" title="1">return config{config: msg}, nil</span>
}

func (builder) ParseFilterConfig(cfg proto.Message) (httpfilter.FilterConfig, error) <span class="cov8" title="1">{
        return parseConfig(cfg)
}</span>

func (builder) ParseFilterConfigOverride(override proto.Message) (httpfilter.FilterConfig, error) <span class="cov0" title="0">{
        return parseConfig(override)
}</span>

func (builder) IsTerminal() bool <span class="cov8" title="1">{
        return false
}</span>

var _ httpfilter.ClientInterceptorBuilder = builder{}

func (builder) BuildClientInterceptor(cfg, override httpfilter.FilterConfig) (iresolver.ClientInterceptor, error) <span class="cov8" title="1">{
        if cfg == nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("fault: nil config provided")
        }</span>

        <span class="cov8" title="1">c, ok := cfg.(config)
        if !ok </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("fault: incorrect config type provided (%T): %v", cfg, cfg)
        }</span>

        <span class="cov8" title="1">if override != nil </span><span class="cov0" title="0">{
                // override completely replaces the listener configuration; but we
                // still validate the listener config type.
                c, ok = override.(config)
                if !ok </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("fault: incorrect override config type provided (%T): %v", override, override)
                }</span>
        }

        <span class="cov8" title="1">icfg := c.config
        if (icfg.GetMaxActiveFaults() != nil &amp;&amp; icfg.GetMaxActiveFaults().GetValue() == 0) ||
                (icfg.GetDelay() == nil &amp;&amp; icfg.GetAbort() == nil) </span><span class="cov8" title="1">{
                return nil, nil
        }</span>
        <span class="cov8" title="1">return &amp;interceptor{config: icfg}, nil</span>
}

type interceptor struct {
        config *fpb.HTTPFault
}

var activeFaults uint32 // global active faults; accessed atomically

func (i *interceptor) NewStream(ctx context.Context, ri iresolver.RPCInfo, done func(), newStream func(ctx context.Context, done func()) (iresolver.ClientStream, error)) (iresolver.ClientStream, error) <span class="cov8" title="1">{
        if maxAF := i.config.GetMaxActiveFaults(); maxAF != nil </span><span class="cov8" title="1">{
                defer atomic.AddUint32(&amp;activeFaults, ^uint32(0)) // decrement counter
                if af := atomic.AddUint32(&amp;activeFaults, 1); af &gt; maxAF.GetValue() </span><span class="cov8" title="1">{
                        // Would exceed maximum active fault limit.
                        return newStream(ctx, done)
                }</span>
        }

        <span class="cov8" title="1">if err := injectDelay(ctx, i.config.GetDelay()); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov8" title="1">if err := injectAbort(ctx, i.config.GetAbort()); err != nil </span><span class="cov8" title="1">{
                if err == errOKStream </span><span class="cov8" title="1">{
                        return &amp;okStream{ctx: ctx}, nil
                }</span>
                <span class="cov8" title="1">return nil, err</span>
        }
        <span class="cov8" title="1">return newStream(ctx, done)</span>
}

// For overriding in tests
var randIntn = grpcrand.Intn
var newTimer = time.NewTimer

func injectDelay(ctx context.Context, delayCfg *cpb.FaultDelay) error <span class="cov8" title="1">{
        numerator, denominator := splitPct(delayCfg.GetPercentage())
        var delay time.Duration
        switch delayType := delayCfg.GetFaultDelaySecifier().(type) </span>{
        case *cpb.FaultDelay_FixedDelay:<span class="cov8" title="1">
                delay = delayType.FixedDelay.AsDuration()</span>
        case *cpb.FaultDelay_HeaderDelay_:<span class="cov8" title="1">
                md, _ := metadata.FromOutgoingContext(ctx)
                v := md[headerDelayDuration]
                if v == nil </span><span class="cov0" title="0">{
                        // No delay configured for this RPC.
                        return nil
                }</span>
                <span class="cov8" title="1">ms, ok := parseIntFromMD(v)
                if !ok </span><span class="cov8" title="1">{
                        // Malformed header; no delay.
                        return nil
                }</span>
                <span class="cov8" title="1">delay = time.Duration(ms) * time.Millisecond
                if v := md[headerDelayPercentage]; v != nil </span><span class="cov8" title="1">{
                        if num, ok := parseIntFromMD(v); ok &amp;&amp; num &lt; numerator </span><span class="cov8" title="1">{
                                numerator = num
                        }</span>
                }
        }
        <span class="cov8" title="1">if delay == 0 || randIntn(denominator) &gt;= numerator </span><span class="cov8" title="1">{
                return nil
        }</span>
        <span class="cov8" title="1">t := newTimer(delay)
        select </span>{
        case &lt;-t.C:<span class="cov8" title="1"></span>
        case &lt;-ctx.Done():<span class="cov0" title="0">
                t.Stop()
                return ctx.Err()</span>
        }
        <span class="cov8" title="1">return nil</span>
}

func injectAbort(ctx context.Context, abortCfg *fpb.FaultAbort) error <span class="cov8" title="1">{
        numerator, denominator := splitPct(abortCfg.GetPercentage())
        code := codes.OK
        okCode := false
        switch errType := abortCfg.GetErrorType().(type) </span>{
        case *fpb.FaultAbort_HttpStatus:<span class="cov0" title="0">
                code, okCode = grpcFromHTTP(int(errType.HttpStatus))</span>
        case *fpb.FaultAbort_GrpcStatus:<span class="cov8" title="1">
                code, okCode = sanitizeGRPCCode(codes.Code(errType.GrpcStatus)), true</span>
        case *fpb.FaultAbort_HeaderAbort_:<span class="cov8" title="1">
                md, _ := metadata.FromOutgoingContext(ctx)
                if v := md[headerAbortHTTPStatus]; v != nil </span><span class="cov8" title="1">{
                        // HTTP status has priority over gRPC status.
                        if httpStatus, ok := parseIntFromMD(v); ok </span><span class="cov8" title="1">{
                                code, okCode = grpcFromHTTP(httpStatus)
                        }</span>
                } else<span class="cov8" title="1"> if v := md[headerAbortGRPCStatus]; v != nil </span><span class="cov8" title="1">{
                        if grpcStatus, ok := parseIntFromMD(v); ok </span><span class="cov8" title="1">{
                                code, okCode = sanitizeGRPCCode(codes.Code(grpcStatus)), true
                        }</span>
                }
                <span class="cov8" title="1">if v := md[headerAbortPercentage]; v != nil </span><span class="cov8" title="1">{
                        if num, ok := parseIntFromMD(v); ok &amp;&amp; num &lt; numerator </span><span class="cov8" title="1">{
                                numerator = num
                        }</span>
                }
        }
        <span class="cov8" title="1">if !okCode || randIntn(denominator) &gt;= numerator </span><span class="cov8" title="1">{
                return nil
        }</span>
        <span class="cov8" title="1">if code == codes.OK </span><span class="cov8" title="1">{
                return errOKStream
        }</span>
        <span class="cov8" title="1">return status.Errorf(code, "RPC terminated due to fault injection")</span>
}

var errOKStream = errors.New("stream terminated early with OK status")

// parseIntFromMD returns the integer in the last header or nil if parsing
// failed.
func parseIntFromMD(header []string) (int, bool) <span class="cov8" title="1">{
        if len(header) == 0 </span><span class="cov0" title="0">{
                return 0, false
        }</span>
        <span class="cov8" title="1">v, err := strconv.Atoi(header[len(header)-1])
        return v, err == nil</span>
}

func splitPct(fp *tpb.FractionalPercent) (num int, den int) <span class="cov8" title="1">{
        if fp == nil </span><span class="cov8" title="1">{
                return 0, 100
        }</span>
        <span class="cov8" title="1">num = int(fp.GetNumerator())
        switch fp.GetDenominator() </span>{
        case tpb.FractionalPercent_HUNDRED:<span class="cov8" title="1">
                return num, 100</span>
        case tpb.FractionalPercent_TEN_THOUSAND:<span class="cov8" title="1">
                return num, 10 * 1000</span>
        case tpb.FractionalPercent_MILLION:<span class="cov8" title="1">
                return num, 1000 * 1000</span>
        }
        <span class="cov0" title="0">return num, 100</span>
}

func grpcFromHTTP(httpStatus int) (codes.Code, bool) <span class="cov8" title="1">{
        if httpStatus &lt; 200 || httpStatus &gt;= 600 </span><span class="cov0" title="0">{
                // Malformed; ignore this fault type.
                return codes.OK, false
        }</span>
        <span class="cov8" title="1">if c := statusMap[httpStatus]; c != codes.OK </span><span class="cov8" title="1">{
                // OK = 0/the default for the map.
                return c, true
        }</span>
        // All undefined HTTP status codes convert to Unknown. HTTP status of 200
        // is "success", but gRPC converts to Unknown due to missing grpc status.
        <span class="cov8" title="1">return codes.Unknown, true</span>
}

func sanitizeGRPCCode(c codes.Code) codes.Code <span class="cov8" title="1">{
        if c &gt; codes.Code(16) </span><span class="cov0" title="0">{
                return codes.Unknown
        }</span>
        <span class="cov8" title="1">return c</span>
}

type okStream struct {
        ctx context.Context
}

func (*okStream) Header() (metadata.MD, error) <span class="cov0" title="0">{ return nil, nil }</span>
func (*okStream) Trailer() metadata.MD         <span class="cov0" title="0">{ return nil }</span>
func (*okStream) CloseSend() error             <span class="cov0" title="0">{ return nil }</span>
func (o *okStream) Context() context.Context   <span class="cov0" title="0">{ return o.ctx }</span>
func (*okStream) SendMsg(m interface{}) error  <span class="cov8" title="1">{ return io.EOF }</span>
func (*okStream) RecvMsg(m interface{}) error  <span class="cov0" title="0">{ return io.EOF }</span>
</pre>
		
		<pre class="file" id="file183" style="display: none">/*
 *
 * Copyright 2019 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// Package internal contains functions/structs shared by xds
// balancers/resolvers.
package internal

import (
        "encoding/json"
        "fmt"

        "google.golang.org/grpc/resolver"
)

// LocalityID is xds.Locality without XXX fields, so it can be used as map
// keys.
//
// xds.Locality cannot be map keys because one of the XXX fields is a slice.
type LocalityID struct {
        Region  string `json:"region,omitempty"`
        Zone    string `json:"zone,omitempty"`
        SubZone string `json:"subZone,omitempty"`
}

// ToString generates a string representation of LocalityID by marshalling it into
// json. Not calling it String() so printf won't call it.
func (l LocalityID) ToString() (string, error) <span class="cov8" title="1">{
        b, err := json.Marshal(l)
        if err != nil </span><span class="cov0" title="0">{
                return "", err
        }</span>
        <span class="cov8" title="1">return string(b), nil</span>
}

// Equal allows the values to be compared by Attributes.Equal.
func (l LocalityID) Equal(o interface{}) bool <span class="cov8" title="1">{
        ol, ok := o.(LocalityID)
        if !ok </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov8" title="1">return l.Region == ol.Region &amp;&amp; l.Zone == ol.Zone &amp;&amp; l.SubZone == ol.SubZone</span>
}

// LocalityIDFromString converts a json representation of locality, into a
// LocalityID struct.
func LocalityIDFromString(s string) (ret LocalityID, _ error) <span class="cov8" title="1">{
        err := json.Unmarshal([]byte(s), &amp;ret)
        if err != nil </span><span class="cov0" title="0">{
                return LocalityID{}, fmt.Errorf("%s is not a well formatted locality ID, error: %v", s, err)
        }</span>
        <span class="cov8" title="1">return ret, nil</span>
}

type localityKeyType string

const localityKey = localityKeyType("grpc.xds.internal.address.locality")

// GetLocalityID returns the locality ID of addr.
func GetLocalityID(addr resolver.Address) LocalityID <span class="cov0" title="0">{
        path, _ := addr.BalancerAttributes.Value(localityKey).(LocalityID)
        return path
}</span>

// SetLocalityID sets locality ID in addr to l.
func SetLocalityID(addr resolver.Address, l LocalityID) resolver.Address <span class="cov0" title="0">{
        addr.BalancerAttributes = addr.BalancerAttributes.WithValue(localityKey, l)
        return addr
}</span>
</pre>
		
		<pre class="file" id="file184" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package resolver

import (
        "fmt"

        "google.golang.org/grpc/grpclog"
        internalgrpclog "google.golang.org/grpc/internal/grpclog"
)

const prefix = "[xds-resolver %p] "

var logger = grpclog.Component("xds")

func prefixLogger(p *xdsResolver) *internalgrpclog.PrefixLogger <span class="cov8" title="1">{
        return internalgrpclog.NewPrefixLogger(logger, fmt.Sprintf(prefix, p))
}</span>
</pre>
		
		<pre class="file" id="file185" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package resolver

import (
        "context"
        "encoding/json"
        "fmt"
        "math/bits"
        "strings"
        "sync/atomic"
        "time"

        xxhash "github.com/cespare/xxhash/v2"
        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/internal/envconfig"
        "google.golang.org/grpc/internal/grpcrand"
        iresolver "google.golang.org/grpc/internal/resolver"
        "google.golang.org/grpc/internal/serviceconfig"
        "google.golang.org/grpc/internal/wrr"
        "google.golang.org/grpc/metadata"
        "google.golang.org/grpc/status"
        "google.golang.org/grpc/xds/internal/balancer/clustermanager"
        "google.golang.org/grpc/xds/internal/balancer/ringhash"
        "google.golang.org/grpc/xds/internal/httpfilter"
        "google.golang.org/grpc/xds/internal/httpfilter/router"
        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource"
)

const (
        cdsName                      = "cds_experimental"
        xdsClusterManagerName        = "xds_cluster_manager_experimental"
        clusterPrefix                = "cluster:"
        clusterSpecifierPluginPrefix = "cluster_specifier_plugin:"
)

type serviceConfig struct {
        LoadBalancingConfig balancerConfig `json:"loadBalancingConfig"`
}

type balancerConfig []map[string]interface{}

func newBalancerConfig(name string, config interface{}) balancerConfig <span class="cov8" title="1">{
        return []map[string]interface{}{{name: config}}
}</span>

type cdsBalancerConfig struct {
        Cluster string `json:"cluster"`
}

type xdsChildConfig struct {
        ChildPolicy balancerConfig `json:"childPolicy"`
}

type xdsClusterManagerConfig struct {
        Children map[string]xdsChildConfig `json:"children"`
}

// pruneActiveClusters deletes entries in r.activeClusters with zero
// references.
func (r *xdsResolver) pruneActiveClusters() <span class="cov8" title="1">{
        for cluster, ci := range r.activeClusters </span><span class="cov8" title="1">{
                if atomic.LoadInt32(&amp;ci.refCount) == 0 </span><span class="cov8" title="1">{
                        delete(r.activeClusters, cluster)
                }</span>
        }
}

// serviceConfigJSON produces a service config in JSON format representing all
// the clusters referenced in activeClusters.  This includes clusters with zero
// references, so they must be pruned first.
func serviceConfigJSON(activeClusters map[string]*clusterInfo) ([]byte, error) <span class="cov8" title="1">{
        // Generate children (all entries in activeClusters).
        children := make(map[string]xdsChildConfig)
        for cluster, ci := range activeClusters </span><span class="cov8" title="1">{
                children[cluster] = ci.cfg
        }</span>

        <span class="cov8" title="1">sc := serviceConfig{
                LoadBalancingConfig: newBalancerConfig(
                        xdsClusterManagerName, xdsClusterManagerConfig{Children: children},
                ),
        }

        bs, err := json.Marshal(sc)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to marshal json: %v", err)
        }</span>
        <span class="cov8" title="1">return bs, nil</span>
}

type virtualHost struct {
        // map from filter name to its config
        httpFilterConfigOverride map[string]httpfilter.FilterConfig
        // retry policy present in virtual host
        retryConfig *xdsresource.RetryConfig
}

// routeCluster holds information about a cluster as referenced by a route.
type routeCluster struct {
        name string
        // map from filter name to its config
        httpFilterConfigOverride map[string]httpfilter.FilterConfig
}

type route struct {
        m                 *xdsresource.CompositeMatcher // converted from route matchers
        clusters          wrr.WRR                       // holds *routeCluster entries
        maxStreamDuration time.Duration
        // map from filter name to its config
        httpFilterConfigOverride map[string]httpfilter.FilterConfig
        retryConfig              *xdsresource.RetryConfig
        hashPolicies             []*xdsresource.HashPolicy
}

func (r route) String() string <span class="cov0" title="0">{
        return fmt.Sprintf("%s -&gt; { clusters: %v, maxStreamDuration: %v }", r.m.String(), r.clusters, r.maxStreamDuration)
}</span>

type configSelector struct {
        r                *xdsResolver
        virtualHost      virtualHost
        routes           []route
        clusters         map[string]*clusterInfo
        httpFilterConfig []xdsresource.HTTPFilter
}

var errNoMatchedRouteFound = status.Errorf(codes.Unavailable, "no matched route was found")

func (cs *configSelector) SelectConfig(rpcInfo iresolver.RPCInfo) (*iresolver.RPCConfig, error) <span class="cov8" title="1">{
        if cs == nil </span><span class="cov8" title="1">{
                return nil, status.Errorf(codes.Unavailable, "no valid clusters")
        }</span>
        <span class="cov8" title="1">var rt *route
        // Loop through routes in order and select first match.
        for _, r := range cs.routes </span><span class="cov8" title="1">{
                if r.m.Match(rpcInfo) </span><span class="cov8" title="1">{
                        rt = &amp;r
                        break</span>
                }
        }
        <span class="cov8" title="1">if rt == nil || rt.clusters == nil </span><span class="cov0" title="0">{
                return nil, errNoMatchedRouteFound
        }</span>

        <span class="cov8" title="1">cluster, ok := rt.clusters.Next().(*routeCluster)
        if !ok </span><span class="cov0" title="0">{
                return nil, status.Errorf(codes.Internal, "error retrieving cluster for match: %v (%T)", cluster, cluster)
        }</span>

        // Add a ref to the selected cluster, as this RPC needs this cluster until
        // it is committed.
        <span class="cov8" title="1">ref := &amp;cs.clusters[cluster.name].refCount
        atomic.AddInt32(ref, 1)

        interceptor, err := cs.newInterceptor(rt, cluster)
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>

        <span class="cov8" title="1">lbCtx := clustermanager.SetPickedCluster(rpcInfo.Context, cluster.name)
        // Request Hashes are only applicable for a Ring Hash LB.
        if envconfig.XDSRingHash </span><span class="cov8" title="1">{
                lbCtx = ringhash.SetRequestHash(lbCtx, cs.generateHash(rpcInfo, rt.hashPolicies))
        }</span>

        <span class="cov8" title="1">config := &amp;iresolver.RPCConfig{
                // Communicate to the LB policy the chosen cluster and request hash, if Ring Hash LB policy.
                Context: lbCtx,
                OnCommitted: func() </span><span class="cov8" title="1">{
                        // When the RPC is committed, the cluster is no longer required.
                        // Decrease its ref.
                        if v := atomic.AddInt32(ref, -1); v == 0 </span><span class="cov8" title="1">{
                                // This entry will be removed from activeClusters when
                                // producing the service config for the empty update.
                                select </span>{
                                case cs.r.updateCh &lt;- suWithError{emptyUpdate: true}:<span class="cov8" title="1"></span>
                                default:<span class="cov0" title="0"></span>
                                }
                        }
                },
                Interceptor: interceptor,
        }

        <span class="cov8" title="1">if rt.maxStreamDuration != 0 </span><span class="cov8" title="1">{
                config.MethodConfig.Timeout = &amp;rt.maxStreamDuration
        }</span>
        <span class="cov8" title="1">if rt.retryConfig != nil </span><span class="cov0" title="0">{
                config.MethodConfig.RetryPolicy = retryConfigToPolicy(rt.retryConfig)
        }</span> else<span class="cov8" title="1"> if cs.virtualHost.retryConfig != nil </span><span class="cov0" title="0">{
                config.MethodConfig.RetryPolicy = retryConfigToPolicy(cs.virtualHost.retryConfig)
        }</span>

        <span class="cov8" title="1">return config, nil</span>
}

func retryConfigToPolicy(config *xdsresource.RetryConfig) *serviceconfig.RetryPolicy <span class="cov0" title="0">{
        return &amp;serviceconfig.RetryPolicy{
                MaxAttempts:          int(config.NumRetries) + 1,
                InitialBackoff:       config.RetryBackoff.BaseInterval,
                MaxBackoff:           config.RetryBackoff.MaxInterval,
                BackoffMultiplier:    2,
                RetryableStatusCodes: config.RetryOn,
        }
}</span>

func (cs *configSelector) generateHash(rpcInfo iresolver.RPCInfo, hashPolicies []*xdsresource.HashPolicy) uint64 <span class="cov8" title="1">{
        var hash uint64
        var generatedHash bool
        for _, policy := range hashPolicies </span><span class="cov8" title="1">{
                var policyHash uint64
                var generatedPolicyHash bool
                switch policy.HashPolicyType </span>{
                case xdsresource.HashPolicyTypeHeader:<span class="cov8" title="1">
                        md, ok := metadata.FromOutgoingContext(rpcInfo.Context)
                        if !ok </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        <span class="cov8" title="1">values := md.Get(policy.HeaderName)
                        // If the header isn't present, no-op.
                        if len(values) == 0 </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        <span class="cov8" title="1">joinedValues := strings.Join(values, ",")
                        if policy.Regex != nil </span><span class="cov8" title="1">{
                                joinedValues = policy.Regex.ReplaceAllString(joinedValues, policy.RegexSubstitution)
                        }</span>
                        <span class="cov8" title="1">policyHash = xxhash.Sum64String(joinedValues)
                        generatedHash = true
                        generatedPolicyHash = true</span>
                case xdsresource.HashPolicyTypeChannelID:<span class="cov8" title="1">
                        // Hash the ClientConn pointer which logically uniquely
                        // identifies the client.
                        policyHash = xxhash.Sum64String(fmt.Sprintf("%p", &amp;cs.r.cc))
                        generatedHash = true
                        generatedPolicyHash = true</span>
                }

                // Deterministically combine the hash policies. Rotating prevents
                // duplicate hash policies from cancelling each other out and preserves
                // the 64 bits of entropy.
                <span class="cov8" title="1">if generatedPolicyHash </span><span class="cov8" title="1">{
                        hash = bits.RotateLeft64(hash, 1)
                        hash = hash ^ policyHash
                }</span>

                // If terminal policy and a hash has already been generated, ignore the
                // rest of the policies and use that hash already generated.
                <span class="cov8" title="1">if policy.Terminal &amp;&amp; generatedHash </span><span class="cov0" title="0">{
                        break</span>
                }
        }

        <span class="cov8" title="1">if generatedHash </span><span class="cov8" title="1">{
                return hash
        }</span>
        // If no generated hash return a random long. In the grand scheme of things
        // this logically will map to choosing a random backend to route request to.
        <span class="cov8" title="1">return grpcrand.Uint64()</span>
}

func (cs *configSelector) newInterceptor(rt *route, cluster *routeCluster) (iresolver.ClientInterceptor, error) <span class="cov8" title="1">{
        if len(cs.httpFilterConfig) == 0 </span><span class="cov0" title="0">{
                return nil, nil
        }</span>
        <span class="cov8" title="1">interceptors := make([]iresolver.ClientInterceptor, 0, len(cs.httpFilterConfig))
        for _, filter := range cs.httpFilterConfig </span><span class="cov8" title="1">{
                if router.IsRouterFilter(filter.Filter) </span><span class="cov8" title="1">{
                        // Ignore any filters after the router filter.  The router itself
                        // is currently a nop.
                        return &amp;interceptorList{interceptors: interceptors}, nil
                }</span>
                <span class="cov8" title="1">override := cluster.httpFilterConfigOverride[filter.Name] // cluster is highest priority
                if override == nil </span><span class="cov8" title="1">{
                        override = rt.httpFilterConfigOverride[filter.Name] // route is second priority
                }</span>
                <span class="cov8" title="1">if override == nil </span><span class="cov8" title="1">{
                        override = cs.virtualHost.httpFilterConfigOverride[filter.Name] // VH is third &amp; lowest priority
                }</span>
                <span class="cov8" title="1">ib, ok := filter.Filter.(httpfilter.ClientInterceptorBuilder)
                if !ok </span><span class="cov0" title="0">{
                        // Should not happen if it passed xdsClient validation.
                        return nil, fmt.Errorf("filter does not support use in client")
                }</span>
                <span class="cov8" title="1">i, err := ib.BuildClientInterceptor(filter.Config, override)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("error constructing filter: %v", err)
                }</span>
                <span class="cov8" title="1">if i != nil </span><span class="cov8" title="1">{
                        interceptors = append(interceptors, i)
                }</span>
        }
        <span class="cov8" title="1">return nil, fmt.Errorf("error in xds config: no router filter present")</span>
}

// stop decrements refs of all clusters referenced by this config selector.
func (cs *configSelector) stop() <span class="cov8" title="1">{
        // The resolver's old configSelector may be nil.  Handle that here.
        if cs == nil </span><span class="cov8" title="1">{
                return
        }</span>
        // If any refs drop to zero, we'll need a service config update to delete
        // the cluster.
        <span class="cov8" title="1">needUpdate := false
        // Loops over cs.clusters, but these are pointers to entries in
        // activeClusters.
        for _, ci := range cs.clusters </span><span class="cov8" title="1">{
                if v := atomic.AddInt32(&amp;ci.refCount, -1); v == 0 </span><span class="cov8" title="1">{
                        needUpdate = true
                }</span>
        }
        // We stop the old config selector immediately after sending a new config
        // selector; we need another update to delete clusters from the config (if
        // we don't have another update pending already).
        <span class="cov8" title="1">if needUpdate </span><span class="cov8" title="1">{
                select </span>{
                case cs.r.updateCh &lt;- suWithError{emptyUpdate: true}:<span class="cov8" title="1"></span>
                default:<span class="cov0" title="0"></span>
                }
        }
}

// A global for testing.
var newWRR = wrr.NewRandom

// newConfigSelector creates the config selector for su; may add entries to
// r.activeClusters for previously-unseen clusters.
func (r *xdsResolver) newConfigSelector(su serviceUpdate) (*configSelector, error) <span class="cov8" title="1">{
        cs := &amp;configSelector{
                r: r,
                virtualHost: virtualHost{
                        httpFilterConfigOverride: su.virtualHost.HTTPFilterConfigOverride,
                        retryConfig:              su.virtualHost.RetryConfig,
                },
                routes:           make([]route, len(su.virtualHost.Routes)),
                clusters:         make(map[string]*clusterInfo),
                httpFilterConfig: su.ldsConfig.httpFilterConfig,
        }

        for i, rt := range su.virtualHost.Routes </span><span class="cov8" title="1">{
                clusters := newWRR()
                if rt.ClusterSpecifierPlugin != "" </span><span class="cov8" title="1">{
                        clusterName := clusterSpecifierPluginPrefix + rt.ClusterSpecifierPlugin
                        clusters.Add(&amp;routeCluster{
                                name: clusterName,
                        }, 1)
                        cs.initializeCluster(clusterName, xdsChildConfig{
                                ChildPolicy: balancerConfig(su.clusterSpecifierPlugins[rt.ClusterSpecifierPlugin]),
                        })
                }</span> else<span class="cov8" title="1"> {
                        for cluster, wc := range rt.WeightedClusters </span><span class="cov8" title="1">{
                                clusterName := clusterPrefix + cluster
                                clusters.Add(&amp;routeCluster{
                                        name:                     clusterName,
                                        httpFilterConfigOverride: wc.HTTPFilterConfigOverride,
                                }, int64(wc.Weight))
                                cs.initializeCluster(clusterName, xdsChildConfig{
                                        ChildPolicy: newBalancerConfig(cdsName, cdsBalancerConfig{Cluster: cluster}),
                                })
                        }</span>
                }
                <span class="cov8" title="1">cs.routes[i].clusters = clusters

                var err error
                cs.routes[i].m, err = xdsresource.RouteToMatcher(rt)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov8" title="1">if rt.MaxStreamDuration == nil </span><span class="cov8" title="1">{
                        cs.routes[i].maxStreamDuration = su.ldsConfig.maxStreamDuration
                }</span> else<span class="cov8" title="1"> {
                        cs.routes[i].maxStreamDuration = *rt.MaxStreamDuration
                }</span>

                <span class="cov8" title="1">cs.routes[i].httpFilterConfigOverride = rt.HTTPFilterConfigOverride
                cs.routes[i].retryConfig = rt.RetryConfig
                cs.routes[i].hashPolicies = rt.HashPolicies</span>
        }

        // Account for this config selector's clusters.  Do this after no further
        // errors may occur.  Note: cs.clusters are pointers to entries in
        // activeClusters.
        <span class="cov8" title="1">for _, ci := range cs.clusters </span><span class="cov8" title="1">{
                atomic.AddInt32(&amp;ci.refCount, 1)
        }</span>

        <span class="cov8" title="1">return cs, nil</span>
}

// initializeCluster initializes entries in cs.clusters map, creating entries in
// r.activeClusters as necessary.  Any created entries will have a ref count set
// to zero as their ref count will be incremented by incRefs.
func (cs *configSelector) initializeCluster(clusterName string, cfg xdsChildConfig) <span class="cov8" title="1">{
        ci := cs.r.activeClusters[clusterName]
        if ci == nil </span><span class="cov8" title="1">{
                ci = &amp;clusterInfo{refCount: 0}
                cs.r.activeClusters[clusterName] = ci
        }</span>
        <span class="cov8" title="1">cs.clusters[clusterName] = ci
        cs.clusters[clusterName].cfg = cfg</span>
}

type clusterInfo struct {
        // number of references to this cluster; accessed atomically
        refCount int32
        // cfg is the child configuration for this cluster, containing either the
        // csp config or the cds cluster config.
        cfg xdsChildConfig
}

type interceptorList struct {
        interceptors []iresolver.ClientInterceptor
}

func (il *interceptorList) NewStream(ctx context.Context, ri iresolver.RPCInfo, done func(), newStream func(ctx context.Context, done func()) (iresolver.ClientStream, error)) (iresolver.ClientStream, error) <span class="cov8" title="1">{
        for i := len(il.interceptors) - 1; i &gt;= 0; i-- </span><span class="cov8" title="1">{
                ns := newStream
                interceptor := il.interceptors[i]
                newStream = func(ctx context.Context, done func()) (iresolver.ClientStream, error) </span><span class="cov8" title="1">{
                        return interceptor.NewStream(ctx, ri, done, ns)
                }</span>
        }
        <span class="cov8" title="1">return newStream(ctx, func() </span>{<span class="cov8" title="1">}</span>)
}
</pre>
		
		<pre class="file" id="file186" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package resolver

import (
        "fmt"
        "sync"
        "time"

        "google.golang.org/grpc/internal/grpclog"
        "google.golang.org/grpc/internal/pretty"
        "google.golang.org/grpc/xds/internal/clusterspecifier"
        "google.golang.org/grpc/xds/internal/xdsclient"
        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource"
)

// serviceUpdate contains information received from the LDS/RDS responses which
// are of interest to the xds resolver. The RDS request is built by first
// making a LDS to get the RouteConfig name.
type serviceUpdate struct {
        // virtualHost contains routes and other configuration to route RPCs.
        virtualHost *xdsresource.VirtualHost
        // clusterSpecifierPlugins contains the configurations for any cluster
        // specifier plugins emitted by the xdsclient.
        clusterSpecifierPlugins map[string]clusterspecifier.BalancerConfig
        // ldsConfig contains configuration that applies to all routes.
        ldsConfig ldsConfig
}

// ldsConfig contains information received from the LDS responses which are of
// interest to the xds resolver.
type ldsConfig struct {
        // maxStreamDuration is from the HTTP connection manager's
        // common_http_protocol_options field.
        maxStreamDuration time.Duration
        httpFilterConfig  []xdsresource.HTTPFilter
}

// watchService uses LDS and RDS to discover information about the provided
// serviceName.
//
// Note that during race (e.g. an xDS response is received while the user is
// calling cancel()), there's a small window where the callback can be called
// after the watcher is canceled. The caller needs to handle this case.
//
// TODO(easwars): Make this function a method on the xdsResolver type.
// Currently, there is a single call site for this function, and all arguments
// passed to it are fields of the xdsResolver type.
func watchService(c xdsclient.XDSClient, serviceName string, cb func(serviceUpdate, error), logger *grpclog.PrefixLogger) (cancel func()) <span class="cov8" title="1">{
        w := &amp;serviceUpdateWatcher{
                logger:      logger,
                c:           c,
                serviceName: serviceName,
                serviceCb:   cb,
        }
        w.ldsCancel = c.WatchListener(serviceName, w.handleLDSResp)

        return w.close
}</span>

// serviceUpdateWatcher handles LDS and RDS response, and calls the service
// callback at the right time.
type serviceUpdateWatcher struct {
        logger      *grpclog.PrefixLogger
        c           xdsclient.XDSClient
        serviceName string
        ldsCancel   func()
        serviceCb   func(serviceUpdate, error)
        lastUpdate  serviceUpdate

        mu        sync.Mutex
        closed    bool
        rdsName   string
        rdsCancel func()
}

func (w *serviceUpdateWatcher) handleLDSResp(update xdsresource.ListenerUpdate, err error) <span class="cov8" title="1">{
        w.logger.Infof("received LDS update: %+v, err: %v", pretty.ToJSON(update), err)
        w.mu.Lock()
        defer w.mu.Unlock()
        if w.closed </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov8" title="1">if err != nil </span><span class="cov0" title="0">{
                // We check the error type and do different things. For now, the only
                // type we check is ResourceNotFound, which indicates the LDS resource
                // was removed, and besides sending the error to callback, we also
                // cancel the RDS watch.
                if xdsresource.ErrType(err) == xdsresource.ErrorTypeResourceNotFound &amp;&amp; w.rdsCancel != nil </span><span class="cov0" title="0">{
                        w.rdsCancel()
                        w.rdsName = ""
                        w.rdsCancel = nil
                        w.lastUpdate = serviceUpdate{}
                }</span>
                // The other error cases still return early without canceling the
                // existing RDS watch.
                <span class="cov0" title="0">w.serviceCb(serviceUpdate{}, err)
                return</span>
        }

        <span class="cov8" title="1">w.lastUpdate.ldsConfig = ldsConfig{
                maxStreamDuration: update.MaxStreamDuration,
                httpFilterConfig:  update.HTTPFilters,
        }

        if update.InlineRouteConfig != nil </span><span class="cov8" title="1">{
                // If there was an RDS watch, cancel it.
                w.rdsName = ""
                if w.rdsCancel != nil </span><span class="cov8" title="1">{
                        w.rdsCancel()
                        w.rdsCancel = nil
                }</span>

                // Handle the inline RDS update as if it's from an RDS watch.
                <span class="cov8" title="1">w.applyRouteConfigUpdate(*update.InlineRouteConfig)
                return</span>
        }

        // RDS name from update is not an empty string, need RDS to fetch the
        // routes.

        <span class="cov8" title="1">if w.rdsName == update.RouteConfigName </span><span class="cov8" title="1">{
                // If the new RouteConfigName is same as the previous, don't cancel and
                // restart the RDS watch.
                //
                // If the route name did change, then we must wait until the first RDS
                // update before reporting this LDS config.
                if w.lastUpdate.virtualHost != nil </span><span class="cov8" title="1">{
                        // We want to send an update with the new fields from the new LDS
                        // (e.g. max stream duration), and old fields from the the previous
                        // RDS.
                        //
                        // But note that this should only happen when virtual host is set,
                        // which means an RDS was received.
                        w.serviceCb(w.lastUpdate, nil)
                }</span>
                <span class="cov8" title="1">return</span>
        }
        <span class="cov8" title="1">w.rdsName = update.RouteConfigName
        if w.rdsCancel != nil </span><span class="cov8" title="1">{
                w.rdsCancel()
        }</span>
        <span class="cov8" title="1">w.rdsCancel = w.c.WatchRouteConfig(update.RouteConfigName, w.handleRDSResp)</span>
}

func (w *serviceUpdateWatcher) applyRouteConfigUpdate(update xdsresource.RouteConfigUpdate) <span class="cov8" title="1">{
        matchVh := xdsresource.FindBestMatchingVirtualHost(w.serviceName, update.VirtualHosts)
        if matchVh == nil </span><span class="cov0" title="0">{
                // No matching virtual host found.
                w.serviceCb(serviceUpdate{}, fmt.Errorf("no matching virtual host found for %q", w.serviceName))
                return
        }</span>

        <span class="cov8" title="1">w.lastUpdate.virtualHost = matchVh
        w.lastUpdate.clusterSpecifierPlugins = update.ClusterSpecifierPlugins
        w.serviceCb(w.lastUpdate, nil)</span>
}

func (w *serviceUpdateWatcher) handleRDSResp(update xdsresource.RouteConfigUpdate, err error) <span class="cov8" title="1">{
        w.logger.Infof("received RDS update: %+v, err: %v", pretty.ToJSON(update), err)
        w.mu.Lock()
        defer w.mu.Unlock()
        if w.closed </span><span class="cov8" title="1">{
                return
        }</span>
        <span class="cov8" title="1">if w.rdsCancel == nil </span><span class="cov0" title="0">{
                // This mean only the RDS watch is canceled, can happen if the LDS
                // resource is removed.
                return
        }</span>
        <span class="cov8" title="1">if err != nil </span><span class="cov8" title="1">{
                w.serviceCb(serviceUpdate{}, err)
                return
        }</span>
        <span class="cov8" title="1">w.applyRouteConfigUpdate(update)</span>
}

func (w *serviceUpdateWatcher) close() <span class="cov8" title="1">{
        w.mu.Lock()
        defer w.mu.Unlock()
        w.closed = true
        w.ldsCancel()
        if w.rdsCancel != nil </span><span class="cov8" title="1">{
                w.rdsCancel()
                w.rdsCancel = nil
        }</span>
}
</pre>
		
		<pre class="file" id="file187" style="display: none">/*
 * Copyright 2019 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package resolver implements the xds resolver, that does LDS and RDS to find
// the cluster to use.
package resolver

import (
        "errors"
        "fmt"
        "strings"

        "google.golang.org/grpc/credentials"
        "google.golang.org/grpc/internal"
        "google.golang.org/grpc/internal/grpclog"
        "google.golang.org/grpc/internal/grpcsync"
        "google.golang.org/grpc/internal/pretty"
        iresolver "google.golang.org/grpc/internal/resolver"
        "google.golang.org/grpc/resolver"
        "google.golang.org/grpc/xds/internal/xdsclient"
        "google.golang.org/grpc/xds/internal/xdsclient/bootstrap"
        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource"
)

const xdsScheme = "xds"

// newBuilderForTesting creates a new xds resolver builder using a specific xds
// bootstrap config, so tests can use multiple xds clients in different
// ClientConns at the same time.
func newBuilderForTesting(config []byte) (resolver.Builder, error) <span class="cov0" title="0">{
        return &amp;xdsResolverBuilder{
                newXDSClient: func() (xdsclient.XDSClient, error) </span><span class="cov0" title="0">{
                        return xdsclient.NewWithBootstrapContentsForTesting(config)
                }</span>,
        }, nil
}

// For overriding in unittests.
var newXDSClient = func() (xdsclient.XDSClient, error) <span class="cov0" title="0">{ return xdsclient.New() }</span>

func init() <span class="cov8" title="1">{
        resolver.Register(&amp;xdsResolverBuilder{})
        internal.NewXDSResolverWithConfigForTesting = newBuilderForTesting
}</span>

type xdsResolverBuilder struct {
        newXDSClient func() (xdsclient.XDSClient, error)
}

// Build helps implement the resolver.Builder interface.
//
// The xds bootstrap process is performed (and a new xds client is built) every
// time an xds resolver is built.
func (b *xdsResolverBuilder) Build(target resolver.Target, cc resolver.ClientConn, opts resolver.BuildOptions) (_ resolver.Resolver, retErr error) <span class="cov8" title="1">{
        r := &amp;xdsResolver{
                cc:             cc,
                closed:         grpcsync.NewEvent(),
                updateCh:       make(chan suWithError, 1),
                activeClusters: make(map[string]*clusterInfo),
        }
        defer func() </span><span class="cov8" title="1">{
                if retErr != nil </span><span class="cov8" title="1">{
                        r.Close()
                }</span>
        }()
        <span class="cov8" title="1">r.logger = prefixLogger(r)
        r.logger.Infof("Creating resolver for target: %+v", target)

        newXDSClient := newXDSClient
        if b.newXDSClient != nil </span><span class="cov0" title="0">{
                newXDSClient = b.newXDSClient
        }</span>

        <span class="cov8" title="1">client, err := newXDSClient()
        if err != nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("xds: failed to create xds-client: %v", err)
        }</span>
        <span class="cov8" title="1">r.client = client
        bootstrapConfig := client.BootstrapConfig()
        if bootstrapConfig == nil </span><span class="cov0" title="0">{
                return nil, errors.New("bootstrap configuration is empty")
        }</span>

        // If xds credentials were specified by the user, but bootstrap configs do
        // not contain any certificate provider configuration, it is better to fail
        // right now rather than failing when attempting to create certificate
        // providers after receiving an CDS response with security configuration.
        <span class="cov8" title="1">var creds credentials.TransportCredentials
        switch </span>{
        case opts.DialCreds != nil:<span class="cov8" title="1">
                creds = opts.DialCreds</span>
        case opts.CredsBundle != nil:<span class="cov0" title="0">
                creds = opts.CredsBundle.TransportCredentials()</span>
        }
        <span class="cov8" title="1">if xc, ok := creds.(interface{ UsesXDS() bool }); ok &amp;&amp; xc.UsesXDS() </span><span class="cov8" title="1">{
                if len(bootstrapConfig.CertProviderConfigs) == 0 </span><span class="cov8" title="1">{
                        return nil, errors.New("xds: xdsCreds specified but certificate_providers config missing in bootstrap file")
                }</span>
        }

        // Find the client listener template to use from the bootstrap config:
        // - If authority is not set in the target, use the top level template
        // - If authority is set, use the template from the authority map.
        <span class="cov8" title="1">template := bootstrapConfig.ClientDefaultListenerResourceNameTemplate
        if authority := target.URL.Host; authority != "" </span><span class="cov8" title="1">{
                a := bootstrapConfig.Authorities[authority]
                if a == nil </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("xds: authority %q is not found in the bootstrap file", authority)
                }</span>
                <span class="cov8" title="1">if a.ClientListenerResourceNameTemplate != "" </span><span class="cov8" title="1">{
                        // This check will never be false, because
                        // ClientListenerResourceNameTemplate is required to start with
                        // xdstp://, and has a default value (not an empty string) if unset.
                        template = a.ClientListenerResourceNameTemplate
                }</span>
        }
        <span class="cov8" title="1">endpoint := target.URL.Path
        if endpoint == "" </span><span class="cov0" title="0">{
                endpoint = target.URL.Opaque
        }</span>
        <span class="cov8" title="1">endpoint = strings.TrimPrefix(endpoint, "/")
        r.ldsResourceName = bootstrap.PopulateResourceTemplate(template, endpoint)

        // Register a watch on the xdsClient for the resource name determined above.
        cancelWatch := watchService(r.client, r.ldsResourceName, r.handleServiceUpdate, r.logger)
        r.logger.Infof("Watch started on resource name %v with xds-client %p", r.ldsResourceName, r.client)
        r.cancelWatch = func() </span><span class="cov8" title="1">{
                cancelWatch()
                r.logger.Infof("Watch cancel on resource name %v with xds-client %p", r.ldsResourceName, r.client)
        }</span>

        <span class="cov8" title="1">go r.run()
        return r, nil</span>
}

// Name helps implement the resolver.Builder interface.
func (*xdsResolverBuilder) Scheme() string <span class="cov8" title="1">{
        return xdsScheme
}</span>

// suWithError wraps the ServiceUpdate and error received through a watch API
// callback, so that it can pushed onto the update channel as a single entity.
type suWithError struct {
        su          serviceUpdate
        emptyUpdate bool
        err         error
}

// xdsResolver implements the resolver.Resolver interface.
//
// It registers a watcher for ServiceConfig updates with the xdsClient object
// (which performs LDS/RDS queries for the same), and passes the received
// updates to the ClientConn.
type xdsResolver struct {
        cc              resolver.ClientConn
        closed          *grpcsync.Event
        logger          *grpclog.PrefixLogger
        ldsResourceName string

        // The underlying xdsClient which performs all xDS requests and responses.
        client xdsclient.XDSClient
        // A channel for the watch API callback to write service updates on to. The
        // updates are read by the run goroutine and passed on to the ClientConn.
        updateCh chan suWithError
        // cancelWatch is the function to cancel the watcher.
        cancelWatch func()

        // activeClusters is a map from cluster name to a ref count.  Only read or
        // written during a service update (synchronous).
        activeClusters map[string]*clusterInfo

        curConfigSelector *configSelector
}

// sendNewServiceConfig prunes active clusters, generates a new service config
// based on the current set of active clusters, and sends an update to the
// channel with that service config and the provided config selector.  Returns
// false if an error occurs while generating the service config and the update
// cannot be sent.
func (r *xdsResolver) sendNewServiceConfig(cs *configSelector) bool <span class="cov8" title="1">{
        // Delete entries from r.activeClusters with zero references;
        // otherwise serviceConfigJSON will generate a config including
        // them.
        r.pruneActiveClusters()

        if cs == nil &amp;&amp; len(r.activeClusters) == 0 </span><span class="cov8" title="1">{
                // There are no clusters and we are sending a failing configSelector.
                // Send an empty config, which picks pick-first, with no address, and
                // puts the ClientConn into transient failure.
                r.cc.UpdateState(resolver.State{ServiceConfig: r.cc.ParseServiceConfig("{}")})
                return true
        }</span>

        <span class="cov8" title="1">sc, err := serviceConfigJSON(r.activeClusters)
        if err != nil </span><span class="cov0" title="0">{
                // JSON marshal error; should never happen.
                r.logger.Errorf("%v", err)
                r.cc.ReportError(err)
                return false
        }</span>
        <span class="cov8" title="1">r.logger.Infof("Received update on resource %v from xds-client %p, generated service config: %v", r.ldsResourceName, r.client, pretty.FormatJSON(sc))

        // Send the update to the ClientConn.
        state := iresolver.SetConfigSelector(resolver.State{
                ServiceConfig: r.cc.ParseServiceConfig(string(sc)),
        }, cs)
        r.cc.UpdateState(xdsclient.SetClient(state, r.client))
        return true</span>
}

// run is a long running goroutine which blocks on receiving service updates
// and passes it on the ClientConn.
func (r *xdsResolver) run() <span class="cov8" title="1">{
        for </span><span class="cov8" title="1">{
                select </span>{
                case &lt;-r.closed.Done():<span class="cov8" title="1">
                        return</span>
                case update := &lt;-r.updateCh:<span class="cov8" title="1">
                        if update.err != nil </span><span class="cov8" title="1">{
                                r.logger.Warningf("Watch error on resource %v from xds-client %p, %v", r.ldsResourceName, r.client, update.err)
                                if xdsresource.ErrType(update.err) == xdsresource.ErrorTypeResourceNotFound </span><span class="cov8" title="1">{
                                        // If error is resource-not-found, it means the LDS
                                        // resource was removed. Ultimately send an empty service
                                        // config, which picks pick-first, with no address, and
                                        // puts the ClientConn into transient failure.  Before we
                                        // can do that, we may need to send a normal service config
                                        // along with an erroring (nil) config selector.
                                        r.sendNewServiceConfig(nil)
                                        // Stop and dereference the active config selector, if one exists.
                                        r.curConfigSelector.stop()
                                        r.curConfigSelector = nil
                                        continue</span>
                                }
                                // Send error to ClientConn, and balancers, if error is not
                                // resource not found.  No need to update resolver state if we
                                // can keep using the old config.
                                <span class="cov8" title="1">r.cc.ReportError(update.err)
                                continue</span>
                        }
                        <span class="cov8" title="1">if update.emptyUpdate </span><span class="cov8" title="1">{
                                r.sendNewServiceConfig(r.curConfigSelector)
                                continue</span>
                        }

                        // Create the config selector for this update.
                        <span class="cov8" title="1">cs, err := r.newConfigSelector(update.su)
                        if err != nil </span><span class="cov0" title="0">{
                                r.logger.Warningf("Error parsing update on resource %v from xds-client %p: %v", r.ldsResourceName, r.client, err)
                                r.cc.ReportError(err)
                                continue</span>
                        }

                        <span class="cov8" title="1">if !r.sendNewServiceConfig(cs) </span><span class="cov0" title="0">{
                                // JSON error creating the service config (unexpected); erase
                                // this config selector and ignore this update, continuing with
                                // the previous config selector.
                                cs.stop()
                                continue</span>
                        }

                        // Decrement references to the old config selector and assign the
                        // new one as the current one.
                        <span class="cov8" title="1">r.curConfigSelector.stop()
                        r.curConfigSelector = cs</span>
                }
        }
}

// handleServiceUpdate is the callback which handles service updates. It writes
// the received update to the update channel, which is picked by the run
// goroutine.
func (r *xdsResolver) handleServiceUpdate(su serviceUpdate, err error) <span class="cov8" title="1">{
        if r.closed.HasFired() </span><span class="cov0" title="0">{
                // Do not pass updates to the ClientConn once the resolver is closed.
                return
        }</span>
        // Remove any existing entry in updateCh and replace with the new one.
        <span class="cov8" title="1">select </span>{
        case &lt;-r.updateCh:<span class="cov0" title="0"></span>
        default:<span class="cov8" title="1"></span>
        }
        <span class="cov8" title="1">r.updateCh &lt;- suWithError{su: su, err: err}</span>
}

// ResolveNow is a no-op at this point.
func (*xdsResolver) ResolveNow(o resolver.ResolveNowOptions) {<span class="cov0" title="0">}</span>

// Close closes the resolver, and also closes the underlying xdsClient.
func (r *xdsResolver) Close() <span class="cov8" title="1">{
        // Note that Close needs to check for nils even if some of them are always
        // set in the constructor. This is because the constructor defers Close() in
        // error cases, and the fields might not be set when the error happens.
        if r.cancelWatch != nil </span><span class="cov8" title="1">{
                r.cancelWatch()
        }</span>
        <span class="cov8" title="1">if r.client != nil </span><span class="cov8" title="1">{
                r.client.Close()
        }</span>
        <span class="cov8" title="1">r.closed.Fire()
        r.logger.Infof("Shutdown")</span>
}
</pre>
		
		<pre class="file" id="file188" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package server

import (
        "errors"
        "fmt"
        "net"
        "sync"
        "time"

        "google.golang.org/grpc/credentials/tls/certprovider"
        xdsinternal "google.golang.org/grpc/internal/credentials/xds"
        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource"
)

// connWrapper is a thin wrapper around a net.Conn returned by Accept(). It
// provides the following additional functionality:
// 1. A way to retrieve the configured deadline. This is required by the
//    ServerHandshake() method of the xdsCredentials when it attempts to read
//    key material from the certificate providers.
// 2. Implements the XDSHandshakeInfo() method used by the xdsCredentials to
//    retrieve the configured certificate providers.
// 3. xDS filter_chain matching logic to select appropriate security
//    configuration for the incoming connection.
type connWrapper struct {
        net.Conn

        // The specific filter chain picked for handling this connection.
        filterChain *xdsresource.FilterChain

        // A reference fo the listenerWrapper on which this connection was accepted.
        parent *listenerWrapper

        // The certificate providers created for this connection.
        rootProvider, identityProvider certprovider.Provider

        // The connection deadline as configured by the grpc.Server on the rawConn
        // that is returned by a call to Accept(). This is set to the connection
        // timeout value configured by the user (or to a default value) before
        // initiating the transport credential handshake, and set to zero after
        // completing the HTTP2 handshake.
        deadlineMu sync.Mutex
        deadline   time.Time

        // The virtual hosts with matchable routes and instantiated HTTP Filters per
        // route.
        virtualHosts []xdsresource.VirtualHostWithInterceptors
}

// VirtualHosts returns the virtual hosts to be used for server side routing.
func (c *connWrapper) VirtualHosts() []xdsresource.VirtualHostWithInterceptors <span class="cov0" title="0">{
        return c.virtualHosts
}</span>

// SetDeadline makes a copy of the passed in deadline and forwards the call to
// the underlying rawConn.
func (c *connWrapper) SetDeadline(t time.Time) error <span class="cov0" title="0">{
        c.deadlineMu.Lock()
        c.deadline = t
        c.deadlineMu.Unlock()
        return c.Conn.SetDeadline(t)
}</span>

// GetDeadline returns the configured deadline. This will be invoked by the
// ServerHandshake() method of the XdsCredentials, which needs a deadline to
// pass to the certificate provider.
func (c *connWrapper) GetDeadline() time.Time <span class="cov0" title="0">{
        c.deadlineMu.Lock()
        t := c.deadline
        c.deadlineMu.Unlock()
        return t
}</span>

// XDSHandshakeInfo returns a HandshakeInfo with appropriate security
// configuration for this connection. This method is invoked by the
// ServerHandshake() method of the XdsCredentials.
func (c *connWrapper) XDSHandshakeInfo() (*xdsinternal.HandshakeInfo, error) <span class="cov0" title="0">{
        // Ideally this should never happen, since xdsCredentials are the only ones
        // which will invoke this method at handshake time. But to be on the safe
        // side, we avoid acting on the security configuration received from the
        // control plane when the user has not configured the use of xDS
        // credentials, by checking the value of this flag.
        if !c.parent.xdsCredsInUse </span><span class="cov0" title="0">{
                return nil, errors.New("user has not configured xDS credentials")
        }</span>

        <span class="cov0" title="0">if c.filterChain.SecurityCfg == nil </span><span class="cov0" title="0">{
                // If the security config is empty, this means that the control plane
                // did not provide any security configuration and therefore we should
                // return an empty HandshakeInfo here so that the xdsCreds can use the
                // configured fallback credentials.
                return xdsinternal.NewHandshakeInfo(nil, nil), nil
        }</span>

        <span class="cov0" title="0">cpc := c.parent.xdsC.BootstrapConfig().CertProviderConfigs
        // Identity provider name is mandatory on the server-side, and this is
        // enforced when the resource is received at the XDSClient layer.
        secCfg := c.filterChain.SecurityCfg
        ip, err := buildProviderFunc(cpc, secCfg.IdentityInstanceName, secCfg.IdentityCertName, true, false)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        // Root provider name is optional and required only when doing mTLS.
        <span class="cov0" title="0">var rp certprovider.Provider
        if instance, cert := secCfg.RootInstanceName, secCfg.RootCertName; instance != "" </span><span class="cov0" title="0">{
                rp, err = buildProviderFunc(cpc, instance, cert, false, true)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
        }
        <span class="cov0" title="0">c.identityProvider = ip
        c.rootProvider = rp

        xdsHI := xdsinternal.NewHandshakeInfo(c.rootProvider, c.identityProvider)
        xdsHI.SetRequireClientCert(secCfg.RequireClientCert)
        return xdsHI, nil</span>
}

// Close closes the providers and the underlying connection.
func (c *connWrapper) Close() error <span class="cov0" title="0">{
        if c.identityProvider != nil </span><span class="cov0" title="0">{
                c.identityProvider.Close()
        }</span>
        <span class="cov0" title="0">if c.rootProvider != nil </span><span class="cov0" title="0">{
                c.rootProvider.Close()
        }</span>
        <span class="cov0" title="0">return c.Conn.Close()</span>
}

func buildProviderFunc(configs map[string]*certprovider.BuildableConfig, instanceName, certName string, wantIdentity, wantRoot bool) (certprovider.Provider, error) <span class="cov0" title="0">{
        cfg, ok := configs[instanceName]
        if !ok </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("certificate provider instance %q not found in bootstrap file", instanceName)
        }</span>
        <span class="cov0" title="0">provider, err := cfg.Build(certprovider.BuildOptions{
                CertName:     certName,
                WantIdentity: wantIdentity,
                WantRoot:     wantRoot,
        })
        if err != nil </span><span class="cov0" title="0">{
                // This error is not expected since the bootstrap process parses the
                // config and makes sure that it is acceptable to the plugin. Still, it
                // is possible that the plugin parses the config successfully, but its
                // Build() method errors out.
                return nil, fmt.Errorf("failed to get security plugin instance (%+v): %v", cfg, err)
        }</span>
        <span class="cov0" title="0">return provider, nil</span>
}
</pre>
		
		<pre class="file" id="file189" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package server contains internal server-side functionality used by the public
// facing xds package.
package server

import (
        "errors"
        "fmt"
        "net"
        "sync"
        "sync/atomic"
        "time"
        "unsafe"

        "google.golang.org/grpc/backoff"
        "google.golang.org/grpc/connectivity"
        "google.golang.org/grpc/grpclog"
        internalbackoff "google.golang.org/grpc/internal/backoff"
        "google.golang.org/grpc/internal/envconfig"
        internalgrpclog "google.golang.org/grpc/internal/grpclog"
        "google.golang.org/grpc/internal/grpcsync"
        "google.golang.org/grpc/xds/internal/xdsclient/bootstrap"
        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource"
)

var (
        logger = grpclog.Component("xds")

        // Backoff strategy for temporary errors received from Accept(). If this
        // needs to be configurable, we can inject it through ListenerWrapperParams.
        bs = internalbackoff.Exponential{Config: backoff.Config{
                BaseDelay:  5 * time.Millisecond,
                Multiplier: 2.0,
                MaxDelay:   1 * time.Second,
        }}
        backoffFunc = bs.Backoff
)

// ServingModeCallback is the callback that users can register to get notified
// about the server's serving mode changes. The callback is invoked with the
// address of the listener and its new mode. The err parameter is set to a
// non-nil error if the server has transitioned into not-serving mode.
type ServingModeCallback func(addr net.Addr, mode connectivity.ServingMode, err error)

// DrainCallback is the callback that an xDS-enabled server registers to get
// notified about updates to the Listener configuration. The server is expected
// to gracefully shutdown existing connections, thereby forcing clients to
// reconnect and have the new configuration applied to the newly created
// connections.
type DrainCallback func(addr net.Addr)

func prefixLogger(p *listenerWrapper) *internalgrpclog.PrefixLogger <span class="cov8" title="1">{
        return internalgrpclog.NewPrefixLogger(logger, fmt.Sprintf("[xds-server-listener %p] ", p))
}</span>

// XDSClient wraps the methods on the XDSClient which are required by
// the listenerWrapper.
type XDSClient interface {
        WatchListener(string, func(xdsresource.ListenerUpdate, error)) func()
        WatchRouteConfig(string, func(xdsresource.RouteConfigUpdate, error)) func()
        BootstrapConfig() *bootstrap.Config
}

// ListenerWrapperParams wraps parameters required to create a listenerWrapper.
type ListenerWrapperParams struct {
        // Listener is the net.Listener passed by the user that is to be wrapped.
        Listener net.Listener
        // ListenerResourceName is the xDS Listener resource to request.
        ListenerResourceName string
        // XDSCredsInUse specifies whether or not the user expressed interest to
        // receive security configuration from the control plane.
        XDSCredsInUse bool
        // XDSClient provides the functionality from the XDSClient required here.
        XDSClient XDSClient
        // ModeCallback is the callback to invoke when the serving mode changes.
        ModeCallback ServingModeCallback
        // DrainCallback is the callback to invoke when the Listener gets a LDS
        // update.
        DrainCallback DrainCallback
}

// NewListenerWrapper creates a new listenerWrapper with params. It returns a
// net.Listener and a channel which is written to, indicating that the former is
// ready to be passed to grpc.Serve().
//
// Only TCP listeners are supported.
func NewListenerWrapper(params ListenerWrapperParams) (net.Listener, &lt;-chan struct{}) <span class="cov8" title="1">{
        lw := &amp;listenerWrapper{
                Listener:          params.Listener,
                name:              params.ListenerResourceName,
                xdsCredsInUse:     params.XDSCredsInUse,
                xdsC:              params.XDSClient,
                modeCallback:      params.ModeCallback,
                drainCallback:     params.DrainCallback,
                isUnspecifiedAddr: params.Listener.Addr().(*net.TCPAddr).IP.IsUnspecified(),

                mode:        connectivity.ServingModeStarting,
                closed:      grpcsync.NewEvent(),
                goodUpdate:  grpcsync.NewEvent(),
                ldsUpdateCh: make(chan ldsUpdateWithError, 1),
                rdsUpdateCh: make(chan rdsHandlerUpdate, 1),
        }
        lw.logger = prefixLogger(lw)

        // Serve() verifies that Addr() returns a valid TCPAddr. So, it is safe to
        // ignore the error from SplitHostPort().
        lisAddr := lw.Listener.Addr().String()
        lw.addr, lw.port, _ = net.SplitHostPort(lisAddr)

        lw.rdsHandler = newRDSHandler(lw.xdsC, lw.rdsUpdateCh)

        cancelWatch := lw.xdsC.WatchListener(lw.name, lw.handleListenerUpdate)
        lw.logger.Infof("Watch started on resource name %v", lw.name)
        lw.cancelWatch = func() </span><span class="cov8" title="1">{
                cancelWatch()
                lw.logger.Infof("Watch cancelled on resource name %v", lw.name)
        }</span>
        <span class="cov8" title="1">go lw.run()
        return lw, lw.goodUpdate.Done()</span>
}

type ldsUpdateWithError struct {
        update xdsresource.ListenerUpdate
        err    error
}

// listenerWrapper wraps the net.Listener associated with the listening address
// passed to Serve(). It also contains all other state associated with this
// particular invocation of Serve().
type listenerWrapper struct {
        net.Listener
        logger *internalgrpclog.PrefixLogger

        name          string
        xdsCredsInUse bool
        xdsC          XDSClient
        cancelWatch   func()
        modeCallback  ServingModeCallback
        drainCallback DrainCallback

        // Set to true if the listener is bound to the IP_ANY address (which is
        // "0.0.0.0" for IPv4 and "::" for IPv6).
        isUnspecifiedAddr bool
        // Listening address and port. Used to validate the socket address in the
        // Listener resource received from the control plane.
        addr, port string

        // This is used to notify that a good update has been received and that
        // Serve() can be invoked on the underlying gRPC server. Using an event
        // instead of a vanilla channel simplifies the update handler as it need not
        // keep track of whether the received update is the first one or not.
        goodUpdate *grpcsync.Event
        // A small race exists in the XDSClient code between the receipt of an xDS
        // response and the user cancelling the associated watch. In this window,
        // the registered callback may be invoked after the watch is canceled, and
        // the user is expected to work around this. This event signifies that the
        // listener is closed (and hence the watch is cancelled), and we drop any
        // updates received in the callback if this event has fired.
        closed *grpcsync.Event

        // mu guards access to the current serving mode and the filter chains. The
        // reason for using an rw lock here is that these fields are read in
        // Accept() for all incoming connections, but writes happen rarely (when we
        // get a Listener resource update).
        mu sync.RWMutex
        // Current serving mode.
        mode connectivity.ServingMode
        // Filter chains received as part of the last good update.
        filterChains *xdsresource.FilterChainManager

        // rdsHandler is used for any dynamic RDS resources specified in a LDS
        // update.
        rdsHandler *rdsHandler
        // rdsUpdates are the RDS resources received from the management
        // server, keyed on the RouteName of the RDS resource.
        rdsUpdates unsafe.Pointer // map[string]xdsclient.RouteConfigUpdate
        // ldsUpdateCh is a channel for XDSClient LDS updates.
        ldsUpdateCh chan ldsUpdateWithError
        // rdsUpdateCh is a channel for XDSClient RDS updates.
        rdsUpdateCh chan rdsHandlerUpdate
}

// Accept blocks on an Accept() on the underlying listener, and wraps the
// returned net.connWrapper with the configured certificate providers.
func (l *listenerWrapper) Accept() (net.Conn, error) <span class="cov8" title="1">{
        var retries int
        for </span><span class="cov8" title="1">{
                conn, err := l.Listener.Accept()
                if err != nil </span><span class="cov8" title="1">{
                        // Temporary() method is implemented by certain error types returned
                        // from the net package, and it is useful for us to not shutdown the
                        // server in these conditions. The listen queue being full is one
                        // such case.
                        if ne, ok := err.(interface{ Temporary() bool }); !ok || !ne.Temporary() </span><span class="cov8" title="1">{
                                return nil, err
                        }</span>
                        <span class="cov8" title="1">retries++
                        timer := time.NewTimer(backoffFunc(retries))
                        select </span>{
                        case &lt;-timer.C:<span class="cov8" title="1"></span>
                        case &lt;-l.closed.Done():<span class="cov0" title="0">
                                timer.Stop()
                                // Continuing here will cause us to call Accept() again
                                // which will return a non-temporary error.
                                continue</span>
                        }
                        <span class="cov8" title="1">continue</span>
                }
                // Reset retries after a successful Accept().
                <span class="cov8" title="1">retries = 0

                // Since the net.Conn represents an incoming connection, the source and
                // destination address can be retrieved from the local address and
                // remote address of the net.Conn respectively.
                destAddr, ok1 := conn.LocalAddr().(*net.TCPAddr)
                srcAddr, ok2 := conn.RemoteAddr().(*net.TCPAddr)
                if !ok1 || !ok2 </span><span class="cov0" title="0">{
                        // If the incoming connection is not a TCP connection, which is
                        // really unexpected since we check whether the provided listener is
                        // a TCP listener in Serve(), we return an error which would cause
                        // us to stop serving.
                        return nil, fmt.Errorf("received connection with non-TCP address (local: %T, remote %T)", conn.LocalAddr(), conn.RemoteAddr())
                }</span>

                <span class="cov8" title="1">l.mu.RLock()
                if l.mode == connectivity.ServingModeNotServing </span><span class="cov0" title="0">{
                        // Close connections as soon as we accept them when we are in
                        // "not-serving" mode. Since we accept a net.Listener from the user
                        // in Serve(), we cannot close the listener when we move to
                        // "not-serving". Closing the connection immediately upon accepting
                        // is one of the other ways to implement the "not-serving" mode as
                        // outlined in gRFC A36.
                        l.mu.RUnlock()
                        conn.Close()
                        continue</span>
                }
                <span class="cov8" title="1">fc, err := l.filterChains.Lookup(xdsresource.FilterChainLookupParams{
                        IsUnspecifiedListener: l.isUnspecifiedAddr,
                        DestAddr:              destAddr.IP,
                        SourceAddr:            srcAddr.IP,
                        SourcePort:            srcAddr.Port,
                })
                l.mu.RUnlock()
                if err != nil </span><span class="cov8" title="1">{
                        // When a matching filter chain is not found, we close the
                        // connection right away, but do not return an error back to
                        // `grpc.Serve()` from where this Accept() was invoked. Returning an
                        // error to `grpc.Serve()` causes the server to shutdown. If we want
                        // to avoid the server from shutting down, we would need to return
                        // an error type which implements the `Temporary() bool` method,
                        // which is invoked by `grpc.Serve()` to see if the returned error
                        // represents a temporary condition. In the case of a temporary
                        // error, `grpc.Serve()` method sleeps for a small duration and
                        // therefore ends up blocking all connection attempts during that
                        // time frame, which is also not ideal for an error like this.
                        l.logger.Warningf("connection from %s to %s failed to find any matching filter chain", conn.RemoteAddr().String(), conn.LocalAddr().String())
                        conn.Close()
                        continue</span>
                }
                <span class="cov8" title="1">if !envconfig.XDSRBAC </span><span class="cov0" title="0">{
                        return &amp;connWrapper{Conn: conn, filterChain: fc, parent: l}, nil
                }</span>
                <span class="cov8" title="1">var rc xdsresource.RouteConfigUpdate
                if fc.InlineRouteConfig != nil </span><span class="cov8" title="1">{
                        rc = *fc.InlineRouteConfig
                }</span> else<span class="cov0" title="0"> {
                        rcPtr := atomic.LoadPointer(&amp;l.rdsUpdates)
                        rcuPtr := (*map[string]xdsresource.RouteConfigUpdate)(rcPtr)
                        // This shouldn't happen, but this error protects against a panic.
                        if rcuPtr == nil </span><span class="cov0" title="0">{
                                return nil, errors.New("route configuration pointer is nil")
                        }</span>
                        <span class="cov0" title="0">rcu := *rcuPtr
                        rc = rcu[fc.RouteConfigName]</span>
                }
                // The filter chain will construct a usuable route table on each
                // connection accept. This is done because preinstantiating every route
                // table before it is needed for a connection would potentially lead to
                // a lot of cpu time and memory allocated for route tables that will
                // never be used. There was also a thought to cache this configuration,
                // and reuse it for the next accepted connection. However, this would
                // lead to a lot of code complexity (RDS Updates for a given route name
                // can come it at any time), and connections aren't accepted too often,
                // so this reinstantation of the Route Configuration is an acceptable
                // tradeoff for simplicity.
                <span class="cov8" title="1">vhswi, err := fc.ConstructUsableRouteConfiguration(rc)
                if err != nil </span><span class="cov0" title="0">{
                        l.logger.Warningf("route configuration construction: %v", err)
                        conn.Close()
                        continue</span>
                }
                <span class="cov8" title="1">return &amp;connWrapper{Conn: conn, filterChain: fc, parent: l, virtualHosts: vhswi}, nil</span>
        }
}

// Close closes the underlying listener. It also cancels the xDS watch
// registered in Serve() and closes any certificate provider instances created
// based on security configuration received in the LDS response.
func (l *listenerWrapper) Close() error <span class="cov8" title="1">{
        l.closed.Fire()
        l.Listener.Close()
        if l.cancelWatch != nil </span><span class="cov8" title="1">{
                l.cancelWatch()
        }</span>
        <span class="cov8" title="1">l.rdsHandler.close()
        return nil</span>
}

// run is a long running goroutine which handles all xds updates. LDS and RDS
// push updates onto a channel which is read and acted upon from this goroutine.
func (l *listenerWrapper) run() <span class="cov8" title="1">{
        for </span><span class="cov8" title="1">{
                select </span>{
                case &lt;-l.closed.Done():<span class="cov8" title="1">
                        return</span>
                case u := &lt;-l.ldsUpdateCh:<span class="cov8" title="1">
                        l.handleLDSUpdate(u)</span>
                case u := &lt;-l.rdsUpdateCh:<span class="cov8" title="1">
                        l.handleRDSUpdate(u)</span>
                }
        }
}

// handleLDSUpdate is the callback which handles LDS Updates. It writes the
// received update to the update channel, which is picked up by the run
// goroutine.
func (l *listenerWrapper) handleListenerUpdate(update xdsresource.ListenerUpdate, err error) <span class="cov8" title="1">{
        if l.closed.HasFired() </span><span class="cov0" title="0">{
                l.logger.Warningf("Resource %q received update: %v with error: %v, after listener was closed", l.name, update, err)
                return
        }</span>
        // Remove any existing entry in ldsUpdateCh and replace with the new one, as the only update
        // listener cares about is most recent update.
        <span class="cov8" title="1">select </span>{
        case &lt;-l.ldsUpdateCh:<span class="cov0" title="0"></span>
        default:<span class="cov8" title="1"></span>
        }
        <span class="cov8" title="1">l.ldsUpdateCh &lt;- ldsUpdateWithError{update: update, err: err}</span>
}

// handleRDSUpdate handles a full rds update from rds handler. On a successful
// update, the server will switch to ServingModeServing as the full
// configuration (both LDS and RDS) has been received.
func (l *listenerWrapper) handleRDSUpdate(update rdsHandlerUpdate) <span class="cov8" title="1">{
        if l.closed.HasFired() </span><span class="cov0" title="0">{
                l.logger.Warningf("RDS received update: %v with error: %v, after listener was closed", update.updates, update.err)
                return
        }</span>
        <span class="cov8" title="1">if update.err != nil </span><span class="cov0" title="0">{
                l.logger.Warningf("Received error for rds names specified in resource %q: %+v", l.name, update.err)
                if xdsresource.ErrType(update.err) == xdsresource.ErrorTypeResourceNotFound </span><span class="cov0" title="0">{
                        l.switchMode(nil, connectivity.ServingModeNotServing, update.err)
                }</span>
                // For errors which are anything other than "resource-not-found", we
                // continue to use the old configuration.
                <span class="cov0" title="0">return</span>
        }
        <span class="cov8" title="1">atomic.StorePointer(&amp;l.rdsUpdates, unsafe.Pointer(&amp;update.updates))

        l.switchMode(l.filterChains, connectivity.ServingModeServing, nil)
        l.goodUpdate.Fire()</span>
}

func (l *listenerWrapper) handleLDSUpdate(update ldsUpdateWithError) <span class="cov8" title="1">{
        if update.err != nil </span><span class="cov8" title="1">{
                l.logger.Warningf("Received error for resource %q: %+v", l.name, update.err)
                if xdsresource.ErrType(update.err) == xdsresource.ErrorTypeResourceNotFound </span><span class="cov0" title="0">{
                        l.switchMode(nil, connectivity.ServingModeNotServing, update.err)
                }</span>
                // For errors which are anything other than "resource-not-found", we
                // continue to use the old configuration.
                <span class="cov8" title="1">return</span>
        }
        <span class="cov8" title="1">l.logger.Infof("Received update for resource %q: %+v", l.name, update.update)

        // Make sure that the socket address on the received Listener resource
        // matches the address of the net.Listener passed to us by the user. This
        // check is done here instead of at the XDSClient layer because of the
        // following couple of reasons:
        // - XDSClient cannot know the listening address of every listener in the
        //   system, and hence cannot perform this check.
        // - this is a very context-dependent check and only the server has the
        //   appropriate context to perform this check.
        //
        // What this means is that the XDSClient has ACKed a resource which can push
        // the server into a "not serving" mode. This is not ideal, but this is
        // what we have decided to do. See gRPC A36 for more details.
        ilc := update.update.InboundListenerCfg
        if ilc.Address != l.addr || ilc.Port != l.port </span><span class="cov8" title="1">{
                l.switchMode(nil, connectivity.ServingModeNotServing, fmt.Errorf("address (%s:%s) in Listener update does not match listening address: (%s:%s)", ilc.Address, ilc.Port, l.addr, l.port))
                return
        }</span>

        // "Updates to a Listener cause all older connections on that Listener to be
        // gracefully shut down with a grace period of 10 minutes for long-lived
        // RPC's, such that clients will reconnect and have the updated
        // configuration apply." - A36 Note that this is not the same as moving the
        // Server's state to ServingModeNotServing. That prevents new connections
        // from being accepted, whereas here we simply want the clients to reconnect
        // to get the updated configuration.
        <span class="cov8" title="1">if envconfig.XDSRBAC </span><span class="cov8" title="1">{
                if l.drainCallback != nil </span><span class="cov0" title="0">{
                        l.drainCallback(l.Listener.Addr())
                }</span>
        }
        <span class="cov8" title="1">l.rdsHandler.updateRouteNamesToWatch(ilc.FilterChains.RouteConfigNames)
        // If there are no dynamic RDS Configurations still needed to be received
        // from the management server, this listener has all the configuration
        // needed, and is ready to serve.
        if len(ilc.FilterChains.RouteConfigNames) == 0 </span><span class="cov8" title="1">{
                l.switchMode(ilc.FilterChains, connectivity.ServingModeServing, nil)
                l.goodUpdate.Fire()
        }</span>
}

// switchMode updates the value of serving mode and filter chains stored in the
// listenerWrapper. And if the serving mode has changed, it invokes the
// registered mode change callback.
func (l *listenerWrapper) switchMode(fcs *xdsresource.FilterChainManager, newMode connectivity.ServingMode, err error) <span class="cov8" title="1">{
        l.mu.Lock()
        defer l.mu.Unlock()

        l.filterChains = fcs
        if l.mode == newMode &amp;&amp; l.mode == connectivity.ServingModeServing </span><span class="cov0" title="0">{
                // Redundant updates are suppressed only when we are SERVING and the new
                // mode is also SERVING. In the other case (where we are NOT_SERVING and the
                // new mode is also NOT_SERVING), the update is not suppressed as:
                //   1. the error may have change
                //   2. it provides a timestamp of the last backoff attempt
                return
        }</span>
        <span class="cov8" title="1">l.mode = newMode
        if l.modeCallback != nil </span><span class="cov0" title="0">{
                l.modeCallback(l.Listener.Addr(), newMode, err)
        }</span>
}
</pre>
		
		<pre class="file" id="file190" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package server

import (
        "sync"

        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource"
)

// rdsHandlerUpdate wraps the full RouteConfigUpdate that are dynamically
// queried for a given server side listener.
type rdsHandlerUpdate struct {
        updates map[string]xdsresource.RouteConfigUpdate
        err     error
}

// rdsHandler handles any RDS queries that need to be started for a given server
// side listeners Filter Chains (i.e. not inline).
type rdsHandler struct {
        xdsC XDSClient

        mu      sync.Mutex
        updates map[string]xdsresource.RouteConfigUpdate
        cancels map[string]func()

        // For a rdsHandler update, the only update wrapped listener cares about is
        // most recent one, so this channel will be opportunistically drained before
        // sending any new updates.
        updateChannel chan rdsHandlerUpdate
}

// newRDSHandler creates a new rdsHandler to watch for RDS resources.
// listenerWrapper updates the list of route names to watch by calling
// updateRouteNamesToWatch() upon receipt of new Listener configuration.
func newRDSHandler(xdsC XDSClient, ch chan rdsHandlerUpdate) *rdsHandler <span class="cov8" title="1">{
        return &amp;rdsHandler{
                xdsC:          xdsC,
                updateChannel: ch,
                updates:       make(map[string]xdsresource.RouteConfigUpdate),
                cancels:       make(map[string]func()),
        }
}</span>

// updateRouteNamesToWatch handles a list of route names to watch for a given
// server side listener (if a filter chain specifies dynamic RDS configuration).
// This function handles all the logic with respect to any routes that may have
// been added or deleted as compared to what was previously present.
func (rh *rdsHandler) updateRouteNamesToWatch(routeNamesToWatch map[string]bool) <span class="cov8" title="1">{
        rh.mu.Lock()
        defer rh.mu.Unlock()
        // Add and start watches for any routes for any new routes in
        // routeNamesToWatch.
        for routeName := range routeNamesToWatch </span><span class="cov8" title="1">{
                if _, ok := rh.cancels[routeName]; !ok </span><span class="cov8" title="1">{
                        func(routeName string) </span><span class="cov8" title="1">{
                                rh.cancels[routeName] = rh.xdsC.WatchRouteConfig(routeName, func(update xdsresource.RouteConfigUpdate, err error) </span><span class="cov8" title="1">{
                                        rh.handleRouteUpdate(routeName, update, err)
                                }</span>)
                        }(routeName)
                }
        }

        // Delete and cancel watches for any routes from persisted routeNamesToWatch
        // that are no longer present.
        <span class="cov8" title="1">for routeName := range rh.cancels </span><span class="cov8" title="1">{
                if _, ok := routeNamesToWatch[routeName]; !ok </span><span class="cov8" title="1">{
                        rh.cancels[routeName]()
                        delete(rh.cancels, routeName)
                        delete(rh.updates, routeName)
                }</span>
        }

        // If the full list (determined by length) of updates are now successfully
        // updated, the listener is ready to be updated.
        <span class="cov8" title="1">if len(rh.updates) == len(rh.cancels) &amp;&amp; len(routeNamesToWatch) != 0 </span><span class="cov8" title="1">{
                drainAndPush(rh.updateChannel, rdsHandlerUpdate{updates: rh.updates})
        }</span>
}

// handleRouteUpdate persists the route config for a given route name, and also
// sends an update to the Listener Wrapper on an error received or if the rds
// handler has a full collection of updates.
func (rh *rdsHandler) handleRouteUpdate(routeName string, update xdsresource.RouteConfigUpdate, err error) <span class="cov8" title="1">{
        if err != nil </span><span class="cov8" title="1">{
                drainAndPush(rh.updateChannel, rdsHandlerUpdate{err: err})
                return
        }</span>
        <span class="cov8" title="1">rh.mu.Lock()
        defer rh.mu.Unlock()
        rh.updates[routeName] = update

        // If the full list (determined by length) of updates have successfully
        // updated, the listener is ready to be updated.
        if len(rh.updates) == len(rh.cancels) </span><span class="cov8" title="1">{
                drainAndPush(rh.updateChannel, rdsHandlerUpdate{updates: rh.updates})
        }</span>
}

func drainAndPush(ch chan rdsHandlerUpdate, update rdsHandlerUpdate) <span class="cov8" title="1">{
        select </span>{
        case &lt;-ch:<span class="cov0" title="0"></span>
        default:<span class="cov8" title="1"></span>
        }
        <span class="cov8" title="1">ch &lt;- update</span>
}

// close() is meant to be called by wrapped listener when the wrapped listener
// is closed, and it cleans up resources by canceling all the active RDS
// watches.
func (rh *rdsHandler) close() <span class="cov8" title="1">{
        rh.mu.Lock()
        defer rh.mu.Unlock()
        for _, cancel := range rh.cancels </span><span class="cov8" title="1">{
                cancel()
        }</span>
}
</pre>
		
		<pre class="file" id="file191" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package e2e

import (
        "fmt"

        "github.com/google/uuid"
        "google.golang.org/grpc/internal/testutils/xds/e2e"
        xdsinternal "google.golang.org/grpc/internal/xds"
)

type controlPlane struct {
        server           *e2e.ManagementServer
        nodeID           string
        bootstrapContent string
}

func newControlPlane() (*controlPlane, error) <span class="cov0" title="0">{
        // Spin up an xDS management server on a local port.
        server, err := e2e.StartManagementServer(nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to spin up the xDS management server: %v", err)
        }</span>

        <span class="cov0" title="0">nodeID := uuid.New().String()
        bootstrapContentBytes, err := xdsinternal.BootstrapContents(xdsinternal.BootstrapOptions{
                Version:                            xdsinternal.TransportV3,
                NodeID:                             nodeID,
                ServerURI:                          server.Address,
                ServerListenerResourceNameTemplate: e2e.ServerListenerResourceNameTemplate,
        })
        if err != nil </span><span class="cov0" title="0">{
                server.Stop()
                return nil, fmt.Errorf("failed to create bootstrap file: %v", err)
        }</span>

        <span class="cov0" title="0">return &amp;controlPlane{
                server:           server,
                nodeID:           nodeID,
                bootstrapContent: string(bootstrapContentBytes),
        }, nil</span>
}

func (cp *controlPlane) stop() <span class="cov0" title="0">{
        cp.server.Stop()
}</span>
</pre>
		
		<pre class="file" id="file192" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// Package e2e implements xds e2e tests using go-control-plane.
package e2e

import (
        "context"
        "fmt"
        "io"
        "os"
        "os/exec"

        "google.golang.org/grpc"
        channelzgrpc "google.golang.org/grpc/channelz/grpc_channelz_v1"
        channelzpb "google.golang.org/grpc/channelz/grpc_channelz_v1"
        "google.golang.org/grpc/credentials/insecure"
        testgrpc "google.golang.org/grpc/interop/grpc_testing"
        testpb "google.golang.org/grpc/interop/grpc_testing"
)

func cmd(path string, logger io.Writer, args []string, env []string) *exec.Cmd <span class="cov0" title="0">{
        cmd := exec.Command(path, args...)
        cmd.Env = append(os.Environ(), env...)
        cmd.Stdout = logger
        cmd.Stderr = logger
        return cmd
}</span>

const (
        clientStatsPort = 60363 // TODO: make this different per-test, only needed for parallel tests.
)

type client struct {
        cmd *exec.Cmd

        target  string
        statsCC *grpc.ClientConn
}

// newClient create a client with the given target and bootstrap content.
func newClient(target, binaryPath, bootstrap string, logger io.Writer, flags ...string) (*client, error) <span class="cov0" title="0">{
        cmd := cmd(
                binaryPath,
                logger,
                append([]string{
                        "--server=" + target,
                        "--print_response=true",
                        "--qps=100",
                        fmt.Sprintf("--stats_port=%d", clientStatsPort),
                }, flags...), // Append any flags from caller.
                []string{
                        "GRPC_GO_LOG_VERBOSITY_LEVEL=99",
                        "GRPC_GO_LOG_SEVERITY_LEVEL=info",
                        "GRPC_XDS_BOOTSTRAP_CONFIG=" + bootstrap, // The bootstrap content doesn't need to be quoted.
                },
        )
        cmd.Start()

        cc, err := grpc.Dial(fmt.Sprintf("localhost:%d", clientStatsPort), grpc.WithTransportCredentials(insecure.NewCredentials()), grpc.WithDefaultCallOptions(grpc.WaitForReady(true)))
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">return &amp;client{
                cmd:     cmd,
                target:  target,
                statsCC: cc,
        }, nil</span>
}

func (c *client) clientStats(ctx context.Context) (*testpb.LoadBalancerStatsResponse, error) <span class="cov0" title="0">{
        ccc := testgrpc.NewLoadBalancerStatsServiceClient(c.statsCC)
        return ccc.GetClientStats(ctx, &amp;testpb.LoadBalancerStatsRequest{
                NumRpcs:    100,
                TimeoutSec: 10,
        })
}</span>

func (c *client) configRPCs(ctx context.Context, req *testpb.ClientConfigureRequest) error <span class="cov0" title="0">{
        ccc := testgrpc.NewXdsUpdateClientConfigureServiceClient(c.statsCC)
        _, err := ccc.Configure(ctx, req)
        return err
}</span>

func (c *client) channelzSubChannels(ctx context.Context) ([]*channelzpb.Subchannel, error) <span class="cov0" title="0">{
        ccc := channelzgrpc.NewChannelzClient(c.statsCC)
        r, err := ccc.GetTopChannels(ctx, &amp;channelzpb.GetTopChannelsRequest{})
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov0" title="0">var ret []*channelzpb.Subchannel
        for _, cc := range r.Channel </span><span class="cov0" title="0">{
                if cc.Data.Target != c.target </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov0" title="0">for _, sc := range cc.SubchannelRef </span><span class="cov0" title="0">{
                        rr, err := ccc.GetSubchannel(ctx, &amp;channelzpb.GetSubchannelRequest{SubchannelId: sc.SubchannelId})
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov0" title="0">ret = append(ret, rr.Subchannel)</span>
                }
        }
        <span class="cov0" title="0">return ret, nil</span>
}

func (c *client) stop() <span class="cov0" title="0">{
        c.cmd.Process.Kill()
        c.cmd.Wait()
}</span>

const (
        serverPort = 50051 // TODO: make this different per-test, only needed for parallel tests.
)

type server struct {
        cmd  *exec.Cmd
        port int
}

// newServer creates multiple servers with the given bootstrap content.
//
// Each server gets a different hostname, in the format of
// &lt;hostnamePrefix&gt;-&lt;index&gt;.
func newServers(hostnamePrefix, binaryPath, bootstrap string, logger io.Writer, count int) (_ []*server, err error) <span class="cov0" title="0">{
        var ret []*server
        defer func() </span><span class="cov0" title="0">{
                if err != nil </span><span class="cov0" title="0">{
                        for _, s := range ret </span><span class="cov0" title="0">{
                                s.stop()
                        }</span>
                }
        }()
        <span class="cov0" title="0">for i := 0; i &lt; count; i++ </span><span class="cov0" title="0">{
                port := serverPort + i
                cmd := cmd(
                        binaryPath,
                        logger,
                        []string{
                                fmt.Sprintf("--port=%d", port),
                                fmt.Sprintf("--host_name_override=%s-%d", hostnamePrefix, i),
                        },
                        []string{
                                "GRPC_GO_LOG_VERBOSITY_LEVEL=99",
                                "GRPC_GO_LOG_SEVERITY_LEVEL=info",
                                "GRPC_XDS_BOOTSTRAP_CONFIG=" + bootstrap, // The bootstrap content doesn't need to be quoted.,
                        },
                )
                cmd.Start()
                ret = append(ret, &amp;server{cmd: cmd, port: port})
        }</span>
        <span class="cov0" title="0">return ret, nil</span>
}

func (s *server) stop() <span class="cov0" title="0">{
        s.cmd.Process.Kill()
        s.cmd.Wait()
}</span>
</pre>
		
		<pre class="file" id="file193" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package e2e

import (
        "testing"

        "github.com/google/go-cmp/cmp"
        channelzpb "google.golang.org/grpc/channelz/grpc_channelz_v1"
)

func verifySubConnStates(t *testing.T, scs []*channelzpb.Subchannel, want map[channelzpb.ChannelConnectivityState_State]int) <span class="cov0" title="0">{
        t.Helper()
        var scStatsCount = map[channelzpb.ChannelConnectivityState_State]int{}
        for _, sc := range scs </span><span class="cov0" title="0">{
                scStatsCount[sc.Data.State.State]++
        }</span>
        <span class="cov0" title="0">if diff := cmp.Diff(scStatsCount, want); diff != "" </span><span class="cov0" title="0">{
                t.Fatalf("got unexpected number of subchannels in state Ready, %v, scs: %v", diff, scs)
        }</span>
}
</pre>
		
		<pre class="file" id="file194" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package testutils

import (
        "net"
        "strconv"

        v2xdspb "github.com/envoyproxy/go-control-plane/envoy/api/v2"
        v2corepb "github.com/envoyproxy/go-control-plane/envoy/api/v2/core"
        v2endpointpb "github.com/envoyproxy/go-control-plane/envoy/api/v2/endpoint"
        v3corepb "github.com/envoyproxy/go-control-plane/envoy/config/core/v3"
        v2typepb "github.com/envoyproxy/go-control-plane/envoy/type"
        wrapperspb "github.com/golang/protobuf/ptypes/wrappers"
        "google.golang.org/grpc/xds/internal"
)

// EmptyNodeProtoV2 is a v2 Node proto with no fields set.
var EmptyNodeProtoV2 = &amp;v2corepb.Node{}

// EmptyNodeProtoV3 is a v3 Node proto with no fields set.
var EmptyNodeProtoV3 = &amp;v3corepb.Node{}

// LocalityIDToProto converts a LocalityID to its proto representation.
func LocalityIDToProto(l internal.LocalityID) *v2corepb.Locality <span class="cov0" title="0">{
        return &amp;v2corepb.Locality{
                Region:  l.Region,
                Zone:    l.Zone,
                SubZone: l.SubZone,
        }
}</span>

// The helper structs/functions related to EDS protos are used in EDS balancer
// tests now, to generate test inputs. Eventually, EDS balancer tests should
// generate EndpointsUpdate directly, instead of generating and parsing the
// proto message.
// TODO: Once EDS balancer tests don't use these, these can be moved to v2 client code.

// ClusterLoadAssignmentBuilder builds a ClusterLoadAssignment, aka EDS
// response.
type ClusterLoadAssignmentBuilder struct {
        v *v2xdspb.ClusterLoadAssignment
}

// NewClusterLoadAssignmentBuilder creates a ClusterLoadAssignmentBuilder.
func NewClusterLoadAssignmentBuilder(clusterName string, dropPercents map[string]uint32) *ClusterLoadAssignmentBuilder <span class="cov0" title="0">{
        drops := make([]*v2xdspb.ClusterLoadAssignment_Policy_DropOverload, 0, len(dropPercents))
        for n, d := range dropPercents </span><span class="cov0" title="0">{
                drops = append(drops, &amp;v2xdspb.ClusterLoadAssignment_Policy_DropOverload{
                        Category: n,
                        DropPercentage: &amp;v2typepb.FractionalPercent{
                                Numerator:   d,
                                Denominator: v2typepb.FractionalPercent_HUNDRED,
                        },
                })
        }</span>

        <span class="cov0" title="0">return &amp;ClusterLoadAssignmentBuilder{
                v: &amp;v2xdspb.ClusterLoadAssignment{
                        ClusterName: clusterName,
                        Policy: &amp;v2xdspb.ClusterLoadAssignment_Policy{
                                DropOverloads: drops,
                        },
                },
        }</span>
}

// AddLocalityOptions contains options when adding locality to the builder.
type AddLocalityOptions struct {
        Health []v2corepb.HealthStatus
        Weight []uint32
}

// AddLocality adds a locality to the builder.
func (clab *ClusterLoadAssignmentBuilder) AddLocality(subzone string, weight uint32, priority uint32, addrsWithPort []string, opts *AddLocalityOptions) <span class="cov0" title="0">{
        lbEndPoints := make([]*v2endpointpb.LbEndpoint, 0, len(addrsWithPort))
        for i, a := range addrsWithPort </span><span class="cov0" title="0">{
                host, portStr, err := net.SplitHostPort(a)
                if err != nil </span><span class="cov0" title="0">{
                        panic("failed to split " + a)</span>
                }
                <span class="cov0" title="0">port, err := strconv.Atoi(portStr)
                if err != nil </span><span class="cov0" title="0">{
                        panic("failed to atoi " + portStr)</span>
                }

                <span class="cov0" title="0">lbe := &amp;v2endpointpb.LbEndpoint{
                        HostIdentifier: &amp;v2endpointpb.LbEndpoint_Endpoint{
                                Endpoint: &amp;v2endpointpb.Endpoint{
                                        Address: &amp;v2corepb.Address{
                                                Address: &amp;v2corepb.Address_SocketAddress{
                                                        SocketAddress: &amp;v2corepb.SocketAddress{
                                                                Protocol: v2corepb.SocketAddress_TCP,
                                                                Address:  host,
                                                                PortSpecifier: &amp;v2corepb.SocketAddress_PortValue{
                                                                        PortValue: uint32(port)}}}}}},
                }
                if opts != nil </span><span class="cov0" title="0">{
                        if i &lt; len(opts.Health) </span><span class="cov0" title="0">{
                                lbe.HealthStatus = opts.Health[i]
                        }</span>
                        <span class="cov0" title="0">if i &lt; len(opts.Weight) </span><span class="cov0" title="0">{
                                lbe.LoadBalancingWeight = &amp;wrapperspb.UInt32Value{Value: opts.Weight[i]}
                        }</span>
                }
                <span class="cov0" title="0">lbEndPoints = append(lbEndPoints, lbe)</span>
        }

        <span class="cov0" title="0">var localityID *v2corepb.Locality
        if subzone != "" </span><span class="cov0" title="0">{
                localityID = &amp;v2corepb.Locality{
                        Region:  "",
                        Zone:    "",
                        SubZone: subzone,
                }
        }</span>

        <span class="cov0" title="0">clab.v.Endpoints = append(clab.v.Endpoints, &amp;v2endpointpb.LocalityLbEndpoints{
                Locality:            localityID,
                LbEndpoints:         lbEndPoints,
                LoadBalancingWeight: &amp;wrapperspb.UInt32Value{Value: weight},
                Priority:            priority,
        })</span>
}

// Build builds ClusterLoadAssignment.
func (clab *ClusterLoadAssignmentBuilder) Build() *v2xdspb.ClusterLoadAssignment <span class="cov0" title="0">{
        return clab.v
}</span>
</pre>
		
		<pre class="file" id="file195" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// Package testutils provides utility types, for use in xds tests.
package testutils

import (
        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource"
        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource/version"
)

// BuildResourceName returns the resource name in the format of an xdstp://
// resource.
func BuildResourceName(typ xdsresource.ResourceType, auth, id string, ctxParams map[string]string) string <span class="cov0" title="0">{
        var typS string
        switch typ </span>{
        case xdsresource.ListenerResource:<span class="cov0" title="0">
                typS = version.V3ListenerType</span>
        case xdsresource.RouteConfigResource:<span class="cov0" title="0">
                typS = version.V3RouteConfigType</span>
        case xdsresource.ClusterResource:<span class="cov0" title="0">
                typS = version.V3ClusterType</span>
        case xdsresource.EndpointsResource:<span class="cov0" title="0">
                typS = version.V3EndpointsType</span>
        }
        <span class="cov0" title="0">return (&amp;xdsresource.Name{
                Scheme:        "xdstp",
                Authority:     auth,
                Type:          typS,
                ID:            id,
                ContextParams: ctxParams,
        }).String()</span>
}
</pre>
		
		<pre class="file" id="file196" style="display: none">/*
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package xdsclient

import "google.golang.org/grpc/resolver"

type clientKeyType string

const clientKey = clientKeyType("grpc.xds.internal.client.Client")

// FromResolverState returns the Client from state, or nil if not present.
func FromResolverState(state resolver.State) XDSClient <span class="cov0" title="0">{
        cs, _ := state.Attributes.Value(clientKey).(XDSClient)
        return cs
}</span>

// SetClient sets c in state and returns the new state.
func SetClient(state resolver.State, c XDSClient) resolver.State <span class="cov0" title="0">{
        state.Attributes = state.Attributes.WithValue(clientKey, c)
        return state
}</span>
</pre>
		
		<pre class="file" id="file197" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package xdsclient

import (
        "google.golang.org/grpc/xds/internal/xdsclient/bootstrap"
        "google.golang.org/grpc/xds/internal/xdsclient/load"
        "google.golang.org/grpc/xds/internal/xdsclient/pubsub"
        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource"
)

// authority is a combination of pubsub and the controller for this authority.
//
// Note that it might make sense to use one pubsub for all the resources (for
// all the controllers). One downside is the handling of StoW APIs (LDS/CDS).
// These responses contain all the resources from that control plane, so pubsub
// will need to keep lists of resources from each control plane, to know what
// are removed.
type authority struct {
        config     *bootstrap.ServerConfig
        pubsub     *pubsub.Pubsub
        controller controllerInterface
        refCount   int
}

// caller must hold parent's authorityMu.
func (a *authority) ref() <span class="cov8" title="1">{
        a.refCount++
}</span>

// caller must hold parent's authorityMu.
func (a *authority) unref() int <span class="cov8" title="1">{
        a.refCount--
        return a.refCount
}</span>

func (a *authority) close() <span class="cov8" title="1">{
        if a.pubsub != nil </span><span class="cov8" title="1">{
                a.pubsub.Close()
        }</span>
        <span class="cov8" title="1">if a.controller != nil </span><span class="cov8" title="1">{
                a.controller.Close()
        }</span>
}

func (a *authority) watchListener(serviceName string, cb func(xdsresource.ListenerUpdate, error)) (cancel func()) <span class="cov8" title="1">{
        first, cancelF := a.pubsub.WatchListener(serviceName, cb)
        if first </span><span class="cov8" title="1">{
                a.controller.AddWatch(xdsresource.ListenerResource, serviceName)
        }</span>
        <span class="cov8" title="1">return func() </span><span class="cov8" title="1">{
                if cancelF() </span><span class="cov8" title="1">{
                        a.controller.RemoveWatch(xdsresource.ListenerResource, serviceName)
                }</span>
        }
}

func (a *authority) watchRouteConfig(routeName string, cb func(xdsresource.RouteConfigUpdate, error)) (cancel func()) <span class="cov8" title="1">{
        first, cancelF := a.pubsub.WatchRouteConfig(routeName, cb)
        if first </span><span class="cov8" title="1">{
                a.controller.AddWatch(xdsresource.RouteConfigResource, routeName)
        }</span>
        <span class="cov8" title="1">return func() </span><span class="cov8" title="1">{
                if cancelF() </span><span class="cov8" title="1">{
                        a.controller.RemoveWatch(xdsresource.RouteConfigResource, routeName)
                }</span>
        }
}

func (a *authority) watchCluster(clusterName string, cb func(xdsresource.ClusterUpdate, error)) (cancel func()) <span class="cov8" title="1">{
        first, cancelF := a.pubsub.WatchCluster(clusterName, cb)
        if first </span><span class="cov8" title="1">{
                a.controller.AddWatch(xdsresource.ClusterResource, clusterName)
        }</span>
        <span class="cov8" title="1">return func() </span><span class="cov8" title="1">{
                if cancelF() </span><span class="cov8" title="1">{
                        a.controller.RemoveWatch(xdsresource.ClusterResource, clusterName)
                }</span>
        }
}

func (a *authority) watchEndpoints(clusterName string, cb func(xdsresource.EndpointsUpdate, error)) (cancel func()) <span class="cov8" title="1">{
        first, cancelF := a.pubsub.WatchEndpoints(clusterName, cb)
        if first </span><span class="cov8" title="1">{
                a.controller.AddWatch(xdsresource.EndpointsResource, clusterName)
        }</span>
        <span class="cov8" title="1">return func() </span><span class="cov8" title="1">{
                if cancelF() </span><span class="cov8" title="1">{
                        a.controller.RemoveWatch(xdsresource.EndpointsResource, clusterName)
                }</span>
        }
}

func (a *authority) reportLoad() (*load.Store, func()) <span class="cov8" title="1">{
        // An empty string means to report load to the same same used for ADS. There
        // should never be a need to specify a string other than an empty string. If
        // a different server is to be used, a different authority (controller) will
        // be created.
        return a.controller.ReportLoad("")
}</span>

func (a *authority) dump(t xdsresource.ResourceType) map[string]xdsresource.UpdateWithMD <span class="cov8" title="1">{
        return a.pubsub.Dump(t)
}</span>
</pre>
		
		<pre class="file" id="file198" style="display: none">/*
 *
 * Copyright 2019 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package bootstrap provides the functionality to initialize certain aspects
// of an xDS client by reading a bootstrap file.
package bootstrap

import (
        "bytes"
        "encoding/json"
        "fmt"
        "io/ioutil"
        "net/url"
        "strings"

        "github.com/golang/protobuf/jsonpb"
        "github.com/golang/protobuf/proto"
        "google.golang.org/grpc"
        "google.golang.org/grpc/credentials"
        "google.golang.org/grpc/credentials/google"
        "google.golang.org/grpc/credentials/insecure"
        "google.golang.org/grpc/credentials/tls/certprovider"
        "google.golang.org/grpc/internal"
        "google.golang.org/grpc/internal/envconfig"
        "google.golang.org/grpc/internal/pretty"
        "google.golang.org/grpc/xds/bootstrap"
        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource/version"

        v2corepb "github.com/envoyproxy/go-control-plane/envoy/api/v2/core"
        v3corepb "github.com/envoyproxy/go-control-plane/envoy/config/core/v3"
)

const (
        // The "server_features" field in the bootstrap file contains a list of
        // features supported by the server. A value of "xds_v3" indicates that the
        // server supports the v3 version of the xDS transport protocol.
        serverFeaturesV3 = "xds_v3"

        gRPCUserAgentName               = "gRPC Go"
        clientFeatureNoOverprovisioning = "envoy.lb.does_not_support_overprovisioning"
        clientFeatureResourceWrapper    = "xds.config.resource-in-sotw"
)

func init() <span class="cov8" title="1">{
        bootstrap.RegisterCredentials(&amp;insecureCredsBuilder{})
        bootstrap.RegisterCredentials(&amp;googleDefaultCredsBuilder{})
}</span>

var gRPCVersion = fmt.Sprintf("%s %s", gRPCUserAgentName, grpc.Version)

// For overriding in unit tests.
var bootstrapFileReadFunc = ioutil.ReadFile

// insecureCredsBuilder implements the `Credentials` interface defined in
// package `xds/bootstrap` and encapsulates an insecure credential.
type insecureCredsBuilder struct{}

func (i *insecureCredsBuilder) Build(json.RawMessage) (credentials.Bundle, error) <span class="cov8" title="1">{
        return insecure.NewBundle(), nil
}</span>

func (i *insecureCredsBuilder) Name() string <span class="cov8" title="1">{
        return "insecure"
}</span>

// googleDefaultCredsBuilder implements the `Credentials` interface defined in
// package `xds/boostrap` and encapsulates a Google Default credential.
type googleDefaultCredsBuilder struct{}

func (d *googleDefaultCredsBuilder) Build(json.RawMessage) (credentials.Bundle, error) <span class="cov8" title="1">{
        return google.NewDefaultCredentials(), nil
}</span>

func (d *googleDefaultCredsBuilder) Name() string <span class="cov8" title="1">{
        return "google_default"
}</span>

// ServerConfig contains the configuration to connect to a server, including
// URI, creds, and transport API version (e.g. v2 or v3).
type ServerConfig struct {
        // ServerURI is the management server to connect to.
        //
        // The bootstrap file contains an ordered list of xDS servers to contact for
        // this authority. The first one is picked.
        ServerURI string
        // Creds contains the credentials to be used while talking to the xDS
        // server, as a grpc.DialOption.
        Creds grpc.DialOption
        // CredsType is the type of the creds. It will be used to dedup servers.
        CredsType string
        // TransportAPI indicates the API version of xDS transport protocol to use.
        // This describes the xDS gRPC endpoint and version of
        // DiscoveryRequest/Response used on the wire.
        TransportAPI version.TransportAPI
        // NodeProto contains the Node proto to be used in xDS requests. The actual
        // type depends on the transport protocol version used.
        //
        // Note that it's specified in the bootstrap globally for all the servers,
        // but we keep it in each server config so that its type (e.g. *v2pb.Node or
        // *v3pb.Node) is consistent with the transport API version.
        NodeProto proto.Message
}

// String returns the string representation of the ServerConfig.
//
// This string representation will be used as map keys in federation
// (`map[ServerConfig]authority`), so that the xDS ClientConn and stream will be
// shared by authorities with different names but the same server config.
//
// It covers (almost) all the fields so the string can represent the config
// content. It doesn't cover NodeProto because NodeProto isn't used by
// federation.
func (sc *ServerConfig) String() string <span class="cov0" title="0">{
        var ver string
        switch sc.TransportAPI </span>{
        case version.TransportV3:<span class="cov0" title="0">
                ver = "xDSv3"</span>
        case version.TransportV2:<span class="cov0" title="0">
                ver = "xDSv2"</span>
        }
        <span class="cov0" title="0">return strings.Join([]string{sc.ServerURI, sc.CredsType, ver}, "-")</span>
}

// MarshalJSON marshals the ServerConfig to json.
func (sc ServerConfig) MarshalJSON() ([]byte, error) <span class="cov8" title="1">{
        server := xdsServer{
                ServerURI:    sc.ServerURI,
                ChannelCreds: []channelCreds{{Type: sc.CredsType, Config: nil}},
        }
        if sc.TransportAPI == version.TransportV3 </span><span class="cov8" title="1">{
                server.ServerFeatures = []string{serverFeaturesV3}
        }</span>
        <span class="cov8" title="1">return json.Marshal(server)</span>
}

// UnmarshalJSON takes the json data (a server) and unmarshals it to the struct.
func (sc *ServerConfig) UnmarshalJSON(data []byte) error <span class="cov8" title="1">{
        var server xdsServer
        if err := json.Unmarshal(data, &amp;server); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("xds: json.Unmarshal(data) for field ServerConfig failed during bootstrap: %v", err)
        }</span>
        <span class="cov8" title="1">sc.ServerURI = server.ServerURI
        for _, cc := range server.ChannelCreds </span><span class="cov8" title="1">{
                // We stop at the first credential type that we support.
                sc.CredsType = cc.Type
                c := bootstrap.GetCredentials(cc.Type)
                if c == nil </span><span class="cov8" title="1">{
                        continue</span>
                }
                <span class="cov8" title="1">bundle, err := c.Build(cc.Config)
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to build credentials bundle from bootstrap for %q: %v", cc.Type, err)
                }</span>
                <span class="cov8" title="1">sc.Creds = grpc.WithCredentialsBundle(bundle)
                break</span>
        }
        <span class="cov8" title="1">for _, f := range server.ServerFeatures </span><span class="cov8" title="1">{
                if f == serverFeaturesV3 </span><span class="cov8" title="1">{
                        sc.TransportAPI = version.TransportV3
                }</span>
        }
        <span class="cov8" title="1">return nil</span>
}

// unmarshalJSONServerConfigSlice unmarshals JSON to a slice.
func unmarshalJSONServerConfigSlice(data []byte) ([]*ServerConfig, error) <span class="cov8" title="1">{
        var servers []*ServerConfig
        if err := json.Unmarshal(data, &amp;servers); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to unmarshal JSON to []*ServerConfig: %v", err)
        }</span>
        <span class="cov8" title="1">if len(servers) &lt; 1 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no management server found in JSON")
        }</span>
        <span class="cov8" title="1">return servers, nil</span>
}

// Authority contains configuration for an Authority for an xDS control plane
// server. See the Authorities field in the Config struct for how it's used.
type Authority struct {
        // ClientListenerResourceNameTemplate is template for the name of the
        // Listener resource to subscribe to for a gRPC client channel.  Used only
        // when the channel is created using an "xds:" URI with this authority name.
        //
        // The token "%s", if present in this string, will be replaced
        // with %-encoded service authority (i.e., the path part of the target
        // URI used to create the gRPC channel).
        //
        // Must start with "xdstp://&lt;authority_name&gt;/".  If it does not,
        // that is considered a bootstrap file parsing error.
        //
        // If not present in the bootstrap file, defaults to
        // "xdstp://&lt;authority_name&gt;/envoy.config.listener.v3.Listener/%s".
        ClientListenerResourceNameTemplate string
        // XDSServer contains the management server and config to connect to for
        // this authority.
        XDSServer *ServerConfig
}

// UnmarshalJSON implement json unmarshaller.
func (a *Authority) UnmarshalJSON(data []byte) error <span class="cov8" title="1">{
        var jsonData map[string]json.RawMessage
        if err := json.Unmarshal(data, &amp;jsonData); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("xds: failed to parse authority: %v", err)
        }</span>

        <span class="cov8" title="1">for k, v := range jsonData </span><span class="cov8" title="1">{
                switch k </span>{
                case "xds_servers":<span class="cov8" title="1">
                        servers, err := unmarshalJSONServerConfigSlice(v)
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("xds: json.Unmarshal(data) for field %q failed during bootstrap: %v", k, err)
                        }</span>
                        <span class="cov8" title="1">a.XDSServer = servers[0]</span>
                case "client_listener_resource_name_template":<span class="cov8" title="1">
                        if err := json.Unmarshal(v, &amp;a.ClientListenerResourceNameTemplate); err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("xds: json.Unmarshal(%v) for field %q failed during bootstrap: %v", string(v), k, err)
                        }</span>
                }
        }
        <span class="cov8" title="1">return nil</span>
}

// Config provides the xDS client with several key bits of information that it
// requires in its interaction with the management server. The Config is
// initialized from the bootstrap file.
type Config struct {
        // XDSServer is the management server to connect to.
        //
        // The bootstrap file contains a list of servers (with name+creds), but we
        // pick the first one.
        XDSServer *ServerConfig
        // CertProviderConfigs contains a mapping from certificate provider plugin
        // instance names to parsed buildable configs.
        CertProviderConfigs map[string]*certprovider.BuildableConfig
        // ServerListenerResourceNameTemplate is a template for the name of the
        // Listener resource to subscribe to for a gRPC server.
        //
        // If starts with "xdstp:", will be interpreted as a new-style name,
        // in which case the authority of the URI will be used to select the
        // relevant configuration in the "authorities" map.
        //
        // The token "%s", if present in this string, will be replaced with the IP
        // and port on which the server is listening.  (e.g., "0.0.0.0:8080",
        // "[::]:8080"). For example, a value of "example/resource/%s" could become
        // "example/resource/0.0.0.0:8080". If the template starts with "xdstp:",
        // the replaced string will be %-encoded.
        //
        // There is no default; if unset, xDS-based server creation fails.
        ServerListenerResourceNameTemplate string
        // A template for the name of the Listener resource to subscribe to
        // for a gRPC client channel.  Used only when the channel is created
        // with an "xds:" URI with no authority.
        //
        // If starts with "xdstp:", will be interpreted as a new-style name,
        // in which case the authority of the URI will be used to select the
        // relevant configuration in the "authorities" map.
        //
        // The token "%s", if present in this string, will be replaced with
        // the service authority (i.e., the path part of the target URI
        // used to create the gRPC channel).  If the template starts with
        // "xdstp:", the replaced string will be %-encoded.
        //
        // Defaults to "%s".
        ClientDefaultListenerResourceNameTemplate string

        // Authorities is a map of authority name to corresponding configuration.
        //
        // This is used in the following cases:
        // - A gRPC client channel is created using an "xds:" URI that includes
        //   an authority.
        // - A gRPC client channel is created using an "xds:" URI with no
        //   authority, but the "client_default_listener_resource_name_template"
        //   field above turns it into an "xdstp:" URI.
        // - A gRPC server is created and the
        //   "server_listener_resource_name_template" field is an "xdstp:" URI.
        //
        // In any of those cases, it is an error if the specified authority is
        // not present in this map.
        Authorities map[string]*Authority
}

type channelCreds struct {
        Type   string          `json:"type"`
        Config json.RawMessage `json:"config,omitempty"`
}

type xdsServer struct {
        ServerURI      string         `json:"server_uri"`
        ChannelCreds   []channelCreds `json:"channel_creds"`
        ServerFeatures []string       `json:"server_features"`
}

func bootstrapConfigFromEnvVariable() ([]byte, error) <span class="cov8" title="1">{
        fName := envconfig.XDSBootstrapFileName
        fContent := envconfig.XDSBootstrapFileContent

        // Bootstrap file name has higher priority than bootstrap content.
        if fName != "" </span><span class="cov8" title="1">{
                // If file name is set
                // - If file not found (or other errors), fail
                // - Otherwise, use the content.
                //
                // Note that even if the content is invalid, we don't failover to the
                // file content env variable.
                logger.Debugf("xds: using bootstrap file with name %q", fName)
                return bootstrapFileReadFunc(fName)
        }</span>

        <span class="cov8" title="1">if fContent != "" </span><span class="cov8" title="1">{
                return []byte(fContent), nil
        }</span>

        <span class="cov8" title="1">return nil, fmt.Errorf("none of the bootstrap environment variables (%q or %q) defined",
                envconfig.XDSBootstrapFileNameEnv, envconfig.XDSBootstrapFileContentEnv)</span>
}

// NewConfig returns a new instance of Config initialized by reading the
// bootstrap file found at ${GRPC_XDS_BOOTSTRAP} or bootstrap contents specified
// at ${GRPC_XDS_BOOTSTRAP_CONFIG}. If both env vars are set, the former is
// preferred.
//
// We support a credential registration mechanism and only credentials
// registered through that mechanism will be accepted here. See package
// `xds/bootstrap` for details.
//
// This function tries to process as much of the bootstrap file as possible (in
// the presence of the errors) and may return a Config object with certain
// fields left unspecified, in which case the caller should use some sane
// defaults.
func NewConfig() (*Config, error) <span class="cov8" title="1">{
        // Examples of the bootstrap json can be found in the generator tests
        // https://github.com/GoogleCloudPlatform/traffic-director-grpc-bootstrap/blob/master/main_test.go.
        data, err := bootstrapConfigFromEnvVariable()
        if err != nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("xds: Failed to read bootstrap config: %v", err)
        }</span>
        <span class="cov8" title="1">logger.Debugf("Bootstrap content: %s", data)
        return newConfigFromContents(data)</span>
}

// NewConfigFromContentsForTesting returns a new Config using the specified
// bootstrap file contents instead of reading the environment variable.
//
// This is only suitable for testing purposes.
func NewConfigFromContentsForTesting(data []byte) (*Config, error) <span class="cov0" title="0">{
        return newConfigFromContents(data)
}</span>

func newConfigFromContents(data []byte) (*Config, error) <span class="cov8" title="1">{
        config := &amp;Config{}

        var jsonData map[string]json.RawMessage
        if err := json.Unmarshal(data, &amp;jsonData); err != nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("xds: Failed to parse bootstrap config: %v", err)
        }</span>

        <span class="cov8" title="1">var node *v3corepb.Node
        m := jsonpb.Unmarshaler{AllowUnknownFields: true}
        for k, v := range jsonData </span><span class="cov8" title="1">{
                switch k </span>{
                case "node":<span class="cov8" title="1">
                        // We unconditionally convert the JSON into a v3.Node proto. The v3
                        // proto does not contain the deprecated field "build_version" from
                        // the v2 proto. We do not expect the bootstrap file to contain the
                        // "build_version" field. In any case, the unmarshal will succeed
                        // because we have set the `AllowUnknownFields` option on the
                        // unmarshaler.
                        node = &amp;v3corepb.Node{}
                        if err := m.Unmarshal(bytes.NewReader(v), node); err != nil </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("xds: jsonpb.Unmarshal(%v) for field %q failed during bootstrap: %v", string(v), k, err)
                        }</span>
                case "xds_servers":<span class="cov8" title="1">
                        servers, err := unmarshalJSONServerConfigSlice(v)
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("xds: json.Unmarshal(data) for field %q failed during bootstrap: %v", k, err)
                        }</span>
                        <span class="cov8" title="1">config.XDSServer = servers[0]</span>
                case "certificate_providers":<span class="cov8" title="1">
                        var providerInstances map[string]json.RawMessage
                        if err := json.Unmarshal(v, &amp;providerInstances); err != nil </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("xds: json.Unmarshal(%v) for field %q failed during bootstrap: %v", string(v), k, err)
                        }</span>
                        <span class="cov8" title="1">configs := make(map[string]*certprovider.BuildableConfig)
                        getBuilder := internal.GetCertificateProviderBuilder.(func(string) certprovider.Builder)
                        for instance, data := range providerInstances </span><span class="cov8" title="1">{
                                var nameAndConfig struct {
                                        PluginName string          `json:"plugin_name"`
                                        Config     json.RawMessage `json:"config"`
                                }
                                if err := json.Unmarshal(data, &amp;nameAndConfig); err != nil </span><span class="cov0" title="0">{
                                        return nil, fmt.Errorf("xds: json.Unmarshal(%v) for field %q failed during bootstrap: %v", string(v), instance, err)
                                }</span>

                                <span class="cov8" title="1">name := nameAndConfig.PluginName
                                parser := getBuilder(nameAndConfig.PluginName)
                                if parser == nil </span><span class="cov8" title="1">{
                                        // We ignore plugins that we do not know about.
                                        continue</span>
                                }
                                <span class="cov8" title="1">bc, err := parser.ParseConfig(nameAndConfig.Config)
                                if err != nil </span><span class="cov0" title="0">{
                                        return nil, fmt.Errorf("xds: Config parsing for plugin %q failed: %v", name, err)
                                }</span>
                                <span class="cov8" title="1">configs[instance] = bc</span>
                        }
                        <span class="cov8" title="1">config.CertProviderConfigs = configs</span>
                case "server_listener_resource_name_template":<span class="cov8" title="1">
                        if err := json.Unmarshal(v, &amp;config.ServerListenerResourceNameTemplate); err != nil </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("xds: json.Unmarshal(%v) for field %q failed during bootstrap: %v", string(v), k, err)
                        }</span>
                case "client_default_listener_resource_name_template":<span class="cov8" title="1">
                        if !envconfig.XDSFederation </span><span class="cov0" title="0">{
                                logger.Warningf("xds: bootstrap field %v is not support when Federation is disabled", k)
                                continue</span>
                        }
                        <span class="cov8" title="1">if err := json.Unmarshal(v, &amp;config.ClientDefaultListenerResourceNameTemplate); err != nil </span><span class="cov8" title="1">{
                                return nil, fmt.Errorf("xds: json.Unmarshal(%v) for field %q failed during bootstrap: %v", string(v), k, err)
                        }</span>
                case "authorities":<span class="cov8" title="1">
                        if !envconfig.XDSFederation </span><span class="cov0" title="0">{
                                logger.Warningf("xds: bootstrap field %v is not support when Federation is disabled", k)
                                continue</span>
                        }
                        <span class="cov8" title="1">if err := json.Unmarshal(v, &amp;config.Authorities); err != nil </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("xds: json.Unmarshal(%v) for field %q failed during bootstrap: %v", string(v), k, err)
                        }</span>
                default:<span class="cov8" title="1">
                        logger.Warningf("Bootstrap content has unknown field: %s", k)</span>
                }
                // Do not fail the xDS bootstrap when an unknown field is seen. This can
                // happen when an older version client reads a newer version bootstrap
                // file with new fields.
        }

        <span class="cov8" title="1">if config.ClientDefaultListenerResourceNameTemplate == "" </span><span class="cov8" title="1">{
                // Default value of the default client listener name template is "%s".
                config.ClientDefaultListenerResourceNameTemplate = "%s"
        }</span>
        <span class="cov8" title="1">if config.XDSServer == nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("xds: Required field %q not found in bootstrap %s", "xds_servers", jsonData["xds_servers"])
        }</span>
        <span class="cov8" title="1">if config.XDSServer.ServerURI == "" </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("xds: Required field %q not found in bootstrap %s", "xds_servers.server_uri", jsonData["xds_servers"])
        }</span>
        <span class="cov8" title="1">if config.XDSServer.Creds == nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("xds: Required field %q doesn't contain valid value in bootstrap %s", "xds_servers.channel_creds", jsonData["xds_servers"])
        }</span>
        // Post-process the authorities' client listener resource template field:
        // - if set, it must start with "xdstp://&lt;authority_name&gt;/"
        // - if not set, it defaults to "xdstp://&lt;authority_name&gt;/envoy.config.listener.v3.Listener/%s"
        <span class="cov8" title="1">for name, authority := range config.Authorities </span><span class="cov8" title="1">{
                prefix := fmt.Sprintf("xdstp://%s", url.PathEscape(name))
                if authority.ClientListenerResourceNameTemplate == "" </span><span class="cov8" title="1">{
                        authority.ClientListenerResourceNameTemplate = prefix + "/envoy.config.listener.v3.Listener/%s"
                        continue</span>
                }
                <span class="cov8" title="1">if !strings.HasPrefix(authority.ClientListenerResourceNameTemplate, prefix) </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("xds: field ClientListenerResourceNameTemplate %q of authority %q doesn't start with prefix %q", authority.ClientListenerResourceNameTemplate, name, prefix)
                }</span>
        }

        <span class="cov8" title="1">if err := config.updateNodeProto(node); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">logger.Infof("Bootstrap config for creating xds-client: %v", pretty.ToJSON(config))
        return config, nil</span>
}

// updateNodeProto updates the node proto read from the bootstrap file.
//
// The input node is a v3.Node protobuf message corresponding to the JSON
// contents found in the bootstrap file. This method performs some post
// processing on it:
// 1. If the node is nil, we create an empty one here. That way, callers of this
// function can always expect that the NodeProto field is non-nil.
// 2. Some additional fields which are not expected to be set in the bootstrap
// file are populated here.
// 3. For each server config (both top level and in each authority), we set its
// node field to the v3.Node, or a v2.Node with the same content, depending on
// the server's transport API version.
func (c *Config) updateNodeProto(node *v3corepb.Node) error <span class="cov8" title="1">{
        v3 := node
        if v3 == nil </span><span class="cov8" title="1">{
                v3 = &amp;v3corepb.Node{}
        }</span>
        <span class="cov8" title="1">v3.UserAgentName = gRPCUserAgentName
        v3.UserAgentVersionType = &amp;v3corepb.Node_UserAgentVersion{UserAgentVersion: grpc.Version}
        v3.ClientFeatures = append(v3.ClientFeatures, clientFeatureNoOverprovisioning, clientFeatureResourceWrapper)

        v3bytes, err := proto.Marshal(v3)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("xds: proto.Marshal(%v): %v", v3, err)
        }</span>
        <span class="cov8" title="1">v2 := &amp;v2corepb.Node{}
        if err := proto.Unmarshal(v3bytes, v2); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("xds: proto.Unmarshal(%v): %v", v3bytes, err)
        }</span>
        // BuildVersion is deprecated, and is replaced by user_agent_name and
        // user_agent_version. But the management servers are still using the old
        // field, so we will keep both set.
        <span class="cov8" title="1">v2.BuildVersion = gRPCVersion
        v2.UserAgentVersionType = &amp;v2corepb.Node_UserAgentVersion{UserAgentVersion: grpc.Version}

        switch c.XDSServer.TransportAPI </span>{
        case version.TransportV2:<span class="cov8" title="1">
                c.XDSServer.NodeProto = v2</span>
        case version.TransportV3:<span class="cov8" title="1">
                c.XDSServer.NodeProto = v3</span>
        }

        <span class="cov8" title="1">for _, a := range c.Authorities </span><span class="cov8" title="1">{
                if a.XDSServer == nil </span><span class="cov8" title="1">{
                        continue</span>
                }
                <span class="cov8" title="1">switch a.XDSServer.TransportAPI </span>{
                case version.TransportV2:<span class="cov0" title="0">
                        a.XDSServer.NodeProto = v2</span>
                case version.TransportV3:<span class="cov8" title="1">
                        a.XDSServer.NodeProto = v3</span>
                }
        }

        <span class="cov8" title="1">return nil</span>
}
</pre>
		
		<pre class="file" id="file199" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package bootstrap

import (
        "net/url"
        "strings"
)

// PopulateResourceTemplate populates the given template using the target
// string. "%s", if exists in the template, will be replaced with target.
//
// If the template starts with "xdstp:", the replaced string will be %-encoded.
// But note that "/" is not percent encoded.
func PopulateResourceTemplate(template, target string) string <span class="cov8" title="1">{
        if !strings.Contains(template, "%s") </span><span class="cov8" title="1">{
                return template
        }</span>
        <span class="cov8" title="1">if strings.HasPrefix(template, "xdstp:") </span><span class="cov8" title="1">{
                target = percentEncode(target)
        }</span>
        <span class="cov8" title="1">return strings.Replace(template, "%s", target, -1)</span>
}

// percentEncode percent encode t, except for "/". See the tests for examples.
func percentEncode(t string) string <span class="cov8" title="1">{
        segs := strings.Split(t, "/")
        for i := range segs </span><span class="cov8" title="1">{
                segs[i] = url.PathEscape(segs[i])
        }</span>
        <span class="cov8" title="1">return strings.Join(segs, "/")</span>
}
</pre>
		
		<pre class="file" id="file200" style="display: none">/*
 *
 * Copyright 2022 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package xdsclient

import (
        "bytes"
        "encoding/json"
        "fmt"
        "sync"
        "time"

        "google.golang.org/grpc/internal/cache"
        "google.golang.org/grpc/internal/grpcsync"
        "google.golang.org/grpc/xds/internal/xdsclient/bootstrap"
)

// New returns a new xDS client configured by the bootstrap file specified in env
// variable GRPC_XDS_BOOTSTRAP or GRPC_XDS_BOOTSTRAP_CONFIG.
//
// The returned client is a reference counted singleton instance. This function
// creates a new client only when one doesn't already exist.
//
// Note that the first invocation of New() or NewWithConfig() sets the client
// singleton. The following calls will return the singleton client without
// checking or using the config.
func New() (XDSClient, error) <span class="cov8" title="1">{
        return newRefCountedWithConfig(nil)
}</span>

// NewWithConfig returns a new xDS client configured by the given config.
//
// Internal/Testing Only
//
// This function should ONLY be used for internal (c2p resolver) and/or testing
// purposese. DO NOT use this elsewhere. Use New() instead.
func NewWithConfig(config *bootstrap.Config) (XDSClient, error) <span class="cov0" title="0">{
        return newRefCountedWithConfig(config)
}</span>

// newWithConfig returns a new xdsClient with the given config.
func newWithConfig(config *bootstrap.Config, watchExpiryTimeout time.Duration, idleAuthorityDeleteTimeout time.Duration) (*clientImpl, error) <span class="cov8" title="1">{
        c := &amp;clientImpl{
                done:               grpcsync.NewEvent(),
                config:             config,
                watchExpiryTimeout: watchExpiryTimeout,
                authorities:        make(map[string]*authority),
                idleAuthorities:    cache.NewTimeoutCache(idleAuthorityDeleteTimeout),
        }

        c.logger = prefixLogger(c)
        c.logger.Infof("Created ClientConn to xDS management server: %s", config.XDSServer)
        c.logger.Infof("Created")
        return c, nil
}</span>

// NewWithConfigForTesting returns an xDS client for the specified bootstrap
// config, separate from the global singleton.
//
// Testing Only
//
// This function should ONLY be used for testing purposes.
func NewWithConfigForTesting(config *bootstrap.Config, watchExpiryTimeout time.Duration) (XDSClient, error) <span class="cov8" title="1">{
        cl, err := newWithConfig(config, watchExpiryTimeout, defaultIdleAuthorityDeleteTimeout)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return &amp;clientRefCounted{clientImpl: cl, refCount: 1}, nil</span>
}

// NewWithBootstrapContentsForTesting returns an xDS client for this config,
// separate from the global singleton.
//
//
// Testing Only
//
// This function should ONLY be used for testing purposes.
func NewWithBootstrapContentsForTesting(contents []byte) (XDSClient, error) <span class="cov0" title="0">{
        // Normalize the contents
        buf := bytes.Buffer{}
        err := json.Indent(&amp;buf, contents, "", "")
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("xds: error normalizing JSON: %v", err)
        }</span>
        <span class="cov0" title="0">contents = bytes.TrimSpace(buf.Bytes())

        clientsMu.Lock()
        defer clientsMu.Unlock()
        if c := clients[string(contents)]; c != nil </span><span class="cov0" title="0">{
                c.mu.Lock()
                // Since we don't remove the *Client from the map when it is closed, we
                // need to recreate the impl if the ref count dropped to zero.
                if c.refCount &gt; 0 </span><span class="cov0" title="0">{
                        c.refCount++
                        c.mu.Unlock()
                        return c, nil
                }</span>
                <span class="cov0" title="0">c.mu.Unlock()</span>
        }

        <span class="cov0" title="0">bcfg, err := bootstrap.NewConfigFromContentsForTesting(contents)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("xds: error with bootstrap config: %v", err)
        }</span>

        <span class="cov0" title="0">cImpl, err := newWithConfig(bcfg, defaultWatchExpiryTimeout, defaultIdleAuthorityDeleteTimeout)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov0" title="0">c := &amp;clientRefCounted{clientImpl: cImpl, refCount: 1}
        clients[string(contents)] = c
        return c, nil</span>
}

var (
        clients   = map[string]*clientRefCounted{}
        clientsMu sync.Mutex
)
</pre>
		
		<pre class="file" id="file201" style="display: none">/*
 *
 * Copyright 2022 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package xdsclient

import (
        "sync"
        "time"

        "google.golang.org/grpc/internal/cache"
        "google.golang.org/grpc/internal/grpclog"
        "google.golang.org/grpc/internal/grpcsync"
        "google.golang.org/grpc/xds/internal/xdsclient/bootstrap"
)

var _ XDSClient = &amp;clientImpl{}

// clientImpl is the real implementation of the xds client. The exported Client
// is a wrapper of this struct with a ref count.
//
// Implements UpdateHandler interface.
// TODO(easwars): Make a wrapper struct which implements this interface in the
// style of ccBalancerWrapper so that the Client type does not implement these
// exported methods.
type clientImpl struct {
        done   *grpcsync.Event
        config *bootstrap.Config

        // authorityMu protects the authority fields. It's necessary because an
        // authority is created when it's used.
        authorityMu sync.Mutex
        // authorities is a map from ServerConfig to authority. So that
        // different authorities sharing the same ServerConfig can share the
        // authority.
        //
        // The key is **ServerConfig.String()**, not the authority name.
        //
        // An authority is either in authorities, or idleAuthorities,
        // never both.
        authorities map[string]*authority
        // idleAuthorities keeps the authorities that are not used (the last
        // watch on it was canceled). They are kept in the cache and will be deleted
        // after a timeout. The key is ServerConfig.String().
        //
        // An authority is either in authorities, or idleAuthorities,
        // never both.
        idleAuthorities *cache.TimeoutCache

        logger             *grpclog.PrefixLogger
        watchExpiryTimeout time.Duration
}

// BootstrapConfig returns the configuration read from the bootstrap file.
// Callers must treat the return value as read-only.
func (c *clientImpl) BootstrapConfig() *bootstrap.Config <span class="cov0" title="0">{
        return c.config
}</span>

// Close closes the gRPC connection to the management server.
func (c *clientImpl) Close() <span class="cov8" title="1">{
        if c.done.HasFired() </span><span class="cov8" title="1">{
                return
        }</span>
        <span class="cov8" title="1">c.done.Fire()
        // TODO: Should we invoke the registered callbacks here with an error that
        // the client is closed?

        // Note that Close needs to check for nils even if some of them are always
        // set in the constructor. This is because the constructor defers Close() in
        // error cases, and the fields might not be set when the error happens.

        c.authorityMu.Lock()
        for _, a := range c.authorities </span><span class="cov8" title="1">{
                a.close()
        }</span>
        <span class="cov8" title="1">c.idleAuthorities.Clear(true)
        c.authorityMu.Unlock()

        c.logger.Infof("Shutdown")</span>
}
</pre>
		
		<pre class="file" id="file202" style="display: none">/*
 *
 * Copyright 2022 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package xdsclient

import (
        "errors"
        "fmt"
        "time"

        "google.golang.org/grpc/internal/grpclog"
        "google.golang.org/grpc/xds/internal/xdsclient/bootstrap"
        "google.golang.org/grpc/xds/internal/xdsclient/controller"
        "google.golang.org/grpc/xds/internal/xdsclient/load"
        "google.golang.org/grpc/xds/internal/xdsclient/pubsub"
        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource"

        v2corepb "github.com/envoyproxy/go-control-plane/envoy/api/v2/core"
        v3corepb "github.com/envoyproxy/go-control-plane/envoy/config/core/v3"
)

type controllerInterface interface {
        AddWatch(resourceType xdsresource.ResourceType, resourceName string)
        RemoveWatch(resourceType xdsresource.ResourceType, resourceName string)
        ReportLoad(server string) (*load.Store, func())
        Close()
}

var newController = func(config *bootstrap.ServerConfig, pubsub *pubsub.Pubsub, validator xdsresource.UpdateValidatorFunc, logger *grpclog.PrefixLogger, boff func(int) time.Duration) (controllerInterface, error) <span class="cov8" title="1">{
        return controller.New(config, pubsub, validator, logger, boff)
}</span>

// findAuthority returns the authority for this name. If it doesn't already
// exist, one will be created.
//
// Note that this doesn't always create new authority. authorities with the same
// config but different names are shared.
//
// The returned unref function must be called when the caller is done using this
// authority, without holding c.authorityMu.
//
// Caller must not hold c.authorityMu.
func (c *clientImpl) findAuthority(n *xdsresource.Name) (_ *authority, unref func(), _ error) <span class="cov8" title="1">{
        scheme, authority := n.Scheme, n.Authority

        c.authorityMu.Lock()
        defer c.authorityMu.Unlock()
        if c.done.HasFired() </span><span class="cov0" title="0">{
                return nil, nil, errors.New("the xds-client is closed")
        }</span>

        <span class="cov8" title="1">config := c.config.XDSServer
        if scheme == xdsresource.FederationScheme </span><span class="cov8" title="1">{
                cfg, ok := c.config.Authorities[authority]
                if !ok </span><span class="cov0" title="0">{
                        return nil, nil, fmt.Errorf("xds: failed to find authority %q", authority)
                }</span>
                <span class="cov8" title="1">if cfg.XDSServer != nil </span><span class="cov8" title="1">{
                        config = cfg.XDSServer
                }</span>
        }

        <span class="cov8" title="1">a, err := c.newAuthorityLocked(config)
        if err != nil </span><span class="cov0" title="0">{
                return nil, nil, fmt.Errorf("xds: failed to connect to the control plane for authority %q: %v", authority, err)
        }</span>
        // All returned authority from this function will be used by a watch,
        // holding the ref here.
        //
        // Note that this must be done while c.authorityMu is held, to avoid the
        // race that an authority is returned, but before the watch starts, the
        // old last watch is canceled (in another goroutine), causing this
        // authority to be removed, and then a watch will start on a removed
        // authority.
        //
        // unref() will be done when the watch is canceled.
        <span class="cov8" title="1">a.ref()
        return a, func() </span><span class="cov8" title="1">{ c.unrefAuthority(a) }</span>, nil
}

// newAuthorityLocked creates a new authority for the config. But before that, it
// checks the cache to see if an authority for this config already exists.
//
// The caller must take a reference of the returned authority before using, and
// unref afterwards.
//
// caller must hold c.authorityMu
func (c *clientImpl) newAuthorityLocked(config *bootstrap.ServerConfig) (_ *authority, retErr error) <span class="cov8" title="1">{
        // First check if there's already an authority for this config. If found, it
        // means this authority is used by other watches (could be the same
        // authority name, or a different authority name but the same server
        // config). Return it.
        configStr := config.String()
        if a, ok := c.authorities[configStr]; ok </span><span class="cov8" title="1">{
                return a, nil
        }</span>
        // Second check if there's an authority in the idle cache. If found, it
        // means this authority was created, but moved to the idle cache because the
        // watch was canceled. Move it from idle cache to the authority cache, and
        // return.
        <span class="cov8" title="1">if old, ok := c.idleAuthorities.Remove(configStr); ok </span><span class="cov8" title="1">{
                oldA, _ := old.(*authority)
                if oldA != nil </span><span class="cov8" title="1">{
                        c.authorities[configStr] = oldA
                        return oldA, nil
                }</span>
        }

        // Make a new authority since there's no existing authority for this config.
        <span class="cov8" title="1">nodeID := ""
        if v3, ok := c.config.XDSServer.NodeProto.(*v3corepb.Node); ok </span><span class="cov0" title="0">{
                nodeID = v3.GetId()
        }</span> else<span class="cov8" title="1"> if v2, ok := c.config.XDSServer.NodeProto.(*v2corepb.Node); ok </span><span class="cov8" title="1">{
                nodeID = v2.GetId()
        }</span>
        <span class="cov8" title="1">ret := &amp;authority{config: config, pubsub: pubsub.New(c.watchExpiryTimeout, nodeID, c.logger)}
        defer func() </span><span class="cov8" title="1">{
                if retErr != nil </span><span class="cov0" title="0">{
                        ret.close()
                }</span>
        }()
        <span class="cov8" title="1">ctr, err := newController(config, ret.pubsub, c.updateValidator, c.logger, nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">ret.controller = ctr
        // Add it to the cache, so it will be reused.
        c.authorities[configStr] = ret
        return ret, nil</span>
}

// unrefAuthority unrefs the authority. It also moves the authority to idle
// cache if it's ref count is 0.
//
// This function doesn't need to called explicitly. It's called by the returned
// unref from findAuthority().
//
// Caller must not hold c.authorityMu.
func (c *clientImpl) unrefAuthority(a *authority) <span class="cov8" title="1">{
        c.authorityMu.Lock()
        defer c.authorityMu.Unlock()
        if a.unref() &gt; 0 </span><span class="cov8" title="1">{
                return
        }</span>
        <span class="cov8" title="1">configStr := a.config.String()
        delete(c.authorities, configStr)
        c.idleAuthorities.Add(configStr, a, func() </span><span class="cov8" title="1">{
                a.close()
        }</span>)
}
</pre>
		
		<pre class="file" id="file203" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package xdsclient

import (
        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource"
)

func mergeMaps(maps []map[string]xdsresource.UpdateWithMD) map[string]xdsresource.UpdateWithMD <span class="cov8" title="1">{
        ret := make(map[string]xdsresource.UpdateWithMD)
        for _, m := range maps </span><span class="cov8" title="1">{
                for k, v := range m </span><span class="cov8" title="1">{
                        ret[k] = v
                }</span>
        }
        <span class="cov8" title="1">return ret</span>
}

func (c *clientImpl) dump(t xdsresource.ResourceType) map[string]xdsresource.UpdateWithMD <span class="cov8" title="1">{
        c.authorityMu.Lock()
        defer c.authorityMu.Unlock()
        maps := make([]map[string]xdsresource.UpdateWithMD, 0, len(c.authorities))
        for _, a := range c.authorities </span><span class="cov8" title="1">{
                maps = append(maps, a.dump(t))
        }</span>
        <span class="cov8" title="1">return mergeMaps(maps)</span>
}

// DumpLDS returns the status and contents of LDS.
func (c *clientImpl) DumpLDS() map[string]xdsresource.UpdateWithMD <span class="cov8" title="1">{
        return c.dump(xdsresource.ListenerResource)
}</span>

// DumpRDS returns the status and contents of RDS.
func (c *clientImpl) DumpRDS() map[string]xdsresource.UpdateWithMD <span class="cov8" title="1">{
        return c.dump(xdsresource.RouteConfigResource)
}</span>

// DumpCDS returns the status and contents of CDS.
func (c *clientImpl) DumpCDS() map[string]xdsresource.UpdateWithMD <span class="cov8" title="1">{
        return c.dump(xdsresource.ClusterResource)
}</span>

// DumpEDS returns the status and contents of EDS.
func (c *clientImpl) DumpEDS() map[string]xdsresource.UpdateWithMD <span class="cov8" title="1">{
        return c.dump(xdsresource.EndpointsResource)
}</span>
</pre>
		
		<pre class="file" id="file204" style="display: none">/*
 *
 * Copyright 2019 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package xdsclient

import (
        "google.golang.org/grpc/xds/internal/xdsclient/bootstrap"
        "google.golang.org/grpc/xds/internal/xdsclient/load"
)

// ReportLoad starts a load reporting stream to the given server. All load
// reports to the same server share the LRS stream.
//
// It returns a Store for the user to report loads, a function to cancel the
// load reporting stream.
func (c *clientImpl) ReportLoad(server *bootstrap.ServerConfig) (*load.Store, func()) <span class="cov8" title="1">{
        c.authorityMu.Lock()
        a, err := c.newAuthorityLocked(server)
        c.authorityMu.Unlock()
        if err != nil </span><span class="cov0" title="0">{
                c.logger.Infof("xds: failed to connect to the control plane to do load reporting for authority %q: %v", server, err)
                return nil, func() </span>{<span class="cov0" title="0">}</span>
        }
        // Hold the ref before starting load reporting.
        <span class="cov8" title="1">a.ref()
        store, cancelF := a.reportLoad()
        return store, func() </span><span class="cov8" title="1">{
                cancelF()
                c.unrefAuthority(a)
        }</span>
}
</pre>
		
		<pre class="file" id="file205" style="display: none">/*
 *
 * Copyright 2022 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package xdsclient

import (
        "fmt"

        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource"
)

func (c *clientImpl) filterChainUpdateValidator(fc *xdsresource.FilterChain) error <span class="cov0" title="0">{
        if fc == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">return c.securityConfigUpdateValidator(fc.SecurityCfg)</span>
}

func (c *clientImpl) securityConfigUpdateValidator(sc *xdsresource.SecurityConfig) error <span class="cov0" title="0">{
        if sc == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">if sc.IdentityInstanceName != "" </span><span class="cov0" title="0">{
                if _, ok := c.config.CertProviderConfigs[sc.IdentityInstanceName]; !ok </span><span class="cov0" title="0">{
                        return fmt.Errorf("identitiy certificate provider instance name %q missing in bootstrap configuration", sc.IdentityInstanceName)
                }</span>
        }
        <span class="cov0" title="0">if sc.RootInstanceName != "" </span><span class="cov0" title="0">{
                if _, ok := c.config.CertProviderConfigs[sc.RootInstanceName]; !ok </span><span class="cov0" title="0">{
                        return fmt.Errorf("root certificate provider instance name %q missing in bootstrap configuration", sc.RootInstanceName)
                }</span>
        }
        <span class="cov0" title="0">return nil</span>
}

func (c *clientImpl) updateValidator(u interface{}) error <span class="cov0" title="0">{
        switch update := u.(type) </span>{
        case xdsresource.ListenerUpdate:<span class="cov0" title="0">
                if update.InboundListenerCfg == nil || update.InboundListenerCfg.FilterChains == nil </span><span class="cov0" title="0">{
                        return nil
                }</span>
                <span class="cov0" title="0">return update.InboundListenerCfg.FilterChains.Validate(c.filterChainUpdateValidator)</span>
        case xdsresource.ClusterUpdate:<span class="cov0" title="0">
                return c.securityConfigUpdateValidator(update.SecurityCfg)</span>
        default:<span class="cov0" title="0"></span>
                // We currently invoke this update validation function only for LDS and
                // CDS updates. In the future, if we wish to invoke it for other xDS
                // updates, corresponding plumbing needs to be added to those unmarshal
                // functions.
        }
        <span class="cov0" title="0">return nil</span>
}
</pre>
		
		<pre class="file" id="file206" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package xdsclient

import (
        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource"
)

// WatchListener uses LDS to discover information about the provided listener.
//
// Note that during race (e.g. an xDS response is received while the user is
// calling cancel()), there's a small window where the callback can be called
// after the watcher is canceled. The caller needs to handle this case.
func (c *clientImpl) WatchListener(serviceName string, cb func(xdsresource.ListenerUpdate, error)) (cancel func()) <span class="cov8" title="1">{
        n := xdsresource.ParseName(serviceName)
        a, unref, err := c.findAuthority(n)
        if err != nil </span><span class="cov0" title="0">{
                cb(xdsresource.ListenerUpdate{}, err)
                return func() </span>{<span class="cov0" title="0">}</span>
        }
        <span class="cov8" title="1">cancelF := a.watchListener(n.String(), cb)
        return func() </span><span class="cov8" title="1">{
                cancelF()
                unref()
        }</span>
}

// WatchRouteConfig starts a listener watcher for the service.
//
// Note that during race (e.g. an xDS response is received while the user is
// calling cancel()), there's a small window where the callback can be called
// after the watcher is canceled. The caller needs to handle this case.
func (c *clientImpl) WatchRouteConfig(routeName string, cb func(xdsresource.RouteConfigUpdate, error)) (cancel func()) <span class="cov8" title="1">{
        n := xdsresource.ParseName(routeName)
        a, unref, err := c.findAuthority(n)
        if err != nil </span><span class="cov0" title="0">{
                cb(xdsresource.RouteConfigUpdate{}, err)
                return func() </span>{<span class="cov0" title="0">}</span>
        }
        <span class="cov8" title="1">cancelF := a.watchRouteConfig(n.String(), cb)
        return func() </span><span class="cov8" title="1">{
                cancelF()
                unref()
        }</span>
}

// WatchCluster uses CDS to discover information about the provided
// clusterName.
//
// WatchCluster can be called multiple times, with same or different
// clusterNames. Each call will start an independent watcher for the resource.
//
// Note that during race (e.g. an xDS response is received while the user is
// calling cancel()), there's a small window where the callback can be called
// after the watcher is canceled. The caller needs to handle this case.
func (c *clientImpl) WatchCluster(clusterName string, cb func(xdsresource.ClusterUpdate, error)) (cancel func()) <span class="cov8" title="1">{
        n := xdsresource.ParseName(clusterName)
        a, unref, err := c.findAuthority(n)
        if err != nil </span><span class="cov0" title="0">{
                cb(xdsresource.ClusterUpdate{}, err)
                return func() </span>{<span class="cov0" title="0">}</span>
        }
        <span class="cov8" title="1">cancelF := a.watchCluster(n.String(), cb)
        return func() </span><span class="cov8" title="1">{
                cancelF()
                unref()
        }</span>
}

// WatchEndpoints uses EDS to discover endpoints in the provided clusterName.
//
// WatchEndpoints can be called multiple times, with same or different
// clusterNames. Each call will start an independent watcher for the resource.
//
// Note that during race (e.g. an xDS response is received while the user is
// calling cancel()), there's a small window where the callback can be called
// after the watcher is canceled. The caller needs to handle this case.
func (c *clientImpl) WatchEndpoints(clusterName string, cb func(xdsresource.EndpointsUpdate, error)) (cancel func()) <span class="cov8" title="1">{
        n := xdsresource.ParseName(clusterName)
        a, unref, err := c.findAuthority(n)
        if err != nil </span><span class="cov0" title="0">{
                cb(xdsresource.EndpointsUpdate{}, err)
                return func() </span>{<span class="cov0" title="0">}</span>
        }
        <span class="cov8" title="1">cancelF := a.watchEndpoints(n.String(), cb)
        return func() </span><span class="cov8" title="1">{
                cancelF()
                unref()
        }</span>
}
</pre>
		
		<pre class="file" id="file207" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// Package controller contains implementation to connect to the control plane.
// Including starting the ClientConn, starting the xDS stream, and
// sending/receiving messages.
//
// All the messages are parsed by the resource package (e.g.
// UnmarshalListener()) and sent to the Pubsub watchers.
package controller

import (
        "context"
        "errors"
        "fmt"
        "sync"
        "time"

        "google.golang.org/grpc"
        "google.golang.org/grpc/internal/backoff"
        "google.golang.org/grpc/internal/buffer"
        "google.golang.org/grpc/internal/grpclog"
        "google.golang.org/grpc/keepalive"
        "google.golang.org/grpc/xds/internal/xdsclient/bootstrap"
        "google.golang.org/grpc/xds/internal/xdsclient/controller/version"
        "google.golang.org/grpc/xds/internal/xdsclient/pubsub"
        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource"
)

// Controller manages the connection and stream to the control plane.
//
// It keeps track of what resources are being watched, and send new requests
// when new watches are added.
//
// It takes a pubsub (as an interface) as input. When a response is received,
// it's parsed, and the updates are sent to the pubsub.
type Controller struct {
        config          *bootstrap.ServerConfig
        updateHandler   pubsub.UpdateHandler
        updateValidator xdsresource.UpdateValidatorFunc
        logger          *grpclog.PrefixLogger

        cc               *grpc.ClientConn // Connection to the management server.
        vClient          version.VersionedClient
        stopRunGoroutine context.CancelFunc

        backoff  func(int) time.Duration
        streamCh chan grpc.ClientStream
        sendCh   *buffer.Unbounded

        mu sync.Mutex
        // Message specific watch infos, protected by the above mutex. These are
        // written to, after successfully reading from the update channel, and are
        // read from when recovering from a broken stream to resend the xDS
        // messages. When the user of this client object cancels a watch call,
        // these are set to nil. All accesses to the map protected and any value
        // inside the map should be protected with the above mutex.
        watchMap map[xdsresource.ResourceType]map[string]bool
        // versionMap contains the version that was acked (the version in the ack
        // request that was sent on wire). The key is rType, the value is the
        // version string, because the versions for different resource types should
        // be independent.
        versionMap map[xdsresource.ResourceType]string
        // nonceMap contains the nonce from the most recent received response.
        nonceMap map[xdsresource.ResourceType]string

        // Changes to map lrsClients and the lrsClient inside the map need to be
        // protected by lrsMu.
        //
        // TODO: after LRS refactoring, each controller should only manage the LRS
        // stream to its server. LRS streams to other servers should be managed by
        // other controllers.
        lrsMu      sync.Mutex
        lrsClients map[string]*lrsClient
}

var grpcDial = grpc.Dial

// SetGRPCDial sets the dialer for the controller. The dial can be used to
// manipulate the dial options or change the target if needed.
// The SetGRPCDial must be called before gRPC initialization to make sure it
// affects all the controllers created.
// To reset any dialer set, pass in grpc.Dial as the parameter.
func SetGRPCDial(dialer func(target string, opts ...grpc.DialOption) (*grpc.ClientConn, error)) <span class="cov8" title="1">{
        grpcDial = dialer
}</span>

// New creates a new controller.
func New(config *bootstrap.ServerConfig, updateHandler pubsub.UpdateHandler, validator xdsresource.UpdateValidatorFunc, logger *grpclog.PrefixLogger, boff func(int) time.Duration) (_ *Controller, retErr error) <span class="cov8" title="1">{
        switch </span>{
        case config == nil:<span class="cov0" title="0">
                return nil, errors.New("xds: no xds_server provided")</span>
        case config.ServerURI == "":<span class="cov8" title="1">
                return nil, errors.New("xds: no xds_server name provided in options")</span>
        case config.Creds == nil:<span class="cov8" title="1">
                return nil, errors.New("xds: no credentials provided in options")</span>
        case config.NodeProto == nil:<span class="cov8" title="1">
                return nil, errors.New("xds: no node_proto provided in options")</span>
        }

        <span class="cov8" title="1">dopts := []grpc.DialOption{
                config.Creds,
                grpc.WithKeepaliveParams(keepalive.ClientParameters{
                        Time:    5 * time.Minute,
                        Timeout: 20 * time.Second,
                }),
        }

        if boff == nil </span><span class="cov8" title="1">{
                boff = backoff.DefaultExponential.Backoff
        }</span>
        <span class="cov8" title="1">ret := &amp;Controller{
                config:          config,
                updateValidator: validator,
                updateHandler:   updateHandler,

                backoff:    boff,
                streamCh:   make(chan grpc.ClientStream, 1),
                sendCh:     buffer.NewUnbounded(),
                watchMap:   make(map[xdsresource.ResourceType]map[string]bool),
                versionMap: make(map[xdsresource.ResourceType]string),
                nonceMap:   make(map[xdsresource.ResourceType]string),

                lrsClients: make(map[string]*lrsClient),
        }

        defer func() </span><span class="cov8" title="1">{
                if retErr != nil </span><span class="cov8" title="1">{
                        ret.Close()
                }</span>
        }()

        <span class="cov8" title="1">cc, err := grpcDial(config.ServerURI, dopts...)
        if err != nil </span><span class="cov0" title="0">{
                // An error from a non-blocking dial indicates something serious.
                return nil, fmt.Errorf("xds: failed to dial control plane {%s}: %v", config.ServerURI, err)
        }</span>
        <span class="cov8" title="1">ret.cc = cc

        builder := version.GetAPIClientBuilder(config.TransportAPI)
        if builder == nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no client builder for xDS API version: %v", config.TransportAPI)
        }</span>
        <span class="cov8" title="1">apiClient, err := builder(version.BuildOptions{NodeProto: config.NodeProto, Logger: logger})
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">ret.vClient = apiClient

        ctx, cancel := context.WithCancel(context.Background())
        ret.stopRunGoroutine = cancel
        go ret.run(ctx)

        return ret, nil</span>
}

// Close closes the controller.
func (t *Controller) Close() <span class="cov8" title="1">{
        // Note that Close needs to check for nils even if some of them are always
        // set in the constructor. This is because the constructor defers Close() in
        // error cases, and the fields might not be set when the error happens.
        if t.stopRunGoroutine != nil </span><span class="cov8" title="1">{
                t.stopRunGoroutine()
        }</span>
        <span class="cov8" title="1">if t.cc != nil </span><span class="cov8" title="1">{
                t.cc.Close()
        }</span>
}
</pre>
		
		<pre class="file" id="file208" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package controller

import (
        "context"

        "google.golang.org/grpc"
        "google.golang.org/grpc/xds/internal/xdsclient/controller/version"
        "google.golang.org/grpc/xds/internal/xdsclient/load"
)

// ReportLoad starts an load reporting stream to the given server. If the server
// is not an empty string, and is different from the management server, a new
// ClientConn will be created.
//
// The same options used for creating the Client will be used (including
// NodeProto, and dial options if necessary).
//
// It returns a Store for the user to report loads, a function to cancel the
// load reporting stream.
//
// TODO(xdsfed): LRS refactor, delete the parameter of this function, and
// cleanup the multiple LRS ClientConn code. Each controller should have one
// ClientConn to the authority it's created for, all LRS streams (and ADS
// streams) in this controller should all share that ClientConn.
func (c *Controller) ReportLoad(server string) (*load.Store, func()) <span class="cov0" title="0">{
        c.lrsMu.Lock()
        defer c.lrsMu.Unlock()

        // If there's already a client to this server, use it. Otherwise, create
        // one.
        lrsC, ok := c.lrsClients[server]
        if !ok </span><span class="cov0" title="0">{
                lrsC = newLRSClient(c, server)
                c.lrsClients[server] = lrsC
        }</span>

        <span class="cov0" title="0">store := lrsC.ref()
        return store, func() </span><span class="cov0" title="0">{
                // This is a callback, need to hold lrsMu.
                c.lrsMu.Lock()
                defer c.lrsMu.Unlock()
                if lrsC.unRef() </span><span class="cov0" title="0">{
                        // Delete the lrsClient from map if this is the last reference.
                        delete(c.lrsClients, server)
                }</span>
        }
}

// lrsClient maps to one lrsServer. It contains:
// - a ClientConn to this server (only if it's different from the management
// server)
// - a load.Store that contains loads only for this server
type lrsClient struct {
        parent *Controller
        server string

        cc           *grpc.ClientConn // nil if the server is same as the management server
        refCount     int
        cancelStream func()
        loadStore    *load.Store
}

// newLRSClient creates a new LRS stream to the server.
func newLRSClient(parent *Controller, server string) *lrsClient <span class="cov0" title="0">{
        return &amp;lrsClient{
                parent:   parent,
                server:   server,
                refCount: 0,
        }
}</span>

// ref increments the refCount. If this is the first ref, it starts the LRS stream.
//
// Not thread-safe, caller needs to synchronize.
func (lrsC *lrsClient) ref() *load.Store <span class="cov0" title="0">{
        lrsC.refCount++
        if lrsC.refCount == 1 </span><span class="cov0" title="0">{
                lrsC.startStream()
        }</span>
        <span class="cov0" title="0">return lrsC.loadStore</span>
}

// unRef decrements the refCount, and closes the stream if refCount reaches 0
// (and close the cc if cc is not xDS cc). It returns whether refCount reached 0
// after this call.
//
// Not thread-safe, caller needs to synchronize.
func (lrsC *lrsClient) unRef() (closed bool) <span class="cov0" title="0">{
        lrsC.refCount--
        if lrsC.refCount != 0 </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov0" title="0">lrsC.parent.logger.Infof("Stopping load report to server: %s", lrsC.server)
        lrsC.cancelStream()
        if lrsC.cc != nil </span><span class="cov0" title="0">{
                lrsC.cc.Close()
        }</span>
        <span class="cov0" title="0">return true</span>
}

// startStream starts the LRS stream to the server. If server is not the same
// management server from the parent, it also creates a ClientConn.
func (lrsC *lrsClient) startStream() <span class="cov0" title="0">{
        var cc *grpc.ClientConn

        lrsC.parent.logger.Infof("Starting load report to server: %s", lrsC.server)
        if lrsC.server == "" || lrsC.server == lrsC.parent.config.ServerURI </span><span class="cov0" title="0">{
                // Reuse the xDS client if server is the same.
                cc = lrsC.parent.cc
        }</span> else<span class="cov0" title="0"> {
                lrsC.parent.logger.Infof("LRS server is different from management server, starting a new ClientConn")
                ccNew, err := grpc.Dial(lrsC.server, lrsC.parent.config.Creds)
                if err != nil </span><span class="cov0" title="0">{
                        // An error from a non-blocking dial indicates something serious.
                        lrsC.parent.logger.Infof("xds: failed to dial load report server {%s}: %v", lrsC.server, err)
                        return
                }</span>
                <span class="cov0" title="0">cc = ccNew
                lrsC.cc = ccNew</span>
        }

        <span class="cov0" title="0">var ctx context.Context
        ctx, lrsC.cancelStream = context.WithCancel(context.Background())

        // Create the store and stream.
        lrsC.loadStore = load.NewStore()
        go lrsC.parent.reportLoad(ctx, cc, version.LoadReportingOptions{LoadStore: lrsC.loadStore})</span>
}
</pre>
		
		<pre class="file" id="file209" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package controller

import (
        "context"
        "fmt"
        "time"

        "github.com/golang/protobuf/proto"
        "google.golang.org/grpc"
        controllerversion "google.golang.org/grpc/xds/internal/xdsclient/controller/version"
        xdsresourceversion "google.golang.org/grpc/xds/internal/xdsclient/controller/version"
        "google.golang.org/grpc/xds/internal/xdsclient/load"
        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource"
)

// AddWatch adds a watch for an xDS resource given its type and name.
func (t *Controller) AddWatch(rType xdsresource.ResourceType, resourceName string) <span class="cov8" title="1">{
        t.sendCh.Put(&amp;watchAction{
                rType:    rType,
                remove:   false,
                resource: resourceName,
        })
}</span>

// RemoveWatch cancels an already registered watch for an xDS resource
// given its type and name.
func (t *Controller) RemoveWatch(rType xdsresource.ResourceType, resourceName string) <span class="cov8" title="1">{
        t.sendCh.Put(&amp;watchAction{
                rType:    rType,
                remove:   true,
                resource: resourceName,
        })
}</span>

// run starts an ADS stream (and backs off exponentially, if the previous
// stream failed without receiving a single reply) and runs the sender and
// receiver routines to send and receive data from the stream respectively.
func (t *Controller) run(ctx context.Context) <span class="cov8" title="1">{
        go t.send(ctx)
        // TODO: start a goroutine monitoring ClientConn's connectivity state, and
        // report error (and log) when stats is transient failure.

        retries := 0
        lastStreamStartTime := time.Time{}
        for ctx.Err() == nil </span><span class="cov8" title="1">{
                dur := time.Until(lastStreamStartTime.Add(t.backoff(retries)))
                if dur &gt; 0 </span><span class="cov0" title="0">{
                        timer := time.NewTimer(dur)
                        select </span>{
                        case &lt;-timer.C:<span class="cov0" title="0"></span>
                        case &lt;-ctx.Done():<span class="cov0" title="0">
                                timer.Stop()
                                return</span>
                        }
                }

                <span class="cov8" title="1">retries++
                lastStreamStartTime = time.Now()
                stream, err := t.vClient.NewStream(ctx, t.cc)
                if err != nil </span><span class="cov8" title="1">{
                        t.updateHandler.NewConnectionError(err)
                        t.logger.Warningf("xds: ADS stream creation failed: %v", err)
                        continue</span>
                }
                <span class="cov8" title="1">t.logger.Infof("ADS stream created")

                select </span>{
                case &lt;-t.streamCh:<span class="cov0" title="0"></span>
                default:<span class="cov8" title="1"></span>
                }
                <span class="cov8" title="1">t.streamCh &lt;- stream
                if t.recv(stream) </span><span class="cov8" title="1">{
                        retries = 0
                }</span>
        }
}

// send is a separate goroutine for sending watch requests on the xds stream.
//
// It watches the stream channel for new streams, and the request channel for
// new requests to send on the stream.
//
// For each new request (watchAction), it's
//   - processed and added to the watch map
//     so, resend will pick them up when there are new streams
//   - sent on the current stream if there's one
//     the current stream is cleared when any send on it fails
//
// For each new stream, all the existing requests will be resent.
//
// Note that this goroutine doesn't do anything to the old stream when there's a
// new one. In fact, there should be only one stream in progress, and new one
// should only be created when the old one fails (recv returns an error).
func (t *Controller) send(ctx context.Context) <span class="cov8" title="1">{
        var stream grpc.ClientStream
        for </span><span class="cov8" title="1">{
                select </span>{
                case &lt;-ctx.Done():<span class="cov8" title="1">
                        return</span>
                case stream = &lt;-t.streamCh:<span class="cov8" title="1">
                        if !t.sendExisting(stream) </span><span class="cov0" title="0">{
                                // send failed, clear the current stream.
                                stream = nil
                        }</span>
                case u := &lt;-t.sendCh.Get():<span class="cov8" title="1">
                        t.sendCh.Load()

                        var (
                                target                 []string
                                rType                  xdsresource.ResourceType
                                version, nonce, errMsg string
                                send                   bool
                        )
                        switch update := u.(type) </span>{
                        case *watchAction:<span class="cov8" title="1">
                                target, rType, version, nonce = t.processWatchInfo(update)</span>
                        case *ackAction:<span class="cov8" title="1">
                                target, rType, version, nonce, send = t.processAckInfo(update, stream)
                                if !send </span><span class="cov8" title="1">{
                                        continue</span>
                                }
                                <span class="cov8" title="1">errMsg = update.errMsg</span>
                        }
                        <span class="cov8" title="1">if stream == nil </span><span class="cov8" title="1">{
                                // There's no stream yet. Skip the request. This request
                                // will be resent to the new streams. If no stream is
                                // created, the watcher will timeout (same as server not
                                // sending response back).
                                continue</span>
                        }
                        <span class="cov8" title="1">if err := t.vClient.SendRequest(stream, target, rType, version, nonce, errMsg); err != nil </span><span class="cov0" title="0">{
                                t.logger.Warningf("ADS request for {target: %q, type: %v, version: %q, nonce: %q} failed: %v", target, rType, version, nonce, err)
                                // send failed, clear the current stream.
                                stream = nil
                        }</span>
                }
        }
}

// sendExisting sends out xDS requests for registered watchers when recovering
// from a broken stream.
//
// We call stream.Send() here with the lock being held. It should be OK to do
// that here because the stream has just started and Send() usually returns
// quickly (once it pushes the message onto the transport layer) and is only
// ever blocked if we don't have enough flow control quota.
func (t *Controller) sendExisting(stream grpc.ClientStream) bool <span class="cov8" title="1">{
        t.mu.Lock()
        defer t.mu.Unlock()

        // Reset only the nonce when the stream restarts.
        //
        // xDS spec says the following. See section:
        // https://www.envoyproxy.io/docs/envoy/latest/api-docs/xds_protocol#ack-nack-and-resource-type-instance-version
        //
        // Note that the version for a resource type is not a property of an
        // individual xDS stream but rather a property of the resources themselves. If
        // the stream becomes broken and the client creates a new stream, the client’s
        // initial request on the new stream should indicate the most recent version
        // seen by the client on the previous stream
        t.nonceMap = make(map[xdsresource.ResourceType]string)

        for rType, s := range t.watchMap </span><span class="cov8" title="1">{
                if err := t.vClient.SendRequest(stream, mapToSlice(s), rType, t.versionMap[rType], "", ""); err != nil </span><span class="cov0" title="0">{
                        t.logger.Warningf("ADS request failed: %v", err)
                        return false
                }</span>
        }

        <span class="cov8" title="1">return true</span>
}

// recv receives xDS responses on the provided ADS stream and branches out to
// message specific handlers.
func (t *Controller) recv(stream grpc.ClientStream) bool <span class="cov8" title="1">{
        msgReceived := false
        for </span><span class="cov8" title="1">{
                resp, err := t.vClient.RecvResponse(stream)
                if err != nil </span><span class="cov8" title="1">{
                        t.updateHandler.NewConnectionError(err)
                        t.logger.Warningf("ADS stream is closed with error: %v", err)
                        return msgReceived
                }</span>
                <span class="cov8" title="1">msgReceived = true

                rType, version, nonce, err := t.handleResponse(resp)
                if e, ok := err.(xdsresourceversion.ErrResourceTypeUnsupported); ok </span><span class="cov0" title="0">{
                        t.logger.Warningf("%s", e.ErrStr)
                        continue</span>
                }
                <span class="cov8" title="1">if err != nil </span><span class="cov8" title="1">{
                        t.sendCh.Put(&amp;ackAction{
                                rType:   rType,
                                version: "",
                                nonce:   nonce,
                                errMsg:  err.Error(),
                                stream:  stream,
                        })
                        t.logger.Warningf("Sending NACK for response type: %v, version: %v, nonce: %v, reason: %v", rType, version, nonce, err)
                        continue</span>
                }
                <span class="cov8" title="1">t.sendCh.Put(&amp;ackAction{
                        rType:   rType,
                        version: version,
                        nonce:   nonce,
                        stream:  stream,
                })
                t.logger.Infof("Sending ACK for response type: %v, version: %v, nonce: %v", rType, version, nonce)</span>
        }
}

func (t *Controller) handleResponse(resp proto.Message) (xdsresource.ResourceType, string, string, error) <span class="cov8" title="1">{
        rType, resource, version, nonce, err := t.vClient.ParseResponse(resp)
        if err != nil </span><span class="cov0" title="0">{
                return rType, version, nonce, err
        }</span>
        <span class="cov8" title="1">opts := &amp;xdsresource.UnmarshalOptions{
                Version:         version,
                Resources:       resource,
                Logger:          t.logger,
                UpdateValidator: t.updateValidator,
        }
        var md xdsresource.UpdateMetadata
        switch rType </span>{
        case xdsresource.ListenerResource:<span class="cov8" title="1">
                var update map[string]xdsresource.ListenerUpdateErrTuple
                update, md, err = xdsresource.UnmarshalListener(opts)
                t.updateHandler.NewListeners(update, md)</span>
        case xdsresource.RouteConfigResource:<span class="cov8" title="1">
                var update map[string]xdsresource.RouteConfigUpdateErrTuple
                update, md, err = xdsresource.UnmarshalRouteConfig(opts)
                t.updateHandler.NewRouteConfigs(update, md)</span>
        case xdsresource.ClusterResource:<span class="cov8" title="1">
                var update map[string]xdsresource.ClusterUpdateErrTuple
                update, md, err = xdsresource.UnmarshalCluster(opts)
                t.updateHandler.NewClusters(update, md)</span>
        case xdsresource.EndpointsResource:<span class="cov8" title="1">
                var update map[string]xdsresource.EndpointsUpdateErrTuple
                update, md, err = xdsresource.UnmarshalEndpoints(opts)
                t.updateHandler.NewEndpoints(update, md)</span>
        default:<span class="cov0" title="0">
                return rType, "", "", xdsresourceversion.ErrResourceTypeUnsupported{
                        ErrStr: fmt.Sprintf("Resource type %v unknown in response from server", rType),
                }</span>
        }
        <span class="cov8" title="1">return rType, version, nonce, err</span>
}

func mapToSlice(m map[string]bool) []string <span class="cov8" title="1">{
        ret := make([]string, 0, len(m))
        for i := range m </span><span class="cov8" title="1">{
                ret = append(ret, i)
        }</span>
        <span class="cov8" title="1">return ret</span>
}

type watchAction struct {
        rType    xdsresource.ResourceType
        remove   bool // Whether this is to remove watch for the resource.
        resource string
}

// processWatchInfo pulls the fields needed by the request from a watchAction.
//
// It also updates the watch map.
func (t *Controller) processWatchInfo(w *watchAction) (target []string, rType xdsresource.ResourceType, ver, nonce string) <span class="cov8" title="1">{
        t.mu.Lock()
        defer t.mu.Unlock()

        var current map[string]bool
        current, ok := t.watchMap[w.rType]
        if !ok </span><span class="cov8" title="1">{
                current = make(map[string]bool)
                t.watchMap[w.rType] = current
        }</span>

        <span class="cov8" title="1">if w.remove </span><span class="cov8" title="1">{
                delete(current, w.resource)
                if len(current) == 0 </span><span class="cov8" title="1">{
                        delete(t.watchMap, w.rType)
                }</span>
        } else<span class="cov8" title="1"> {
                current[w.resource] = true
        }</span>

        <span class="cov8" title="1">rType = w.rType
        target = mapToSlice(current)
        // We don't reset version or nonce when a new watch is started. The version
        // and nonce from previous response are carried by the request. Only the nonce
        // is reset when the stream is recreated.
        ver = t.versionMap[rType]
        nonce = t.nonceMap[rType]
        return target, rType, ver, nonce</span>
}

type ackAction struct {
        rType   xdsresource.ResourceType
        version string // NACK if version is an empty string.
        nonce   string
        errMsg  string // Empty unless it's a NACK.
        // ACK/NACK are tagged with the stream it's for. When the stream is down,
        // all the ACK/NACK for this stream will be dropped, and the version/nonce
        // won't be updated.
        stream grpc.ClientStream
}

// processAckInfo pulls the fields needed by the ack request from a ackAction.
//
// If no active watch is found for this ack, it returns false for send.
func (t *Controller) processAckInfo(ack *ackAction, stream grpc.ClientStream) (target []string, rType xdsresource.ResourceType, version, nonce string, send bool) <span class="cov8" title="1">{
        if ack.stream != stream </span><span class="cov0" title="0">{
                // If ACK's stream isn't the current sending stream, this means the ACK
                // was pushed to queue before the old stream broke, and a new stream has
                // been started since. Return immediately here so we don't update the
                // nonce for the new stream.
                return nil, xdsresource.UnknownResource, "", "", false
        }</span>
        <span class="cov8" title="1">rType = ack.rType

        t.mu.Lock()
        defer t.mu.Unlock()

        // Update the nonce no matter if we are going to send the ACK request on
        // wire. We may not send the request if the watch is canceled. But the nonce
        // needs to be updated so the next request will have the right nonce.
        nonce = ack.nonce
        t.nonceMap[rType] = nonce

        s, ok := t.watchMap[rType]
        if !ok || len(s) == 0 </span><span class="cov8" title="1">{
                // We don't send the request ack if there's no active watch (this can be
                // either the server sends responses before any request, or the watch is
                // canceled while the ackAction is in queue), because there's no resource
                // name. And if we send a request with empty resource name list, the
                // server may treat it as a wild card and send us everything.
                return nil, xdsresource.UnknownResource, "", "", false
        }</span>
        <span class="cov8" title="1">send = true
        target = mapToSlice(s)

        version = ack.version
        if version == "" </span><span class="cov8" title="1">{
                // This is a nack, get the previous acked version.
                version = t.versionMap[rType]
                // version will still be an empty string if rType isn't
                // found in versionMap, this can happen if there wasn't any ack
                // before.
        }</span> else<span class="cov8" title="1"> {
                t.versionMap[rType] = version
        }</span>
        <span class="cov8" title="1">return target, rType, version, nonce, send</span>
}

// reportLoad starts an LRS stream to report load data to the management server.
// It blocks until the context is cancelled.
func (t *Controller) reportLoad(ctx context.Context, cc *grpc.ClientConn, opts controllerversion.LoadReportingOptions) <span class="cov0" title="0">{
        retries := 0
        lastStreamStartTime := time.Time{}
        for ctx.Err() == nil </span><span class="cov0" title="0">{
                dur := time.Until(lastStreamStartTime.Add(t.backoff(retries)))
                if dur &gt; 0 </span><span class="cov0" title="0">{
                        timer := time.NewTimer(dur)
                        select </span>{
                        case &lt;-timer.C:<span class="cov0" title="0"></span>
                        case &lt;-ctx.Done():<span class="cov0" title="0">
                                timer.Stop()
                                return</span>
                        }
                }

                <span class="cov0" title="0">retries++
                lastStreamStartTime = time.Now()
                func() </span><span class="cov0" title="0">{
                        // streamCtx is created and canceled in case we terminate the stream
                        // early for any reason, to avoid gRPC-Go leaking the RPC's monitoring
                        // goroutine.
                        streamCtx, cancel := context.WithCancel(ctx)
                        defer cancel()
                        stream, err := t.vClient.NewLoadStatsStream(streamCtx, cc)
                        if err != nil </span><span class="cov0" title="0">{
                                t.logger.Warningf("lrs: failed to create stream: %v", err)
                                return
                        }</span>
                        <span class="cov0" title="0">t.logger.Infof("lrs: created LRS stream")

                        if err := t.vClient.SendFirstLoadStatsRequest(stream); err != nil </span><span class="cov0" title="0">{
                                t.logger.Warningf("lrs: failed to send first request: %v", err)
                                return
                        }</span>

                        <span class="cov0" title="0">clusters, interval, err := t.vClient.HandleLoadStatsResponse(stream)
                        if err != nil </span><span class="cov0" title="0">{
                                t.logger.Warningf("lrs: error from stream: %v", err)
                                return
                        }</span>

                        <span class="cov0" title="0">retries = 0
                        t.sendLoads(streamCtx, stream, opts.LoadStore, clusters, interval)</span>
                }()
        }
}

func (t *Controller) sendLoads(ctx context.Context, stream grpc.ClientStream, store *load.Store, clusterNames []string, interval time.Duration) <span class="cov0" title="0">{
        tick := time.NewTicker(interval)
        defer tick.Stop()
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-tick.C:<span class="cov0" title="0"></span>
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        return</span>
                }
                <span class="cov0" title="0">if err := t.vClient.SendLoadStatsRequest(stream, store.Stats(clusterNames)); err != nil </span><span class="cov0" title="0">{
                        t.logger.Warningf("lrs: error from stream: %v", err)
                        return
                }</span>
        }
}
</pre>
		
		<pre class="file" id="file210" style="display: none">/*
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// Package load provides functionality to record and maintain load data.
package load

import (
        "sync"
        "sync/atomic"
        "time"
)

const negativeOneUInt64 = ^uint64(0)

// Store keeps the loads for multiple clusters and services to be reported via
// LRS. It contains loads to reported to one LRS server. Create multiple stores
// for multiple servers.
//
// It is safe for concurrent use.
type Store struct {
        // mu only protects the map (2 layers). The read/write to *perClusterStore
        // doesn't need to hold the mu.
        mu sync.Mutex
        // clusters is a map with cluster name as the key. The second layer is a map
        // with service name as the key. Each value (perClusterStore) contains data
        // for a (cluster, service) pair.
        //
        // Note that new entries are added to this map, but never removed. This is
        // potentially a memory leak. But the memory is allocated for each new
        // (cluster,service) pair, and the memory allocated is just pointers and
        // maps. So this shouldn't get too bad.
        clusters map[string]map[string]*perClusterStore
}

// NewStore creates a Store.
func NewStore() *Store <span class="cov8" title="1">{
        return &amp;Store{
                clusters: make(map[string]map[string]*perClusterStore),
        }
}</span>

// Stats returns the load data for the given cluster names. Data is returned in
// a slice with no specific order.
//
// If no clusterName is given (an empty slice), all data for all known clusters
// is returned.
//
// If a cluster's Data is empty (no load to report), it's not appended to the
// returned slice.
func (s *Store) Stats(clusterNames []string) []*Data <span class="cov8" title="1">{
        var ret []*Data
        s.mu.Lock()
        defer s.mu.Unlock()

        if len(clusterNames) == 0 </span><span class="cov8" title="1">{
                for _, c := range s.clusters </span><span class="cov8" title="1">{
                        ret = appendClusterStats(ret, c)
                }</span>
                <span class="cov8" title="1">return ret</span>
        }

        <span class="cov8" title="1">for _, n := range clusterNames </span><span class="cov8" title="1">{
                if c, ok := s.clusters[n]; ok </span><span class="cov8" title="1">{
                        ret = appendClusterStats(ret, c)
                }</span>
        }
        <span class="cov8" title="1">return ret</span>
}

// appendClusterStats gets Data for the given cluster, append to ret, and return
// the new slice.
//
// Data is only appended to ret if it's not empty.
func appendClusterStats(ret []*Data, cluster map[string]*perClusterStore) []*Data <span class="cov8" title="1">{
        for _, d := range cluster </span><span class="cov8" title="1">{
                data := d.stats()
                if data == nil </span><span class="cov8" title="1">{
                        // Skip this data if it doesn't contain any information.
                        continue</span>
                }
                <span class="cov8" title="1">ret = append(ret, data)</span>
        }
        <span class="cov8" title="1">return ret</span>
}

// PerCluster returns the perClusterStore for the given clusterName +
// serviceName.
func (s *Store) PerCluster(clusterName, serviceName string) PerClusterReporter <span class="cov8" title="1">{
        if s == nil </span><span class="cov0" title="0">{
                return nil
        }</span>

        <span class="cov8" title="1">s.mu.Lock()
        defer s.mu.Unlock()
        c, ok := s.clusters[clusterName]
        if !ok </span><span class="cov8" title="1">{
                c = make(map[string]*perClusterStore)
                s.clusters[clusterName] = c
        }</span>

        <span class="cov8" title="1">if p, ok := c[serviceName]; ok </span><span class="cov8" title="1">{
                return p
        }</span>
        <span class="cov8" title="1">p := &amp;perClusterStore{
                cluster: clusterName,
                service: serviceName,
        }
        c[serviceName] = p
        return p</span>
}

// perClusterStore is a repository for LB policy implementations to report store
// load data. It contains load for a (cluster, edsService) pair.
//
// It is safe for concurrent use.
//
// TODO(easwars): Use regular maps with mutexes instead of sync.Map here. The
// latter is optimized for two common use cases: (1) when the entry for a given
// key is only ever written once but read many times, as in caches that only
// grow, or (2) when multiple goroutines read, write, and overwrite entries for
// disjoint sets of keys. In these two cases, use of a Map may significantly
// reduce lock contention compared to a Go map paired with a separate Mutex or
// RWMutex.
// Neither of these conditions are met here, and we should transition to a
// regular map with a mutex for better type safety.
type perClusterStore struct {
        cluster, service string
        drops            sync.Map // map[string]*uint64
        localityRPCCount sync.Map // map[string]*rpcCountData

        mu               sync.Mutex
        lastLoadReportAt time.Time
}

// Update functions are called by picker for each RPC. To avoid contention, all
// updates are done atomically.

// CallDropped adds one drop record with the given category to store.
func (ls *perClusterStore) CallDropped(category string) <span class="cov8" title="1">{
        if ls == nil </span><span class="cov0" title="0">{
                return
        }</span>

        <span class="cov8" title="1">p, ok := ls.drops.Load(category)
        if !ok </span><span class="cov8" title="1">{
                tp := new(uint64)
                p, _ = ls.drops.LoadOrStore(category, tp)
        }</span>
        <span class="cov8" title="1">atomic.AddUint64(p.(*uint64), 1)</span>
}

// CallStarted adds one call started record for the given locality.
func (ls *perClusterStore) CallStarted(locality string) <span class="cov8" title="1">{
        if ls == nil </span><span class="cov0" title="0">{
                return
        }</span>

        <span class="cov8" title="1">p, ok := ls.localityRPCCount.Load(locality)
        if !ok </span><span class="cov8" title="1">{
                tp := newRPCCountData()
                p, _ = ls.localityRPCCount.LoadOrStore(locality, tp)
        }</span>
        <span class="cov8" title="1">p.(*rpcCountData).incrInProgress()</span>
}

// CallFinished adds one call finished record for the given locality.
// For successful calls, err needs to be nil.
func (ls *perClusterStore) CallFinished(locality string, err error) <span class="cov8" title="1">{
        if ls == nil </span><span class="cov0" title="0">{
                return
        }</span>

        <span class="cov8" title="1">p, ok := ls.localityRPCCount.Load(locality)
        if !ok </span><span class="cov0" title="0">{
                // The map is never cleared, only values in the map are reset. So the
                // case where entry for call-finish is not found should never happen.
                return
        }</span>
        <span class="cov8" title="1">p.(*rpcCountData).decrInProgress()
        if err == nil </span><span class="cov8" title="1">{
                p.(*rpcCountData).incrSucceeded()
        }</span> else<span class="cov8" title="1"> {
                p.(*rpcCountData).incrErrored()
        }</span>
}

// CallServerLoad adds one server load record for the given locality. The
// load type is specified by desc, and its value by val.
func (ls *perClusterStore) CallServerLoad(locality, name string, d float64) <span class="cov8" title="1">{
        if ls == nil </span><span class="cov0" title="0">{
                return
        }</span>

        <span class="cov8" title="1">p, ok := ls.localityRPCCount.Load(locality)
        if !ok </span><span class="cov0" title="0">{
                // The map is never cleared, only values in the map are reset. So the
                // case where entry for callServerLoad is not found should never happen.
                return
        }</span>
        <span class="cov8" title="1">p.(*rpcCountData).addServerLoad(name, d)</span>
}

// Data contains all load data reported to the Store since the most recent call
// to stats().
type Data struct {
        // Cluster is the name of the cluster this data is for.
        Cluster string
        // Service is the name of the EDS service this data is for.
        Service string
        // TotalDrops is the total number of dropped requests.
        TotalDrops uint64
        // Drops is the number of dropped requests per category.
        Drops map[string]uint64
        // LocalityStats contains load reports per locality.
        LocalityStats map[string]LocalityData
        // ReportInternal is the duration since last time load was reported (stats()
        // was called).
        ReportInterval time.Duration
}

// LocalityData contains load data for a single locality.
type LocalityData struct {
        // RequestStats contains counts of requests made to the locality.
        RequestStats RequestData
        // LoadStats contains server load data for requests made to the locality,
        // indexed by the load type.
        LoadStats map[string]ServerLoadData
}

// RequestData contains request counts.
type RequestData struct {
        // Succeeded is the number of succeeded requests.
        Succeeded uint64
        // Errored is the number of requests which ran into errors.
        Errored uint64
        // InProgress is the number of requests in flight.
        InProgress uint64
}

// ServerLoadData contains server load data.
type ServerLoadData struct {
        // Count is the number of load reports.
        Count uint64
        // Sum is the total value of all load reports.
        Sum float64
}

func newData(cluster, service string) *Data <span class="cov8" title="1">{
        return &amp;Data{
                Cluster:       cluster,
                Service:       service,
                Drops:         make(map[string]uint64),
                LocalityStats: make(map[string]LocalityData),
        }
}</span>

// stats returns and resets all loads reported to the store, except inProgress
// rpc counts.
//
// It returns nil if the store doesn't contain any (new) data.
func (ls *perClusterStore) stats() *Data <span class="cov8" title="1">{
        if ls == nil </span><span class="cov0" title="0">{
                return nil
        }</span>

        <span class="cov8" title="1">sd := newData(ls.cluster, ls.service)
        ls.drops.Range(func(key, val interface{}) bool </span><span class="cov8" title="1">{
                d := atomic.SwapUint64(val.(*uint64), 0)
                if d == 0 </span><span class="cov8" title="1">{
                        return true
                }</span>
                <span class="cov8" title="1">sd.TotalDrops += d
                keyStr := key.(string)
                if keyStr != "" </span><span class="cov8" title="1">{
                        // Skip drops without category. They are counted in total_drops, but
                        // not in per category. One example is drops by circuit breaking.
                        sd.Drops[keyStr] = d
                }</span>
                <span class="cov8" title="1">return true</span>
        })
        <span class="cov8" title="1">ls.localityRPCCount.Range(func(key, val interface{}) bool </span><span class="cov8" title="1">{
                countData := val.(*rpcCountData)
                succeeded := countData.loadAndClearSucceeded()
                inProgress := countData.loadInProgress()
                errored := countData.loadAndClearErrored()
                if succeeded == 0 &amp;&amp; inProgress == 0 &amp;&amp; errored == 0 </span><span class="cov8" title="1">{
                        return true
                }</span>

                <span class="cov8" title="1">ld := LocalityData{
                        RequestStats: RequestData{
                                Succeeded:  succeeded,
                                Errored:    errored,
                                InProgress: inProgress,
                        },
                        LoadStats: make(map[string]ServerLoadData),
                }
                countData.serverLoads.Range(func(key, val interface{}) bool </span><span class="cov8" title="1">{
                        sum, count := val.(*rpcLoadData).loadAndClear()
                        if count == 0 </span><span class="cov0" title="0">{
                                return true
                        }</span>
                        <span class="cov8" title="1">ld.LoadStats[key.(string)] = ServerLoadData{
                                Count: count,
                                Sum:   sum,
                        }
                        return true</span>
                })
                <span class="cov8" title="1">sd.LocalityStats[key.(string)] = ld
                return true</span>
        })

        <span class="cov8" title="1">ls.mu.Lock()
        sd.ReportInterval = time.Since(ls.lastLoadReportAt)
        ls.lastLoadReportAt = time.Now()
        ls.mu.Unlock()

        if sd.TotalDrops == 0 &amp;&amp; len(sd.Drops) == 0 &amp;&amp; len(sd.LocalityStats) == 0 </span><span class="cov8" title="1">{
                return nil
        }</span>
        <span class="cov8" title="1">return sd</span>
}

type rpcCountData struct {
        // Only atomic accesses are allowed for the fields.
        succeeded  *uint64
        errored    *uint64
        inProgress *uint64

        // Map from load desc to load data (sum+count). Loading data from map is
        // atomic, but updating data takes a lock, which could cause contention when
        // multiple RPCs try to report loads for the same desc.
        //
        // To fix the contention, shard this map.
        serverLoads sync.Map // map[string]*rpcLoadData
}

func newRPCCountData() *rpcCountData <span class="cov8" title="1">{
        return &amp;rpcCountData{
                succeeded:  new(uint64),
                errored:    new(uint64),
                inProgress: new(uint64),
        }
}</span>

func (rcd *rpcCountData) incrSucceeded() <span class="cov8" title="1">{
        atomic.AddUint64(rcd.succeeded, 1)
}</span>

func (rcd *rpcCountData) loadAndClearSucceeded() uint64 <span class="cov8" title="1">{
        return atomic.SwapUint64(rcd.succeeded, 0)
}</span>

func (rcd *rpcCountData) incrErrored() <span class="cov8" title="1">{
        atomic.AddUint64(rcd.errored, 1)
}</span>

func (rcd *rpcCountData) loadAndClearErrored() uint64 <span class="cov8" title="1">{
        return atomic.SwapUint64(rcd.errored, 0)
}</span>

func (rcd *rpcCountData) incrInProgress() <span class="cov8" title="1">{
        atomic.AddUint64(rcd.inProgress, 1)
}</span>

func (rcd *rpcCountData) decrInProgress() <span class="cov8" title="1">{
        atomic.AddUint64(rcd.inProgress, negativeOneUInt64) // atomic.Add(x, -1)
}</span>

func (rcd *rpcCountData) loadInProgress() uint64 <span class="cov8" title="1">{
        return atomic.LoadUint64(rcd.inProgress) // InProgress count is not clear when reading.
}</span>

func (rcd *rpcCountData) addServerLoad(name string, d float64) <span class="cov8" title="1">{
        loads, ok := rcd.serverLoads.Load(name)
        if !ok </span><span class="cov8" title="1">{
                tl := newRPCLoadData()
                loads, _ = rcd.serverLoads.LoadOrStore(name, tl)
        }</span>
        <span class="cov8" title="1">loads.(*rpcLoadData).add(d)</span>
}

// Data for server loads (from trailers or oob). Fields in this struct must be
// updated consistently.
//
// The current solution is to hold a lock, which could cause contention. To fix,
// shard serverLoads map in rpcCountData.
type rpcLoadData struct {
        mu    sync.Mutex
        sum   float64
        count uint64
}

func newRPCLoadData() *rpcLoadData <span class="cov8" title="1">{
        return &amp;rpcLoadData{}
}</span>

func (rld *rpcLoadData) add(v float64) <span class="cov8" title="1">{
        rld.mu.Lock()
        rld.sum += v
        rld.count++
        rld.mu.Unlock()
}</span>

func (rld *rpcLoadData) loadAndClear() (s float64, c uint64) <span class="cov8" title="1">{
        rld.mu.Lock()
        s = rld.sum
        rld.sum = 0
        c = rld.count
        rld.count = 0
        rld.mu.Unlock()
        return
}</span>
</pre>
		
		<pre class="file" id="file211" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package xdsclient

import (
        "fmt"

        "google.golang.org/grpc/grpclog"
        internalgrpclog "google.golang.org/grpc/internal/grpclog"
)

const prefix = "[xds-client %p] "

var logger = grpclog.Component("xds")

func prefixLogger(p *clientImpl) *internalgrpclog.PrefixLogger <span class="cov8" title="1">{
        return internalgrpclog.NewPrefixLogger(logger, fmt.Sprintf(prefix, p))
}</span>
</pre>
		
		<pre class="file" id="file212" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package xdsclient

import (
        "fmt"
        "sync"
        "sync/atomic"
)

type clusterNameAndServiceName struct {
        clusterName, edsServcieName string
}

type clusterRequestsCounter struct {
        mu       sync.Mutex
        clusters map[clusterNameAndServiceName]*ClusterRequestsCounter
}

var src = &amp;clusterRequestsCounter{
        clusters: make(map[clusterNameAndServiceName]*ClusterRequestsCounter),
}

// ClusterRequestsCounter is used to track the total inflight requests for a
// service with the provided name.
type ClusterRequestsCounter struct {
        ClusterName    string
        EDSServiceName string
        numRequests    uint32
}

// GetClusterRequestsCounter returns the ClusterRequestsCounter with the
// provided serviceName. If one does not exist, it creates it.
func GetClusterRequestsCounter(clusterName, edsServiceName string) *ClusterRequestsCounter <span class="cov8" title="1">{
        src.mu.Lock()
        defer src.mu.Unlock()
        k := clusterNameAndServiceName{
                clusterName:    clusterName,
                edsServcieName: edsServiceName,
        }
        c, ok := src.clusters[k]
        if !ok </span><span class="cov8" title="1">{
                c = &amp;ClusterRequestsCounter{ClusterName: clusterName}
                src.clusters[k] = c
        }</span>
        <span class="cov8" title="1">return c</span>
}

// StartRequest starts a request for a cluster, incrementing its number of
// requests by 1. Returns an error if the max number of requests is exceeded.
func (c *ClusterRequestsCounter) StartRequest(max uint32) error <span class="cov8" title="1">{
        // Note that during race, the limits could be exceeded. This is allowed:
        // "Since the implementation is eventually consistent, races between threads
        // may allow limits to be potentially exceeded."
        // https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/upstream/circuit_breaking#arch-overview-circuit-break.
        if atomic.LoadUint32(&amp;c.numRequests) &gt;= max </span><span class="cov8" title="1">{
                return fmt.Errorf("max requests %v exceeded on service %v", max, c.ClusterName)
        }</span>
        <span class="cov8" title="1">atomic.AddUint32(&amp;c.numRequests, 1)
        return nil</span>
}

// EndRequest ends a request for a service, decrementing its number of requests
// by 1.
func (c *ClusterRequestsCounter) EndRequest() <span class="cov8" title="1">{
        atomic.AddUint32(&amp;c.numRequests, ^uint32(0))
}</span>

// ClearCounterForTesting clears the counter for the service. Should be only
// used in tests.
func ClearCounterForTesting(clusterName, edsServiceName string) <span class="cov0" title="0">{
        src.mu.Lock()
        defer src.mu.Unlock()
        k := clusterNameAndServiceName{
                clusterName:    clusterName,
                edsServcieName: edsServiceName,
        }
        c, ok := src.clusters[k]
        if !ok </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov0" title="0">c.numRequests = 0</span>
}

// ClearAllCountersForTesting clears all the counters. Should be only used in
// tests.
func ClearAllCountersForTesting() <span class="cov0" title="0">{
        src.mu.Lock()
        defer src.mu.Unlock()
        src.clusters = make(map[clusterNameAndServiceName]*ClusterRequestsCounter)
}</span>
</pre>
		
		<pre class="file" id="file213" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package xdsclient

import (
        "fmt"
        "sync"
        "time"

        "google.golang.org/grpc/xds/internal/xdsclient/bootstrap"
)

const (
        defaultWatchExpiryTimeout         = 15 * time.Second
        defaultIdleAuthorityDeleteTimeout = 5 * time.Minute
)

var (
        // This is the client returned by New(). It contains one client implementation,
        // and maintains the refcount.
        singletonClient = &amp;clientRefCounted{}

        // The following functions are no-ops in the actual code, but can be
        // overridden in tests to give them visibility into certain events.
        singletonClientImplCreateHook = func() {<span class="cov0" title="0">}</span>
        singletonClientImplCloseHook  = func() {<span class="cov8" title="1">}</span>
)

// To override in tests.
var bootstrapNewConfig = bootstrap.NewConfig

// onceClosingClient is a thin wrapper around clientRefCounted. The Close()
// method is overridden such that the underlying reference counted client's
// Close() is called at most once, thereby making Close() idempotent.
//
// This is the type which is returned by New() and NewWithConfig(), making it
// safe for these callers to call Close() any number of times.
type onceClosingClient struct {
        XDSClient

        once sync.Once
}

func (o *onceClosingClient) Close() <span class="cov8" title="1">{
        o.once.Do(o.XDSClient.Close)
}</span>

func newRefCountedWithConfig(config *bootstrap.Config) (XDSClient, error) <span class="cov8" title="1">{
        singletonClient.mu.Lock()
        defer singletonClient.mu.Unlock()

        // If the client implementation was created, increment ref count and return
        // the client.
        if singletonClient.clientImpl != nil </span><span class="cov8" title="1">{
                singletonClient.refCount++
                return &amp;onceClosingClient{XDSClient: singletonClient}, nil
        }</span>

        // If the passed in config is nil, perform bootstrap to read config.
        <span class="cov8" title="1">if config == nil </span><span class="cov8" title="1">{
                var err error
                config, err = bootstrapNewConfig()
                if err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("xds: failed to read bootstrap file: %v", err)
                }</span>
        }

        // Create the new client implementation.
        <span class="cov8" title="1">c, err := newWithConfig(config, defaultWatchExpiryTimeout, defaultIdleAuthorityDeleteTimeout)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov8" title="1">singletonClient.clientImpl = c
        singletonClient.refCount++
        singletonClientImplCreateHook()
        return &amp;onceClosingClient{XDSClient: singletonClient}, nil</span>
}

// clientRefCounted is ref-counted, and to be shared by the xds resolver and
// balancer implementations, across multiple ClientConns and Servers.
type clientRefCounted struct {
        *clientImpl

        // This mu protects all the fields, including the embedded clientImpl above.
        mu       sync.Mutex
        refCount int
}

// Close closes the client. It does ref count of the xds client implementation,
// and closes the gRPC connection to the management server when ref count
// reaches 0.
func (c *clientRefCounted) Close() <span class="cov8" title="1">{
        c.mu.Lock()
        defer c.mu.Unlock()
        c.refCount--
        if c.refCount == 0 </span><span class="cov8" title="1">{
                c.clientImpl.Close()
                // Set clientImpl back to nil. So if New() is called after this, a new
                // implementation will be created.
                c.clientImpl = nil
                singletonClientImplCloseHook()
        }</span>
}
</pre>
		
		<pre class="file" id="file214" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package xdsresource

import "fmt"

// ErrorType is the type of the error that the watcher will receive from the xds
// client.
type ErrorType int

const (
        // ErrorTypeUnknown indicates the error doesn't have a specific type. It is
        // the default value, and is returned if the error is not an xds error.
        ErrorTypeUnknown ErrorType = iota
        // ErrorTypeConnection indicates a connection error from the gRPC client.
        ErrorTypeConnection
        // ErrorTypeResourceNotFound indicates a resource is not found from the xds
        // response. It's typically returned if the resource is removed in the xds
        // server.
        ErrorTypeResourceNotFound
)

type xdsClientError struct {
        t    ErrorType
        desc string
}

func (e *xdsClientError) Error() string <span class="cov0" title="0">{
        return e.desc
}</span>

// NewErrorf creates an xds client error. The callbacks are called with this
// error, to pass additional information about the error.
func NewErrorf(t ErrorType, format string, args ...interface{}) error <span class="cov0" title="0">{
        return &amp;xdsClientError{t: t, desc: fmt.Sprintf(format, args...)}
}</span>

// ErrType returns the error's type.
func ErrType(e error) ErrorType <span class="cov0" title="0">{
        if xe, ok := e.(*xdsClientError); ok </span><span class="cov0" title="0">{
                return xe.t
        }</span>
        <span class="cov0" title="0">return ErrorTypeUnknown</span>
}
</pre>
		
		<pre class="file" id="file215" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package xdsresource

import (
        "errors"
        "fmt"
        "net"

        v3listenerpb "github.com/envoyproxy/go-control-plane/envoy/config/listener/v3"
        v3httppb "github.com/envoyproxy/go-control-plane/envoy/extensions/filters/network/http_connection_manager/v3"
        v3tlspb "github.com/envoyproxy/go-control-plane/envoy/extensions/transport_sockets/tls/v3"
        "github.com/golang/protobuf/proto"
        "github.com/golang/protobuf/ptypes"
        "google.golang.org/grpc/internal/envconfig"
        "google.golang.org/grpc/internal/grpclog"
        "google.golang.org/grpc/internal/resolver"
        "google.golang.org/grpc/xds/internal/httpfilter"
        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource/version"
)

const (
        // Used as the map key for unspecified prefixes. The actual value of this
        // key is immaterial.
        unspecifiedPrefixMapKey = "unspecified"

        // An unspecified destination or source prefix should be considered a less
        // specific match than a wildcard prefix, `0.0.0.0/0` or `::/0`. Also, an
        // unspecified prefix should match most v4 and v6 addresses compared to the
        // wildcard prefixes which match only a specific network (v4 or v6).
        //
        // We use these constants when looking up the most specific prefix match. A
        // wildcard prefix will match 0 bits, and to make sure that a wildcard
        // prefix is considered a more specific match than an unspecified prefix, we
        // use a value of -1 for the latter.
        noPrefixMatch          = -2
        unspecifiedPrefixMatch = -1
)

// FilterChain captures information from within a FilterChain message in a
// Listener resource.
type FilterChain struct {
        // SecurityCfg contains transport socket security configuration.
        SecurityCfg *SecurityConfig
        // HTTPFilters represent the HTTP Filters that comprise this FilterChain.
        HTTPFilters []HTTPFilter
        // RouteConfigName is the route configuration name for this FilterChain.
        //
        // Exactly one of RouteConfigName and InlineRouteConfig is set.
        RouteConfigName string
        // InlineRouteConfig is the inline route configuration (RDS response)
        // returned for this filter chain.
        //
        // Exactly one of RouteConfigName and InlineRouteConfig is set.
        InlineRouteConfig *RouteConfigUpdate
}

// VirtualHostWithInterceptors captures information present in a VirtualHost
// update, and also contains routes with instantiated HTTP Filters.
type VirtualHostWithInterceptors struct {
        // Domains are the domain names which map to this Virtual Host. On the
        // server side, this will be dictated by the :authority header of the
        // incoming RPC.
        Domains []string
        // Routes are the Routes for this Virtual Host.
        Routes []RouteWithInterceptors
}

// RouteWithInterceptors captures information in a Route, and contains
// a usable matcher and also instantiated HTTP Filters.
type RouteWithInterceptors struct {
        // M is the matcher used to match to this route.
        M *CompositeMatcher
        // ActionType is the type of routing action to initiate once matched to.
        ActionType RouteActionType
        // Interceptors are interceptors instantiated for this route. These will be
        // constructed from a combination of the top level configuration and any
        // HTTP Filter overrides present in Virtual Host or Route.
        Interceptors []resolver.ServerInterceptor
}

// ConstructUsableRouteConfiguration takes Route Configuration and converts it
// into matchable route configuration, with instantiated HTTP Filters per route.
func (f *FilterChain) ConstructUsableRouteConfiguration(config RouteConfigUpdate) ([]VirtualHostWithInterceptors, error) <span class="cov8" title="1">{
        vhs := make([]VirtualHostWithInterceptors, len(config.VirtualHosts))
        for _, vh := range config.VirtualHosts </span><span class="cov8" title="1">{
                vhwi, err := f.convertVirtualHost(vh)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("virtual host construction: %v", err)
                }</span>
                <span class="cov8" title="1">vhs = append(vhs, vhwi)</span>
        }
        <span class="cov8" title="1">return vhs, nil</span>
}

func (f *FilterChain) convertVirtualHost(virtualHost *VirtualHost) (VirtualHostWithInterceptors, error) <span class="cov8" title="1">{
        rs := make([]RouteWithInterceptors, len(virtualHost.Routes))
        for i, r := range virtualHost.Routes </span><span class="cov8" title="1">{
                var err error
                rs[i].ActionType = r.ActionType
                rs[i].M, err = RouteToMatcher(r)
                if err != nil </span><span class="cov0" title="0">{
                        return VirtualHostWithInterceptors{}, fmt.Errorf("matcher construction: %v", err)
                }</span>
                <span class="cov8" title="1">for _, filter := range f.HTTPFilters </span><span class="cov8" title="1">{
                        // Route is highest priority on server side, as there is no concept
                        // of an upstream cluster on server side.
                        override := r.HTTPFilterConfigOverride[filter.Name]
                        if override == nil </span><span class="cov8" title="1">{
                                // Virtual Host is second priority.
                                override = virtualHost.HTTPFilterConfigOverride[filter.Name]
                        }</span>
                        <span class="cov8" title="1">sb, ok := filter.Filter.(httpfilter.ServerInterceptorBuilder)
                        if !ok </span><span class="cov0" title="0">{
                                // Should not happen if it passed xdsClient validation.
                                return VirtualHostWithInterceptors{}, fmt.Errorf("filter does not support use in server")
                        }</span>
                        <span class="cov8" title="1">si, err := sb.BuildServerInterceptor(filter.Config, override)
                        if err != nil </span><span class="cov0" title="0">{
                                return VirtualHostWithInterceptors{}, fmt.Errorf("filter construction: %v", err)
                        }</span>
                        <span class="cov8" title="1">if si != nil </span><span class="cov8" title="1">{
                                rs[i].Interceptors = append(rs[i].Interceptors, si)
                        }</span>
                }
        }
        <span class="cov8" title="1">return VirtualHostWithInterceptors{Domains: virtualHost.Domains, Routes: rs}, nil</span>
}

// SourceType specifies the connection source IP match type.
type SourceType int

const (
        // SourceTypeAny matches connection attempts from any source.
        SourceTypeAny SourceType = iota
        // SourceTypeSameOrLoopback matches connection attempts from the same host.
        SourceTypeSameOrLoopback
        // SourceTypeExternal matches connection attempts from a different host.
        SourceTypeExternal
)

// FilterChainManager contains all the match criteria specified through all
// filter chains in a single Listener resource. It also contains the default
// filter chain specified in the Listener resource. It provides two important
// pieces of functionality:
// 1. Validate the filter chains in an incoming Listener resource to make sure
//    that there aren't filter chains which contain the same match criteria.
// 2. As part of performing the above validation, it builds an internal data
//    structure which will if used to look up the matching filter chain at
//    connection time.
//
// The logic specified in the documentation around the xDS FilterChainMatch
// proto mentions 8 criteria to match on.
// The following order applies:
//
// 1. Destination port.
// 2. Destination IP address.
// 3. Server name (e.g. SNI for TLS protocol),
// 4. Transport protocol.
// 5. Application protocols (e.g. ALPN for TLS protocol).
// 6. Source type (e.g. any, local or external network).
// 7. Source IP address.
// 8. Source port.
type FilterChainManager struct {
        logger *grpclog.PrefixLogger
        // Destination prefix is the first match criteria that we support.
        // Therefore, this multi-stage map is indexed on destination prefixes
        // specified in the match criteria.
        // Unspecified destination prefix matches end up as a wildcard entry here
        // with a key of 0.0.0.0/0.
        dstPrefixMap map[string]*destPrefixEntry

        // At connection time, we do not have the actual destination prefix to match
        // on. We only have the real destination address of the incoming connection.
        // This means that we cannot use the above map at connection time. This list
        // contains the map entries from the above map that we can use at connection
        // time to find matching destination prefixes in O(n) time.
        //
        // TODO: Implement LC-trie to support logarithmic time lookups. If that
        // involves too much time/effort, sort this slice based on the netmask size.
        dstPrefixes []*destPrefixEntry

        def *FilterChain // Default filter chain, if specified.

        // RouteConfigNames are the route configuration names which need to be
        // dynamically queried for RDS Configuration for any FilterChains which
        // specify to load RDS Configuration dynamically.
        RouteConfigNames map[string]bool
}

// destPrefixEntry is the value type of the map indexed on destination prefixes.
type destPrefixEntry struct {
        // The actual destination prefix. Set to nil for unspecified prefixes.
        net *net.IPNet
        // We need to keep track of the transport protocols seen as part of the
        // config validation (and internal structure building) phase. The only two
        // values that we support are empty string and "raw_buffer", with the latter
        // taking preference. Once we have seen one filter chain with "raw_buffer",
        // we can drop everything other filter chain with an empty transport
        // protocol.
        rawBufferSeen bool
        // For each specified source type in the filter chain match criteria, this
        // array points to the set of specified source prefixes.
        // Unspecified source type matches end up as a wildcard entry here with an
        // index of 0, which actually represents the source type `ANY`.
        srcTypeArr sourceTypesArray
}

// An array for the fixed number of source types that we have.
type sourceTypesArray [3]*sourcePrefixes

// sourcePrefixes contains source prefix related information specified in the
// match criteria. These are pointed to by the array of source types.
type sourcePrefixes struct {
        // These are very similar to the 'dstPrefixMap' and 'dstPrefixes' field of
        // FilterChainManager. Go there for more info.
        srcPrefixMap map[string]*sourcePrefixEntry
        srcPrefixes  []*sourcePrefixEntry
}

// sourcePrefixEntry contains match criteria per source prefix.
type sourcePrefixEntry struct {
        // The actual destination prefix. Set to nil for unspecified prefixes.
        net *net.IPNet
        // Mapping from source ports specified in the match criteria to the actual
        // filter chain. Unspecified source port matches en up as a wildcard entry
        // here with a key of 0.
        srcPortMap map[int]*FilterChain
}

// NewFilterChainManager parses the received Listener resource and builds a
// FilterChainManager. Returns a non-nil error on validation failures.
//
// This function is only exported so that tests outside of this package can
// create a FilterChainManager.
func NewFilterChainManager(lis *v3listenerpb.Listener, logger *grpclog.PrefixLogger) (*FilterChainManager, error) <span class="cov8" title="1">{
        // Parse all the filter chains and build the internal data structures.
        fci := &amp;FilterChainManager{
                logger:           logger,
                dstPrefixMap:     make(map[string]*destPrefixEntry),
                RouteConfigNames: make(map[string]bool),
        }
        if err := fci.addFilterChains(lis.GetFilterChains()); err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        // Build the source and dest prefix slices used by Lookup().
        <span class="cov8" title="1">fcSeen := false
        for _, dstPrefix := range fci.dstPrefixMap </span><span class="cov8" title="1">{
                fci.dstPrefixes = append(fci.dstPrefixes, dstPrefix)
                for _, st := range dstPrefix.srcTypeArr </span><span class="cov8" title="1">{
                        if st == nil </span><span class="cov8" title="1">{
                                continue</span>
                        }
                        <span class="cov8" title="1">for _, srcPrefix := range st.srcPrefixMap </span><span class="cov8" title="1">{
                                st.srcPrefixes = append(st.srcPrefixes, srcPrefix)
                                for _, fc := range srcPrefix.srcPortMap </span><span class="cov8" title="1">{
                                        if fc != nil </span><span class="cov8" title="1">{
                                                fcSeen = true
                                        }</span>
                                }
                        }
                }
        }

        // Retrieve the default filter chain. The match criteria specified on the
        // default filter chain is never used. The default filter chain simply gets
        // used when none of the other filter chains match.
        <span class="cov8" title="1">var def *FilterChain
        if dfc := lis.GetDefaultFilterChain(); dfc != nil </span><span class="cov8" title="1">{
                var err error
                if def, err = fci.filterChainFromProto(dfc); err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
        }
        <span class="cov8" title="1">fci.def = def

        // If there are no supported filter chains and no default filter chain, we
        // fail here. This will call the Listener resource to be NACK'ed.
        if !fcSeen &amp;&amp; fci.def == nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("no supported filter chains and no default filter chain")
        }</span>
        <span class="cov8" title="1">return fci, nil</span>
}

// addFilterChains parses the filter chains in fcs and adds the required
// internal data structures corresponding to the match criteria.
func (fci *FilterChainManager) addFilterChains(fcs []*v3listenerpb.FilterChain) error <span class="cov8" title="1">{
        for _, fc := range fcs </span><span class="cov8" title="1">{
                fcm := fc.GetFilterChainMatch()
                if fcm.GetDestinationPort().GetValue() != 0 </span><span class="cov8" title="1">{
                        // Destination port is the first match criteria and we do not
                        // support filter chains which contains this match criteria.
                        fci.logger.Warningf("Dropping filter chain %+v since it contains unsupported destination_port match field", fc)
                        continue</span>
                }

                // Build the internal representation of the filter chain match fields.
                <span class="cov8" title="1">if err := fci.addFilterChainsForDestPrefixes(fc); err != nil </span><span class="cov8" title="1">{
                        return err
                }</span>
        }

        <span class="cov8" title="1">return nil</span>
}

func (fci *FilterChainManager) addFilterChainsForDestPrefixes(fc *v3listenerpb.FilterChain) error <span class="cov8" title="1">{
        ranges := fc.GetFilterChainMatch().GetPrefixRanges()
        dstPrefixes := make([]*net.IPNet, 0, len(ranges))
        for _, pr := range ranges </span><span class="cov8" title="1">{
                cidr := fmt.Sprintf("%s/%d", pr.GetAddressPrefix(), pr.GetPrefixLen().GetValue())
                _, ipnet, err := net.ParseCIDR(cidr)
                if err != nil </span><span class="cov8" title="1">{
                        return fmt.Errorf("failed to parse destination prefix range: %+v", pr)
                }</span>
                <span class="cov8" title="1">dstPrefixes = append(dstPrefixes, ipnet)</span>
        }

        <span class="cov8" title="1">if len(dstPrefixes) == 0 </span><span class="cov8" title="1">{
                // Use the unspecified entry when destination prefix is unspecified, and
                // set the `net` field to nil.
                if fci.dstPrefixMap[unspecifiedPrefixMapKey] == nil </span><span class="cov8" title="1">{
                        fci.dstPrefixMap[unspecifiedPrefixMapKey] = &amp;destPrefixEntry{}
                }</span>
                <span class="cov8" title="1">return fci.addFilterChainsForServerNames(fci.dstPrefixMap[unspecifiedPrefixMapKey], fc)</span>
        }
        <span class="cov8" title="1">for _, prefix := range dstPrefixes </span><span class="cov8" title="1">{
                p := prefix.String()
                if fci.dstPrefixMap[p] == nil </span><span class="cov8" title="1">{
                        fci.dstPrefixMap[p] = &amp;destPrefixEntry{net: prefix}
                }</span>
                <span class="cov8" title="1">if err := fci.addFilterChainsForServerNames(fci.dstPrefixMap[p], fc); err != nil </span><span class="cov8" title="1">{
                        return err
                }</span>
        }
        <span class="cov8" title="1">return nil</span>
}

func (fci *FilterChainManager) addFilterChainsForServerNames(dstEntry *destPrefixEntry, fc *v3listenerpb.FilterChain) error <span class="cov8" title="1">{
        // Filter chains specifying server names in their match criteria always fail
        // a match at connection time. So, these filter chains can be dropped now.
        if len(fc.GetFilterChainMatch().GetServerNames()) != 0 </span><span class="cov8" title="1">{
                fci.logger.Warningf("Dropping filter chain %+v since it contains unsupported server_names match field", fc)
                return nil
        }</span>

        <span class="cov8" title="1">return fci.addFilterChainsForTransportProtocols(dstEntry, fc)</span>
}

func (fci *FilterChainManager) addFilterChainsForTransportProtocols(dstEntry *destPrefixEntry, fc *v3listenerpb.FilterChain) error <span class="cov8" title="1">{
        tp := fc.GetFilterChainMatch().GetTransportProtocol()
        switch </span>{
        case tp != "" &amp;&amp; tp != "raw_buffer":<span class="cov8" title="1">
                // Only allow filter chains with transport protocol set to empty string
                // or "raw_buffer".
                fci.logger.Warningf("Dropping filter chain %+v since it contains unsupported value for transport_protocols match field", fc)
                return nil</span>
        case tp == "" &amp;&amp; dstEntry.rawBufferSeen:<span class="cov8" title="1">
                // If we have already seen filter chains with transport protocol set to
                // "raw_buffer", we can drop filter chains with transport protocol set
                // to empty string, since the former takes precedence.
                fci.logger.Warningf("Dropping filter chain %+v since it contains unsupported value for transport_protocols match field", fc)
                return nil</span>
        case tp != "" &amp;&amp; !dstEntry.rawBufferSeen:<span class="cov8" title="1">
                // This is the first "raw_buffer" that we are seeing. Set the bit and
                // reset the source types array which might contain entries for filter
                // chains with transport protocol set to empty string.
                dstEntry.rawBufferSeen = true
                dstEntry.srcTypeArr = sourceTypesArray{}</span>
        }
        <span class="cov8" title="1">return fci.addFilterChainsForApplicationProtocols(dstEntry, fc)</span>
}

func (fci *FilterChainManager) addFilterChainsForApplicationProtocols(dstEntry *destPrefixEntry, fc *v3listenerpb.FilterChain) error <span class="cov8" title="1">{
        if len(fc.GetFilterChainMatch().GetApplicationProtocols()) != 0 </span><span class="cov8" title="1">{
                fci.logger.Warningf("Dropping filter chain %+v since it contains unsupported application_protocols match field", fc)
                return nil
        }</span>
        <span class="cov8" title="1">return fci.addFilterChainsForSourceType(dstEntry, fc)</span>
}

// addFilterChainsForSourceType adds source types to the internal data
// structures and delegates control to addFilterChainsForSourcePrefixes to
// continue building the internal data structure.
func (fci *FilterChainManager) addFilterChainsForSourceType(dstEntry *destPrefixEntry, fc *v3listenerpb.FilterChain) error <span class="cov8" title="1">{
        var srcType SourceType
        switch st := fc.GetFilterChainMatch().GetSourceType(); st </span>{
        case v3listenerpb.FilterChainMatch_ANY:<span class="cov8" title="1">
                srcType = SourceTypeAny</span>
        case v3listenerpb.FilterChainMatch_SAME_IP_OR_LOOPBACK:<span class="cov8" title="1">
                srcType = SourceTypeSameOrLoopback</span>
        case v3listenerpb.FilterChainMatch_EXTERNAL:<span class="cov8" title="1">
                srcType = SourceTypeExternal</span>
        default:<span class="cov0" title="0">
                return fmt.Errorf("unsupported source type: %v", st)</span>
        }

        <span class="cov8" title="1">st := int(srcType)
        if dstEntry.srcTypeArr[st] == nil </span><span class="cov8" title="1">{
                dstEntry.srcTypeArr[st] = &amp;sourcePrefixes{srcPrefixMap: make(map[string]*sourcePrefixEntry)}
        }</span>
        <span class="cov8" title="1">return fci.addFilterChainsForSourcePrefixes(dstEntry.srcTypeArr[st].srcPrefixMap, fc)</span>
}

// addFilterChainsForSourcePrefixes adds source prefixes to the internal data
// structures and delegates control to addFilterChainsForSourcePorts to continue
// building the internal data structure.
func (fci *FilterChainManager) addFilterChainsForSourcePrefixes(srcPrefixMap map[string]*sourcePrefixEntry, fc *v3listenerpb.FilterChain) error <span class="cov8" title="1">{
        ranges := fc.GetFilterChainMatch().GetSourcePrefixRanges()
        srcPrefixes := make([]*net.IPNet, 0, len(ranges))
        for _, pr := range fc.GetFilterChainMatch().GetSourcePrefixRanges() </span><span class="cov8" title="1">{
                cidr := fmt.Sprintf("%s/%d", pr.GetAddressPrefix(), pr.GetPrefixLen().GetValue())
                _, ipnet, err := net.ParseCIDR(cidr)
                if err != nil </span><span class="cov8" title="1">{
                        return fmt.Errorf("failed to parse source prefix range: %+v", pr)
                }</span>
                <span class="cov8" title="1">srcPrefixes = append(srcPrefixes, ipnet)</span>
        }

        <span class="cov8" title="1">if len(srcPrefixes) == 0 </span><span class="cov8" title="1">{
                // Use the unspecified entry when destination prefix is unspecified, and
                // set the `net` field to nil.
                if srcPrefixMap[unspecifiedPrefixMapKey] == nil </span><span class="cov8" title="1">{
                        srcPrefixMap[unspecifiedPrefixMapKey] = &amp;sourcePrefixEntry{
                                srcPortMap: make(map[int]*FilterChain),
                        }
                }</span>
                <span class="cov8" title="1">return fci.addFilterChainsForSourcePorts(srcPrefixMap[unspecifiedPrefixMapKey], fc)</span>
        }
        <span class="cov8" title="1">for _, prefix := range srcPrefixes </span><span class="cov8" title="1">{
                p := prefix.String()
                if srcPrefixMap[p] == nil </span><span class="cov8" title="1">{
                        srcPrefixMap[p] = &amp;sourcePrefixEntry{
                                net:        prefix,
                                srcPortMap: make(map[int]*FilterChain),
                        }
                }</span>
                <span class="cov8" title="1">if err := fci.addFilterChainsForSourcePorts(srcPrefixMap[p], fc); err != nil </span><span class="cov8" title="1">{
                        return err
                }</span>
        }
        <span class="cov8" title="1">return nil</span>
}

// addFilterChainsForSourcePorts adds source ports to the internal data
// structures and completes the process of building the internal data structure.
// It is here that we determine if there are multiple filter chains with
// overlapping matching rules.
func (fci *FilterChainManager) addFilterChainsForSourcePorts(srcEntry *sourcePrefixEntry, fcProto *v3listenerpb.FilterChain) error <span class="cov8" title="1">{
        ports := fcProto.GetFilterChainMatch().GetSourcePorts()
        srcPorts := make([]int, 0, len(ports))
        for _, port := range ports </span><span class="cov8" title="1">{
                srcPorts = append(srcPorts, int(port))
        }</span>

        <span class="cov8" title="1">fc, err := fci.filterChainFromProto(fcProto)
        if err != nil </span><span class="cov8" title="1">{
                return err
        }</span>

        <span class="cov8" title="1">if len(srcPorts) == 0 </span><span class="cov8" title="1">{
                // Use the wildcard port '0', when source ports are unspecified.
                if curFC := srcEntry.srcPortMap[0]; curFC != nil </span><span class="cov8" title="1">{
                        return errors.New("multiple filter chains with overlapping matching rules are defined")
                }</span>
                <span class="cov8" title="1">srcEntry.srcPortMap[0] = fc
                return nil</span>
        }
        <span class="cov8" title="1">for _, port := range srcPorts </span><span class="cov8" title="1">{
                if curFC := srcEntry.srcPortMap[port]; curFC != nil </span><span class="cov8" title="1">{
                        return errors.New("multiple filter chains with overlapping matching rules are defined")
                }</span>
                <span class="cov8" title="1">srcEntry.srcPortMap[port] = fc</span>
        }
        <span class="cov8" title="1">return nil</span>
}

// filterChainFromProto extracts the relevant information from the FilterChain
// proto and stores it in our internal representation. It also persists any
// RouteNames which need to be queried dynamically via RDS.
func (fci *FilterChainManager) filterChainFromProto(fc *v3listenerpb.FilterChain) (*FilterChain, error) <span class="cov8" title="1">{
        filterChain, err := processNetworkFilters(fc.GetFilters())
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        // These route names will be dynamically queried via RDS in the wrapped
        // listener, which receives the LDS response, if specified for the filter
        // chain.
        <span class="cov8" title="1">if filterChain.RouteConfigName != "" </span><span class="cov8" title="1">{
                fci.RouteConfigNames[filterChain.RouteConfigName] = true
        }</span>
        // If the transport_socket field is not specified, it means that the control
        // plane has not sent us any security config. This is fine and the server
        // will use the fallback credentials configured as part of the
        // xdsCredentials.
        <span class="cov8" title="1">ts := fc.GetTransportSocket()
        if ts == nil </span><span class="cov8" title="1">{
                return filterChain, nil
        }</span>
        <span class="cov8" title="1">if name := ts.GetName(); name != transportSocketName </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("transport_socket field has unexpected name: %s", name)
        }</span>
        <span class="cov8" title="1">any := ts.GetTypedConfig()
        if any == nil || any.TypeUrl != version.V3DownstreamTLSContextURL </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("transport_socket field has unexpected typeURL: %s", any.TypeUrl)
        }</span>
        <span class="cov8" title="1">downstreamCtx := &amp;v3tlspb.DownstreamTlsContext{}
        if err := proto.Unmarshal(any.GetValue(), downstreamCtx); err != nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("failed to unmarshal DownstreamTlsContext in LDS response: %v", err)
        }</span>
        <span class="cov8" title="1">if downstreamCtx.GetRequireSni().GetValue() </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("require_sni field set to true in DownstreamTlsContext message: %v", downstreamCtx)
        }</span>
        <span class="cov8" title="1">if downstreamCtx.GetOcspStaplePolicy() != v3tlspb.DownstreamTlsContext_LENIENT_STAPLING </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("ocsp_staple_policy field set to unsupported value in DownstreamTlsContext message: %v", downstreamCtx)
        }</span>
        // The following fields from `DownstreamTlsContext` are ignore:
        // - disable_stateless_session_resumption
        // - session_ticket_keys
        // - session_ticket_keys_sds_secret_config
        // - session_timeout
        <span class="cov8" title="1">if downstreamCtx.GetCommonTlsContext() == nil </span><span class="cov8" title="1">{
                return nil, errors.New("DownstreamTlsContext in LDS response does not contain a CommonTlsContext")
        }</span>
        <span class="cov8" title="1">sc, err := securityConfigFromCommonTLSContext(downstreamCtx.GetCommonTlsContext(), true)
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">if sc == nil </span><span class="cov0" title="0">{
                // sc == nil is a valid case where the control plane has not sent us any
                // security configuration. xDS creds will use fallback creds.
                return filterChain, nil
        }</span>
        <span class="cov8" title="1">sc.RequireClientCert = downstreamCtx.GetRequireClientCertificate().GetValue()
        if sc.RequireClientCert &amp;&amp; sc.RootInstanceName == "" </span><span class="cov8" title="1">{
                return nil, errors.New("security configuration on the server-side does not contain root certificate provider instance name, but require_client_cert field is set")
        }</span>
        <span class="cov8" title="1">filterChain.SecurityCfg = sc
        return filterChain, nil</span>
}

// Validate takes a function to validate the FilterChains in this manager.
func (fci *FilterChainManager) Validate(f func(fc *FilterChain) error) error <span class="cov0" title="0">{
        for _, dst := range fci.dstPrefixMap </span><span class="cov0" title="0">{
                for _, srcType := range dst.srcTypeArr </span><span class="cov0" title="0">{
                        if srcType == nil </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        <span class="cov0" title="0">for _, src := range srcType.srcPrefixMap </span><span class="cov0" title="0">{
                                for _, fc := range src.srcPortMap </span><span class="cov0" title="0">{
                                        if err := f(fc); err != nil </span><span class="cov0" title="0">{
                                                return err
                                        }</span>
                                }
                        }
                }
        }
        <span class="cov0" title="0">return f(fci.def)</span>
}

func processNetworkFilters(filters []*v3listenerpb.Filter) (*FilterChain, error) <span class="cov8" title="1">{
        filterChain := &amp;FilterChain{}
        seenNames := make(map[string]bool, len(filters))
        seenHCM := false
        for _, filter := range filters </span><span class="cov8" title="1">{
                name := filter.GetName()
                if name == "" </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("network filters {%+v} is missing name field in filter: {%+v}", filters, filter)
                }</span>
                <span class="cov8" title="1">if seenNames[name] </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("network filters {%+v} has duplicate filter name %q", filters, name)
                }</span>
                <span class="cov8" title="1">seenNames[name] = true

                // Network filters have a oneof field named `config_type` where we
                // only support `TypedConfig` variant.
                switch typ := filter.GetConfigType().(type) </span>{
                case *v3listenerpb.Filter_TypedConfig:<span class="cov8" title="1">
                        // The typed_config field has an `anypb.Any` proto which could
                        // directly contain the serialized bytes of the actual filter
                        // configuration, or it could be encoded as a `TypedStruct`.
                        // TODO: Add support for `TypedStruct`.
                        tc := filter.GetTypedConfig()

                        // The only network filter that we currently support is the v3
                        // HttpConnectionManager. So, we can directly check the type_url
                        // and unmarshal the config.
                        // TODO: Implement a registry of supported network filters (like
                        // we have for HTTP filters), when we have to support network
                        // filters other than HttpConnectionManager.
                        if tc.GetTypeUrl() != version.V3HTTPConnManagerURL </span><span class="cov8" title="1">{
                                return nil, fmt.Errorf("network filters {%+v} has unsupported network filter %q in filter {%+v}", filters, tc.GetTypeUrl(), filter)
                        }</span>
                        <span class="cov8" title="1">hcm := &amp;v3httppb.HttpConnectionManager{}
                        if err := ptypes.UnmarshalAny(tc, hcm); err != nil </span><span class="cov8" title="1">{
                                return nil, fmt.Errorf("network filters {%+v} failed unmarshaling of network filter {%+v}: %v", filters, filter, err)
                        }</span>
                        // "Any filters after HttpConnectionManager should be ignored during
                        // connection processing but still be considered for validity.
                        // HTTPConnectionManager must have valid http_filters." - A36
                        <span class="cov8" title="1">filters, err := processHTTPFilters(hcm.GetHttpFilters(), true)
                        if err != nil </span><span class="cov8" title="1">{
                                return nil, fmt.Errorf("network filters {%+v} had invalid server side HTTP Filters {%+v}: %v", filters, hcm.GetHttpFilters(), err)
                        }</span>
                        <span class="cov8" title="1">if !seenHCM </span><span class="cov8" title="1">{
                                // Validate for RBAC in only the HCM that will be used, since this isn't a logical validation failure,
                                // it's simply a validation to support RBAC HTTP Filter.
                                // "HttpConnectionManager.xff_num_trusted_hops must be unset or zero and
                                // HttpConnectionManager.original_ip_detection_extensions must be empty. If
                                // either field has an incorrect value, the Listener must be NACKed." - A41
                                if hcm.XffNumTrustedHops != 0 </span><span class="cov8" title="1">{
                                        return nil, fmt.Errorf("xff_num_trusted_hops must be unset or zero %+v", hcm)
                                }</span>
                                <span class="cov8" title="1">if len(hcm.OriginalIpDetectionExtensions) != 0 </span><span class="cov8" title="1">{
                                        return nil, fmt.Errorf("original_ip_detection_extensions must be empty %+v", hcm)
                                }</span>

                                // TODO: Implement terminal filter logic, as per A36.
                                <span class="cov8" title="1">filterChain.HTTPFilters = filters
                                seenHCM = true
                                if !envconfig.XDSRBAC </span><span class="cov0" title="0">{
                                        continue</span>
                                }
                                <span class="cov8" title="1">switch hcm.RouteSpecifier.(type) </span>{
                                case *v3httppb.HttpConnectionManager_Rds:<span class="cov8" title="1">
                                        if hcm.GetRds().GetConfigSource().GetAds() == nil </span><span class="cov8" title="1">{
                                                return nil, fmt.Errorf("ConfigSource is not ADS: %+v", hcm)
                                        }</span>
                                        <span class="cov8" title="1">name := hcm.GetRds().GetRouteConfigName()
                                        if name == "" </span><span class="cov0" title="0">{
                                                return nil, fmt.Errorf("empty route_config_name: %+v", hcm)
                                        }</span>
                                        <span class="cov8" title="1">filterChain.RouteConfigName = name</span>
                                case *v3httppb.HttpConnectionManager_RouteConfig:<span class="cov8" title="1">
                                        // "RouteConfiguration validation logic inherits all
                                        // previous validations made for client-side usage as RDS
                                        // does not distinguish between client-side and
                                        // server-side." - A36
                                        // Can specify v3 here, as will never get to this function
                                        // if v2.
                                        routeU, err := generateRDSUpdateFromRouteConfiguration(hcm.GetRouteConfig(), nil, false)
                                        if err != nil </span><span class="cov0" title="0">{
                                                return nil, fmt.Errorf("failed to parse inline RDS resp: %v", err)
                                        }</span>
                                        <span class="cov8" title="1">filterChain.InlineRouteConfig = &amp;routeU</span>
                                case nil:<span class="cov8" title="1">
                                        return nil, fmt.Errorf("no RouteSpecifier: %+v", hcm)</span>
                                default:<span class="cov8" title="1">
                                        return nil, fmt.Errorf("unsupported type %T for RouteSpecifier", hcm.RouteSpecifier)</span>
                                }
                        }
                default:<span class="cov8" title="1">
                        return nil, fmt.Errorf("network filters {%+v} has unsupported config_type %T in filter %s", filters, typ, filter.GetName())</span>
                }
        }
        <span class="cov8" title="1">if !seenHCM </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("network filters {%+v} missing HttpConnectionManager filter", filters)
        }</span>
        <span class="cov8" title="1">return filterChain, nil</span>
}

// FilterChainLookupParams wraps parameters to be passed to Lookup.
type FilterChainLookupParams struct {
        // IsUnspecified indicates whether the server is listening on a wildcard
        // address, "0.0.0.0" for IPv4 and "::" for IPv6. Only when this is set to
        // true, do we consider the destination prefixes specified in the filter
        // chain match criteria.
        IsUnspecifiedListener bool
        // DestAddr is the local address of an incoming connection.
        DestAddr net.IP
        // SourceAddr is the remote address of an incoming connection.
        SourceAddr net.IP
        // SourcePort is the remote port of an incoming connection.
        SourcePort int
}

// Lookup returns the most specific matching filter chain to be used for an
// incoming connection on the server side.
//
// Returns a non-nil error if no matching filter chain could be found or
// multiple matching filter chains were found, and in both cases, the incoming
// connection must be dropped.
func (fci *FilterChainManager) Lookup(params FilterChainLookupParams) (*FilterChain, error) <span class="cov8" title="1">{
        dstPrefixes := filterByDestinationPrefixes(fci.dstPrefixes, params.IsUnspecifiedListener, params.DestAddr)
        if len(dstPrefixes) == 0 </span><span class="cov8" title="1">{
                if fci.def != nil </span><span class="cov8" title="1">{
                        return fci.def, nil
                }</span>
                <span class="cov8" title="1">return nil, fmt.Errorf("no matching filter chain based on destination prefix match for %+v", params)</span>
        }

        <span class="cov8" title="1">srcType := SourceTypeExternal
        if params.SourceAddr.Equal(params.DestAddr) || params.SourceAddr.IsLoopback() </span><span class="cov8" title="1">{
                srcType = SourceTypeSameOrLoopback
        }</span>
        <span class="cov8" title="1">srcPrefixes := filterBySourceType(dstPrefixes, srcType)
        if len(srcPrefixes) == 0 </span><span class="cov8" title="1">{
                if fci.def != nil </span><span class="cov0" title="0">{
                        return fci.def, nil
                }</span>
                <span class="cov8" title="1">return nil, fmt.Errorf("no matching filter chain based on source type match for %+v", params)</span>
        }
        <span class="cov8" title="1">srcPrefixEntry, err := filterBySourcePrefixes(srcPrefixes, params.SourceAddr)
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">if fc := filterBySourcePorts(srcPrefixEntry, params.SourcePort); fc != nil </span><span class="cov8" title="1">{
                return fc, nil
        }</span>
        <span class="cov8" title="1">if fci.def != nil </span><span class="cov0" title="0">{
                return fci.def, nil
        }</span>
        <span class="cov8" title="1">return nil, fmt.Errorf("no matching filter chain after all match criteria for %+v", params)</span>
}

// filterByDestinationPrefixes is the first stage of the filter chain
// matching algorithm. It takes the complete set of configured filter chain
// matchers and returns the most specific matchers based on the destination
// prefix match criteria (the prefixes which match the most number of bits).
func filterByDestinationPrefixes(dstPrefixes []*destPrefixEntry, isUnspecified bool, dstAddr net.IP) []*destPrefixEntry <span class="cov8" title="1">{
        if !isUnspecified </span><span class="cov8" title="1">{
                // Destination prefix matchers are considered only when the listener is
                // bound to the wildcard address.
                return dstPrefixes
        }</span>

        <span class="cov8" title="1">var matchingDstPrefixes []*destPrefixEntry
        maxSubnetMatch := noPrefixMatch
        for _, prefix := range dstPrefixes </span><span class="cov8" title="1">{
                if prefix.net != nil &amp;&amp; !prefix.net.Contains(dstAddr) </span><span class="cov8" title="1">{
                        // Skip prefixes which don't match.
                        continue</span>
                }
                // For unspecified prefixes, since we do not store a real net.IPNet
                // inside prefix, we do not perform a match. Instead we simply set
                // the matchSize to -1, which is less than the matchSize (0) for a
                // wildcard prefix.
                <span class="cov8" title="1">matchSize := unspecifiedPrefixMatch
                if prefix.net != nil </span><span class="cov8" title="1">{
                        matchSize, _ = prefix.net.Mask.Size()
                }</span>
                <span class="cov8" title="1">if matchSize &lt; maxSubnetMatch </span><span class="cov8" title="1">{
                        continue</span>
                }
                <span class="cov8" title="1">if matchSize &gt; maxSubnetMatch </span><span class="cov8" title="1">{
                        maxSubnetMatch = matchSize
                        matchingDstPrefixes = make([]*destPrefixEntry, 0, 1)
                }</span>
                <span class="cov8" title="1">matchingDstPrefixes = append(matchingDstPrefixes, prefix)</span>
        }
        <span class="cov8" title="1">return matchingDstPrefixes</span>
}

// filterBySourceType is the second stage of the matching algorithm. It
// trims the filter chains based on the most specific source type match.
func filterBySourceType(dstPrefixes []*destPrefixEntry, srcType SourceType) []*sourcePrefixes <span class="cov8" title="1">{
        var (
                srcPrefixes      []*sourcePrefixes
                bestSrcTypeMatch int
        )
        for _, prefix := range dstPrefixes </span><span class="cov8" title="1">{
                var (
                        srcPrefix *sourcePrefixes
                        match     int
                )
                switch srcType </span>{
                case SourceTypeExternal:<span class="cov8" title="1">
                        match = int(SourceTypeExternal)
                        srcPrefix = prefix.srcTypeArr[match]</span>
                case SourceTypeSameOrLoopback:<span class="cov8" title="1">
                        match = int(SourceTypeSameOrLoopback)
                        srcPrefix = prefix.srcTypeArr[match]</span>
                }
                <span class="cov8" title="1">if srcPrefix == nil </span><span class="cov8" title="1">{
                        match = int(SourceTypeAny)
                        srcPrefix = prefix.srcTypeArr[match]
                }</span>
                <span class="cov8" title="1">if match &lt; bestSrcTypeMatch </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov8" title="1">if match &gt; bestSrcTypeMatch </span><span class="cov8" title="1">{
                        bestSrcTypeMatch = match
                        srcPrefixes = make([]*sourcePrefixes, 0)
                }</span>
                <span class="cov8" title="1">if srcPrefix != nil </span><span class="cov8" title="1">{
                        // The source type array always has 3 entries, but these could be
                        // nil if the appropriate source type match was not specified.
                        srcPrefixes = append(srcPrefixes, srcPrefix)
                }</span>
        }
        <span class="cov8" title="1">return srcPrefixes</span>
}

// filterBySourcePrefixes is the third stage of the filter chain matching
// algorithm. It trims the filter chains based on the source prefix. At most one
// filter chain with the most specific match progress to the next stage.
func filterBySourcePrefixes(srcPrefixes []*sourcePrefixes, srcAddr net.IP) (*sourcePrefixEntry, error) <span class="cov8" title="1">{
        var matchingSrcPrefixes []*sourcePrefixEntry
        maxSubnetMatch := noPrefixMatch
        for _, sp := range srcPrefixes </span><span class="cov8" title="1">{
                for _, prefix := range sp.srcPrefixes </span><span class="cov8" title="1">{
                        if prefix.net != nil &amp;&amp; !prefix.net.Contains(srcAddr) </span><span class="cov8" title="1">{
                                // Skip prefixes which don't match.
                                continue</span>
                        }
                        // For unspecified prefixes, since we do not store a real net.IPNet
                        // inside prefix, we do not perform a match. Instead we simply set
                        // the matchSize to -1, which is less than the matchSize (0) for a
                        // wildcard prefix.
                        <span class="cov8" title="1">matchSize := unspecifiedPrefixMatch
                        if prefix.net != nil </span><span class="cov8" title="1">{
                                matchSize, _ = prefix.net.Mask.Size()
                        }</span>
                        <span class="cov8" title="1">if matchSize &lt; maxSubnetMatch </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        <span class="cov8" title="1">if matchSize &gt; maxSubnetMatch </span><span class="cov8" title="1">{
                                maxSubnetMatch = matchSize
                                matchingSrcPrefixes = make([]*sourcePrefixEntry, 0, 1)
                        }</span>
                        <span class="cov8" title="1">matchingSrcPrefixes = append(matchingSrcPrefixes, prefix)</span>
                }
        }
        <span class="cov8" title="1">if len(matchingSrcPrefixes) == 0 </span><span class="cov8" title="1">{
                // Finding no match is not an error condition. The caller will end up
                // using the default filter chain if one was configured.
                return nil, nil
        }</span>
        // We expect at most a single matching source prefix entry at this point. If
        // we have multiple entries here, and some of their source port matchers had
        // wildcard entries, we could be left with more than one matching filter
        // chain and hence would have been flagged as an invalid configuration at
        // config validation time.
        <span class="cov8" title="1">if len(matchingSrcPrefixes) != 1 </span><span class="cov8" title="1">{
                return nil, errors.New("multiple matching filter chains")
        }</span>
        <span class="cov8" title="1">return matchingSrcPrefixes[0], nil</span>
}

// filterBySourcePorts is the last stage of the filter chain matching
// algorithm. It trims the filter chains based on the source ports.
func filterBySourcePorts(spe *sourcePrefixEntry, srcPort int) *FilterChain <span class="cov8" title="1">{
        if spe == nil </span><span class="cov8" title="1">{
                return nil
        }</span>
        // A match could be a wildcard match (this happens when the match
        // criteria does not specify source ports) or a specific port match (this
        // happens when the match criteria specifies a set of ports and the source
        // port of the incoming connection matches one of the specified ports). The
        // latter is considered to be a more specific match.
        <span class="cov8" title="1">if fc := spe.srcPortMap[srcPort]; fc != nil </span><span class="cov8" title="1">{
                return fc
        }</span>
        <span class="cov8" title="1">if fc := spe.srcPortMap[0]; fc != nil </span><span class="cov8" title="1">{
                return fc
        }</span>
        <span class="cov8" title="1">return nil</span>
}
</pre>
		
		<pre class="file" id="file216" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package xdsresource

import (
        "fmt"
        "strings"

        "google.golang.org/grpc/internal/grpcrand"
        "google.golang.org/grpc/internal/grpcutil"
        iresolver "google.golang.org/grpc/internal/resolver"
        "google.golang.org/grpc/internal/xds/matcher"
        "google.golang.org/grpc/metadata"
)

// RouteToMatcher converts a route to a Matcher to match incoming RPC's against.
func RouteToMatcher(r *Route) (*CompositeMatcher, error) <span class="cov8" title="1">{
        var pm pathMatcher
        switch </span>{
        case r.Regex != nil:<span class="cov0" title="0">
                pm = newPathRegexMatcher(r.Regex)</span>
        case r.Path != nil:<span class="cov0" title="0">
                pm = newPathExactMatcher(*r.Path, r.CaseInsensitive)</span>
        case r.Prefix != nil:<span class="cov8" title="1">
                pm = newPathPrefixMatcher(*r.Prefix, r.CaseInsensitive)</span>
        default:<span class="cov0" title="0">
                return nil, fmt.Errorf("illegal route: missing path_matcher")</span>
        }

        <span class="cov8" title="1">headerMatchers := make([]matcher.HeaderMatcher, 0, len(r.Headers))
        for _, h := range r.Headers </span><span class="cov0" title="0">{
                var matcherT matcher.HeaderMatcher
                invert := h.InvertMatch != nil &amp;&amp; *h.InvertMatch
                switch </span>{
                case h.ExactMatch != nil &amp;&amp; *h.ExactMatch != "":<span class="cov0" title="0">
                        matcherT = matcher.NewHeaderExactMatcher(h.Name, *h.ExactMatch, invert)</span>
                case h.RegexMatch != nil:<span class="cov0" title="0">
                        matcherT = matcher.NewHeaderRegexMatcher(h.Name, h.RegexMatch, invert)</span>
                case h.PrefixMatch != nil &amp;&amp; *h.PrefixMatch != "":<span class="cov0" title="0">
                        matcherT = matcher.NewHeaderPrefixMatcher(h.Name, *h.PrefixMatch, invert)</span>
                case h.SuffixMatch != nil &amp;&amp; *h.SuffixMatch != "":<span class="cov0" title="0">
                        matcherT = matcher.NewHeaderSuffixMatcher(h.Name, *h.SuffixMatch, invert)</span>
                case h.RangeMatch != nil:<span class="cov0" title="0">
                        matcherT = matcher.NewHeaderRangeMatcher(h.Name, h.RangeMatch.Start, h.RangeMatch.End, invert)</span>
                case h.PresentMatch != nil:<span class="cov0" title="0">
                        matcherT = matcher.NewHeaderPresentMatcher(h.Name, *h.PresentMatch, invert)</span>
                default:<span class="cov0" title="0">
                        return nil, fmt.Errorf("illegal route: missing header_match_specifier")</span>
                }
                <span class="cov0" title="0">headerMatchers = append(headerMatchers, matcherT)</span>
        }

        <span class="cov8" title="1">var fractionMatcher *fractionMatcher
        if r.Fraction != nil </span><span class="cov0" title="0">{
                fractionMatcher = newFractionMatcher(*r.Fraction)
        }</span>
        <span class="cov8" title="1">return newCompositeMatcher(pm, headerMatchers, fractionMatcher), nil</span>
}

// CompositeMatcher is a matcher that holds onto many matchers and aggregates
// the matching results.
type CompositeMatcher struct {
        pm  pathMatcher
        hms []matcher.HeaderMatcher
        fm  *fractionMatcher
}

func newCompositeMatcher(pm pathMatcher, hms []matcher.HeaderMatcher, fm *fractionMatcher) *CompositeMatcher <span class="cov8" title="1">{
        return &amp;CompositeMatcher{pm: pm, hms: hms, fm: fm}
}</span>

// Match returns true if all matchers return true.
func (a *CompositeMatcher) Match(info iresolver.RPCInfo) bool <span class="cov8" title="1">{
        if a.pm != nil &amp;&amp; !a.pm.match(info.Method) </span><span class="cov8" title="1">{
                return false
        }</span>

        // Call headerMatchers even if md is nil, because routes may match
        // non-presence of some headers.
        <span class="cov8" title="1">var md metadata.MD
        if info.Context != nil </span><span class="cov8" title="1">{
                md, _ = metadata.FromOutgoingContext(info.Context)
                if extraMD, ok := grpcutil.ExtraMetadata(info.Context); ok </span><span class="cov8" title="1">{
                        md = metadata.Join(md, extraMD)
                        // Remove all binary headers. They are hard to match with. May need
                        // to add back if asked by users.
                        for k := range md </span><span class="cov8" title="1">{
                                if strings.HasSuffix(k, "-bin") </span><span class="cov8" title="1">{
                                        delete(md, k)
                                }</span>
                        }
                }
        }
        <span class="cov8" title="1">for _, m := range a.hms </span><span class="cov8" title="1">{
                if !m.Match(md) </span><span class="cov8" title="1">{
                        return false
                }</span>
        }

        <span class="cov8" title="1">if a.fm != nil &amp;&amp; !a.fm.match() </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov8" title="1">return true</span>
}

func (a *CompositeMatcher) String() string <span class="cov0" title="0">{
        var ret string
        if a.pm != nil </span><span class="cov0" title="0">{
                ret += a.pm.String()
        }</span>
        <span class="cov0" title="0">for _, m := range a.hms </span><span class="cov0" title="0">{
                ret += m.String()
        }</span>
        <span class="cov0" title="0">if a.fm != nil </span><span class="cov0" title="0">{
                ret += a.fm.String()
        }</span>
        <span class="cov0" title="0">return ret</span>
}

type fractionMatcher struct {
        fraction int64 // real fraction is fraction/1,000,000.
}

func newFractionMatcher(fraction uint32) *fractionMatcher <span class="cov8" title="1">{
        return &amp;fractionMatcher{fraction: int64(fraction)}
}</span>

// RandInt63n overwrites grpcrand for control in tests.
var RandInt63n = grpcrand.Int63n

func (fm *fractionMatcher) match() bool <span class="cov8" title="1">{
        t := RandInt63n(1000000)
        return t &lt;= fm.fraction
}</span>

func (fm *fractionMatcher) String() string <span class="cov0" title="0">{
        return fmt.Sprintf("fraction:%v", fm.fraction)
}</span>

type domainMatchType int

const (
        domainMatchTypeInvalid domainMatchType = iota
        domainMatchTypeUniversal
        domainMatchTypePrefix
        domainMatchTypeSuffix
        domainMatchTypeExact
)

// Exact &gt; Suffix &gt; Prefix &gt; Universal &gt; Invalid.
func (t domainMatchType) betterThan(b domainMatchType) bool <span class="cov0" title="0">{
        return t &gt; b
}</span>

func matchTypeForDomain(d string) domainMatchType <span class="cov8" title="1">{
        if d == "" </span><span class="cov8" title="1">{
                return domainMatchTypeInvalid
        }</span>
        <span class="cov8" title="1">if d == "*" </span><span class="cov8" title="1">{
                return domainMatchTypeUniversal
        }</span>
        <span class="cov8" title="1">if strings.HasPrefix(d, "*") </span><span class="cov8" title="1">{
                return domainMatchTypeSuffix
        }</span>
        <span class="cov8" title="1">if strings.HasSuffix(d, "*") </span><span class="cov8" title="1">{
                return domainMatchTypePrefix
        }</span>
        <span class="cov8" title="1">if strings.Contains(d, "*") </span><span class="cov8" title="1">{
                return domainMatchTypeInvalid
        }</span>
        <span class="cov8" title="1">return domainMatchTypeExact</span>
}

func match(domain, host string) (domainMatchType, bool) <span class="cov8" title="1">{
        switch typ := matchTypeForDomain(domain); typ </span>{
        case domainMatchTypeInvalid:<span class="cov8" title="1">
                return typ, false</span>
        case domainMatchTypeUniversal:<span class="cov8" title="1">
                return typ, true</span>
        case domainMatchTypePrefix:<span class="cov8" title="1">
                // abc.*
                return typ, strings.HasPrefix(host, strings.TrimSuffix(domain, "*"))</span>
        case domainMatchTypeSuffix:<span class="cov8" title="1">
                // *.123
                return typ, strings.HasSuffix(host, strings.TrimPrefix(domain, "*"))</span>
        case domainMatchTypeExact:<span class="cov8" title="1">
                return typ, domain == host</span>
        default:<span class="cov0" title="0">
                return domainMatchTypeInvalid, false</span>
        }
}

// FindBestMatchingVirtualHost returns the virtual host whose domains field best
// matches host
//
// The domains field support 4 different matching pattern types:
//  - Exact match
//  - Suffix match (e.g. “*ABC”)
//  - Prefix match (e.g. “ABC*)
//  - Universal match (e.g. “*”)
//
// The best match is defined as:
//  - A match is better if it’s matching pattern type is better
//    - Exact match &gt; suffix match &gt; prefix match &gt; universal match
//  - If two matches are of the same pattern type, the longer match is better
//    - This is to compare the length of the matching pattern, e.g. “*ABCDE” &gt;
//    “*ABC”
func FindBestMatchingVirtualHost(host string, vHosts []*VirtualHost) *VirtualHost <span class="cov0" title="0">{ // Maybe move this crap to client
        var (
                matchVh   *VirtualHost
                matchType = domainMatchTypeInvalid
                matchLen  int
        )
        for _, vh := range vHosts </span><span class="cov0" title="0">{
                for _, domain := range vh.Domains </span><span class="cov0" title="0">{
                        typ, matched := match(domain, host)
                        if typ == domainMatchTypeInvalid </span><span class="cov0" title="0">{
                                // The rds response is invalid.
                                return nil
                        }</span>
                        <span class="cov0" title="0">if matchType.betterThan(typ) || matchType == typ &amp;&amp; matchLen &gt;= len(domain) || !matched </span><span class="cov0" title="0">{
                                // The previous match has better type, or the previous match has
                                // better length, or this domain isn't a match.
                                continue</span>
                        }
                        <span class="cov0" title="0">matchVh = vh
                        matchType = typ
                        matchLen = len(domain)</span>
                }
        }
        <span class="cov0" title="0">return matchVh</span>
}

// FindBestMatchingVirtualHostServer returns the virtual host whose domains field best
// matches authority.
func FindBestMatchingVirtualHostServer(authority string, vHosts []VirtualHostWithInterceptors) *VirtualHostWithInterceptors <span class="cov0" title="0">{
        var (
                matchVh   *VirtualHostWithInterceptors
                matchType = domainMatchTypeInvalid
                matchLen  int
        )
        for _, vh := range vHosts </span><span class="cov0" title="0">{
                for _, domain := range vh.Domains </span><span class="cov0" title="0">{
                        typ, matched := match(domain, authority)
                        if typ == domainMatchTypeInvalid </span><span class="cov0" title="0">{
                                // The rds response is invalid.
                                return nil
                        }</span>
                        <span class="cov0" title="0">if matchType.betterThan(typ) || matchType == typ &amp;&amp; matchLen &gt;= len(domain) || !matched </span><span class="cov0" title="0">{
                                // The previous match has better type, or the previous match has
                                // better length, or this domain isn't a match.
                                continue</span>
                        }
                        <span class="cov0" title="0">matchVh = &amp;vh
                        matchType = typ
                        matchLen = len(domain)</span>
                }
        }
        <span class="cov0" title="0">return matchVh</span>
}
</pre>
		
		<pre class="file" id="file217" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package xdsresource

import (
        "regexp"
        "strings"

        "google.golang.org/grpc/internal/grpcutil"
)

type pathMatcher interface {
        match(path string) bool
        String() string
}

type pathExactMatcher struct {
        // fullPath is all upper case if caseInsensitive is true.
        fullPath        string
        caseInsensitive bool
}

func newPathExactMatcher(p string, caseInsensitive bool) *pathExactMatcher <span class="cov8" title="1">{
        ret := &amp;pathExactMatcher{
                fullPath:        p,
                caseInsensitive: caseInsensitive,
        }
        if caseInsensitive </span><span class="cov8" title="1">{
                ret.fullPath = strings.ToUpper(p)
        }</span>
        <span class="cov8" title="1">return ret</span>
}

func (pem *pathExactMatcher) match(path string) bool <span class="cov8" title="1">{
        if pem.caseInsensitive </span><span class="cov8" title="1">{
                return pem.fullPath == strings.ToUpper(path)
        }</span>
        <span class="cov8" title="1">return pem.fullPath == path</span>
}

func (pem *pathExactMatcher) String() string <span class="cov0" title="0">{
        return "pathExact:" + pem.fullPath
}</span>

type pathPrefixMatcher struct {
        // prefix is all upper case if caseInsensitive is true.
        prefix          string
        caseInsensitive bool
}

func newPathPrefixMatcher(p string, caseInsensitive bool) *pathPrefixMatcher <span class="cov8" title="1">{
        ret := &amp;pathPrefixMatcher{
                prefix:          p,
                caseInsensitive: caseInsensitive,
        }
        if caseInsensitive </span><span class="cov8" title="1">{
                ret.prefix = strings.ToUpper(p)
        }</span>
        <span class="cov8" title="1">return ret</span>
}

func (ppm *pathPrefixMatcher) match(path string) bool <span class="cov8" title="1">{
        if ppm.caseInsensitive </span><span class="cov8" title="1">{
                return strings.HasPrefix(strings.ToUpper(path), ppm.prefix)
        }</span>
        <span class="cov8" title="1">return strings.HasPrefix(path, ppm.prefix)</span>
}

func (ppm *pathPrefixMatcher) String() string <span class="cov0" title="0">{
        return "pathPrefix:" + ppm.prefix
}</span>

type pathRegexMatcher struct {
        re *regexp.Regexp
}

func newPathRegexMatcher(re *regexp.Regexp) *pathRegexMatcher <span class="cov8" title="1">{
        return &amp;pathRegexMatcher{re: re}
}</span>

func (prm *pathRegexMatcher) match(path string) bool <span class="cov8" title="1">{
        return grpcutil.FullMatchWithRegex(prm.re, path)
}</span>

func (prm *pathRegexMatcher) String() string <span class="cov0" title="0">{
        return "pathRegex:" + prm.re.String()
}</span>
</pre>
		
		<pre class="file" id="file218" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package xdsresource

import (
        "net/url"
        "sort"
        "strings"

        "google.golang.org/grpc/internal/envconfig"
)

// FederationScheme is the scheme of a federation resource name.
const FederationScheme = "xdstp"

// Name contains the parsed component of an xDS resource name.
//
// An xDS resource name is in the format of
// xdstp://[{authority}]/{resource type}/{id/*}?{context parameters}{#processing directive,*}
//
// See
// https://github.com/cncf/xds/blob/main/proposals/TP1-xds-transport-next.md#uri-based-xds-resource-names
// for details, and examples.
type Name struct {
        Scheme    string
        Authority string
        Type      string
        ID        string

        ContextParams map[string]string

        processingDirective string
}

// ParseName splits the name and returns a struct representation of the Name.
//
// If the name isn't a valid new-style xDS name, field ID is set to the input.
// Note that this is not an error, because we still support the old-style
// resource names (those not starting with "xdstp:").
//
// The caller can tell if the parsing is successful by checking the returned
// Scheme.
func ParseName(name string) *Name <span class="cov8" title="1">{
        if !envconfig.XDSFederation </span><span class="cov8" title="1">{
                // Return "" scheme to use the default authority for the server.
                return &amp;Name{ID: name}
        }</span>
        <span class="cov8" title="1">if !strings.Contains(name, "://") </span><span class="cov8" title="1">{
                // Only the long form URL, with ://, is valid.
                return &amp;Name{ID: name}
        }</span>
        <span class="cov8" title="1">parsed, err := url.Parse(name)
        if err != nil </span><span class="cov0" title="0">{
                return &amp;Name{ID: name}
        }</span>

        <span class="cov8" title="1">ret := &amp;Name{
                Scheme:    parsed.Scheme,
                Authority: parsed.Host,
        }
        split := strings.SplitN(parsed.Path, "/", 3)
        if len(split) &lt; 3 </span><span class="cov8" title="1">{
                // Path is in the format of "/type/id". There must be at least 3
                // segments after splitting.
                return &amp;Name{ID: name}
        }</span>
        <span class="cov8" title="1">ret.Type = split[1]
        ret.ID = split[2]
        if len(parsed.Query()) != 0 </span><span class="cov8" title="1">{
                ret.ContextParams = make(map[string]string)
                for k, vs := range parsed.Query() </span><span class="cov8" title="1">{
                        if len(vs) &gt; 0 </span><span class="cov8" title="1">{
                                // We only keep one value of each key. Behavior for multiple values
                                // is undefined.
                                ret.ContextParams[k] = vs[0]
                        }</span>
                }
        }
        // TODO: processing directive (the part comes after "#" in the URL, stored
        // in parsed.RawFragment) is kept but not processed. Add support for that
        // when it's needed.
        <span class="cov8" title="1">ret.processingDirective = parsed.RawFragment
        return ret</span>
}

// String returns a canonicalized string of name. The context parameters are
// sorted by the keys.
func (n *Name) String() string <span class="cov8" title="1">{
        if n.Scheme == "" </span><span class="cov8" title="1">{
                return n.ID
        }</span>

        // Sort and build query.
        <span class="cov8" title="1">keys := make([]string, 0, len(n.ContextParams))
        for k := range n.ContextParams </span><span class="cov8" title="1">{
                keys = append(keys, k)
        }</span>
        <span class="cov8" title="1">sort.Strings(keys)
        var pairs []string
        for _, k := range keys </span><span class="cov8" title="1">{
                pairs = append(pairs, strings.Join([]string{k, n.ContextParams[k]}, "="))
        }</span>
        <span class="cov8" title="1">rawQuery := strings.Join(pairs, "&amp;")

        path := n.Type
        if n.ID != "" </span><span class="cov8" title="1">{
                path = "/" + path + "/" + n.ID
        }</span>

        <span class="cov8" title="1">tempURL := &amp;url.URL{
                Scheme:      n.Scheme,
                Host:        n.Authority,
                Path:        path,
                RawQuery:    rawQuery,
                RawFragment: n.processingDirective,
        }
        return tempURL.String()</span>
}
</pre>
		
		<pre class="file" id="file219" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package xdsresource

import (
        "time"

        v3discoverypb "github.com/envoyproxy/go-control-plane/envoy/service/discovery/v3"
        "github.com/golang/protobuf/proto"
        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource/version"
        "google.golang.org/protobuf/types/known/anypb"
)

// UpdateValidatorFunc performs validations on update structs using
// context/logic available at the xdsClient layer. Since these validation are
// performed on internal update structs, they can be shared between different
// API clients.
type UpdateValidatorFunc func(interface{}) error

// UpdateMetadata contains the metadata for each update, including timestamp,
// raw message, and so on.
type UpdateMetadata struct {
        // Status is the status of this resource, e.g. ACKed, NACKed, or
        // Not_exist(removed).
        Status ServiceStatus
        // Version is the version of the xds response. Note that this is the version
        // of the resource in use (previous ACKed). If a response is NACKed, the
        // NACKed version is in ErrState.
        Version string
        // Timestamp is when the response is received.
        Timestamp time.Time
        // ErrState is set when the update is NACKed.
        ErrState *UpdateErrorMetadata
}

// IsListenerResource returns true if the provider URL corresponds to an xDS
// Listener resource.
func IsListenerResource(url string) bool <span class="cov8" title="1">{
        return url == version.V2ListenerURL || url == version.V3ListenerURL
}</span>

// IsHTTPConnManagerResource returns true if the provider URL corresponds to an xDS
// HTTPConnManager resource.
func IsHTTPConnManagerResource(url string) bool <span class="cov8" title="1">{
        return url == version.V2HTTPConnManagerURL || url == version.V3HTTPConnManagerURL
}</span>

// IsRouteConfigResource returns true if the provider URL corresponds to an xDS
// RouteConfig resource.
func IsRouteConfigResource(url string) bool <span class="cov8" title="1">{
        return url == version.V2RouteConfigURL || url == version.V3RouteConfigURL
}</span>

// IsClusterResource returns true if the provider URL corresponds to an xDS
// Cluster resource.
func IsClusterResource(url string) bool <span class="cov8" title="1">{
        return url == version.V2ClusterURL || url == version.V3ClusterURL
}</span>

// IsEndpointsResource returns true if the provider URL corresponds to an xDS
// Endpoints resource.
func IsEndpointsResource(url string) bool <span class="cov8" title="1">{
        return url == version.V2EndpointsURL || url == version.V3EndpointsURL
}</span>

// unwrapResource unwraps and returns the inner resource if it's in a resource
// wrapper. The original resource is returned if it's not wrapped.
func unwrapResource(r *anypb.Any) (*anypb.Any, error) <span class="cov8" title="1">{
        url := r.GetTypeUrl()
        if url != version.V2ResourceWrapperURL &amp;&amp; url != version.V3ResourceWrapperURL </span><span class="cov8" title="1">{
                // Not wrapped.
                return r, nil
        }</span>
        <span class="cov8" title="1">inner := &amp;v3discoverypb.Resource{}
        if err := proto.Unmarshal(r.GetValue(), inner); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return inner.Resource, nil</span>
}

// ServiceStatus is the status of the update.
type ServiceStatus int

const (
        // ServiceStatusUnknown is the default state, before a watch is started for
        // the resource.
        ServiceStatusUnknown ServiceStatus = iota
        // ServiceStatusRequested is when the watch is started, but before and
        // response is received.
        ServiceStatusRequested
        // ServiceStatusNotExist is when the resource doesn't exist in
        // state-of-the-world responses (e.g. LDS and CDS), which means the resource
        // is removed by the management server.
        ServiceStatusNotExist // Resource is removed in the server, in LDS/CDS.
        // ServiceStatusACKed is when the resource is ACKed.
        ServiceStatusACKed
        // ServiceStatusNACKed is when the resource is NACKed.
        ServiceStatusNACKed
)

// UpdateErrorMetadata is part of UpdateMetadata. It contains the error state
// when a response is NACKed.
type UpdateErrorMetadata struct {
        // Version is the version of the NACKed response.
        Version string
        // Err contains why the response was NACKed.
        Err error
        // Timestamp is when the NACKed response was received.
        Timestamp time.Time
}

// UpdateWithMD contains the raw message of the update and the metadata,
// including version, raw message, timestamp.
//
// This is to be used for config dump and CSDS, not directly by users (like
// resolvers/balancers).
type UpdateWithMD struct {
        MD  UpdateMetadata
        Raw *anypb.Any
}

// ResourceType identifies resources in a transport protocol agnostic way. These
// will be used in transport version agnostic code, while the versioned API
// clients will map these to appropriate version URLs.
type ResourceType int

// Version agnostic resource type constants.
const (
        UnknownResource ResourceType = iota
        ListenerResource
        HTTPConnManagerResource
        RouteConfigResource
        ClusterResource
        EndpointsResource
)

func (r ResourceType) String() string <span class="cov0" title="0">{
        switch r </span>{
        case ListenerResource:<span class="cov0" title="0">
                return "ListenerResource"</span>
        case HTTPConnManagerResource:<span class="cov0" title="0">
                return "HTTPConnManagerResource"</span>
        case RouteConfigResource:<span class="cov0" title="0">
                return "RouteConfigResource"</span>
        case ClusterResource:<span class="cov0" title="0">
                return "ClusterResource"</span>
        case EndpointsResource:<span class="cov0" title="0">
                return "EndpointsResource"</span>
        default:<span class="cov0" title="0">
                return "UnknownResource"</span>
        }
}
</pre>
		
		<pre class="file" id="file220" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package xdsresource

import (
        "regexp"
        "time"

        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/internal/xds/matcher"
        "google.golang.org/grpc/xds/internal/clusterspecifier"
        "google.golang.org/grpc/xds/internal/httpfilter"
        "google.golang.org/protobuf/types/known/anypb"
)

// RouteConfigUpdate contains information received in an RDS response, which is
// of interest to the registered RDS watcher.
type RouteConfigUpdate struct {
        VirtualHosts []*VirtualHost
        // ClusterSpecifierPlugins are the LB Configurations for any
        // ClusterSpecifierPlugins referenced by the Route Table.
        ClusterSpecifierPlugins map[string]clusterspecifier.BalancerConfig
        // Raw is the resource from the xds response.
        Raw *anypb.Any
}

// VirtualHost contains the routes for a list of Domains.
//
// Note that the domains in this slice can be a wildcard, not an exact string.
// The consumer of this struct needs to find the best match for its hostname.
type VirtualHost struct {
        Domains []string
        // Routes contains a list of routes, each containing matchers and
        // corresponding action.
        Routes []*Route
        // HTTPFilterConfigOverride contains any HTTP filter config overrides for
        // the virtual host which may be present.  An individual filter's override
        // may be unused if the matching Route contains an override for that
        // filter.
        HTTPFilterConfigOverride map[string]httpfilter.FilterConfig
        RetryConfig              *RetryConfig
}

// RetryConfig contains all retry-related configuration in either a VirtualHost
// or Route.
type RetryConfig struct {
        // RetryOn is a set of status codes on which to retry.  Only Canceled,
        // DeadlineExceeded, Internal, ResourceExhausted, and Unavailable are
        // supported; any other values will be omitted.
        RetryOn      map[codes.Code]bool
        NumRetries   uint32       // maximum number of retry attempts
        RetryBackoff RetryBackoff // retry backoff policy
}

// RetryBackoff describes the backoff policy for retries.
type RetryBackoff struct {
        BaseInterval time.Duration // initial backoff duration between attempts
        MaxInterval  time.Duration // maximum backoff duration
}

// HashPolicyType specifies the type of HashPolicy from a received RDS Response.
type HashPolicyType int

const (
        // HashPolicyTypeHeader specifies to hash a Header in the incoming request.
        HashPolicyTypeHeader HashPolicyType = iota
        // HashPolicyTypeChannelID specifies to hash a unique Identifier of the
        // Channel. In grpc-go, this will be done using the ClientConn pointer.
        HashPolicyTypeChannelID
)

// HashPolicy specifies the HashPolicy if the upstream cluster uses a hashing
// load balancer.
type HashPolicy struct {
        HashPolicyType HashPolicyType
        Terminal       bool
        // Fields used for type HEADER.
        HeaderName        string
        Regex             *regexp.Regexp
        RegexSubstitution string
}

// RouteActionType is the action of the route from a received RDS response.
type RouteActionType int

const (
        // RouteActionUnsupported are routing types currently unsupported by grpc.
        // According to A36, "A Route with an inappropriate action causes RPCs
        // matching that route to fail."
        RouteActionUnsupported RouteActionType = iota
        // RouteActionRoute is the expected route type on the client side. Route
        // represents routing a request to some upstream cluster. On the client
        // side, if an RPC matches to a route that is not RouteActionRoute, the RPC
        // will fail according to A36.
        RouteActionRoute
        // RouteActionNonForwardingAction is the expected route type on the server
        // side. NonForwardingAction represents when a route will generate a
        // response directly, without forwarding to an upstream host.
        RouteActionNonForwardingAction
)

// Route is both a specification of how to match a request as well as an
// indication of the action to take upon match.
type Route struct {
        Path   *string
        Prefix *string
        Regex  *regexp.Regexp
        // Indicates if prefix/path matching should be case insensitive. The default
        // is false (case sensitive).
        CaseInsensitive bool
        Headers         []*HeaderMatcher
        Fraction        *uint32

        HashPolicies []*HashPolicy

        // If the matchers above indicate a match, the below configuration is used.
        // If MaxStreamDuration is nil, it indicates neither of the route action's
        // max_stream_duration fields (grpc_timeout_header_max nor
        // max_stream_duration) were set.  In this case, the ListenerUpdate's
        // MaxStreamDuration field should be used.  If MaxStreamDuration is set to
        // an explicit zero duration, the application's deadline should be used.
        MaxStreamDuration *time.Duration
        // HTTPFilterConfigOverride contains any HTTP filter config overrides for
        // the route which may be present.  An individual filter's override may be
        // unused if the matching WeightedCluster contains an override for that
        // filter.
        HTTPFilterConfigOverride map[string]httpfilter.FilterConfig
        RetryConfig              *RetryConfig

        ActionType RouteActionType

        // Only one of the following fields (WeightedClusters or
        // ClusterSpecifierPlugin) will be set for a route.
        WeightedClusters map[string]WeightedCluster
        // ClusterSpecifierPlugin is the name of the Cluster Specifier Plugin that
        // this Route is linked to, if specified by xDS.
        ClusterSpecifierPlugin string
}

// WeightedCluster contains settings for an xds ActionType.WeightedCluster.
type WeightedCluster struct {
        // Weight is the relative weight of the cluster.  It will never be zero.
        Weight uint32
        // HTTPFilterConfigOverride contains any HTTP filter config overrides for
        // the weighted cluster which may be present.
        HTTPFilterConfigOverride map[string]httpfilter.FilterConfig
}

// HeaderMatcher represents header matchers.
type HeaderMatcher struct {
        Name         string
        InvertMatch  *bool
        ExactMatch   *string
        RegexMatch   *regexp.Regexp
        PrefixMatch  *string
        SuffixMatch  *string
        RangeMatch   *Int64Range
        PresentMatch *bool
}

// Int64Range is a range for header range match.
type Int64Range struct {
        Start int64
        End   int64
}

// SecurityConfig contains the security configuration received as part of the
// Cluster resource on the client-side, and as part of the Listener resource on
// the server-side.
type SecurityConfig struct {
        // RootInstanceName identifies the certProvider plugin to be used to fetch
        // root certificates. This instance name will be resolved to the plugin name
        // and its associated configuration from the certificate_providers field of
        // the bootstrap file.
        RootInstanceName string
        // RootCertName is the certificate name to be passed to the plugin (looked
        // up from the bootstrap file) while fetching root certificates.
        RootCertName string
        // IdentityInstanceName identifies the certProvider plugin to be used to
        // fetch identity certificates. This instance name will be resolved to the
        // plugin name and its associated configuration from the
        // certificate_providers field of the bootstrap file.
        IdentityInstanceName string
        // IdentityCertName is the certificate name to be passed to the plugin
        // (looked up from the bootstrap file) while fetching identity certificates.
        IdentityCertName string
        // SubjectAltNameMatchers is an optional list of match criteria for SANs
        // specified on the peer certificate. Used only on the client-side.
        //
        // Some intricacies:
        // - If this field is empty, then any peer certificate is accepted.
        // - If the peer certificate contains a wildcard DNS SAN, and an `exact`
        //   matcher is configured, a wildcard DNS match is performed instead of a
        //   regular string comparison.
        SubjectAltNameMatchers []matcher.StringMatcher
        // RequireClientCert indicates if the server handshake process expects the
        // client to present a certificate. Set to true when performing mTLS. Used
        // only on the server-side.
        RequireClientCert bool
}

// Equal returns true if sc is equal to other.
func (sc *SecurityConfig) Equal(other *SecurityConfig) bool <span class="cov8" title="1">{
        switch </span>{
        case sc == nil &amp;&amp; other == nil:<span class="cov8" title="1">
                return true</span>
        case (sc != nil) != (other != nil):<span class="cov0" title="0">
                return false</span>
        }
        <span class="cov8" title="1">switch </span>{
        case sc.RootInstanceName != other.RootInstanceName:<span class="cov8" title="1">
                return false</span>
        case sc.RootCertName != other.RootCertName:<span class="cov0" title="0">
                return false</span>
        case sc.IdentityInstanceName != other.IdentityInstanceName:<span class="cov8" title="1">
                return false</span>
        case sc.IdentityCertName != other.IdentityCertName:<span class="cov0" title="0">
                return false</span>
        case sc.RequireClientCert != other.RequireClientCert:<span class="cov0" title="0">
                return false</span>
        default:<span class="cov8" title="1">
                if len(sc.SubjectAltNameMatchers) != len(other.SubjectAltNameMatchers) </span><span class="cov0" title="0">{
                        return false
                }</span>
                <span class="cov8" title="1">for i := 0; i &lt; len(sc.SubjectAltNameMatchers); i++ </span><span class="cov8" title="1">{
                        if !sc.SubjectAltNameMatchers[i].Equal(other.SubjectAltNameMatchers[i]) </span><span class="cov0" title="0">{
                                return false
                        }</span>
                }
        }
        <span class="cov8" title="1">return true</span>
}

// RouteConfigUpdateErrTuple is a tuple with the update and error. It contains
// the results from unmarshal functions. It's used to pass unmarshal results of
// multiple resources together, e.g. in maps like `map[string]{Update,error}`.
type RouteConfigUpdateErrTuple struct {
        Update RouteConfigUpdate
        Err    error
}
</pre>
		
		<pre class="file" id="file221" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// Package xdsresource contains functions to proto xds updates (unmarshal from
// proto), and types for the resource updates.
package xdsresource

import (
        "errors"
        "fmt"
        "strings"
        "time"

        "google.golang.org/grpc/internal/grpclog"
        "google.golang.org/protobuf/types/known/anypb"
)

// UnmarshalOptions wraps the input parameters for `UnmarshalXxx` functions.
type UnmarshalOptions struct {
        // Version is the version of the received response.
        Version string
        // Resources are the xDS resources resources in the received response.
        Resources []*anypb.Any
        // Logger is the prefix logger to be used during unmarshaling.
        Logger *grpclog.PrefixLogger
        // UpdateValidator is a post unmarshal validation check provided by the
        // upper layer.
        UpdateValidator UpdateValidatorFunc
}

// processAllResources unmarshals and validates the resources, populates the
// provided ret (a map), and returns metadata and error.
//
// After this function, the ret map will be populated with both valid and
// invalid updates. Invalid resources will have an entry with the key as the
// resource name, value as an empty update.
//
// The type of the resource is determined by the type of ret. E.g.
// map[string]ListenerUpdate means this is for LDS.
func processAllResources(opts *UnmarshalOptions, ret interface{}) (UpdateMetadata, error) <span class="cov8" title="1">{
        timestamp := time.Now()
        md := UpdateMetadata{
                Version:   opts.Version,
                Timestamp: timestamp,
        }
        var topLevelErrors []error
        perResourceErrors := make(map[string]error)

        for _, r := range opts.Resources </span><span class="cov8" title="1">{
                switch ret2 := ret.(type) </span>{
                case map[string]ListenerUpdateErrTuple:<span class="cov8" title="1">
                        name, update, err := unmarshalListenerResource(r, opts.UpdateValidator, opts.Logger)
                        name = ParseName(name).String()
                        if err == nil </span><span class="cov8" title="1">{
                                ret2[name] = ListenerUpdateErrTuple{Update: update}
                                continue</span>
                        }
                        <span class="cov8" title="1">if name == "" </span><span class="cov8" title="1">{
                                topLevelErrors = append(topLevelErrors, err)
                                continue</span>
                        }
                        <span class="cov8" title="1">perResourceErrors[name] = err
                        // Add place holder in the map so we know this resource name was in
                        // the response.
                        ret2[name] = ListenerUpdateErrTuple{Err: err}</span>
                case map[string]RouteConfigUpdateErrTuple:<span class="cov8" title="1">
                        name, update, err := unmarshalRouteConfigResource(r, opts.Logger)
                        name = ParseName(name).String()
                        if err == nil </span><span class="cov8" title="1">{
                                ret2[name] = RouteConfigUpdateErrTuple{Update: update}
                                continue</span>
                        }
                        <span class="cov8" title="1">if name == "" </span><span class="cov8" title="1">{
                                topLevelErrors = append(topLevelErrors, err)
                                continue</span>
                        }
                        <span class="cov8" title="1">perResourceErrors[name] = err
                        // Add place holder in the map so we know this resource name was in
                        // the response.
                        ret2[name] = RouteConfigUpdateErrTuple{Err: err}</span>
                case map[string]ClusterUpdateErrTuple:<span class="cov8" title="1">
                        name, update, err := unmarshalClusterResource(r, opts.UpdateValidator, opts.Logger)
                        name = ParseName(name).String()
                        if err == nil </span><span class="cov8" title="1">{
                                ret2[name] = ClusterUpdateErrTuple{Update: update}
                                continue</span>
                        }
                        <span class="cov8" title="1">if name == "" </span><span class="cov8" title="1">{
                                topLevelErrors = append(topLevelErrors, err)
                                continue</span>
                        }
                        <span class="cov8" title="1">perResourceErrors[name] = err
                        // Add place holder in the map so we know this resource name was in
                        // the response.
                        ret2[name] = ClusterUpdateErrTuple{Err: err}</span>
                case map[string]EndpointsUpdateErrTuple:<span class="cov8" title="1">
                        name, update, err := unmarshalEndpointsResource(r, opts.Logger)
                        name = ParseName(name).String()
                        if err == nil </span><span class="cov8" title="1">{
                                ret2[name] = EndpointsUpdateErrTuple{Update: update}
                                continue</span>
                        }
                        <span class="cov8" title="1">if name == "" </span><span class="cov8" title="1">{
                                topLevelErrors = append(topLevelErrors, err)
                                continue</span>
                        }
                        <span class="cov8" title="1">perResourceErrors[name] = err
                        // Add place holder in the map so we know this resource name was in
                        // the response.
                        ret2[name] = EndpointsUpdateErrTuple{Err: err}</span>
                }
        }

        <span class="cov8" title="1">if len(topLevelErrors) == 0 &amp;&amp; len(perResourceErrors) == 0 </span><span class="cov8" title="1">{
                md.Status = ServiceStatusACKed
                return md, nil
        }</span>

        <span class="cov8" title="1">var typeStr string
        switch ret.(type) </span>{
        case map[string]ListenerUpdate:<span class="cov0" title="0">
                typeStr = "LDS"</span>
        case map[string]RouteConfigUpdate:<span class="cov0" title="0">
                typeStr = "RDS"</span>
        case map[string]ClusterUpdate:<span class="cov0" title="0">
                typeStr = "CDS"</span>
        case map[string]EndpointsUpdate:<span class="cov0" title="0">
                typeStr = "EDS"</span>
        }

        <span class="cov8" title="1">md.Status = ServiceStatusNACKed
        errRet := combineErrors(typeStr, topLevelErrors, perResourceErrors)
        md.ErrState = &amp;UpdateErrorMetadata{
                Version:   opts.Version,
                Err:       errRet,
                Timestamp: timestamp,
        }
        return md, errRet</span>
}

func combineErrors(rType string, topLevelErrors []error, perResourceErrors map[string]error) error <span class="cov8" title="1">{
        var errStrB strings.Builder
        errStrB.WriteString(fmt.Sprintf("error parsing %q response: ", rType))
        if len(topLevelErrors) &gt; 0 </span><span class="cov8" title="1">{
                errStrB.WriteString("top level errors: ")
                for i, err := range topLevelErrors </span><span class="cov8" title="1">{
                        if i != 0 </span><span class="cov0" title="0">{
                                errStrB.WriteString(";\n")
                        }</span>
                        <span class="cov8" title="1">errStrB.WriteString(err.Error())</span>
                }
        }
        <span class="cov8" title="1">if len(perResourceErrors) &gt; 0 </span><span class="cov8" title="1">{
                var i int
                for name, err := range perResourceErrors </span><span class="cov8" title="1">{
                        if i != 0 </span><span class="cov0" title="0">{
                                errStrB.WriteString(";\n")
                        }</span>
                        <span class="cov8" title="1">i++
                        errStrB.WriteString(fmt.Sprintf("resource %q: %v", name, err.Error()))</span>
                }
        }
        <span class="cov8" title="1">return errors.New(errStrB.String())</span>
}
</pre>
		
		<pre class="file" id="file222" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package xdsresource

import (
        "errors"
        "fmt"
        "net"
        "strconv"
        "time"

        v3clusterpb "github.com/envoyproxy/go-control-plane/envoy/config/cluster/v3"
        v3corepb "github.com/envoyproxy/go-control-plane/envoy/config/core/v3"
        v3aggregateclusterpb "github.com/envoyproxy/go-control-plane/envoy/extensions/clusters/aggregate/v3"
        v3tlspb "github.com/envoyproxy/go-control-plane/envoy/extensions/transport_sockets/tls/v3"
        "github.com/golang/protobuf/proto"
        "google.golang.org/grpc/internal/envconfig"
        "google.golang.org/grpc/internal/grpclog"
        "google.golang.org/grpc/internal/pretty"
        "google.golang.org/grpc/internal/xds/matcher"
        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource/version"
        "google.golang.org/protobuf/types/known/anypb"
)

// TransportSocket proto message has a `name` field which is expected to be set
// to this value by the management server.
const transportSocketName = "envoy.transport_sockets.tls"

// UnmarshalCluster processes resources received in an CDS response, validates
// them, and transforms them into a native struct which contains only fields we
// are interested in.
func UnmarshalCluster(opts *UnmarshalOptions) (map[string]ClusterUpdateErrTuple, UpdateMetadata, error) <span class="cov8" title="1">{
        update := make(map[string]ClusterUpdateErrTuple)
        md, err := processAllResources(opts, update)
        return update, md, err
}</span>

func unmarshalClusterResource(r *anypb.Any, f UpdateValidatorFunc, logger *grpclog.PrefixLogger) (string, ClusterUpdate, error) <span class="cov8" title="1">{
        r, err := unwrapResource(r)
        if err != nil </span><span class="cov0" title="0">{
                return "", ClusterUpdate{}, fmt.Errorf("failed to unwrap resource: %v", err)
        }</span>

        <span class="cov8" title="1">if !IsClusterResource(r.GetTypeUrl()) </span><span class="cov8" title="1">{
                return "", ClusterUpdate{}, fmt.Errorf("unexpected resource type: %q ", r.GetTypeUrl())
        }</span>

        <span class="cov8" title="1">cluster := &amp;v3clusterpb.Cluster{}
        if err := proto.Unmarshal(r.GetValue(), cluster); err != nil </span><span class="cov8" title="1">{
                return "", ClusterUpdate{}, fmt.Errorf("failed to unmarshal resource: %v", err)
        }</span>
        <span class="cov8" title="1">logger.Infof("Resource with name: %v, type: %T, contains: %v", cluster.GetName(), cluster, pretty.ToJSON(cluster))
        cu, err := validateClusterAndConstructClusterUpdate(cluster)
        if err != nil </span><span class="cov8" title="1">{
                return cluster.GetName(), ClusterUpdate{}, err
        }</span>
        <span class="cov8" title="1">cu.Raw = r
        if f != nil </span><span class="cov0" title="0">{
                if err := f(cu); err != nil </span><span class="cov0" title="0">{
                        return "", ClusterUpdate{}, err
                }</span>
        }

        <span class="cov8" title="1">return cluster.GetName(), cu, nil</span>
}

const (
        defaultRingHashMinSize = 1024
        defaultRingHashMaxSize = 8 * 1024 * 1024 // 8M
        ringHashSizeUpperBound = 8 * 1024 * 1024 // 8M
)

func validateClusterAndConstructClusterUpdate(cluster *v3clusterpb.Cluster) (ClusterUpdate, error) <span class="cov8" title="1">{
        var lbPolicy *ClusterLBPolicyRingHash
        switch cluster.GetLbPolicy() </span>{
        case v3clusterpb.Cluster_ROUND_ROBIN:<span class="cov8" title="1">
                lbPolicy = nil</span> // The default is round_robin, and there's no config to set.
        case v3clusterpb.Cluster_RING_HASH:<span class="cov8" title="1">
                if !envconfig.XDSRingHash </span><span class="cov0" title="0">{
                        return ClusterUpdate{}, fmt.Errorf("unexpected lbPolicy %v in response: %+v", cluster.GetLbPolicy(), cluster)
                }</span>
                <span class="cov8" title="1">rhc := cluster.GetRingHashLbConfig()
                if rhc.GetHashFunction() != v3clusterpb.Cluster_RingHashLbConfig_XX_HASH </span><span class="cov8" title="1">{
                        return ClusterUpdate{}, fmt.Errorf("unsupported ring_hash hash function %v in response: %+v", rhc.GetHashFunction(), cluster)
                }</span>
                // Minimum defaults to 1024 entries, and limited to 8M entries Maximum
                // defaults to 8M entries, and limited to 8M entries
                <span class="cov8" title="1">var minSize, maxSize uint64 = defaultRingHashMinSize, defaultRingHashMaxSize
                if min := rhc.GetMinimumRingSize(); min != nil </span><span class="cov8" title="1">{
                        if min.GetValue() &gt; ringHashSizeUpperBound </span><span class="cov8" title="1">{
                                return ClusterUpdate{}, fmt.Errorf("unexpected ring_hash mininum ring size %v in response: %+v", min.GetValue(), cluster)
                        }</span>
                        <span class="cov8" title="1">minSize = min.GetValue()</span>
                }
                <span class="cov8" title="1">if max := rhc.GetMaximumRingSize(); max != nil </span><span class="cov8" title="1">{
                        if max.GetValue() &gt; ringHashSizeUpperBound </span><span class="cov8" title="1">{
                                return ClusterUpdate{}, fmt.Errorf("unexpected ring_hash maxinum ring size %v in response: %+v", max.GetValue(), cluster)
                        }</span>
                        <span class="cov8" title="1">maxSize = max.GetValue()</span>
                }
                <span class="cov8" title="1">if minSize &gt; maxSize </span><span class="cov8" title="1">{
                        return ClusterUpdate{}, fmt.Errorf("ring_hash config min size %v is greater than max %v", minSize, maxSize)
                }</span>
                <span class="cov8" title="1">lbPolicy = &amp;ClusterLBPolicyRingHash{MinimumRingSize: minSize, MaximumRingSize: maxSize}</span>
        default:<span class="cov8" title="1">
                return ClusterUpdate{}, fmt.Errorf("unexpected lbPolicy %v in response: %+v", cluster.GetLbPolicy(), cluster)</span>
        }

        // Process security configuration received from the control plane iff the
        // corresponding environment variable is set.
        <span class="cov8" title="1">var sc *SecurityConfig
        if envconfig.XDSClientSideSecurity </span><span class="cov8" title="1">{
                var err error
                if sc, err = securityConfigFromCluster(cluster); err != nil </span><span class="cov8" title="1">{
                        return ClusterUpdate{}, err
                }</span>
        }

        // Process outlier detection received from the control plane iff the
        // corresponding environment variable is set.
        <span class="cov8" title="1">var od *OutlierDetection
        if envconfig.XDSOutlierDetection </span><span class="cov8" title="1">{
                var err error
                if od, err = outlierConfigFromCluster(cluster); err != nil </span><span class="cov8" title="1">{
                        return ClusterUpdate{}, err
                }</span>
        }

        <span class="cov8" title="1">ret := ClusterUpdate{
                ClusterName:      cluster.GetName(),
                SecurityCfg:      sc,
                MaxRequests:      circuitBreakersFromCluster(cluster),
                LBPolicy:         lbPolicy,
                OutlierDetection: od,
        }

        // Note that this is different from the gRFC (gRFC A47 says to include the
        // full ServerConfig{URL,creds,server feature} here). This information is
        // not available here, because this function doesn't have access to the
        // xdsclient bootstrap information now (can be added if necessary). The
        // ServerConfig will be read and populated by the CDS balancer when
        // processing this field.
        if cluster.GetLrsServer().GetSelf() != nil </span><span class="cov8" title="1">{
                ret.LRSServerConfig = ClusterLRSServerSelf
        }</span>

        // Validate and set cluster type from the response.
        <span class="cov8" title="1">switch </span>{
        case cluster.GetType() == v3clusterpb.Cluster_EDS:<span class="cov8" title="1">
                if configsource := cluster.GetEdsClusterConfig().GetEdsConfig(); configsource.GetAds() == nil &amp;&amp; configsource.GetSelf() == nil </span><span class="cov8" title="1">{
                        return ClusterUpdate{}, fmt.Errorf("CDS's EDS config source is not ADS or Self: %+v", cluster)
                }</span>
                <span class="cov8" title="1">ret.ClusterType = ClusterTypeEDS
                ret.EDSServiceName = cluster.GetEdsClusterConfig().GetServiceName()
                return ret, nil</span>
        case cluster.GetType() == v3clusterpb.Cluster_LOGICAL_DNS:<span class="cov8" title="1">
                if !envconfig.XDSAggregateAndDNS </span><span class="cov0" title="0">{
                        return ClusterUpdate{}, fmt.Errorf("unsupported cluster type (%v, %v) in response: %+v", cluster.GetType(), cluster.GetClusterType(), cluster)
                }</span>
                <span class="cov8" title="1">ret.ClusterType = ClusterTypeLogicalDNS
                dnsHN, err := dnsHostNameFromCluster(cluster)
                if err != nil </span><span class="cov8" title="1">{
                        return ClusterUpdate{}, err
                }</span>
                <span class="cov8" title="1">ret.DNSHostName = dnsHN
                return ret, nil</span>
        case cluster.GetClusterType() != nil &amp;&amp; cluster.GetClusterType().Name == "envoy.clusters.aggregate":<span class="cov8" title="1">
                if !envconfig.XDSAggregateAndDNS </span><span class="cov0" title="0">{
                        return ClusterUpdate{}, fmt.Errorf("unsupported cluster type (%v, %v) in response: %+v", cluster.GetType(), cluster.GetClusterType(), cluster)
                }</span>
                <span class="cov8" title="1">clusters := &amp;v3aggregateclusterpb.ClusterConfig{}
                if err := proto.Unmarshal(cluster.GetClusterType().GetTypedConfig().GetValue(), clusters); err != nil </span><span class="cov0" title="0">{
                        return ClusterUpdate{}, fmt.Errorf("failed to unmarshal resource: %v", err)
                }</span>
                <span class="cov8" title="1">ret.ClusterType = ClusterTypeAggregate
                ret.PrioritizedClusterNames = clusters.Clusters
                return ret, nil</span>
        default:<span class="cov8" title="1">
                return ClusterUpdate{}, fmt.Errorf("unsupported cluster type (%v, %v) in response: %+v", cluster.GetType(), cluster.GetClusterType(), cluster)</span>
        }
}

// dnsHostNameFromCluster extracts the DNS host name from the cluster's load
// assignment.
//
// There should be exactly one locality, with one endpoint, whose address
// contains the address and port.
func dnsHostNameFromCluster(cluster *v3clusterpb.Cluster) (string, error) <span class="cov8" title="1">{
        loadAssignment := cluster.GetLoadAssignment()
        if loadAssignment == nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("load_assignment not present for LOGICAL_DNS cluster")
        }</span>
        <span class="cov8" title="1">if len(loadAssignment.GetEndpoints()) != 1 </span><span class="cov8" title="1">{
                return "", fmt.Errorf("load_assignment for LOGICAL_DNS cluster must have exactly one locality, got: %+v", loadAssignment)
        }</span>
        <span class="cov8" title="1">endpoints := loadAssignment.GetEndpoints()[0].GetLbEndpoints()
        if len(endpoints) != 1 </span><span class="cov0" title="0">{
                return "", fmt.Errorf("locality for LOGICAL_DNS cluster must have exactly one endpoint, got: %+v", endpoints)
        }</span>
        <span class="cov8" title="1">endpoint := endpoints[0].GetEndpoint()
        if endpoint == nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("endpoint for LOGICAL_DNS cluster not set")
        }</span>
        <span class="cov8" title="1">socketAddr := endpoint.GetAddress().GetSocketAddress()
        if socketAddr == nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("socket address for endpoint for LOGICAL_DNS cluster not set")
        }</span>
        <span class="cov8" title="1">if socketAddr.GetResolverName() != "" </span><span class="cov0" title="0">{
                return "", fmt.Errorf("socket address for endpoint for LOGICAL_DNS cluster not set has unexpected custom resolver name: %v", socketAddr.GetResolverName())
        }</span>
        <span class="cov8" title="1">host := socketAddr.GetAddress()
        if host == "" </span><span class="cov0" title="0">{
                return "", fmt.Errorf("host for endpoint for LOGICAL_DNS cluster not set")
        }</span>
        <span class="cov8" title="1">port := socketAddr.GetPortValue()
        if port == 0 </span><span class="cov0" title="0">{
                return "", fmt.Errorf("port for endpoint for LOGICAL_DNS cluster not set")
        }</span>
        <span class="cov8" title="1">return net.JoinHostPort(host, strconv.Itoa(int(port))), nil</span>
}

// securityConfigFromCluster extracts the relevant security configuration from
// the received Cluster resource.
func securityConfigFromCluster(cluster *v3clusterpb.Cluster) (*SecurityConfig, error) <span class="cov8" title="1">{
        if tsm := cluster.GetTransportSocketMatches(); len(tsm) != 0 </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("unsupport transport_socket_matches field is non-empty: %+v", tsm)
        }</span>
        // The Cluster resource contains a `transport_socket` field, which contains
        // a oneof `typed_config` field of type `protobuf.Any`. The any proto
        // contains a marshaled representation of an `UpstreamTlsContext` message.
        <span class="cov8" title="1">ts := cluster.GetTransportSocket()
        if ts == nil </span><span class="cov8" title="1">{
                return nil, nil
        }</span>
        <span class="cov8" title="1">if name := ts.GetName(); name != transportSocketName </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("transport_socket field has unexpected name: %s", name)
        }</span>
        <span class="cov8" title="1">any := ts.GetTypedConfig()
        if any == nil || any.TypeUrl != version.V3UpstreamTLSContextURL </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("transport_socket field has unexpected typeURL: %s", any.TypeUrl)
        }</span>
        <span class="cov8" title="1">upstreamCtx := &amp;v3tlspb.UpstreamTlsContext{}
        if err := proto.Unmarshal(any.GetValue(), upstreamCtx); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to unmarshal UpstreamTlsContext in CDS response: %v", err)
        }</span>
        // The following fields from `UpstreamTlsContext` are ignored:
        // - sni
        // - allow_renegotiation
        // - max_session_keys
        <span class="cov8" title="1">if upstreamCtx.GetCommonTlsContext() == nil </span><span class="cov0" title="0">{
                return nil, errors.New("UpstreamTlsContext in CDS response does not contain a CommonTlsContext")
        }</span>

        <span class="cov8" title="1">return securityConfigFromCommonTLSContext(upstreamCtx.GetCommonTlsContext(), false)</span>
}

// common is expected to be not nil.
// The `alpn_protocols` field is ignored.
func securityConfigFromCommonTLSContext(common *v3tlspb.CommonTlsContext, server bool) (*SecurityConfig, error) <span class="cov8" title="1">{
        if common.GetTlsParams() != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("unsupported tls_params field in CommonTlsContext message: %+v", common)
        }</span>
        <span class="cov8" title="1">if common.GetCustomHandshaker() != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("unsupported custom_handshaker field in CommonTlsContext message: %+v", common)
        }</span>

        // For now, if we can't get a valid security config from the new fields, we
        // fallback to the old deprecated fields.
        // TODO: Drop support for deprecated fields. NACK if err != nil here.
        <span class="cov8" title="1">sc, _ := securityConfigFromCommonTLSContextUsingNewFields(common, server)
        if sc == nil || sc.Equal(&amp;SecurityConfig{}) </span><span class="cov8" title="1">{
                var err error
                sc, err = securityConfigFromCommonTLSContextWithDeprecatedFields(common, server)
                if err != nil </span><span class="cov8" title="1">{
                        return nil, err
                }</span>
        }
        <span class="cov8" title="1">if sc != nil </span><span class="cov8" title="1">{
                // sc == nil is a valid case where the control plane has not sent us any
                // security configuration. xDS creds will use fallback creds.
                if server </span><span class="cov8" title="1">{
                        if sc.IdentityInstanceName == "" </span><span class="cov8" title="1">{
                                return nil, errors.New("security configuration on the server-side does not contain identity certificate provider instance name")
                        }</span>
                } else<span class="cov8" title="1"> {
                        if sc.RootInstanceName == "" </span><span class="cov0" title="0">{
                                return nil, errors.New("security configuration on the client-side does not contain root certificate provider instance name")
                        }</span>
                }
        }
        <span class="cov8" title="1">return sc, nil</span>
}

func securityConfigFromCommonTLSContextWithDeprecatedFields(common *v3tlspb.CommonTlsContext, server bool) (*SecurityConfig, error) <span class="cov8" title="1">{
        // The `CommonTlsContext` contains a
        // `tls_certificate_certificate_provider_instance` field of type
        // `CertificateProviderInstance`, which contains the provider instance name
        // and the certificate name to fetch identity certs.
        sc := &amp;SecurityConfig{}
        if identity := common.GetTlsCertificateCertificateProviderInstance(); identity != nil </span><span class="cov8" title="1">{
                sc.IdentityInstanceName = identity.GetInstanceName()
                sc.IdentityCertName = identity.GetCertificateName()
        }</span>

        // The `CommonTlsContext` contains a `validation_context_type` field which
        // is a oneof. We can get the values that we are interested in from two of
        // those possible values:
        //  - combined validation context:
        //    - contains a default validation context which holds the list of
        //      matchers for accepted SANs.
        //    - contains certificate provider instance configuration
        //  - certificate provider instance configuration
        //    - in this case, we do not get a list of accepted SANs.
        <span class="cov8" title="1">switch t := common.GetValidationContextType().(type) </span>{
        case *v3tlspb.CommonTlsContext_CombinedValidationContext:<span class="cov8" title="1">
                combined := common.GetCombinedValidationContext()
                var matchers []matcher.StringMatcher
                if def := combined.GetDefaultValidationContext(); def != nil </span><span class="cov8" title="1">{
                        for _, m := range def.GetMatchSubjectAltNames() </span><span class="cov8" title="1">{
                                matcher, err := matcher.StringMatcherFromProto(m)
                                if err != nil </span><span class="cov0" title="0">{
                                        return nil, err
                                }</span>
                                <span class="cov8" title="1">matchers = append(matchers, matcher)</span>
                        }
                }
                <span class="cov8" title="1">if server &amp;&amp; len(matchers) != 0 </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("match_subject_alt_names field in validation context is not supported on the server: %v", common)
                }</span>
                <span class="cov8" title="1">sc.SubjectAltNameMatchers = matchers
                if pi := combined.GetValidationContextCertificateProviderInstance(); pi != nil </span><span class="cov8" title="1">{
                        sc.RootInstanceName = pi.GetInstanceName()
                        sc.RootCertName = pi.GetCertificateName()
                }</span>
        case *v3tlspb.CommonTlsContext_ValidationContextCertificateProviderInstance:<span class="cov8" title="1">
                pi := common.GetValidationContextCertificateProviderInstance()
                sc.RootInstanceName = pi.GetInstanceName()
                sc.RootCertName = pi.GetCertificateName()</span>
        case nil:<span class="cov8" title="1"></span>
                // It is valid for the validation context to be nil on the server side.
        default:<span class="cov8" title="1">
                return nil, fmt.Errorf("validation context contains unexpected type: %T", t)</span>
        }
        <span class="cov8" title="1">return sc, nil</span>
}

// gRFC A29 https://github.com/grpc/proposal/blob/master/A29-xds-tls-security.md
// specifies the new way to fetch security configuration and says the following:
//
// Although there are various ways to obtain certificates as per this proto
// (which are supported by Envoy), gRPC supports only one of them and that is
// the `CertificateProviderPluginInstance` proto.
//
// This helper function attempts to fetch security configuration from the
// `CertificateProviderPluginInstance` message, given a CommonTlsContext.
func securityConfigFromCommonTLSContextUsingNewFields(common *v3tlspb.CommonTlsContext, server bool) (*SecurityConfig, error) <span class="cov8" title="1">{
        // The `tls_certificate_provider_instance` field of type
        // `CertificateProviderPluginInstance` is used to fetch the identity
        // certificate provider.
        sc := &amp;SecurityConfig{}
        identity := common.GetTlsCertificateProviderInstance()
        if identity == nil &amp;&amp; len(common.GetTlsCertificates()) != 0 </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("expected field tls_certificate_provider_instance is not set, while unsupported field tls_certificates is set in CommonTlsContext message: %+v", common)
        }</span>
        <span class="cov8" title="1">if identity == nil &amp;&amp; common.GetTlsCertificateSdsSecretConfigs() != nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("expected field tls_certificate_provider_instance is not set, while unsupported field tls_certificate_sds_secret_configs is set in CommonTlsContext message: %+v", common)
        }</span>
        <span class="cov8" title="1">sc.IdentityInstanceName = identity.GetInstanceName()
        sc.IdentityCertName = identity.GetCertificateName()

        // The `CommonTlsContext` contains a oneof field `validation_context_type`,
        // which contains the `CertificateValidationContext` message in one of the
        // following ways:
        //  - `validation_context` field
        //    - this is directly of type `CertificateValidationContext`
        //  - `combined_validation_context` field
        //    - this is of type `CombinedCertificateValidationContext` and contains
        //      a `default validation context` field of type
        //      `CertificateValidationContext`
        //
        // The `CertificateValidationContext` message has the following fields that
        // we are interested in:
        //  - `ca_certificate_provider_instance`
        //    - this is of type `CertificateProviderPluginInstance`
        //  - `match_subject_alt_names`
        //    - this is a list of string matchers
        //
        // The `CertificateProviderPluginInstance` message contains two fields
        //  - instance_name
        //    - this is the certificate provider instance name to be looked up in
        //      the bootstrap configuration
        //  - certificate_name
        //    -  this is an opaque name passed to the certificate provider
        var validationCtx *v3tlspb.CertificateValidationContext
        switch typ := common.GetValidationContextType().(type) </span>{
        case *v3tlspb.CommonTlsContext_ValidationContext:<span class="cov8" title="1">
                validationCtx = common.GetValidationContext()</span>
        case *v3tlspb.CommonTlsContext_CombinedValidationContext:<span class="cov8" title="1">
                validationCtx = common.GetCombinedValidationContext().GetDefaultValidationContext()</span>
        case nil:<span class="cov8" title="1">
                // It is valid for the validation context to be nil on the server side.
                return sc, nil</span>
        default:<span class="cov8" title="1">
                return nil, fmt.Errorf("validation context contains unexpected type: %T", typ)</span>
        }
        // If we get here, it means that the `CertificateValidationContext` message
        // was found through one of the supported ways. It is an error if the
        // validation context is specified, but it does not contain the
        // ca_certificate_provider_instance field which contains information about
        // the certificate provider to be used for the root certificates.
        <span class="cov8" title="1">if validationCtx.GetCaCertificateProviderInstance() == nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("expected field ca_certificate_provider_instance is missing in CommonTlsContext message: %+v", common)
        }</span>
        // The following fields are ignored:
        // - trusted_ca
        // - watched_directory
        // - allow_expired_certificate
        // - trust_chain_verification
        <span class="cov8" title="1">switch </span>{
        case len(validationCtx.GetVerifyCertificateSpki()) != 0:<span class="cov8" title="1">
                return nil, fmt.Errorf("unsupported verify_certificate_spki field in CommonTlsContext message: %+v", common)</span>
        case len(validationCtx.GetVerifyCertificateHash()) != 0:<span class="cov8" title="1">
                return nil, fmt.Errorf("unsupported verify_certificate_hash field in CommonTlsContext message: %+v", common)</span>
        case validationCtx.GetRequireSignedCertificateTimestamp().GetValue():<span class="cov8" title="1">
                return nil, fmt.Errorf("unsupported require_sugned_ceritificate_timestamp field in CommonTlsContext message: %+v", common)</span>
        case validationCtx.GetCrl() != nil:<span class="cov8" title="1">
                return nil, fmt.Errorf("unsupported crl field in CommonTlsContext message: %+v", common)</span>
        case validationCtx.GetCustomValidatorConfig() != nil:<span class="cov8" title="1">
                return nil, fmt.Errorf("unsupported custom_validator_config field in CommonTlsContext message: %+v", common)</span>
        }

        <span class="cov8" title="1">if rootProvider := validationCtx.GetCaCertificateProviderInstance(); rootProvider != nil </span><span class="cov8" title="1">{
                sc.RootInstanceName = rootProvider.GetInstanceName()
                sc.RootCertName = rootProvider.GetCertificateName()
        }</span>
        <span class="cov8" title="1">var matchers []matcher.StringMatcher
        for _, m := range validationCtx.GetMatchSubjectAltNames() </span><span class="cov8" title="1">{
                matcher, err := matcher.StringMatcherFromProto(m)
                if err != nil </span><span class="cov8" title="1">{
                        return nil, err
                }</span>
                <span class="cov8" title="1">matchers = append(matchers, matcher)</span>
        }
        <span class="cov8" title="1">if server &amp;&amp; len(matchers) != 0 </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("match_subject_alt_names field in validation context is not supported on the server: %v", common)
        }</span>
        <span class="cov8" title="1">sc.SubjectAltNameMatchers = matchers
        return sc, nil</span>
}

// circuitBreakersFromCluster extracts the circuit breakers configuration from
// the received cluster resource. Returns nil if no CircuitBreakers or no
// Thresholds in CircuitBreakers.
func circuitBreakersFromCluster(cluster *v3clusterpb.Cluster) *uint32 <span class="cov8" title="1">{
        for _, threshold := range cluster.GetCircuitBreakers().GetThresholds() </span><span class="cov8" title="1">{
                if threshold.GetPriority() != v3corepb.RoutingPriority_DEFAULT </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov8" title="1">maxRequestsPb := threshold.GetMaxRequests()
                if maxRequestsPb == nil </span><span class="cov0" title="0">{
                        return nil
                }</span>
                <span class="cov8" title="1">maxRequests := maxRequestsPb.GetValue()
                return &amp;maxRequests</span>
        }
        <span class="cov8" title="1">return nil</span>
}

// outlierConfigFromCluster extracts the relevant outlier detection
// configuration from the received cluster resource. Returns nil if no
// OutlierDetection field set in the cluster resource.
func outlierConfigFromCluster(cluster *v3clusterpb.Cluster) (*OutlierDetection, error) <span class="cov8" title="1">{
        od := cluster.GetOutlierDetection()
        if od == nil </span><span class="cov0" title="0">{
                return nil, nil
        }</span>
        <span class="cov8" title="1">const (
                defaultInterval                       = 10 * time.Second
                defaultBaseEjectionTime               = 30 * time.Second
                defaultMaxEjectionTime                = 300 * time.Second
                defaultMaxEjectionPercent             = 10
                defaultSuccessRateStdevFactor         = 1900
                defaultEnforcingSuccessRate           = 100
                defaultSuccessRateMinimumHosts        = 5
                defaultSuccessRateRequestVolume       = 100
                defaultFailurePercentageThreshold     = 85
                defaultEnforcingFailurePercentage     = 0
                defaultFailurePercentageMinimumHosts  = 5
                defaultFailurePercentageRequestVolume = 50
        )
        // "The google.protobuf.Duration fields interval, base_ejection_time, and
        // max_ejection_time must obey the restrictions in the
        // google.protobuf.Duration documentation and they must have non-negative
        // values." - A50
        interval := defaultInterval
        if i := od.GetInterval(); i != nil </span><span class="cov8" title="1">{
                if err := i.CheckValid(); err != nil </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("outlier_detection.interval is invalid with error %v", err)
                }</span>
                <span class="cov8" title="1">if interval = i.AsDuration(); interval &lt; 0 </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("outlier_detection.interval = %v; must be a valid duration and &gt;= 0", interval)
                }</span>
        }

        <span class="cov8" title="1">baseEjectionTime := defaultBaseEjectionTime
        if bet := od.GetBaseEjectionTime(); bet != nil </span><span class="cov8" title="1">{
                if err := bet.CheckValid(); err != nil </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("outlier_detection.base_ejection_time is invalid with error %v", err)
                }</span>
                <span class="cov8" title="1">if baseEjectionTime = bet.AsDuration(); baseEjectionTime &lt; 0 </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("outlier_detection.base_ejection_time = %v; must be &gt;= 0", baseEjectionTime)
                }</span>
        }

        <span class="cov8" title="1">maxEjectionTime := defaultMaxEjectionTime
        if met := od.GetMaxEjectionTime(); met != nil </span><span class="cov8" title="1">{
                if err := met.CheckValid(); err != nil </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("outlier_detection.max_ejection_time is invalid with error %v", err)
                }</span>
                <span class="cov8" title="1">if maxEjectionTime = met.AsDuration(); maxEjectionTime &lt; 0 </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("outlier_detection.max_ejection_time = %v; must be &gt;= 0", maxEjectionTime)
                }</span>
        }

        // "The fields max_ejection_percent, enforcing_success_rate,
        // failure_percentage_threshold, and enforcing_failure_percentage must have
        // values less than or equal to 100. If any of these requirements is
        // violated, the Cluster resource should be NACKed." - A50
        <span class="cov8" title="1">maxEjectionPercent := uint32(defaultMaxEjectionPercent)
        if mep := od.GetMaxEjectionPercent(); mep != nil </span><span class="cov8" title="1">{
                if maxEjectionPercent = mep.GetValue(); maxEjectionPercent &gt; 100 </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("outlier_detection.max_ejection_percent = %v; must be &lt;= 100", maxEjectionPercent)
                }</span>
        }
        <span class="cov8" title="1">enforcingSuccessRate := uint32(defaultEnforcingSuccessRate)
        if esr := od.GetEnforcingSuccessRate(); esr != nil </span><span class="cov8" title="1">{
                if enforcingSuccessRate = esr.GetValue(); enforcingSuccessRate &gt; 100 </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("outlier_detection.enforcing_success_rate = %v; must be &lt;= 100", enforcingSuccessRate)
                }</span>
        }
        <span class="cov8" title="1">failurePercentageThreshold := uint32(defaultFailurePercentageThreshold)
        if fpt := od.GetFailurePercentageThreshold(); fpt != nil </span><span class="cov8" title="1">{
                if failurePercentageThreshold = fpt.GetValue(); failurePercentageThreshold &gt; 100 </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("outlier_detection.failure_percentage_threshold = %v; must be &lt;= 100", failurePercentageThreshold)
                }</span>
        }
        <span class="cov8" title="1">enforcingFailurePercentage := uint32(defaultEnforcingFailurePercentage)
        if efp := od.GetEnforcingFailurePercentage(); efp != nil </span><span class="cov8" title="1">{
                if enforcingFailurePercentage = efp.GetValue(); enforcingFailurePercentage &gt; 100 </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("outlier_detection.enforcing_failure_percentage = %v; must be &lt;= 100", enforcingFailurePercentage)
                }</span>
        }

        <span class="cov8" title="1">successRateStdevFactor := uint32(defaultSuccessRateStdevFactor)
        if srsf := od.GetSuccessRateStdevFactor(); srsf != nil </span><span class="cov8" title="1">{
                successRateStdevFactor = srsf.GetValue()
        }</span>
        <span class="cov8" title="1">successRateMinimumHosts := uint32(defaultSuccessRateMinimumHosts)
        if srmh := od.GetSuccessRateMinimumHosts(); srmh != nil </span><span class="cov8" title="1">{
                successRateMinimumHosts = srmh.GetValue()
        }</span>
        <span class="cov8" title="1">successRateRequestVolume := uint32(defaultSuccessRateRequestVolume)
        if srrv := od.GetSuccessRateRequestVolume(); srrv != nil </span><span class="cov8" title="1">{
                successRateRequestVolume = srrv.GetValue()
        }</span>
        <span class="cov8" title="1">failurePercentageMinimumHosts := uint32(defaultFailurePercentageMinimumHosts)
        if fpmh := od.GetFailurePercentageMinimumHosts(); fpmh != nil </span><span class="cov8" title="1">{
                failurePercentageMinimumHosts = fpmh.GetValue()
        }</span>
        <span class="cov8" title="1">failurePercentageRequestVolume := uint32(defaultFailurePercentageRequestVolume)
        if fprv := od.GetFailurePercentageRequestVolume(); fprv != nil </span><span class="cov8" title="1">{
                failurePercentageRequestVolume = fprv.GetValue()
        }</span>

        <span class="cov8" title="1">return &amp;OutlierDetection{
                Interval:                       interval,
                BaseEjectionTime:               baseEjectionTime,
                MaxEjectionTime:                maxEjectionTime,
                MaxEjectionPercent:             maxEjectionPercent,
                EnforcingSuccessRate:           enforcingSuccessRate,
                FailurePercentageThreshold:     failurePercentageThreshold,
                EnforcingFailurePercentage:     enforcingFailurePercentage,
                SuccessRateStdevFactor:         successRateStdevFactor,
                SuccessRateMinimumHosts:        successRateMinimumHosts,
                SuccessRateRequestVolume:       successRateRequestVolume,
                FailurePercentageMinimumHosts:  failurePercentageMinimumHosts,
                FailurePercentageRequestVolume: failurePercentageRequestVolume,
        }, nil</span>
}
</pre>
		
		<pre class="file" id="file223" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package xdsresource

import (
        "fmt"
        "net"
        "strconv"

        v3corepb "github.com/envoyproxy/go-control-plane/envoy/config/core/v3"
        v3endpointpb "github.com/envoyproxy/go-control-plane/envoy/config/endpoint/v3"
        v3typepb "github.com/envoyproxy/go-control-plane/envoy/type/v3"
        "github.com/golang/protobuf/proto"
        "google.golang.org/grpc/internal/grpclog"
        "google.golang.org/grpc/internal/pretty"
        "google.golang.org/grpc/xds/internal"
        "google.golang.org/protobuf/types/known/anypb"
)

// UnmarshalEndpoints processes resources received in an EDS response,
// validates them, and transforms them into a native struct which contains only
// fields we are interested in.
func UnmarshalEndpoints(opts *UnmarshalOptions) (map[string]EndpointsUpdateErrTuple, UpdateMetadata, error) <span class="cov8" title="1">{
        update := make(map[string]EndpointsUpdateErrTuple)
        md, err := processAllResources(opts, update)
        return update, md, err
}</span>

func unmarshalEndpointsResource(r *anypb.Any, logger *grpclog.PrefixLogger) (string, EndpointsUpdate, error) <span class="cov8" title="1">{
        r, err := unwrapResource(r)
        if err != nil </span><span class="cov0" title="0">{
                return "", EndpointsUpdate{}, fmt.Errorf("failed to unwrap resource: %v", err)
        }</span>

        <span class="cov8" title="1">if !IsEndpointsResource(r.GetTypeUrl()) </span><span class="cov8" title="1">{
                return "", EndpointsUpdate{}, fmt.Errorf("unexpected resource type: %q ", r.GetTypeUrl())
        }</span>

        <span class="cov8" title="1">cla := &amp;v3endpointpb.ClusterLoadAssignment{}
        if err := proto.Unmarshal(r.GetValue(), cla); err != nil </span><span class="cov8" title="1">{
                return "", EndpointsUpdate{}, fmt.Errorf("failed to unmarshal resource: %v", err)
        }</span>
        <span class="cov8" title="1">logger.Infof("Resource with name: %v, type: %T, contains: %v", cla.GetClusterName(), cla, pretty.ToJSON(cla))

        u, err := parseEDSRespProto(cla, logger)
        if err != nil </span><span class="cov8" title="1">{
                return cla.GetClusterName(), EndpointsUpdate{}, err
        }</span>
        <span class="cov8" title="1">u.Raw = r
        return cla.GetClusterName(), u, nil</span>
}

func parseAddress(socketAddress *v3corepb.SocketAddress) string <span class="cov8" title="1">{
        return net.JoinHostPort(socketAddress.GetAddress(), strconv.Itoa(int(socketAddress.GetPortValue())))
}</span>

func parseDropPolicy(dropPolicy *v3endpointpb.ClusterLoadAssignment_Policy_DropOverload) OverloadDropConfig <span class="cov0" title="0">{
        percentage := dropPolicy.GetDropPercentage()
        var (
                numerator   = percentage.GetNumerator()
                denominator uint32
        )
        switch percentage.GetDenominator() </span>{
        case v3typepb.FractionalPercent_HUNDRED:<span class="cov0" title="0">
                denominator = 100</span>
        case v3typepb.FractionalPercent_TEN_THOUSAND:<span class="cov0" title="0">
                denominator = 10000</span>
        case v3typepb.FractionalPercent_MILLION:<span class="cov0" title="0">
                denominator = 1000000</span>
        }
        <span class="cov0" title="0">return OverloadDropConfig{
                Category:    dropPolicy.GetCategory(),
                Numerator:   numerator,
                Denominator: denominator,
        }</span>
}

func parseEndpoints(lbEndpoints []*v3endpointpb.LbEndpoint) ([]Endpoint, error) <span class="cov8" title="1">{
        endpoints := make([]Endpoint, 0, len(lbEndpoints))
        for _, lbEndpoint := range lbEndpoints </span><span class="cov8" title="1">{
                // If the load_balancing_weight field is specified, it must be set to a
                // value of at least 1.  If unspecified, each host is presumed to have
                // equal weight in a locality.
                weight := uint32(1)
                if w := lbEndpoint.GetLoadBalancingWeight(); w != nil </span><span class="cov8" title="1">{
                        if w.GetValue() == 0 </span><span class="cov8" title="1">{
                                return nil, fmt.Errorf("EDS response contains an endpoint with zero weight: %+v", lbEndpoint)
                        }</span>
                        <span class="cov8" title="1">weight = w.GetValue()</span>
                }
                <span class="cov8" title="1">endpoints = append(endpoints, Endpoint{
                        HealthStatus: EndpointHealthStatus(lbEndpoint.GetHealthStatus()),
                        Address:      parseAddress(lbEndpoint.GetEndpoint().GetAddress().GetSocketAddress()),
                        Weight:       weight,
                })</span>
        }
        <span class="cov8" title="1">return endpoints, nil</span>
}

func parseEDSRespProto(m *v3endpointpb.ClusterLoadAssignment, logger *grpclog.PrefixLogger) (EndpointsUpdate, error) <span class="cov8" title="1">{
        ret := EndpointsUpdate{}
        for _, dropPolicy := range m.GetPolicy().GetDropOverloads() </span><span class="cov0" title="0">{
                ret.Drops = append(ret.Drops, parseDropPolicy(dropPolicy))
        }</span>
        <span class="cov8" title="1">priorities := make(map[uint32]map[string]bool)
        for _, locality := range m.Endpoints </span><span class="cov8" title="1">{
                l := locality.GetLocality()
                if l == nil </span><span class="cov8" title="1">{
                        return EndpointsUpdate{}, fmt.Errorf("EDS response contains a locality without ID, locality: %+v", locality)
                }</span>
                <span class="cov8" title="1">weight := locality.GetLoadBalancingWeight().GetValue()
                if weight == 0 </span><span class="cov8" title="1">{
                        logger.Warningf("Ignoring locality %s with weight 0", pretty.ToJSON(l))
                        continue</span>
                }
                <span class="cov8" title="1">lid := internal.LocalityID{
                        Region:  l.Region,
                        Zone:    l.Zone,
                        SubZone: l.SubZone,
                }
                priority := locality.GetPriority()
                localitiesWithPriority := priorities[priority]
                if localitiesWithPriority == nil </span><span class="cov8" title="1">{
                        localitiesWithPriority = make(map[string]bool)
                        priorities[priority] = localitiesWithPriority
                }</span>
                <span class="cov8" title="1">lidStr, _ := lid.ToString()
                if localitiesWithPriority[lidStr] </span><span class="cov8" title="1">{
                        return EndpointsUpdate{}, fmt.Errorf("duplicate locality %s with the same priority %v", lidStr, priority)
                }</span>
                <span class="cov8" title="1">localitiesWithPriority[lidStr] = true
                endpoints, err := parseEndpoints(locality.GetLbEndpoints())
                if err != nil </span><span class="cov8" title="1">{
                        return EndpointsUpdate{}, err
                }</span>
                <span class="cov8" title="1">ret.Localities = append(ret.Localities, Locality{
                        ID:        lid,
                        Endpoints: endpoints,
                        Weight:    locality.GetLoadBalancingWeight().GetValue(),
                        Priority:  priority,
                })</span>
        }
        <span class="cov8" title="1">for i := 0; i &lt; len(priorities); i++ </span><span class="cov8" title="1">{
                if _, ok := priorities[uint32(i)]; !ok </span><span class="cov8" title="1">{
                        return EndpointsUpdate{}, fmt.Errorf("priority %v missing (with different priorities %v received)", i, priorities)
                }</span>
        }
        <span class="cov8" title="1">return ret, nil</span>
}
</pre>
		
		<pre class="file" id="file224" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package xdsresource

import (
        "errors"
        "fmt"
        "strconv"

        v1udpatypepb "github.com/cncf/udpa/go/udpa/type/v1"
        v3cncftypepb "github.com/cncf/xds/go/xds/type/v3"
        v3listenerpb "github.com/envoyproxy/go-control-plane/envoy/config/listener/v3"
        v3routepb "github.com/envoyproxy/go-control-plane/envoy/config/route/v3"
        v3httppb "github.com/envoyproxy/go-control-plane/envoy/extensions/filters/network/http_connection_manager/v3"
        "github.com/golang/protobuf/proto"
        "github.com/golang/protobuf/ptypes"
        "google.golang.org/grpc/internal/grpclog"
        "google.golang.org/grpc/internal/pretty"
        "google.golang.org/grpc/xds/internal/httpfilter"
        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource/version"
        "google.golang.org/protobuf/types/known/anypb"
)

// UnmarshalListener processes resources received in an LDS response, validates
// them, and transforms them into a native struct which contains only fields we
// are interested in.
func UnmarshalListener(opts *UnmarshalOptions) (map[string]ListenerUpdateErrTuple, UpdateMetadata, error) <span class="cov8" title="1">{
        update := make(map[string]ListenerUpdateErrTuple)
        md, err := processAllResources(opts, update)
        return update, md, err
}</span>

func unmarshalListenerResource(r *anypb.Any, f UpdateValidatorFunc, logger *grpclog.PrefixLogger) (string, ListenerUpdate, error) <span class="cov8" title="1">{
        r, err := unwrapResource(r)
        if err != nil </span><span class="cov0" title="0">{
                return "", ListenerUpdate{}, fmt.Errorf("failed to unwrap resource: %v", err)
        }</span>

        <span class="cov8" title="1">if !IsListenerResource(r.GetTypeUrl()) </span><span class="cov8" title="1">{
                return "", ListenerUpdate{}, fmt.Errorf("unexpected resource type: %q ", r.GetTypeUrl())
        }</span>
        // TODO: Pass version.TransportAPI instead of relying upon the type URL
        <span class="cov8" title="1">v2 := r.GetTypeUrl() == version.V2ListenerURL
        lis := &amp;v3listenerpb.Listener{}
        if err := proto.Unmarshal(r.GetValue(), lis); err != nil </span><span class="cov0" title="0">{
                return "", ListenerUpdate{}, fmt.Errorf("failed to unmarshal resource: %v", err)
        }</span>
        <span class="cov8" title="1">logger.Infof("Resource with name: %v, type: %T, contains: %v", lis.GetName(), lis, pretty.ToJSON(lis))

        lu, err := processListener(lis, logger, v2)
        if err != nil </span><span class="cov8" title="1">{
                return lis.GetName(), ListenerUpdate{}, err
        }</span>
        <span class="cov8" title="1">if f != nil </span><span class="cov0" title="0">{
                if err := f(*lu); err != nil </span><span class="cov0" title="0">{
                        return lis.GetName(), ListenerUpdate{}, err
                }</span>
        }
        <span class="cov8" title="1">lu.Raw = r
        return lis.GetName(), *lu, nil</span>
}

func processListener(lis *v3listenerpb.Listener, logger *grpclog.PrefixLogger, v2 bool) (*ListenerUpdate, error) <span class="cov8" title="1">{
        if lis.GetApiListener() != nil </span><span class="cov8" title="1">{
                return processClientSideListener(lis, logger, v2)
        }</span>
        <span class="cov8" title="1">return processServerSideListener(lis, logger)</span>
}

// processClientSideListener checks if the provided Listener proto meets
// the expected criteria. If so, it returns a non-empty routeConfigName.
func processClientSideListener(lis *v3listenerpb.Listener, logger *grpclog.PrefixLogger, v2 bool) (*ListenerUpdate, error) <span class="cov8" title="1">{
        update := &amp;ListenerUpdate{}

        apiLisAny := lis.GetApiListener().GetApiListener()
        if !IsHTTPConnManagerResource(apiLisAny.GetTypeUrl()) </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("unexpected resource type: %q", apiLisAny.GetTypeUrl())
        }</span>
        <span class="cov8" title="1">apiLis := &amp;v3httppb.HttpConnectionManager{}
        if err := proto.Unmarshal(apiLisAny.GetValue(), apiLis); err != nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("failed to unmarshal api_listner: %v", err)
        }</span>
        // "HttpConnectionManager.xff_num_trusted_hops must be unset or zero and
        // HttpConnectionManager.original_ip_detection_extensions must be empty. If
        // either field has an incorrect value, the Listener must be NACKed." - A41
        <span class="cov8" title="1">if apiLis.XffNumTrustedHops != 0 </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("xff_num_trusted_hops must be unset or zero %+v", apiLis)
        }</span>
        <span class="cov8" title="1">if len(apiLis.OriginalIpDetectionExtensions) != 0 </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("original_ip_detection_extensions must be empty %+v", apiLis)
        }</span>

        <span class="cov8" title="1">switch apiLis.RouteSpecifier.(type) </span>{
        case *v3httppb.HttpConnectionManager_Rds:<span class="cov8" title="1">
                if configsource := apiLis.GetRds().GetConfigSource(); configsource.GetAds() == nil &amp;&amp; configsource.GetSelf() == nil </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("LDS's RDS configSource is not ADS or Self: %+v", lis)
                }</span>
                <span class="cov8" title="1">name := apiLis.GetRds().GetRouteConfigName()
                if name == "" </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("empty route_config_name: %+v", lis)
                }</span>
                <span class="cov8" title="1">update.RouteConfigName = name</span>
        case *v3httppb.HttpConnectionManager_RouteConfig:<span class="cov8" title="1">
                routeU, err := generateRDSUpdateFromRouteConfiguration(apiLis.GetRouteConfig(), logger, v2)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to parse inline RDS resp: %v", err)
                }</span>
                <span class="cov8" title="1">update.InlineRouteConfig = &amp;routeU</span>
        case nil:<span class="cov0" title="0">
                return nil, fmt.Errorf("no RouteSpecifier: %+v", apiLis)</span>
        default:<span class="cov8" title="1">
                return nil, fmt.Errorf("unsupported type %T for RouteSpecifier", apiLis.RouteSpecifier)</span>
        }

        <span class="cov8" title="1">if v2 </span><span class="cov8" title="1">{
                return update, nil
        }</span>

        // The following checks and fields only apply to xDS protocol versions v3+.

        <span class="cov8" title="1">update.MaxStreamDuration = apiLis.GetCommonHttpProtocolOptions().GetMaxStreamDuration().AsDuration()

        var err error
        if update.HTTPFilters, err = processHTTPFilters(apiLis.GetHttpFilters(), false); err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>

        <span class="cov8" title="1">return update, nil</span>
}

func unwrapHTTPFilterConfig(config *anypb.Any) (proto.Message, string, error) <span class="cov8" title="1">{
        switch </span>{
        case ptypes.Is(config, &amp;v3cncftypepb.TypedStruct{}):<span class="cov8" title="1">
                // The real type name is inside the new TypedStruct message.
                s := new(v3cncftypepb.TypedStruct)
                if err := ptypes.UnmarshalAny(config, s); err != nil </span><span class="cov0" title="0">{
                        return nil, "", fmt.Errorf("error unmarshalling TypedStruct filter config: %v", err)
                }</span>
                <span class="cov8" title="1">return s, s.GetTypeUrl(), nil</span>
        case ptypes.Is(config, &amp;v1udpatypepb.TypedStruct{}):<span class="cov8" title="1">
                // The real type name is inside the old TypedStruct message.
                s := new(v1udpatypepb.TypedStruct)
                if err := ptypes.UnmarshalAny(config, s); err != nil </span><span class="cov0" title="0">{
                        return nil, "", fmt.Errorf("error unmarshalling TypedStruct filter config: %v", err)
                }</span>
                <span class="cov8" title="1">return s, s.GetTypeUrl(), nil</span>
        default:<span class="cov8" title="1">
                return config, config.GetTypeUrl(), nil</span>
        }
}

func validateHTTPFilterConfig(cfg *anypb.Any, lds, optional bool) (httpfilter.Filter, httpfilter.FilterConfig, error) <span class="cov8" title="1">{
        config, typeURL, err := unwrapHTTPFilterConfig(cfg)
        if err != nil </span><span class="cov0" title="0">{
                return nil, nil, err
        }</span>
        <span class="cov8" title="1">filterBuilder := httpfilter.Get(typeURL)
        if filterBuilder == nil </span><span class="cov8" title="1">{
                if optional </span><span class="cov8" title="1">{
                        return nil, nil, nil
                }</span>
                <span class="cov8" title="1">return nil, nil, fmt.Errorf("no filter implementation found for %q", typeURL)</span>
        }
        <span class="cov8" title="1">parseFunc := filterBuilder.ParseFilterConfig
        if !lds </span><span class="cov8" title="1">{
                parseFunc = filterBuilder.ParseFilterConfigOverride
        }</span>
        <span class="cov8" title="1">filterConfig, err := parseFunc(config)
        if err != nil </span><span class="cov8" title="1">{
                return nil, nil, fmt.Errorf("error parsing config for filter %q: %v", typeURL, err)
        }</span>
        <span class="cov8" title="1">return filterBuilder, filterConfig, nil</span>
}

func processHTTPFilterOverrides(cfgs map[string]*anypb.Any) (map[string]httpfilter.FilterConfig, error) <span class="cov8" title="1">{
        if len(cfgs) == 0 </span><span class="cov8" title="1">{
                return nil, nil
        }</span>
        <span class="cov8" title="1">m := make(map[string]httpfilter.FilterConfig)
        for name, cfg := range cfgs </span><span class="cov8" title="1">{
                optional := false
                s := new(v3routepb.FilterConfig)
                if ptypes.Is(cfg, s) </span><span class="cov8" title="1">{
                        if err := ptypes.UnmarshalAny(cfg, s); err != nil </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("filter override %q: error unmarshalling FilterConfig: %v", name, err)
                        }</span>
                        <span class="cov8" title="1">cfg = s.GetConfig()
                        optional = s.GetIsOptional()</span>
                }

                <span class="cov8" title="1">httpFilter, config, err := validateHTTPFilterConfig(cfg, false, optional)
                if err != nil </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("filter override %q: %v", name, err)
                }</span>
                <span class="cov8" title="1">if httpFilter == nil </span><span class="cov8" title="1">{
                        // Optional configs are ignored.
                        continue</span>
                }
                <span class="cov8" title="1">m[name] = config</span>
        }
        <span class="cov8" title="1">return m, nil</span>
}

func processHTTPFilters(filters []*v3httppb.HttpFilter, server bool) ([]HTTPFilter, error) <span class="cov8" title="1">{
        ret := make([]HTTPFilter, 0, len(filters))
        seenNames := make(map[string]bool, len(filters))
        for _, filter := range filters </span><span class="cov8" title="1">{
                name := filter.GetName()
                if name == "" </span><span class="cov0" title="0">{
                        return nil, errors.New("filter missing name field")
                }</span>
                <span class="cov8" title="1">if seenNames[name] </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("duplicate filter name %q", name)
                }</span>
                <span class="cov8" title="1">seenNames[name] = true

                httpFilter, config, err := validateHTTPFilterConfig(filter.GetTypedConfig(), true, filter.GetIsOptional())
                if err != nil </span><span class="cov8" title="1">{
                        return nil, err
                }</span>
                <span class="cov8" title="1">if httpFilter == nil </span><span class="cov8" title="1">{
                        // Optional configs are ignored.
                        continue</span>
                }
                <span class="cov8" title="1">if server </span><span class="cov8" title="1">{
                        if _, ok := httpFilter.(httpfilter.ServerInterceptorBuilder); !ok </span><span class="cov8" title="1">{
                                if filter.GetIsOptional() </span><span class="cov0" title="0">{
                                        continue</span>
                                }
                                <span class="cov8" title="1">return nil, fmt.Errorf("HTTP filter %q not supported server-side", name)</span>
                        }
                } else<span class="cov8" title="1"> if _, ok := httpFilter.(httpfilter.ClientInterceptorBuilder); !ok </span><span class="cov8" title="1">{
                        if filter.GetIsOptional() </span><span class="cov8" title="1">{
                                continue</span>
                        }
                        <span class="cov8" title="1">return nil, fmt.Errorf("HTTP filter %q not supported client-side", name)</span>
                }

                // Save name/config
                <span class="cov8" title="1">ret = append(ret, HTTPFilter{Name: name, Filter: httpFilter, Config: config})</span>
        }
        // "Validation will fail if a terminal filter is not the last filter in the
        // chain or if a non-terminal filter is the last filter in the chain." - A39
        <span class="cov8" title="1">if len(ret) == 0 </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("http filters list is empty")
        }</span>
        <span class="cov8" title="1">var i int
        for ; i &lt; len(ret)-1; i++ </span><span class="cov8" title="1">{
                if ret[i].Filter.IsTerminal() </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("http filter %q is a terminal filter but it is not last in the filter chain", ret[i].Name)
                }</span>
        }
        <span class="cov8" title="1">if !ret[i].Filter.IsTerminal() </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("http filter %q is not a terminal filter", ret[len(ret)-1].Name)
        }</span>
        <span class="cov8" title="1">return ret, nil</span>
}

func processServerSideListener(lis *v3listenerpb.Listener, logger *grpclog.PrefixLogger) (*ListenerUpdate, error) <span class="cov8" title="1">{
        if n := len(lis.ListenerFilters); n != 0 </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("unsupported field 'listener_filters' contains %d entries", n)
        }</span>
        <span class="cov8" title="1">if useOrigDst := lis.GetUseOriginalDst(); useOrigDst != nil &amp;&amp; useOrigDst.GetValue() </span><span class="cov8" title="1">{
                return nil, errors.New("unsupported field 'use_original_dst' is present and set to true")
        }</span>
        <span class="cov8" title="1">addr := lis.GetAddress()
        if addr == nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("no address field in LDS response: %+v", lis)
        }</span>
        <span class="cov8" title="1">sockAddr := addr.GetSocketAddress()
        if sockAddr == nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("no socket_address field in LDS response: %+v", lis)
        }</span>
        <span class="cov8" title="1">lu := &amp;ListenerUpdate{
                InboundListenerCfg: &amp;InboundListenerConfig{
                        Address: sockAddr.GetAddress(),
                        Port:    strconv.Itoa(int(sockAddr.GetPortValue())),
                },
        }

        fcMgr, err := NewFilterChainManager(lis, logger)
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>
        <span class="cov8" title="1">lu.InboundListenerCfg.FilterChains = fcMgr
        return lu, nil</span>
}
</pre>
		
		<pre class="file" id="file225" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package xdsresource

import (
        "fmt"
        "regexp"
        "strings"
        "time"

        v3routepb "github.com/envoyproxy/go-control-plane/envoy/config/route/v3"
        v3typepb "github.com/envoyproxy/go-control-plane/envoy/type/v3"
        "github.com/golang/protobuf/proto"
        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/internal/envconfig"
        "google.golang.org/grpc/internal/grpclog"
        "google.golang.org/grpc/internal/pretty"
        "google.golang.org/grpc/xds/internal/clusterspecifier"
        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource/version"
        "google.golang.org/protobuf/types/known/anypb"
)

// UnmarshalRouteConfig processes resources received in an RDS response,
// validates them, and transforms them into a native struct which contains only
// fields we are interested in. The provided hostname determines the route
// configuration resources of interest.
func UnmarshalRouteConfig(opts *UnmarshalOptions) (map[string]RouteConfigUpdateErrTuple, UpdateMetadata, error) <span class="cov8" title="1">{
        update := make(map[string]RouteConfigUpdateErrTuple)
        md, err := processAllResources(opts, update)
        return update, md, err
}</span>

func unmarshalRouteConfigResource(r *anypb.Any, logger *grpclog.PrefixLogger) (string, RouteConfigUpdate, error) <span class="cov8" title="1">{
        r, err := unwrapResource(r)
        if err != nil </span><span class="cov0" title="0">{
                return "", RouteConfigUpdate{}, fmt.Errorf("failed to unwrap resource: %v", err)
        }</span>

        <span class="cov8" title="1">if !IsRouteConfigResource(r.GetTypeUrl()) </span><span class="cov8" title="1">{
                return "", RouteConfigUpdate{}, fmt.Errorf("unexpected resource type: %q ", r.GetTypeUrl())
        }</span>
        <span class="cov8" title="1">rc := &amp;v3routepb.RouteConfiguration{}
        if err := proto.Unmarshal(r.GetValue(), rc); err != nil </span><span class="cov8" title="1">{
                return "", RouteConfigUpdate{}, fmt.Errorf("failed to unmarshal resource: %v", err)
        }</span>
        <span class="cov8" title="1">logger.Infof("Resource with name: %v, type: %T, contains: %v.", rc.GetName(), rc, pretty.ToJSON(rc))

        // TODO: Pass version.TransportAPI instead of relying upon the type URL
        v2 := r.GetTypeUrl() == version.V2RouteConfigURL
        u, err := generateRDSUpdateFromRouteConfiguration(rc, logger, v2)
        if err != nil </span><span class="cov8" title="1">{
                return rc.GetName(), RouteConfigUpdate{}, err
        }</span>
        <span class="cov8" title="1">u.Raw = r
        return rc.GetName(), u, nil</span>
}

// generateRDSUpdateFromRouteConfiguration checks if the provided
// RouteConfiguration meets the expected criteria. If so, it returns a
// RouteConfigUpdate with nil error.
//
// A RouteConfiguration resource is considered valid when only if it contains a
// VirtualHost whose domain field matches the server name from the URI passed
// to the gRPC channel, and it contains a clusterName or a weighted cluster.
//
// The RouteConfiguration includes a list of virtualHosts, which may have zero
// or more elements. We are interested in the element whose domains field
// matches the server name specified in the "xds:" URI. The only field in the
// VirtualHost proto that the we are interested in is the list of routes. We
// only look at the last route in the list (the default route), whose match
// field must be empty and whose route field must be set.  Inside that route
// message, the cluster field will contain the clusterName or weighted clusters
// we are looking for.
func generateRDSUpdateFromRouteConfiguration(rc *v3routepb.RouteConfiguration, logger *grpclog.PrefixLogger, v2 bool) (RouteConfigUpdate, error) <span class="cov8" title="1">{
        vhs := make([]*VirtualHost, 0, len(rc.GetVirtualHosts()))
        csps := make(map[string]clusterspecifier.BalancerConfig)
        if envconfig.XDSRLS </span><span class="cov8" title="1">{
                var err error
                csps, err = processClusterSpecifierPlugins(rc.ClusterSpecifierPlugins)
                if err != nil </span><span class="cov8" title="1">{
                        return RouteConfigUpdate{}, fmt.Errorf("received route is invalid %v", err)
                }</span>
        }
        // cspNames represents all the cluster specifiers referenced by Route
        // Actions - any cluster specifiers not referenced by a Route Action can be
        // ignored and not emitted by the xdsclient.
        <span class="cov8" title="1">var cspNames = make(map[string]bool)
        for _, vh := range rc.GetVirtualHosts() </span><span class="cov8" title="1">{
                routes, cspNs, err := routesProtoToSlice(vh.Routes, csps, logger, v2)
                if err != nil </span><span class="cov8" title="1">{
                        return RouteConfigUpdate{}, fmt.Errorf("received route is invalid: %v", err)
                }</span>
                <span class="cov8" title="1">for n := range cspNs </span><span class="cov8" title="1">{
                        cspNames[n] = true
                }</span>
                <span class="cov8" title="1">rc, err := generateRetryConfig(vh.GetRetryPolicy())
                if err != nil </span><span class="cov8" title="1">{
                        return RouteConfigUpdate{}, fmt.Errorf("received route is invalid: %v", err)
                }</span>
                <span class="cov8" title="1">vhOut := &amp;VirtualHost{
                        Domains:     vh.GetDomains(),
                        Routes:      routes,
                        RetryConfig: rc,
                }
                if !v2 </span><span class="cov8" title="1">{
                        cfgs, err := processHTTPFilterOverrides(vh.GetTypedPerFilterConfig())
                        if err != nil </span><span class="cov8" title="1">{
                                return RouteConfigUpdate{}, fmt.Errorf("virtual host %+v: %v", vh, err)
                        }</span>
                        <span class="cov8" title="1">vhOut.HTTPFilterConfigOverride = cfgs</span>
                }
                <span class="cov8" title="1">vhs = append(vhs, vhOut)</span>
        }

        // "For any entry in the RouteConfiguration.cluster_specifier_plugins not
        // referenced by an enclosed ActionType's cluster_specifier_plugin, the xDS
        // client should not provide it to its consumers." - RLS in xDS Design
        <span class="cov8" title="1">for name := range csps </span><span class="cov8" title="1">{
                if !cspNames[name] </span><span class="cov8" title="1">{
                        delete(csps, name)
                }</span>
        }

        <span class="cov8" title="1">return RouteConfigUpdate{VirtualHosts: vhs, ClusterSpecifierPlugins: csps}, nil</span>
}

func processClusterSpecifierPlugins(csps []*v3routepb.ClusterSpecifierPlugin) (map[string]clusterspecifier.BalancerConfig, error) <span class="cov8" title="1">{
        cspCfgs := make(map[string]clusterspecifier.BalancerConfig)
        // "The xDS client will inspect all elements of the
        // cluster_specifier_plugins field looking up a plugin based on the
        // extension.typed_config of each." - RLS in xDS design
        for _, csp := range csps </span><span class="cov8" title="1">{
                cs := clusterspecifier.Get(csp.GetExtension().GetTypedConfig().GetTypeUrl())
                if cs == nil </span><span class="cov8" title="1">{
                        if csp.GetIsOptional() </span><span class="cov8" title="1">{
                                // "If a plugin is not supported but has is_optional set, then
                                // we will ignore any routes that point to that plugin"
                                cspCfgs[csp.GetExtension().GetName()] = nil
                                continue</span>
                        }
                        // "If no plugin is registered for it, the resource will be NACKed."
                        // - RLS in xDS design
                        <span class="cov8" title="1">return nil, fmt.Errorf("cluster specifier %q of type %q was not found", csp.GetExtension().GetName(), csp.GetExtension().GetTypedConfig().GetTypeUrl())</span>
                }
                <span class="cov8" title="1">lbCfg, err := cs.ParseClusterSpecifierConfig(csp.GetExtension().GetTypedConfig())
                if err != nil </span><span class="cov8" title="1">{
                        // "If a plugin is found, the value of the typed_config field will
                        // be passed to it's conversion method, and if an error is
                        // encountered, the resource will be NACKED." - RLS in xDS design
                        return nil, fmt.Errorf("error: %q parsing config %q for cluster specifier %q of type %q", err, csp.GetExtension().GetTypedConfig(), csp.GetExtension().GetName(), csp.GetExtension().GetTypedConfig().GetTypeUrl())
                }</span>
                // "If all cluster specifiers are valid, the xDS client will store the
                // configurations in a map keyed by the name of the extension instance." -
                // RLS in xDS Design
                <span class="cov8" title="1">cspCfgs[csp.GetExtension().GetName()] = lbCfg</span>
        }
        <span class="cov8" title="1">return cspCfgs, nil</span>
}

func generateRetryConfig(rp *v3routepb.RetryPolicy) (*RetryConfig, error) <span class="cov8" title="1">{
        if rp == nil </span><span class="cov8" title="1">{
                return nil, nil
        }</span>

        <span class="cov8" title="1">cfg := &amp;RetryConfig{RetryOn: make(map[codes.Code]bool)}
        for _, s := range strings.Split(rp.GetRetryOn(), ",") </span><span class="cov8" title="1">{
                switch strings.TrimSpace(strings.ToLower(s)) </span>{
                case "cancelled":<span class="cov8" title="1">
                        cfg.RetryOn[codes.Canceled] = true</span>
                case "deadline-exceeded":<span class="cov8" title="1">
                        cfg.RetryOn[codes.DeadlineExceeded] = true</span>
                case "internal":<span class="cov8" title="1">
                        cfg.RetryOn[codes.Internal] = true</span>
                case "resource-exhausted":<span class="cov8" title="1">
                        cfg.RetryOn[codes.ResourceExhausted] = true</span>
                case "unavailable":<span class="cov0" title="0">
                        cfg.RetryOn[codes.Unavailable] = true</span>
                }
        }

        <span class="cov8" title="1">if rp.NumRetries == nil </span><span class="cov8" title="1">{
                cfg.NumRetries = 1
        }</span> else<span class="cov8" title="1"> {
                cfg.NumRetries = rp.GetNumRetries().Value
                if cfg.NumRetries &lt; 1 </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("retry_policy.num_retries = %v; must be &gt;= 1", cfg.NumRetries)
                }</span>
        }

        <span class="cov8" title="1">backoff := rp.GetRetryBackOff()
        if backoff == nil </span><span class="cov8" title="1">{
                cfg.RetryBackoff.BaseInterval = 25 * time.Millisecond
        }</span> else<span class="cov8" title="1"> {
                cfg.RetryBackoff.BaseInterval = backoff.GetBaseInterval().AsDuration()
                if cfg.RetryBackoff.BaseInterval &lt;= 0 </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("retry_policy.base_interval = %v; must be &gt; 0", cfg.RetryBackoff.BaseInterval)
                }</span>
        }
        <span class="cov8" title="1">if max := backoff.GetMaxInterval(); max == nil </span><span class="cov8" title="1">{
                cfg.RetryBackoff.MaxInterval = 10 * cfg.RetryBackoff.BaseInterval
        }</span> else<span class="cov8" title="1"> {
                cfg.RetryBackoff.MaxInterval = max.AsDuration()
                if cfg.RetryBackoff.MaxInterval &lt;= 0 </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("retry_policy.max_interval = %v; must be &gt; 0", cfg.RetryBackoff.MaxInterval)
                }</span>
        }

        <span class="cov8" title="1">if len(cfg.RetryOn) == 0 </span><span class="cov0" title="0">{
                return &amp;RetryConfig{}, nil
        }</span>
        <span class="cov8" title="1">return cfg, nil</span>
}

func routesProtoToSlice(routes []*v3routepb.Route, csps map[string]clusterspecifier.BalancerConfig, logger *grpclog.PrefixLogger, v2 bool) ([]*Route, map[string]bool, error) <span class="cov8" title="1">{
        var routesRet []*Route
        var cspNames = make(map[string]bool)
        for _, r := range routes </span><span class="cov8" title="1">{
                match := r.GetMatch()
                if match == nil </span><span class="cov8" title="1">{
                        return nil, nil, fmt.Errorf("route %+v doesn't have a match", r)
                }</span>

                <span class="cov8" title="1">if len(match.GetQueryParameters()) != 0 </span><span class="cov8" title="1">{
                        // Ignore route with query parameters.
                        logger.Warningf("route %+v has query parameter matchers, the route will be ignored", r)
                        continue</span>
                }

                <span class="cov8" title="1">pathSp := match.GetPathSpecifier()
                if pathSp == nil </span><span class="cov8" title="1">{
                        return nil, nil, fmt.Errorf("route %+v doesn't have a path specifier", r)
                }</span>

                <span class="cov8" title="1">var route Route
                switch pt := pathSp.(type) </span>{
                case *v3routepb.RouteMatch_Prefix:<span class="cov8" title="1">
                        route.Prefix = &amp;pt.Prefix</span>
                case *v3routepb.RouteMatch_Path:<span class="cov0" title="0">
                        route.Path = &amp;pt.Path</span>
                case *v3routepb.RouteMatch_SafeRegex:<span class="cov8" title="1">
                        regex := pt.SafeRegex.GetRegex()
                        re, err := regexp.Compile(regex)
                        if err != nil </span><span class="cov8" title="1">{
                                return nil, nil, fmt.Errorf("route %+v contains an invalid regex %q", r, regex)
                        }</span>
                        <span class="cov8" title="1">route.Regex = re</span>
                default:<span class="cov8" title="1">
                        return nil, nil, fmt.Errorf("route %+v has an unrecognized path specifier: %+v", r, pt)</span>
                }

                <span class="cov8" title="1">if caseSensitive := match.GetCaseSensitive(); caseSensitive != nil </span><span class="cov8" title="1">{
                        route.CaseInsensitive = !caseSensitive.Value
                }</span>

                <span class="cov8" title="1">for _, h := range match.GetHeaders() </span><span class="cov8" title="1">{
                        var header HeaderMatcher
                        switch ht := h.GetHeaderMatchSpecifier().(type) </span>{
                        case *v3routepb.HeaderMatcher_ExactMatch:<span class="cov0" title="0">
                                header.ExactMatch = &amp;ht.ExactMatch</span>
                        case *v3routepb.HeaderMatcher_SafeRegexMatch:<span class="cov8" title="1">
                                regex := ht.SafeRegexMatch.GetRegex()
                                re, err := regexp.Compile(regex)
                                if err != nil </span><span class="cov8" title="1">{
                                        return nil, nil, fmt.Errorf("route %+v contains an invalid regex %q", r, regex)
                                }</span>
                                <span class="cov8" title="1">header.RegexMatch = re</span>
                        case *v3routepb.HeaderMatcher_RangeMatch:<span class="cov0" title="0">
                                header.RangeMatch = &amp;Int64Range{
                                        Start: ht.RangeMatch.Start,
                                        End:   ht.RangeMatch.End,
                                }</span>
                        case *v3routepb.HeaderMatcher_PresentMatch:<span class="cov0" title="0">
                                header.PresentMatch = &amp;ht.PresentMatch</span>
                        case *v3routepb.HeaderMatcher_PrefixMatch:<span class="cov8" title="1">
                                header.PrefixMatch = &amp;ht.PrefixMatch</span>
                        case *v3routepb.HeaderMatcher_SuffixMatch:<span class="cov0" title="0">
                                header.SuffixMatch = &amp;ht.SuffixMatch</span>
                        default:<span class="cov8" title="1">
                                return nil, nil, fmt.Errorf("route %+v has an unrecognized header matcher: %+v", r, ht)</span>
                        }
                        <span class="cov8" title="1">header.Name = h.GetName()
                        invert := h.GetInvertMatch()
                        header.InvertMatch = &amp;invert
                        route.Headers = append(route.Headers, &amp;header)</span>
                }

                <span class="cov8" title="1">if fr := match.GetRuntimeFraction(); fr != nil </span><span class="cov8" title="1">{
                        d := fr.GetDefaultValue()
                        n := d.GetNumerator()
                        switch d.GetDenominator() </span>{
                        case v3typepb.FractionalPercent_HUNDRED:<span class="cov8" title="1">
                                n *= 10000</span>
                        case v3typepb.FractionalPercent_TEN_THOUSAND:<span class="cov0" title="0">
                                n *= 100</span>
                        case v3typepb.FractionalPercent_MILLION:<span class="cov0" title="0"></span>
                        }
                        <span class="cov8" title="1">route.Fraction = &amp;n</span>
                }

                <span class="cov8" title="1">switch r.GetAction().(type) </span>{
                case *v3routepb.Route_Route:<span class="cov8" title="1">
                        route.WeightedClusters = make(map[string]WeightedCluster)
                        action := r.GetRoute()

                        // Hash Policies are only applicable for a Ring Hash LB.
                        if envconfig.XDSRingHash </span><span class="cov8" title="1">{
                                hp, err := hashPoliciesProtoToSlice(action.HashPolicy, logger)
                                if err != nil </span><span class="cov0" title="0">{
                                        return nil, nil, err
                                }</span>
                                <span class="cov8" title="1">route.HashPolicies = hp</span>
                        }

                        <span class="cov8" title="1">switch a := action.GetClusterSpecifier().(type) </span>{
                        case *v3routepb.RouteAction_Cluster:<span class="cov8" title="1">
                                route.WeightedClusters[a.Cluster] = WeightedCluster{Weight: 1}</span>
                        case *v3routepb.RouteAction_WeightedClusters:<span class="cov8" title="1">
                                wcs := a.WeightedClusters
                                var totalWeight uint32
                                for _, c := range wcs.Clusters </span><span class="cov8" title="1">{
                                        w := c.GetWeight().GetValue()
                                        if w == 0 </span><span class="cov8" title="1">{
                                                continue</span>
                                        }
                                        <span class="cov8" title="1">wc := WeightedCluster{Weight: w}
                                        if !v2 </span><span class="cov8" title="1">{
                                                cfgs, err := processHTTPFilterOverrides(c.GetTypedPerFilterConfig())
                                                if err != nil </span><span class="cov8" title="1">{
                                                        return nil, nil, fmt.Errorf("route %+v, action %+v: %v", r, a, err)
                                                }</span>
                                                <span class="cov8" title="1">wc.HTTPFilterConfigOverride = cfgs</span>
                                        }
                                        <span class="cov8" title="1">route.WeightedClusters[c.GetName()] = wc
                                        totalWeight += w</span>
                                }
                                // envoy xds doc
                                // default TotalWeight https://www.envoyproxy.io/docs/envoy/latest/api-v3/config/route/v3/route_components.proto.html#envoy-v3-api-field-config-route-v3-weightedcluster-total-weight
                                <span class="cov8" title="1">wantTotalWeight := uint32(100)
                                if tw := wcs.GetTotalWeight(); tw != nil </span><span class="cov8" title="1">{
                                        wantTotalWeight = tw.GetValue()
                                }</span>
                                <span class="cov8" title="1">if totalWeight != wantTotalWeight </span><span class="cov8" title="1">{
                                        return nil, nil, fmt.Errorf("route %+v, action %+v, weights of clusters do not add up to total total weight, got: %v, expected total weight from response: %v", r, a, totalWeight, wantTotalWeight)
                                }</span>
                                <span class="cov8" title="1">if totalWeight == 0 </span><span class="cov8" title="1">{
                                        return nil, nil, fmt.Errorf("route %+v, action %+v, has no valid cluster in WeightedCluster action", r, a)
                                }</span>
                        case *v3routepb.RouteAction_ClusterSpecifierPlugin:<span class="cov8" title="1">
                                if !envconfig.XDSRLS </span><span class="cov8" title="1">{
                                        return nil, nil, fmt.Errorf("route %+v, has an unknown ClusterSpecifier: %+v", r, a)
                                }</span>
                                <span class="cov8" title="1">if _, ok := csps[a.ClusterSpecifierPlugin]; !ok </span><span class="cov8" title="1">{
                                        // "When processing RouteActions, if any action includes a
                                        // cluster_specifier_plugin value that is not in
                                        // RouteConfiguration.cluster_specifier_plugins, the
                                        // resource will be NACKed." - RLS in xDS design
                                        return nil, nil, fmt.Errorf("route %+v, action %+v, specifies a cluster specifier plugin %+v that is not in Route Configuration", r, a, a.ClusterSpecifierPlugin)
                                }</span>
                                <span class="cov8" title="1">if csps[a.ClusterSpecifierPlugin] == nil </span><span class="cov8" title="1">{
                                        logger.Infof("route %+v references optional and unsupported cluster specifier plugin %v, the route will be ignored", r, a.ClusterSpecifierPlugin)
                                        continue</span>
                                }
                                <span class="cov8" title="1">cspNames[a.ClusterSpecifierPlugin] = true
                                route.ClusterSpecifierPlugin = a.ClusterSpecifierPlugin</span>
                        default:<span class="cov8" title="1">
                                logger.Infof("route %+v references unknown ClusterSpecifier %+v, the route will be ignored", r, a)
                                continue</span>
                        }

                        <span class="cov8" title="1">msd := action.GetMaxStreamDuration()
                        // Prefer grpc_timeout_header_max, if set.
                        dur := msd.GetGrpcTimeoutHeaderMax()
                        if dur == nil </span><span class="cov8" title="1">{
                                dur = msd.GetMaxStreamDuration()
                        }</span>
                        <span class="cov8" title="1">if dur != nil </span><span class="cov8" title="1">{
                                d := dur.AsDuration()
                                route.MaxStreamDuration = &amp;d
                        }</span>

                        <span class="cov8" title="1">var err error
                        route.RetryConfig, err = generateRetryConfig(action.GetRetryPolicy())
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, nil, fmt.Errorf("route %+v, action %+v: %v", r, action, err)
                        }</span>

                        <span class="cov8" title="1">route.ActionType = RouteActionRoute</span>

                case *v3routepb.Route_NonForwardingAction:<span class="cov8" title="1">
                        // Expected to be used on server side.
                        route.ActionType = RouteActionNonForwardingAction</span>
                default:<span class="cov0" title="0">
                        route.ActionType = RouteActionUnsupported</span>
                }

                <span class="cov8" title="1">if !v2 </span><span class="cov8" title="1">{
                        cfgs, err := processHTTPFilterOverrides(r.GetTypedPerFilterConfig())
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, nil, fmt.Errorf("route %+v: %v", r, err)
                        }</span>
                        <span class="cov8" title="1">route.HTTPFilterConfigOverride = cfgs</span>
                }
                <span class="cov8" title="1">routesRet = append(routesRet, &amp;route)</span>
        }
        <span class="cov8" title="1">return routesRet, cspNames, nil</span>
}

func hashPoliciesProtoToSlice(policies []*v3routepb.RouteAction_HashPolicy, logger *grpclog.PrefixLogger) ([]*HashPolicy, error) <span class="cov8" title="1">{
        var hashPoliciesRet []*HashPolicy
        for _, p := range policies </span><span class="cov8" title="1">{
                policy := HashPolicy{Terminal: p.Terminal}
                switch p.GetPolicySpecifier().(type) </span>{
                case *v3routepb.RouteAction_HashPolicy_Header_:<span class="cov8" title="1">
                        policy.HashPolicyType = HashPolicyTypeHeader
                        policy.HeaderName = p.GetHeader().GetHeaderName()
                        if rr := p.GetHeader().GetRegexRewrite(); rr != nil </span><span class="cov8" title="1">{
                                regex := rr.GetPattern().GetRegex()
                                re, err := regexp.Compile(regex)
                                if err != nil </span><span class="cov0" title="0">{
                                        return nil, fmt.Errorf("hash policy %+v contains an invalid regex %q", p, regex)
                                }</span>
                                <span class="cov8" title="1">policy.Regex = re
                                policy.RegexSubstitution = rr.GetSubstitution()</span>
                        }
                case *v3routepb.RouteAction_HashPolicy_FilterState_:<span class="cov8" title="1">
                        if p.GetFilterState().GetKey() != "io.grpc.channel_id" </span><span class="cov8" title="1">{
                                logger.Infof("hash policy %+v contains an invalid key for filter state policy %q", p, p.GetFilterState().GetKey())
                                continue</span>
                        }
                        <span class="cov8" title="1">policy.HashPolicyType = HashPolicyTypeChannelID</span>
                default:<span class="cov0" title="0">
                        logger.Infof("hash policy %T is an unsupported hash policy", p.GetPolicySpecifier())
                        continue</span>
                }

                <span class="cov8" title="1">hashPoliciesRet = append(hashPoliciesRet, &amp;policy)</span>
        }
        <span class="cov8" title="1">return hashPoliciesRet, nil</span>
}
</pre>
		
		<pre class="file" id="file226" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package xds

import (
        "context"
        "errors"
        "fmt"
        "net"
        "sync"

        "google.golang.org/grpc"
        "google.golang.org/grpc/codes"
        "google.golang.org/grpc/connectivity"
        "google.golang.org/grpc/credentials"
        "google.golang.org/grpc/grpclog"
        "google.golang.org/grpc/internal"
        "google.golang.org/grpc/internal/buffer"
        "google.golang.org/grpc/internal/envconfig"
        internalgrpclog "google.golang.org/grpc/internal/grpclog"
        "google.golang.org/grpc/internal/grpcsync"
        iresolver "google.golang.org/grpc/internal/resolver"
        "google.golang.org/grpc/internal/transport"
        "google.golang.org/grpc/metadata"
        "google.golang.org/grpc/status"
        "google.golang.org/grpc/xds/internal/server"
        "google.golang.org/grpc/xds/internal/xdsclient"
        "google.golang.org/grpc/xds/internal/xdsclient/bootstrap"
        "google.golang.org/grpc/xds/internal/xdsclient/xdsresource"
)

const serverPrefix = "[xds-server %p] "

var (
        // These new functions will be overridden in unit tests.
        newXDSClient = func() (xdsclient.XDSClient, error) <span class="cov8" title="1">{
                return xdsclient.New()
        }</span>
        newGRPCServer = func(opts ...grpc.ServerOption) grpcServer <span class="cov8" title="1">{
                return grpc.NewServer(opts...)
        }</span>

        grpcGetServerCreds    = internal.GetServerCredentials.(func(*grpc.Server) credentials.TransportCredentials)
        drainServerTransports = internal.DrainServerTransports.(func(*grpc.Server, string))
        logger                = grpclog.Component("xds")
)

func prefixLogger(p *GRPCServer) *internalgrpclog.PrefixLogger <span class="cov8" title="1">{
        return internalgrpclog.NewPrefixLogger(logger, fmt.Sprintf(serverPrefix, p))
}</span>

// grpcServer contains methods from grpc.Server which are used by the
// GRPCServer type here. This is useful for overriding in unit tests.
type grpcServer interface {
        RegisterService(*grpc.ServiceDesc, interface{})
        Serve(net.Listener) error
        Stop()
        GracefulStop()
        GetServiceInfo() map[string]grpc.ServiceInfo
}

// GRPCServer wraps a gRPC server and provides server-side xDS functionality, by
// communication with a management server using xDS APIs. It implements the
// grpc.ServiceRegistrar interface and can be passed to service registration
// functions in IDL generated code.
type GRPCServer struct {
        gs            grpcServer
        quit          *grpcsync.Event
        logger        *internalgrpclog.PrefixLogger
        xdsCredsInUse bool
        opts          *serverOptions

        // clientMu is used only in initXDSClient(), which is called at the
        // beginning of Serve(), where we have to decide if we have to create a
        // client or use an existing one.
        clientMu sync.Mutex
        xdsC     xdsclient.XDSClient
}

// NewGRPCServer creates an xDS-enabled gRPC server using the passed in opts.
// The underlying gRPC server has no service registered and has not started to
// accept requests yet.
func NewGRPCServer(opts ...grpc.ServerOption) *GRPCServer <span class="cov8" title="1">{
        newOpts := []grpc.ServerOption{
                grpc.ChainUnaryInterceptor(xdsUnaryInterceptor),
                grpc.ChainStreamInterceptor(xdsStreamInterceptor),
        }
        newOpts = append(newOpts, opts...)
        s := &amp;GRPCServer{
                gs:   newGRPCServer(newOpts...),
                quit: grpcsync.NewEvent(),
        }
        s.logger = prefixLogger(s)
        s.logger.Infof("Created xds.GRPCServer")
        s.handleServerOptions(opts)

        // We type assert our underlying gRPC server to the real grpc.Server here
        // before trying to retrieve the configured credentials. This approach
        // avoids performing the same type assertion in the grpc package which
        // provides the implementation for internal.GetServerCredentials, and allows
        // us to use a fake gRPC server in tests.
        if gs, ok := s.gs.(*grpc.Server); ok </span><span class="cov8" title="1">{
                creds := grpcGetServerCreds(gs)
                if xc, ok := creds.(interface{ UsesXDS() bool }); ok &amp;&amp; xc.UsesXDS() </span><span class="cov8" title="1">{
                        s.xdsCredsInUse = true
                }</span>
        }

        <span class="cov8" title="1">s.logger.Infof("xDS credentials in use: %v", s.xdsCredsInUse)
        return s</span>
}

// handleServerOptions iterates through the list of server options passed in by
// the user, and handles the xDS server specific options.
func (s *GRPCServer) handleServerOptions(opts []grpc.ServerOption) <span class="cov8" title="1">{
        so := s.defaultServerOptions()
        for _, opt := range opts </span><span class="cov8" title="1">{
                if o, ok := opt.(*serverOption); ok </span><span class="cov8" title="1">{
                        o.apply(so)
                }</span>
        }
        <span class="cov8" title="1">s.opts = so</span>
}

func (s *GRPCServer) defaultServerOptions() *serverOptions <span class="cov8" title="1">{
        return &amp;serverOptions{
                // A default serving mode change callback which simply logs at the
                // default-visible log level. This will be used if the application does not
                // register a mode change callback.
                //
                // Note that this means that `s.opts.modeCallback` will never be nil and can
                // safely be invoked directly from `handleServingModeChanges`.
                modeCallback: s.loggingServerModeChangeCallback,
        }
}</span>

func (s *GRPCServer) loggingServerModeChangeCallback(addr net.Addr, args ServingModeChangeArgs) <span class="cov0" title="0">{
        switch args.Mode </span>{
        case connectivity.ServingModeServing:<span class="cov0" title="0">
                s.logger.Errorf("Listener %q entering mode: %q", addr.String(), args.Mode)</span>
        case connectivity.ServingModeNotServing:<span class="cov0" title="0">
                s.logger.Errorf("Listener %q entering mode: %q due to error: %v", addr.String(), args.Mode, args.Err)</span>
        }
}

// RegisterService registers a service and its implementation to the underlying
// gRPC server. It is called from the IDL generated code. This must be called
// before invoking Serve.
func (s *GRPCServer) RegisterService(sd *grpc.ServiceDesc, ss interface{}) <span class="cov8" title="1">{
        s.gs.RegisterService(sd, ss)
}</span>

// GetServiceInfo returns a map from service names to ServiceInfo.
// Service names include the package names, in the form of &lt;package&gt;.&lt;service&gt;.
func (s *GRPCServer) GetServiceInfo() map[string]grpc.ServiceInfo <span class="cov0" title="0">{
        return s.gs.GetServiceInfo()
}</span>

// initXDSClient creates a new xdsClient if there is no existing one available.
func (s *GRPCServer) initXDSClient() error <span class="cov8" title="1">{
        s.clientMu.Lock()
        defer s.clientMu.Unlock()

        if s.xdsC != nil </span><span class="cov0" title="0">{
                return nil
        }</span>

        <span class="cov8" title="1">newXDSClient := newXDSClient
        if s.opts.bootstrapContentsForTesting != nil </span><span class="cov0" title="0">{
                // Bootstrap file contents may be specified as a server option for tests.
                newXDSClient = func() (xdsclient.XDSClient, error) </span><span class="cov0" title="0">{
                        return xdsclient.NewWithBootstrapContentsForTesting(s.opts.bootstrapContentsForTesting)
                }</span>
        }

        <span class="cov8" title="1">client, err := newXDSClient()
        if err != nil </span><span class="cov8" title="1">{
                return fmt.Errorf("xds: failed to create xds-client: %v", err)
        }</span>
        <span class="cov8" title="1">s.xdsC = client
        s.logger.Infof("Created an xdsClient")
        return nil</span>
}

// Serve gets the underlying gRPC server to accept incoming connections on the
// listener lis, which is expected to be listening on a TCP port.
//
// A connection to the management server, to receive xDS configuration, is
// initiated here.
//
// Serve will return a non-nil error unless Stop or GracefulStop is called.
func (s *GRPCServer) Serve(lis net.Listener) error <span class="cov8" title="1">{
        s.logger.Infof("Serve() passed a net.Listener on %s", lis.Addr().String())
        if _, ok := lis.Addr().(*net.TCPAddr); !ok </span><span class="cov0" title="0">{
                return fmt.Errorf("xds: GRPCServer expects listener to return a net.TCPAddr. Got %T", lis.Addr())
        }</span>

        // If this is the first time Serve() is being called, we need to initialize
        // our xdsClient. If not, we can use the existing one.
        <span class="cov8" title="1">if err := s.initXDSClient(); err != nil </span><span class="cov8" title="1">{
                return err
        }</span>
        <span class="cov8" title="1">cfg := s.xdsC.BootstrapConfig()
        if cfg == nil </span><span class="cov8" title="1">{
                return errors.New("bootstrap configuration is empty")
        }</span>

        // If xds credentials were specified by the user, but bootstrap configs do
        // not contain any certificate provider configuration, it is better to fail
        // right now rather than failing when attempting to create certificate
        // providers after receiving an LDS response with security configuration.
        <span class="cov8" title="1">if s.xdsCredsInUse </span><span class="cov8" title="1">{
                if len(cfg.CertProviderConfigs) == 0 </span><span class="cov8" title="1">{
                        return errors.New("xds: certificate_providers config missing in bootstrap file")
                }</span>
        }

        // The server listener resource name template from the bootstrap
        // configuration contains a template for the name of the Listener resource
        // to subscribe to for a gRPC server. If the token `%s` is present in the
        // string, it will be replaced with the server's listening "IP:port" (e.g.,
        // "0.0.0.0:8080", "[::]:8080"). The absence of a template will be treated
        // as an error since we do not have any default value for this.
        <span class="cov8" title="1">if cfg.ServerListenerResourceNameTemplate == "" </span><span class="cov8" title="1">{
                return errors.New("missing server_listener_resource_name_template in the bootstrap configuration")
        }</span>
        <span class="cov8" title="1">name := bootstrap.PopulateResourceTemplate(cfg.ServerListenerResourceNameTemplate, lis.Addr().String())

        modeUpdateCh := buffer.NewUnbounded()
        go func() </span><span class="cov8" title="1">{
                s.handleServingModeChanges(modeUpdateCh)
        }</span>()

        // Create a listenerWrapper which handles all functionality required by
        // this particular instance of Serve().
        <span class="cov8" title="1">lw, goodUpdateCh := server.NewListenerWrapper(server.ListenerWrapperParams{
                Listener:             lis,
                ListenerResourceName: name,
                XDSCredsInUse:        s.xdsCredsInUse,
                XDSClient:            s.xdsC,
                ModeCallback: func(addr net.Addr, mode connectivity.ServingMode, err error) </span><span class="cov8" title="1">{
                        modeUpdateCh.Put(&amp;modeChangeArgs{
                                addr: addr,
                                mode: mode,
                                err:  err,
                        })
                }</span>,
                DrainCallback: func(addr net.Addr) <span class="cov8" title="1">{
                        if gs, ok := s.gs.(*grpc.Server); ok </span><span class="cov0" title="0">{
                                drainServerTransports(gs, addr.String())
                        }</span>
                },
        })

        // Block until a good LDS response is received or the server is stopped.
        <span class="cov8" title="1">select </span>{
        case &lt;-s.quit.Done():<span class="cov8" title="1">
                // Since the listener has not yet been handed over to gs.Serve(), we
                // need to explicitly close the listener. Cancellation of the xDS watch
                // is handled by the listenerWrapper.
                lw.Close()
                return nil</span>
        case &lt;-goodUpdateCh:<span class="cov8" title="1"></span>
        }
        <span class="cov8" title="1">return s.gs.Serve(lw)</span>
}

// modeChangeArgs wraps argument required for invoking mode change callback.
type modeChangeArgs struct {
        addr net.Addr
        mode connectivity.ServingMode
        err  error
}

// handleServingModeChanges runs as a separate goroutine, spawned from Serve().
// It reads a channel on to which mode change arguments are pushed, and in turn
// invokes the user registered callback. It also calls an internal method on the
// underlying grpc.Server to gracefully close existing connections, if the
// listener moved to a "not-serving" mode.
func (s *GRPCServer) handleServingModeChanges(updateCh *buffer.Unbounded) <span class="cov8" title="1">{
        for </span><span class="cov8" title="1">{
                select </span>{
                case &lt;-s.quit.Done():<span class="cov8" title="1">
                        return</span>
                case u := &lt;-updateCh.Get():<span class="cov8" title="1">
                        updateCh.Load()
                        args := u.(*modeChangeArgs)
                        if args.mode == connectivity.ServingModeNotServing </span><span class="cov8" title="1">{
                                // We type assert our underlying gRPC server to the real
                                // grpc.Server here before trying to initiate the drain
                                // operation. This approach avoids performing the same type
                                // assertion in the grpc package which provides the
                                // implementation for internal.GetServerCredentials, and allows
                                // us to use a fake gRPC server in tests.
                                if gs, ok := s.gs.(*grpc.Server); ok </span><span class="cov0" title="0">{
                                        drainServerTransports(gs, args.addr.String())
                                }</span>
                        }

                        // The XdsServer API will allow applications to register a "serving state"
                        // callback to be invoked when the server begins serving and when the
                        // server encounters errors that force it to be "not serving". If "not
                        // serving", the callback must be provided error information, for
                        // debugging use by developers - A36.
                        <span class="cov8" title="1">s.opts.modeCallback(args.addr, ServingModeChangeArgs{
                                Mode: args.mode,
                                Err:  args.err,
                        })</span>
                }
        }
}

// Stop stops the underlying gRPC server. It immediately closes all open
// connections. It cancels all active RPCs on the server side and the
// corresponding pending RPCs on the client side will get notified by connection
// errors.
func (s *GRPCServer) Stop() <span class="cov8" title="1">{
        s.quit.Fire()
        s.gs.Stop()
        if s.xdsC != nil </span><span class="cov8" title="1">{
                s.xdsC.Close()
        }</span>
}

// GracefulStop stops the underlying gRPC server gracefully. It stops the server
// from accepting new connections and RPCs and blocks until all the pending RPCs
// are finished.
func (s *GRPCServer) GracefulStop() <span class="cov0" title="0">{
        s.quit.Fire()
        s.gs.GracefulStop()
        if s.xdsC != nil </span><span class="cov0" title="0">{
                s.xdsC.Close()
        }</span>
}

// routeAndProcess routes the incoming RPC to a configured route in the route
// table and also processes the RPC by running the incoming RPC through any HTTP
// Filters configured.
func routeAndProcess(ctx context.Context) error <span class="cov0" title="0">{
        conn := transport.GetConnection(ctx)
        cw, ok := conn.(interface {
                VirtualHosts() []xdsresource.VirtualHostWithInterceptors
        })
        if !ok </span><span class="cov0" title="0">{
                return errors.New("missing virtual hosts in incoming context")
        }</span>
        <span class="cov0" title="0">mn, ok := grpc.Method(ctx)
        if !ok </span><span class="cov0" title="0">{
                return errors.New("missing method name in incoming context")
        }</span>
        <span class="cov0" title="0">md, ok := metadata.FromIncomingContext(ctx)
        if !ok </span><span class="cov0" title="0">{
                return errors.New("missing metadata in incoming context")
        }</span>
        // A41 added logic to the core grpc implementation to guarantee that once
        // the RPC gets to this point, there will be a single, unambiguous authority
        // present in the header map.
        <span class="cov0" title="0">authority := md.Get(":authority")
        vh := xdsresource.FindBestMatchingVirtualHostServer(authority[0], cw.VirtualHosts())
        if vh == nil </span><span class="cov0" title="0">{
                return status.Error(codes.Unavailable, "the incoming RPC did not match a configured Virtual Host")
        }</span>

        <span class="cov0" title="0">var rwi *xdsresource.RouteWithInterceptors
        rpcInfo := iresolver.RPCInfo{
                Context: ctx,
                Method:  mn,
        }
        for _, r := range vh.Routes </span><span class="cov0" title="0">{
                if r.M.Match(rpcInfo) </span><span class="cov0" title="0">{
                        // "NonForwardingAction is expected for all Routes used on server-side; a route with an inappropriate action causes
                        // RPCs matching that route to fail with UNAVAILABLE." - A36
                        if r.ActionType != xdsresource.RouteActionNonForwardingAction </span><span class="cov0" title="0">{
                                return status.Error(codes.Unavailable, "the incoming RPC matched to a route that was not of action type non forwarding")
                        }</span>
                        <span class="cov0" title="0">rwi = &amp;r
                        break</span>
                }
        }
        <span class="cov0" title="0">if rwi == nil </span><span class="cov0" title="0">{
                return status.Error(codes.Unavailable, "the incoming RPC did not match a configured Route")
        }</span>
        <span class="cov0" title="0">for _, interceptor := range rwi.Interceptors </span><span class="cov0" title="0">{
                if err := interceptor.AllowRPC(ctx); err != nil </span><span class="cov0" title="0">{
                        return status.Errorf(codes.PermissionDenied, "Incoming RPC is not allowed: %v", err)
                }</span>
        }
        <span class="cov0" title="0">return nil</span>
}

// xdsUnaryInterceptor is the unary interceptor added to the gRPC server to
// perform any xDS specific functionality on unary RPCs.
func xdsUnaryInterceptor(ctx context.Context, req interface{}, _ *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (resp interface{}, err error) <span class="cov0" title="0">{
        if envconfig.XDSRBAC </span><span class="cov0" title="0">{
                if err := routeAndProcess(ctx); err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
        }
        <span class="cov0" title="0">return handler(ctx, req)</span>
}

// xdsStreamInterceptor is the stream interceptor added to the gRPC server to
// perform any xDS specific functionality on streaming RPCs.
func xdsStreamInterceptor(srv interface{}, ss grpc.ServerStream, _ *grpc.StreamServerInfo, handler grpc.StreamHandler) error <span class="cov0" title="0">{
        if envconfig.XDSRBAC </span><span class="cov0" title="0">{
                if err := routeAndProcess(ss.Context()); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
        }
        <span class="cov0" title="0">return handler(srv, ss)</span>
}
</pre>
		
		<pre class="file" id="file227" style="display: none">/*
 *
 * Copyright 2021 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package xds

import (
        "net"

        "google.golang.org/grpc"
        "google.golang.org/grpc/connectivity"
)

type serverOptions struct {
        modeCallback                ServingModeCallbackFunc
        bootstrapContentsForTesting []byte
}

type serverOption struct {
        grpc.EmptyServerOption
        apply func(*serverOptions)
}

// ServingModeCallback returns a grpc.ServerOption which allows users to
// register a callback to get notified about serving mode changes.
func ServingModeCallback(cb ServingModeCallbackFunc) grpc.ServerOption <span class="cov8" title="1">{
        return &amp;serverOption{apply: func(o *serverOptions) </span><span class="cov8" title="1">{ o.modeCallback = cb }</span>}
}

// ServingModeCallbackFunc is the callback that users can register to get
// notified about the server's serving mode changes. The callback is invoked
// with the address of the listener and its new mode.
//
// Users must not perform any blocking operations in this callback.
type ServingModeCallbackFunc func(addr net.Addr, args ServingModeChangeArgs)

// ServingModeChangeArgs wraps the arguments passed to the serving mode callback
// function.
type ServingModeChangeArgs struct {
        // Mode is the new serving mode of the server listener.
        Mode connectivity.ServingMode
        // Err is set to a non-nil error if the server has transitioned into
        // not-serving mode.
        Err error
}

// BootstrapContentsForTesting returns a grpc.ServerOption which allows users
// to inject a bootstrap configuration used by only this server, instead of the
// global configuration from the environment variables.
//
// Testing Only
//
// This function should ONLY be used for testing and may not work with some
// other features, including the CSDS service.
//
// Experimental
//
// Notice: This API is EXPERIMENTAL and may be changed or removed in a
// later release.
func BootstrapContentsForTesting(contents []byte) grpc.ServerOption <span class="cov0" title="0">{
        return &amp;serverOption{apply: func(o *serverOptions) </span><span class="cov0" title="0">{ o.bootstrapContentsForTesting = contents }</span>}
}
</pre>
		
		<pre class="file" id="file228" style="display: none">/*
 *
 * Copyright 2020 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

// Package xds contains an implementation of the xDS suite of protocols, to be
// used by gRPC client and server applications.
//
// On the client-side, users simply need to import this package to get all xDS
// functionality. On the server-side, users need to use the GRPCServer type
// exported by this package instead of the regular grpc.Server.
//
// See https://github.com/grpc/grpc-go/tree/master/examples/features/xds for
// example.
package xds

import (
        "fmt"

        v3statusgrpc "github.com/envoyproxy/go-control-plane/envoy/service/status/v3"
        "google.golang.org/grpc"
        _ "google.golang.org/grpc/credentials/tls/certprovider/pemfile" // Register the file watcher certificate provider plugin.
        "google.golang.org/grpc/internal"
        internaladmin "google.golang.org/grpc/internal/admin"
        "google.golang.org/grpc/resolver"
        "google.golang.org/grpc/xds/csds"
        _ "google.golang.org/grpc/xds/internal/balancer"                        // Register the balancers.
        _ "google.golang.org/grpc/xds/internal/clusterspecifier/rls"            // Register the RLS cluster specifier plugin. Note that this does not register the RLS LB policy.
        _ "google.golang.org/grpc/xds/internal/httpfilter/fault"                // Register the fault injection filter.
        _ "google.golang.org/grpc/xds/internal/httpfilter/rbac"                 // Register the RBAC filter.
        _ "google.golang.org/grpc/xds/internal/httpfilter/router"               // Register the router filter.
        _ "google.golang.org/grpc/xds/internal/resolver"                        // Register the xds_resolver
        _ "google.golang.org/grpc/xds/internal/xdsclient/controller/version/v2" // Register the v2 xDS API client.
        _ "google.golang.org/grpc/xds/internal/xdsclient/controller/version/v3" // Register the v3 xDS API client.
)

func init() <span class="cov8" title="1">{
        internaladmin.AddService(func(registrar grpc.ServiceRegistrar) (func(), error) </span><span class="cov0" title="0">{
                var grpcServer *grpc.Server
                switch ss := registrar.(type) </span>{
                case *grpc.Server:<span class="cov0" title="0">
                        grpcServer = ss</span>
                case *GRPCServer:<span class="cov0" title="0">
                        sss, ok := ss.gs.(*grpc.Server)
                        if !ok </span><span class="cov0" title="0">{
                                logger.Warningf("grpc server within xds.GRPCServer is not *grpc.Server, CSDS will not be registered")
                                return nil, nil
                        }</span>
                        <span class="cov0" title="0">grpcServer = sss</span>
                default:<span class="cov0" title="0">
                        // Returning an error would cause the top level admin.Register() to
                        // fail. Log a warning instead.
                        logger.Warningf("server to register service on is neither a *grpc.Server or a *xds.GRPCServer, CSDS will not be registered")
                        return nil, nil</span>
                }

                <span class="cov0" title="0">csdss, err := csds.NewClientStatusDiscoveryServer()
                if err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to create csds server: %v", err)
                }</span>
                <span class="cov0" title="0">v3statusgrpc.RegisterClientStatusDiscoveryServiceServer(grpcServer, csdss)
                return csdss.Close, nil</span>
        })
}

// NewXDSResolverWithConfigForTesting creates a new xDS resolver builder using
// the provided xDS bootstrap config instead of the global configuration from
// the supported environment variables.  The resolver.Builder is meant to be
// used in conjunction with the grpc.WithResolvers DialOption.
//
// Testing Only
//
// This function should ONLY be used for testing and may not work with some
// other features, including the CSDS service.
//
// Experimental
//
// Notice: This API is EXPERIMENTAL and may be changed or removed in a
// later release.
func NewXDSResolverWithConfigForTesting(bootstrapConfig []byte) (resolver.Builder, error) <span class="cov0" title="0">{
        return internal.NewXDSResolverWithConfigForTesting.(func([]byte) (resolver.Builder, error))(bootstrapConfig)
}</span>
</pre>
		
		</div>
	</body>
	<script>
	(function() {
		var files = document.getElementById('files');
		var visible;
		files.addEventListener('change', onChange, false);
		function select(part) {
			if (visible)
				visible.style.display = 'none';
			visible = document.getElementById(part);
			if (!visible)
				return;
			files.value = part;
			visible.style.display = 'block';
			location.hash = part;
		}
		function onChange() {
			select(files.value);
			window.scrollTo(0, 0);
		}
		if (location.hash != "") {
			select(location.hash.substr(1));
		}
		if (!visible) {
			select("file0");
		}
	})();
	</script>
</html>
